%; whizzy section

%% Leave the above line for didier
%% No macros before \documentclass

\documentclass[acmsmall,screen,nonacm]{acmart}

\input{suspended.cfg}
\newcommand{\acmart}{\True}
\usepackage{suspended}

%% \Xfirstname defined in {mycomments}
%% Use either
%%   \Xfistname[text to comment]{your comment on the text}
%% or
%%   \Xfirstname{free comment}
%% Uncomment this line to hide all comments.
% \UNXXX{}

\usepackage{marginnote}

\title{Omnidirectional type inference for \ML: principality any way}

\begin{document}

\begin{abstract}
We propose a new concept of \emph{omnidirectional} type inference, which is
the ability to resolve \ML-style typing constraints in disorder, by
contrast with all known implementations that always typecheck the
bindings before the bodies of let-expressions.
%
This relies on two technical devices: \emph{partial type schemes}
and \emph{suspended match constraints}. Partial here means  the
possibility of taking instances of a type scheme that is not yet
completely solved with a mechanism to tack and update their instances when
the type scheme is refined, incrementally.
\emph{Suspended} match constraints means a mechanism to delay the resolution of
some constraints which typically require non-local not-yet-available
contextual information and to  discharge them when we have learned enough
information from the resolution of other constraints, typically when some type
variables have been instantiated.
%
The benefits of omnidirectional type inference are striking for several
advanced \ML extensions, typically those that rely on optional type
annotations for which the principal type property is often fragile.  We
illustrate them with \OCaml's static overloading of record labels and
constructors, semi-explicit first-class polymorphism, and tuple projections
\`a la \SML.
\end{abstract}
\maketitle

\section{Introduction}
\label{sec/introduction}

\parcomment {Introduction (ML, principality)}

The Damas-Hindley-Milner (\HM) \cite{Damas-Milner/W@popl82} type system has
long occupied a sweet spot in the design space of strongly typed programming
languages, as it enjoys the \emph{principal type property}: every well-typed
expression $\e$ has a most general type $\ts$ from which all other valid
types for $\e$ are instances of $\ts$. For example, the identity function
$\efun \x \x$ has the principal type $\tfor \tv \tv \to \tv$, generalizing
types like $\tint \to \tint$ and $\tbool \to \tbool$.

\parcomment {Benefits of principality}

This property ensures predictable and efficient inference. Local typing
decisions are always optimal, yielding most general types, without guessing or
backtracking. As a result, inference of subexpressions can proceed in any
order, and well-typedness is preserved under common program transformations
such as let-contraction, let-expansion, and argument reordering.

\parcomment {Extensions often break pincipality}

Over the years, many extensions of \ML have been proposed. Some of them
constructs, such as extensible records with row-polymorphism, higher-kinded
types, or dimensional types, fit perfectly into the \ML framework. Others such
as GADTs, higher-rank polymorphism, or static overloading, are
\emph{fragile}, as they sometimes require explicit type
annotations.
%
Consider impredicative higher-rank polymorphism,
\MLF~\cite{LeBotlan-Remy/recasting-mlf} for instance:
\begin{program}[input]
  let self f = f f
\end{program}
With higher-rank types, one could \emph{guess} the type of \code{f} to be
either $\tfor \tv \tv \to \tv$ or $\tfor \tv \tv \to \tv \to \tv$ in order
to typecheck \code{self}---neither of which is more general than the other,
violating principality.

\parcomment {Current approaches are kinda bad}

To fix this, inference algorithms require a minimal amount of \emph{known}
type information (\ie annotations) to restore principality. Yet specifying
such requirements declaratively is difficult. As a result, the specifications
are often twisted with some direct or indirect algorithmic flavor in order to
preserve principality and completeness.
%
Moreover, these (more or less) ad-hoc restrictions commonly reject examples
whose type could easily be guessed. For instance, \MLF~ rejects:
\begin{program}[input]
  let self' f = if true then f f else (f : $\forall$'a. 'a -> 'a)
\end{program}

\parcomment {Annotations fixes all the issues (but they're problematic)}

Optional type annotations may sometimes but not always be omitted: the
return type of overloaded data constructors can be annotated; polymorphic
expressions can be annotated with a type scheme; for GADTs, the type of the
\texttt{match} scrutinee and return type can be annotated to a rigid type
which will be
refined by type equalities in each branch. To each fragile construct
corresponds a robust construct where this type annotation is mandatory. The
robust constructs fit perfectly into the \ML framework, but are
significantly more cumbersome to use, as they always require explicit type
annotations.  Fragile constructs can be defined by elaboration into their
robust counterpart. The elaboration determines which annotations can be
omitted and rebuilt from context, a point of view already taken by~\citet
{Pottier-Regis-Gianas/stratified@popl06} in their work on stratified type
inference.
%
The difficulty of fragile constructs lies in finding a specification
that is sufficiently expressive, principled, intuitive for the user,
and for which we have a complete and effective elaboration algorithm.

The solutions proposed so far all enforce some ordering in which type
inference is performed, which can then be used to propagate both inferred
types and user-provided type annotations as \emph{known} types that can be
used for disambiguation and enable the omission of some annotations.

\paragraph{Bidirectional type inference}

Bidirectional type inference is a known alternative to unification for
propagating type information. It can be presented by adding to the type
inference algorithm an optional expected type in addition to the expression
to be typechecked and the context in which it should be typechecked.  Type
inference is said in \emph{checking mode} when the expected type is present,
and in (the usual) \emph{inference mode} when it is absent. The checking
mode allows to pass source type annotations but also previously inferred
types such as the codomain of a function in an application position during
type inference of the arguments.
%
Bidirectional type inference is actually a framework that must be
instantiated by a particular choice of modes for each of the language
construct, while there is no optimal combination of modes for the whole set
of language constructs. Once modes have been fixed, there are usually
principal solutions to the type inference problem, but with respect to a
specification that made non-principal choices.
%
Bidirectional type inference has been largely used for languages with
higher-rank polymorphism, dependent types, or subtyping.  Still, both \OCaml
and \Haskell only use a limited form of bidirectional type checking with an
underlying first-order-unification based type inference engine, which limits
the downsides of bidirectional type checking.


\paragraph{\Geninst-directional type inference}

\OCaml uses another mechanism for propagation of type information,
based on polymorphism, which actually enforces an ordering in the
typechecking of let-bindings, where the (polymorphic part of) a the bound
expression must be typed before the body of the let-expression.  We call it
\textbf{\geninst}-directional (to be read \textbf{pi}-directional) type
inference, to mean that \textbf{p}olymorphic expressions must be typed
before their \textbf{i}nstances.  Initially introduced with the extension of
\ML with semi-explicit first-class polymorphism by~\citet
{Garrigue-Remy/poly-ml}, and later used by~\citet
{LeBotlan-Remy/recasting-mlf} for empowering \MLF, it has also been utilized
for the overloading of record fields in \OCaml, which we use for
illustration here as it is simpler to explain.\footnote {Semi-explicit
polymorphism will be presented in~\cref{sec/constraints/polytypes}.}

The user may define a nominal record, with \eg a single field:
\begin{program}[input]
type 'a one = {x : 'a}
\end{program}
Then, accessing field \ocaml{x} of a record is non-ambiguous, since
\OCaml takes a closed-world view:
\begin{program}[input]
let e_0 r = r.x
\end{program}
Indeed, there is a unique solution that \ocaml$r$ be of type \ocaml$'a foo$.
The user may then define another record with overlapping fields:
\begin{program}[input]
type two = {x : int; y : int}
\end{program}
Now, this can be thought of as having two abstract types \ocaml{'a foo} and
\ocaml{bar} with two accessor functions \ocaml{(_ : 'a one).x} and
\ocaml{(_:two).x} of respective types \ocaml{('a one -> 'a)} and
\ocaml{(two -> int)}, among others.
%
In the absence of overloading, the latter definition would hide the former
and we fall back in \ML.  With overloading enabled, both definitions are
visible and the compiler must statically choose one of them.
%
The question is which one to choose or, equivalently, which type to infer
in the following three expressions:
\begin{program}[input]
let e_1 r = r.x
let e_2 = let r = {x = 1} in r.x
let e_3 = (fun r -> r.x) {x = 1}
\end{program}
To be able to resolve the overloading, the type of the projection should be
\emph{known} to be either (an instance of) \ocaml{'a one} or \ocaml{one}
when typing the projection.  In the new context, expression
\ocaml[indices]{e_1} is clearly ambiguous since there is no clue on the type
of \ocaml{r} and its typechecking fails\footnote {In fact, \OCaml uses a
default resolution strategy instead of failing when the type is ambiguous,
which is to use the last definition. Here, this will amount to chose the
type \ocaml{two} still leading to a failure since the record passed to the
function is actually of type \ocaml{'a one}. But we shall ignore default
resolution strategies for the moment.}\footnote {When running examples in
\OCaml,
\OCaml should be always be called with option \texttt{-principal}, since by
default \OCaml does not quite follow the theory for efficiency reasons.}.
%
By contrast, the only possible type for \ocaml{r} is \ocaml {'a one} in both
\ocaml{e_2} and \ocaml {e_3}.  Still, there is a difference.  Indeed, the
type of~\ocaml{e_2} is considered to be unambiguous, while the type of
\ocaml{e_3} is ambiguous.
%
To understand why \ocaml{e_3} fails, consider the equivalent versions of
\ocaml{e_3} where \texttt{@@} and \ocaml{|>} are the application and the
reverse application functions.
\begin{program}[input,escapechar={}]
let e_4 = (fun r -> r.x) @@ {x = 1}
let e_5 = {x = 1} |> (fun r -> r.x)
\end{program}
\OCaml  does not make any difference between
\ocaml[indices]{e_1}, \ocaml[indices]{e_2}, or \ocaml[indices]{e_3}
and consider all subexpressions in an application, including the function
and all arguments as being inferred simultaneously, until they are
let-bound. More precisely, polymorphic types are considered to be known
while monomorphic types are consider to be unknown---or, rather,
not-yet-known.  In \ocaml{fun r -> r.x}, the type of \ocaml{r}
in the subexpression \ocaml{r.x} is not-yet-known even if equal to
\ocaml{one} since this is the $\lambda$-bound variable~\ocaml{r}, hence in the
typing context, and therefore it is monomorphic.\footnote{Technically, all
type nodes are annotated with a special variable $\av$ called an annotation
variable, so that we may distinguish between the polymorphic binding $\xa :
\all \av \t^\av$ that binds $r$ to the known (raw) type $\t$ and the
monomorphic binding $\xb : \t^\av$ that binds $\xa$ to the unknown (raw)
type $\t$.}


\paragraph{Limitations of directional type inference}

Directional type inference has been in used in different languages and
somehow proven to work in practice---to some extend.  As it often remained
unsatisfactory.  The main critics of \emph{bidirectional} type inference is
to make a somewhat arbitrary choice in the specification of the flow of
information, typically in applications: should the function be typed first
and its codomain be used to improve the typing of its argument or, on the
opposite, should the argument be typed first and be used as the type of the
codomain of the function?  There are examples when the former is a better
choice and others when the latter is preferable---but typing rules have to
choose one of the two alternative forever.  One may also allow information
to flow between multiple arguments passed to the same function, or on the
opposite disallow it entirety. Again, there is no best choice. We eventually
have a complete algorithm with respect to a specification that made somewhat
arbitrary choices.

While \emph{\Geninst-directional} type inference seems a better fit for \ML,
as it relies on polymorphism which is the essence of \ML, it does not even
allow to propagate user-provided type annotations from a function to its
argument!  For example, the following would be rejected as ambiguous with
\geninst-directinal type inference alone:
\begin{program}[input]
let g : ('a one -> int) -> int = fun f -> f {x = 1} in g (fun r -> r.x)
\end{program}
Consequently, \OCaml, which use \geninst-directional type inference as the
primary mechanism, also uses a weak form of bidirectional propagation: by
passing the expected type of the argument so that
\ocaml{(fun r -> r.x)} is typed with the expected type
\ocaml{('a one -> int)} and may be considered non-ambiguous.

Besides, the implementation of \geninst-directional type inference has an
algorithmic cost: for technical reasons, variable annotations must un-share
types (from acyclic graphs as naturally produced by unification to trees),
which may increase the size of types and the cost of type inference. For
that reason, the implementation of \OCaml cheats and is incomplete by
default. The user must explicitly pass the \texttt{-principal} flag to
require the more expensive computation of principal types when desired.

\paragraph{The relative completeness of directional type inference}

Both bidirectional and \geninst-directional type inference rely on an
ordering for type propagation that is partially specified, explicitly or
implicitly, to take advantage of user-provided type annotations and
already-inferred types to alleviated the need for extra annotations.
%
While they come with \emph{complete} algorithms, this is with respect to
their specifications, which include some choices that are subjective and may
sometimes look arbitrary.

\locallabelreset

Indeed, they all reject examples as ambiguous when sometimes there would be
a unique well-typed solution, as seen in the limitation of directional type
inference.  The first source of incompleteness results from the ordering
enforced between the resolution of core-language constraints that prevents
some core information to be taken into account when resolving ambiguities
\llabel {item/order}.
%
However, the resolution of ambiguities is another source of
incompleteness, which is actually two-fold:
\begin{enumerate*}
%% \item\label {item/order}
%%   the resolution is not considering type information from all
%%   terms into account. \Xalistair{I don't see how this is a
%%   new source of incompleteness? The reader already knows that
%%     directionality results in incompleteness at this point.}
\item[\llabel {item/info}]
  the resolution is not taking all contextual type information from
  each ambiguous term into account.
\item[\llabel {item/simultaneous}]
  each ambiguity is solved independently of other, yet unresolved ones.
\end{enumerate*}

Let us illustrate these situations with a few more examples:
\begin{program}[error]
let e_6 r = (r.x, r.y)
let e_7 = let getx r = r.x in getx {x = 1}
let e_8 r = let x = r.x in x + r.y
let e_9 r = (r.x : bool)
let e$_{10}$ r = r.x.x
\end{program}
All thse examples are ambiguous for \OCaml\footnote{Its succeeds on \ocaml{e_6},
using the default choice, but it fails if we reverse the order of the type
declarations.}.  However, \ocaml{r} can only be of type
\ocaml{two} in \ocaml{e_6}. Indeed, considering the second projection first,
we should learn that \ocaml{r} is of type \ocaml{two} and since it is
$\lambda$-bound, this should then make the first projection unambiguous.
The failure is a matter of solving the constraint in the right order, which
should wishfully be eliminated by omnidirectional type inference.
This illustrates the first form of incompleteness~\lref {item/order}.

\parcomment{Backpropagation and old-variable cases}

\OCaml also fails on \ocaml$e_7$, since it typechecks the let-binding first,
where it fails as ambiguous, while omnidirectional type inference has a view
on the whole program and may learn from the body of the let-binding that the
instance of $getx$ must have type \ocaml"int one -> int" and is therefore
its let-bound type (scheme) should be \ocaml$'a one -> 'a$ and is thus
non-ambiguous. This is an example of the second form of
incompleteness~\lref{item/info}.  A similar
failure occurs in \ocaml{e_8}\footnote{Ignoring default rules.}, where the
type of the $\lambda$-bound variable \code{r} is initially ambiguous and
unknown. It is only upon typing the projection \code{r.y} that \code{r} is
forced to have the type \ocaml{two}.
%
Our proposal with omnidirectional type inference succeeds
on \ocaml{e_6}, \ocaml{e_7}, and \ocaml{e_8}.
\begin{version}{}
\Xdidier{to be checked}
\Xalistair{I'm fairly certain your implementation (and our theory) does not
typecheck \code{e_8}. It is another example of incompleteness (like
\code{e_9})}\Xdidier {My prototype solves $e_8$ but not $e_9$. See below:}
\begin{version}{\Draft}
The example $e_8$ generates the following anti-unifier and variabtional
type
\begin{program}
Types antiunifed: one -> int | 'a two -> 'a
Variational anti-unifier: {'b ? {#(one | 'a two)}} -> {'c ? {#(int | 'a)}}
val e8 : bool two -> bool
\end{program}
Hence, the return type which is unified with \ocaml{'c} cancels the left
options (of the binary variation type), which becomes a singleton.  Since,
this is the same variational type on \ocaml{'b}, this is also solved.
\end{version}
\Xalistair{Ok, that is not how I understood your prototype to work. I
thought anti-unifiers were only used for overloading (and not record
fields). Regardless, our theory described in this paper does not typecheck
\code{e_8}.}
\end{version}

In \ocaml{e_9}, the only possible type is \ocaml{one} if we take into account
the return type of the projection. This also illustrates the second
form of incompleteness~\lref {item/info}.
Our current presentation, in this paper, treats this term as ambiguous,
since we do not permit the return type to influence resolution until
the projection itself has been disambiguated. Nonetheless, it is
entirely possible to typecheck such expressions using the omnidirectional
framework, as we discuss in \cref{sec:future-work}.

Omnidirectional still fails on \ocaml{e$_{10}$}, which is an instance of the
third form of incompleteness~\lref {item/simultaneous}. Here, both projections
must be considered simultaneously to infer that the type of
\ocaml{r} must be \ocaml{one}.
%
Requiring an order in which overloarding sites could be solved one after the
other is actually a reasonable design to keep type inference effective,
since the complexity of general overloading without such a restriction is
NP-hard, even in the absence of let-polymorphism, as shown by an encoding of
3-SAT problem as shown by~\citet
{Chargueraud-Bodin-Dunfield-Riboulet/jfla2025}.

\paragraph{Omnidirectional type inference}

The idea of \emph{omnidirectional} type inference is that types can be inferred
in any order. This requires typing constraint to be solved in disorder.
%
This approach eliminates the first source of incompleteness~\lref
{item/order}.  It leaves room to address the second source~\lref
{item/info}, but intendedly keeps the third source of incompleteness~\lref
{ref/simulteanous}---by design.
%
With omnidirectional inference, all examples from \ocaml{e_1} through
\ocaml{e_8} are correctly typed\ignorespaces
\INFO
{See \url
{https://gitlab.inria.fr/remy/semiun/-/blob/main/su/examples/record_fields.ml}}
---without any default strategy mechanism.

In absence of polymorphism, type inference is solely based on unification
constraints which can be solved in any order; omnidirectional inference is
then natural and easy to implement.  The difficulty originates from \ML
let-polymorphism for which all known implementations choose to always infer
the type of a let-binding first, to then turn it into a type scheme that is
assigned to the let-bound variable to extend the typing environment in which
the body is finally typed. The Hindley-Milner algorithm $\mathcal{J}$, one
of its variant $\mathcal{W}$ or $\mathcal{M}$~\cite
{Lee_Yi/algoM@toplas1998}, or more flexible constraint-based type inference
implementations all follow this strategy, to the best of our knowledge.
However, this state of affairs is not a necessity.

\paragraph {Constraint-based type inference}

In fact, typing constraints as presented by~\citet {Pottier-Remy/emlti} can
be instantiated before they are fully solved, although this comes at the
cost of duplicating some computation.  Still, this shows that the
let-binding ordering is a convenience, not a requirement.

In the~\textit{constraint-based} approach, type inference
is split into two stages, mediated by the language of \textit{constraints}
\citep{TODO}.  In the first stage, a term $\e$ is translated into a constraint
$\c$ which is satisfiable if and only if the term $e$ is well-typed. In the
second stage, the generated constraint $\c$ is solved (or shown to be
unsatisfiable).
%
The idea of treating typing judgments as typing constraints, which first
appeared in~\cite{Remy/mleth,Remy/thesis}, was popularized by ~\citet
{Odersky-Sulzmann-Wehr@tpos} with the \HMX framework---the Hindley-Milner
system parameterized by a constraint domain $X$, allowing constraints to
appear within types, and later extended by \citet{Pottier-Remy/emlti} who
were the first to fully decoupled constraint generation from constraint
solving.  The central innovation in their system for the reduction of type
inference to constraint solving is the inclusion of term variables in the
language of constraints.

Our insights into directionality builds on this work, which we extend with
with two technical devices to efficiently achieve omnidirectional type
inference for fragile \ML extensions:
\begin{enumerate*}
\item
  we introduce \emph{suspended match constraints} as a way to suspend
  ambiguity resolution until sufficient information has been found from
  context so that they can be discharged and hopefully resolved.
\item
  we work with partial types schemes, \ie with the ability to instantiate type
  schemes that are not yet fully determined and consequently revisit their
  instances when they are being refined, incrementally. This allows
  inferring parts of a \texttt{let}-body to disambiguate its definition,
  without duplicating constraint-solving work.
\end{enumerate*}

These technical devices are introduced once and for all---in a general
framework of constraint-based type inference. Each fragile \ML construct can
then be implemented as suspended constraints that expand to its robust
counterpart once the annotation has been inferred. This generality comes at
a cost, which is that everything is hard:
\begin{itemize}
\item Implementing partial types schemes (without duplicating
  constraint-solving work) is hard.
\item Giving an adequate semantics for suspended constraints is also hard, as we
  must capture declaratively the intuition that some type information must be
  \emph{known} rather than \emph{guessed}, but also that some programs
  that are semantically non-ambiguous (there is a unique fully-annotated
  version that is well-typed) must still be rejected as ambiguous to prevent
  us from looking into suspended constraints.
\end{itemize}
In return, we found that the declarative semantics of suspended constraints
immediately suggests a systematic way to present user-facing typing rules
for each fragile construct, for which the implementation is correct and
complete.

\subsubsection* {Plan}

The rest of the paper is organized as follows.
\begin{enumerate*}[label={}]
\item
  In \cref{sec:constraints}, we give an overview of suspended constraints
  and their application to various extensions for \ML.
\item
  In \cref{sec:semantics}, we describe suspended constraints and their semantics.
\item
  In \cref{sec:language}, we define \OML, an extension of \ML featuring static
  overloading of record labels, overloaded tuple projections, and
  semi-explicit first-class polymorphism. We also present its typing rules.
  This section gives a precise definition of the constraint generation
  translation and states the theorems of soundness and completeness.
\item
  In \cref{sec:solving}, we provide a formal definition of our constraint
  solver as a series of non-deterministic rewriting rules.
\item In \cref{sec:implementation}, we describe an efficient implementation
  of suspended constraints. We discuss some extensions of suspended
  constraints that we have prototyped but whose theory is less clear.
\item
  In \cref{sec:related-work} and \cref{sec:future-work}, we discuss related
  and future work.
\end{enumerate*}
All proofs are postponed to appendices.

\subsubsection* {Our contributions}

Our contributions are
\begin{enumerate*}
\item
  A novel \emph{omnidirectional} type inference framework for
  extensions of \ML with advanced features, based on two new devices,
  suspended constraints and partial type schemes;

\item A declarative semantics of suspended constraints that captures the
  idea that they wait on information that must be propagated from the
  context, not \emph{guessed}.

  This includes, in particular, a new declarative caracterisation of
  \emph{known} type information.

\item
  A complete yet efficient constraint-solving type inference algorithm.

\item
  Three instantiation of our framework that give new declarative type
  systems and their implementation using suspended constraints for tuple
  projection in the style of \SML, static overloading of record fields and
  datatype constructors, and for semi-explicit first-class polymorphism.

\end{enumerate*}

\section{Suspended constraints: an overview}
\label{sec:constraints}

\begin{bnffig}[t]%
  {fig:constraint-syntax}%
  {Syntax of types and constraints}
\entryset[Type variables]{\tva, \tvb, \tvc}{\TyVars}{}
\\
%% \entryset[Types]{\t}{\Types}\\
\entry[Types]{\t}{
    \tv \and
    \tunit \and
    \tone \to \ttwo \color{gray} \and
    \Pi\iton \ti \and
    \tys \T \and
    \tpoly \ts
}\\
\entry[Type schemes]{\ts}{
    \t \and
    \all \tv \ts
}\\[1ex]
\entry[Constraints]{\c}{
        \ctrue
  \and  \cfalse
  \and  \ca \cand \cb
  \and  \cexists \tv \c
  \and 	\cfor \tv \c
  \and  \cunif \tone \ttwo
  \nextline
  \and  \clet \x \tv \ca \cb
  \and  \capp \x \t
  \nextline
  \and  \cmatch \t \cbrs
}\\[1ex]
\entry[Branches]{\cbr}{\cbranch \cpat \c} \\
\entry[Patterns]{\cpat}{}{} \\[1ex]
\entry[Constraint contexts]{\C}{
  \square
  \and \C \cand \c
  \and \c \cand \C
  \and \cexists \tv \C
  \and \cfor \tv \C
  \nextline
  \and \clet \x \tv \C \c
  \and \clet \x \tv \c \C
} \\
\entryset[Shapes] {\Sh, \sh} {\Shapes} {}
\end{bnffig}

\parcomment{Syntax!}

The syntax of types and constraints is given
in~\Cref{fig:constraint-syntax}. Monotypes (or just types) are as usual
including: type variables $\tv$,
the unit type $\tunit$, arrow types as usual---and also
structual tuples, nominal types $\tys \T$, and polytypes,
in gray, as they which will be introduced in the following subsections.
Type schemes $\ts$
are of the form $\all \tvs \t$, they are equal up to the
reordering of binders. We write $\TyVars$ the set of type variables.


Building atop the constraint-based type inference framework of
\citet{Pottier-Remy/emlti}, we adopt a constraint language that includes both
term and type variables. Its syntax is given in~\Cref{fig:constraint-syntax}.

%
The constraint language contains tautologic constraints ($\ctrue$),
unsatisfiable constraints ($\cfalse$), and logical conjunctions ($\cone \cand
\ctwo$). The constraint form $\cexists \tv \c$ binds an existentially
quantified type variable $\tv$ in $\c$, while the constraint $\cfor \tv \c$
binds $\tv$ universally. The constraint form $\cunif \tone \ttwo$ asserts that
the types $\tone$ and $\ttwo$ are equal.
%
For convenience, we use the notation $\cleq \ts \t$ as syntactic sugar for the
constraint $\cexists \tvs \cunif \tp \t$, where $\ts$ is a universally
quantified type $\tfor \tvs \tp$; its intended meaning is the instantiation of
the polymorphic type $\ts$.

\parcomment{Constraint abstractions}

There are two constructs that deal with the introduction and elimination of
constraint abstractions. As the name suggests, a constraint abstraction
$\cabs \tv \c$ can simply be seen as a function which when applied to some
type $\t$ returns $\c \where {\tv := \t}$. Constraint abstractions are
introduced by a let-construct $\clet \x \tv \cone \ctwo$ which
binds the constraint abstraction to the term variable $\x$ in
$\ctwo$---additionally ensuring the abstraction is satisfiable. They are
eliminated using the application constraint $\capp \x \t$ which applies the
type $\t$ to the abstraction bound to $x$.

\parcomment {Suspended match constraints}

Finally, we introduce \textit{suspended match constraints}\footnote {Previously
dubbed `frozen constraints' in \citep{TODO}}. These constraints defer resolution
until the \textit{shape} of a type, such as its top-level
constructor\footnote{We intentionally leave the notion of shape underspecified
here; it is formalized in \cref{sec:semantics}.}, is known. Once the shape is
determined (typically through unification), the constraint selects a matching
branch from a list of cases. Formally, a suspended constraint is written as
$\cmatch \t \cbrs$, where:
%
\begin{enumerate}
\item
  The matchee $\t$ is a type. The constraint remains suspended until the
  shape of $\t$ is determined.
\item
  $\cbrs$ is a list of branches of the form $\cbranch \cpat \c$, where each
  shape pattern $\cpat$\footnote{Patterns are also left unspecified for now;
    they are defined in \cref{sec/constraint-gen}.}
  describes a structural form of the shape.
  %
  For example, the pattern $\tva \to \tvb$ matches function types, binding the
  argument and return types to $\tva$ and $\tvb$ respectively. The constraint
  $\c$ is then solved in the extended context.
  %
  To ensure determinism, the set of patterns $\bar \cpat$
  must be \emph{shape-disjoint}---that is, no shape may be matched by more
  than one pattern in the list.
\end{enumerate}
\parcomment {Informal semantics}
Suspended match constraints thus express case analysis on the structure of
types in a delayed, declarative form. Once the shape of $\t$ is known, a
unique branch is selected and its associated constraint is discharged and
may be solved. If the shape is never determined, the constraint remains
inaccessible (it cannot be inspected and help solve over constraints)
and unsatisfiable.

\parcomment {Constraint contexts}

Throughout this paper, we will find it convenient to work with
\emph{constraint contexts}. A constraint context is simply a constraint with
a ``hole'', analogous to evaluation contexts $\E$ used extensively in
operational semantics. We write $\C\where{\c}$ to denote filling the hole of
the context $\C$ with the constraint $\c$. Hole filling may capture
variables.  (Hence, we need explicit side-conditions when we mean to avoid
capture of a particular variable.)

\parcomment {Applications}

The remainder of this section illustrates the role of suspended constraints
in supporting \emph{fragile} language features as defined above.
These include:
\begin{enumerate}
  \item Semi-explicit first-class polymorphism;
  \item Constructor and record label overloading for nominal algebraic
  datatypes;
  \item Overloaded tuple projection in the style of \SML.
\end{enumerate}
We demonstrate how the typablity of each of these features can be elaborated
into constraints, formalized using a constraint generation function of the
form $\cinfer \e \tv$, which, given a term $e$ and expected type $\tv$,
produces a constraint $\c$ which is satisfiable if and only if $\e$ is
well-typed. A formal account of the semantics of suspended constraints and
the declarative typing rules for these features is deferred to
\cref{sec:semantics} and \cref{sec:language}, respectively.

\subsection{Semi-explicit first-class polymorphism}
\label {sec/constraints/polytypes}

\parcomment {Intro (and annotations)}
Semi-explicit first-class polymorphism \citep{Garrigue-Remy/poly-ml} uses
\textit{annotated types} to track the origins of polymorphic types.
%
The type constructor $\tapoly \ts \av$ boxes a polymorphic type
$\ts$ turning it into a \textit{polytype} annotated with the annotation
variable $\av$.  Once boxed, the polytype $\tapoly \ts \av$ is considered
a monotype, thereby enabling impredicative polymorphism. Annotation variables
may themselves be generalized, yielding type schemes such as
$\tfor \av {\tapoly \ts \av}$.


\parcomment {Boxing}

The introduction form for polytypes is a boxing operator $\expoly
\e {\exi \tvs \ts}$ with an explicit polytype annotation $\exi \tvs \ts$
where $\tvs$ are type variables that are free in $\ts$.
%
The resulting expression has type $\tapoly {\ts \where {\tvs \is \tys}} \av$
where $\av$ is an arbitrary (typically fresh) annotation variable and $\tys$
are arbritraty types that may be used in place of the free variables $\tvs$.
The annotation variable $\av$ can thus be generalized.  That is $\expoly \e
{\exi \tvs \ts}$ can also be assigned the type scheme $\all \av {\tapoly {\ts
\where {\tvs \is \tys}} \av}$.

\parcomment {Unboxing (principality restriction)}

Conversely, to instantiate a polytype expression, one must use an explicit
unboxing operator $\einst \e$, which requires no accompanying type
annotation.  However, the operator requires $e$ to have a polytype scheme of
the form $\all \av \tapoly \ts \av$ and then assigns $\einst \e$ the type
$\t$ that is an instance of $\ts$. If, by constrast, $\e$ has the type
$\tapoly \ts \av$ for some non-generalizable annotation variable $\av$, then
$\e$ is considered of a not-yet-known polytype, and therefore $\einst \e$ is
ill-typed.  It is precisely the polymorphism of $\av$ that ensures that the
polytype is indeed known and not being inferred.

\parcomment {Example ill-typed term}

In particular $\efun \x {\einst \x}$ is not typable, since the
$\lambda$-bound variable $\x$ is assigned a monotype. Consequently, the
only admissible type for $\x$ is $x : \tapoly \ts \av$ for some $\ts$ and $\av$.
Since $\av$ is bound in the surrounding context at the point of
typing $\einst \x$, it cannot be generalized prior to unboxing, rendering the
term ill-typed.

\parcomment {Annotations}

However, type annotations can be used to freshen annotation variables.
We usually omit annotation variables in annotations, since we can
implicitly introduce fresh ones in their place. For example,
$\efun {\x : \tapoly \ts {}} {\einst \x}$ which is syntactic sugar
for $\efun \x {\elet \x {(\x : \tapoly \ts {})} {\einst \x}}$, is
well-typed because the explicit annotation introduces a fresh
variable annotation $\ava$, which can then be generalized, yielding
$\tfor \ava {\tapoly \ts \ava}$.

\parcomment {Short commings of annotation variables}

The very purpose of annotation variables is to distinguish \emph{known},
polymorphic polytypes from \emph{not-yet-known}, monomorphic ones. However,
they may be sometimes be unintuitive as some information that has just been
inferred must still be considered as yet-unknown until its generalization.
They are also sensitive to the placement of type annotation, an artifact of the
fixed directionality of generalization in \geninst-directional inference. For
instance, the following two terms differ only in the position of the
annotation, yet only the one on the left-hand side is well-typed.
\begin{mathpar}
 \efun f {\eapp {\einst {(f : \tpoly {\tfor \tv {\tv \to \tv}})}} f}

\efun f {\eapp {\einst f} {(f : \tpoly {\tfor \tv {\tv \to \tv}})}}
\end{mathpar}
The difference lies in how generalization and annotation variables interact.
In the first term, the annotation occurs in an unboxing operator introducing
fresh annotation variables and may therefore be generalized to the type
scheme $\tfor \av {\tapoly {\tfor \tv {\tv \to \tv}} \av}$, enabling
unboxing to proceed. Whereas, the second term applies the annotation to the
argument $f$, which fixes $f$'s type to the monotype $\tapoly {\tfor \tv
{\tv \to \tv}} \ava$ for some fresh annotation variable $\ava$. Because this
type is assigned to $f$ at its binding site, $\ava$ is bound in the context
when typing $\einst f$, and cannot be generalized. As unboxing requires a
generalized polytype, the second term is ill-typed despite the annotation.

\parcomment {Suspended match constraints fixes this}

Suspended match constraints eliminate this sensitivity to directionality,
by allowing any type information to be treated as known---rendering annotation
variables unnecessary.
Typechecking $\expoly e \ts$ is, intuitively:
\begin{mathpar}
\cinfer {\expoly \e {\tfor {\tvbs} \t}} \tva \wide\eqdef
  \parens{\cfor \tvbs \cinfer \e \t}
\cand
   \tva = \tpoly {\tfor \tvbs \t}
\end{mathpar}
If $\e$ is already known to have the type $[\ts]$, then we can simply
instantiate it.  However, if the type of $\e$ is not yet known, \ie  it is a
(possibly constrained) type variable $\tv$: then, we must defer until more
information is available.  We capture this behaviour in the following constraint:
\begin{mathpar}
\cinfer {\einst \e} \tva \wide\eqdef
    \cexists \tvb \cinfer \e \tvb
\cand
    \cmatch  \tvb {\parens {\cbranch {\tpoly s} s \leq \tva}}
\end{mathpar}
Here, the match constraint $(\cmatchdots \tvb)$ suspends the instantiation
until $\tvb$ is resolved to a polytype $\tpoly \ts$ matching the pattern
$\tpoly s$, which binds the type scheme $\ts$ to the variable $s$. The
selected branch then performs the instantiation $\cleq s \tva$, that is
$\cleq \ts \tva$.
%
If $\tvb$ is already known to be a polytype, the constraint discharges
immediately and behaves like a standard instantiation constraint $\cleq \ts
\tva$.
%
By waiting for $e$'s type to be \emph{known}, we may ensure principal types
without annotation variables.

\subsection{Static overloading of constuctors and record labels}

% What do we mean by static overloading?

\emph{Static overloading} denotes a form of overloading in which resolution is
performed entirely at compile time, enabling the compiler to select a unique
implementation without relying on runtime information---in contrast to
\emph{dynamic overloading}, which defers resolution to runtime via
mechanisms such as dictionary-passing or dynamic dispatch.

\parcomment {Other languages}

Many languages offer statically resolved overloading to avoid the overhead
of dynamic dispatch. C++ and Java resolve overloaded functions through
compile-time specialization based on argument types. Conversely, languages
like Rust and Haskell primarily employ dynamic overloading via traits and
type classes, respectively, which can incur runtime overhead unless
optimized away by monomorphization and aggressive inlining.

\parcomment {OCaml and OCaml's approach (PI-directionality)}

As noted in the introduction, \OCaml supports a limited yet useful form of
static overloading for record labels and data type constructors. When
encountering overloaded labels or constructors, \OCaml resolves ambiguity using
local type information, guided by \geninst-directional inference. Nominal types
$\tys \Tapp$ carry annotation variables $\av$, written $\tys \Tapp^\av$, to
track which types are \emph{known}. As discussed in
\cref{sec/constraints/polytypes}, this mechanism allows one to deduce known
types from generalized type constructors $\tfor \av {\tys \Tapp^\av}$.

\parcomment {A note on bidirectional expected type propagation}

Because static overloading involves more intricate flows of information than
polytype inference, \OCaml supplements \geninst-directionality with a limited,
ad-hoc form of bidirectional type inference. This mechanism is folklore; no
formal account has previously been given.

\parcomment {Closed-world reasoning}

Beyond propagation, \OCaml also exploits \emph{closed-world reasoning} to resolve
ambiguities in record types. For instance:
\begin{program}[input]
  let e$_{11}$ = {x = 42; y = 1337}
\end{program}
\programjoin
\begin{program}[output]
  val e$_{11}$ : two
\end{program}
Here, \code{x} and \code{y} appear together only in the type \code{two},
allowing the type checker to unambiguously infer the type of \ocaml{e$_{11}$} as
\code{two}.

\parcomment {Default rules}

If local type information and closed-world reasoning are insufficient,
\OCaml falls back to a syntactic default: it selects the most recently
defined compatible type. For example:
\begin{program}[input]
  let getx r = r.x
\end{program}
\programjoin
\begin{program}[output]
  val getx : two -> int
\end{program}
The expression is compatiable with both \code{one} and \code{two},
since each defines a field \code{x}. But \code{two} is chosen simply
because it appears later in the source.
We do not treat this behaviour as principal; accordingly, we provide
no formalization of such ``default'' rules, though their implementation is
discussed further in \cref{sec:implementation}.

This fallback mechanism highlights the directionality of \OCaml inference.
Once the compiler selects a type, it commits to it---even if that choice
causes errors downstream. Consider the example where we flip the order of the
definitons of \code{one} and \code{two}:
\begin{program}[error]
  type two = {x : int; y : int}
  type 'a one = {x : 'a}
  let e$_{12}$ = fun r -> let x (* infers ['a one] *) = r.x in x + r.y
\end{program}
\programjoin
\begin{program}[error, style=message]
  Error: The expression has type int one
	 There is no field y within type one
\end{program}

\parcomment {Record field disambiguation in suspended constraints}

We propose an alternative account of static overloading using suspended
match constraints.  For example, in the case of an ambiguous record
projection $\efield \e \elab$, we generate the typing constraint:
\begin{mathpar}
\cinfer {\efield \e \elab} \tva \wide\eqdef
  \cexists \tvb \cinfer \e \tvb
  \cand
  \cmatch \tvb
    \parens
      {\cbranch {(\wild \Tapp[t])}
	{\labenv(\elab / t) \leq \tva \to \tvb}
      }
\end{mathpar}
This constraint defers resolution until more information is available:
specifically, until the type constructor of $\tvb$ of the record expression
$\e$ is known.

We assume a global typing environment $\labenv$ mapping labels to type schemes,
written $\elab : \tfor \tvs \t \to \tys \Tapp \in \labenv$. Since labels may be
overloaded across distinct type constructors, $\labenv$ may contain multiple
such schemes for a given label.  However, each label is assumed to be uniquely
defined within a given type constructor $\T$, allowing
$\labenv(\elab / \T)$ to denote the unique type scheme for $\elab$ in
$\T$ (if it exists).

Once the record type of $\tvb$ is known, the suspended constraint $(\cmatchdots
\tvb)$ is triggered. It matches against the nominal type pattern $\cpatrcd t$,
binding the type constructor name to $t$. Using this, the appropriate type
scheme for $\elab$ is retrieved from $\labenv(\elab/t)$, instantiated, and the
resulting constraints are imposed on the argument and return types of the label
access.

\TODO{Do some typing constraints for the examples presented in this section}
\Xalistair{What did you have in mind? I think it might be hard to talk about
the constraints without a semantics.}

\parcomment{Suspended constraints are better}

As seen in the examples above, this approach is faithful to \OCaml's current
behaviour\footnote {Modulo default disambiguation rules.}, and in fact
improves on it: certain expressions, such as \code{e}$_{12}$ are well-typed
under our account but rejected by \OCaml's current type checker.

\subsection{Tuple projections \`a la \SML}

\SML supports positional projections from tuples using expressions of the form
\ocaml{#$j$ e} to extract the $j$-th component of the tuple \code{e}.

\parcomment {SML typing rule}

Internally, tuples in \SML are treated as structural records with numeric
labels. While the specification \cite{TODO} does not provide a dedicated typing
rule for tuple projection, its semantics are captured by desugaring $\eproj \e
j$ as $\eapp {\parens {\efun {\erecord {j = \x; \wild}} \x}} \e$. From this
encoding\footnote{This encoding relies on the standard function typing rules
and the \SML typing rule for the pattern matching of record.}, one recovers the
expected typing rule: if $\e$ has the type $\tsrecord {j = \tj; \varrho}$,
where $\varrho$ is a row describing the remaining tuple fields, then $\eproj \e
j$ has type $\tj$.

\SML enforces an additional restriction: the tail $\varrho$ must be fully
determined (\ie cannot be a polymorphic row variable).  This ensures that the
arity of the tuple is \emph{known} statically from the surrounding context,
thereby avoiding the need for row polymorphic. The restriction is not reflected
in the typing rules themselves, but is instead enforced within \SML's type
inference algorithm.

\parcomment {Tuple projection is statically overloaded}

From a typing perspective, tuple projection in \SML behaves like a form
of static overloading: the expression $\eproj \e j$ is valid only when $\e$ is
known to be an $n$-ary tuple for some fixed $n \geq j$. Unlike record or
constructor  overloading, the space of possible overloadings in this case is
countably infinite.

\parcomment {We can precisely specify this with suspended constraints}

We can capture the typing of tuple projections precisely using suspended
constraints. For the projection $\eproj \e j$, we generate the following
constraint:
\begin{mathpar}
  \cinfer {\eproj \e j } \tv \wide\eqdef
  \cexists \tvb
    \cinfer \e \tvb
    \cand \cmatch \tvb {\cbranch {\cpatprod \tvc j} {\cunif \tva \tvc}}
\end{mathpar}
\parcomment{Tuple patterns}
The suspended constraint $\cmatch \tvb {\cbranch {\cpatprod \tvc j} {\cunif
\tva \tvc}}$ blocks until the shape of $\e$ ($\tvb$) is known to be a tuple
of sufficient arity. The pattern $\cpatprod
\tvc j$ matches only tuple types $\tProd \ti$, where $n \geq j$, binding the
$j$-th component to $\tvc$, which is then unified with the expected result type
$\tva$.

\parcomment{Next section}

Suspended constraints offer a robust mechanism for dealing with extensions of
\ML that depend on a notion of \emph{known} type information. What remains
is to formalize this notion: that is, to give a precise semantics for when
a type variable is considered \emph{known}, and how suspended constraints
are discharged accordingly.


\section{Semantics of constraints}
\label{sec:semantics}

\parcomment {Judgement shape}

The semantics of constraints is given, as is standard, by a satisfiability
judgment of the form $\semenv \vdash \c$: the constraint $\c$ is satisfied by
the solution, or valuation, $\semenv$. The semantic environment $\semenv$ is a
total map from type variables to \emph{ground} types---types with no free
variables\footnote{Ground types are thus finite trees, assuming the existence
of a base type such as $\tint$. In \cref{sec/rec-types}, we dissuss the
alternative choice of regular trees for the set of ground types that models
equirecursive types.}---ranged over by $\gt \in \Ground$, where $\Ground
\subseteq \Types$ denotes the set of ground types.
%
Term variables are mapped to sets $\glam \subseteq \Ground$, representing the
set of ground types for which the application $\capp \x \t$ is satisfiable
under the closure of $\x$.

We write $\semenv\where{\tv \is \gt}$ to denote the enviroment that agrees with
$\semenv$ everywhere except at $\tv$, which is mapped to $\gt$; likewise, $\semenv
\where{\x \is \glam}$ denotes the environment identical to $\semenv$ except that
$\x$ is mapped to $\glam$. By homomorphism, $\semenv$ determines a total mapping
from types to ground types, written $\semenv(\t)$.

\parcomment {Definition exampled}

The judgment is defined, for all constraint-formers except suspended
constraints, in \cref{fig:constraint-semantics}. $\ctrue$ is satisfied in any
environment, and $\cfalse$ in none. An environment $\semenv$ satisfies $\cone
\cand \ctwo$ if it satisfies both $\cone$ and $\ctwo$. The existential rule
$\semenv \vdash \cexists \tv \c$ requires that $\semenv$ provides a
``solution'' for $\tv$: it maps $\tv$ to a type $\gt$ that satisfies the expected
constraints in $\c$. The universal constraint $\cfor \tv \c$ requires $\c$ to
be satisfiable under any type mapped to $\tv$ in $\semenv$. A unification
constraint holds if both sides are mapped to the exact same type under the
environment.

The rule for let-bindings reflects that the constraint abstraction $\cabs
\tv \c$ must first be \emph{satisfiable}, checking that $\cone$ holds under
some instantiation of its bound variable; then binding the abstraction's
interpretation to $\x$ in $\semenv$ when checking the satisfiability of $\ctwo$.
Formally, constraint abstractions $\clam \tv \c$ are interpreted semantically as
the set of ground types $\gt$ that satisfy $\semenv\where{\tv \is \gt} \th \c$:
\begin{mathpar}
  \semenv(\clam \tv \c) \uad\eqdef\uad \set {\gt \in \Ground : \semenv\where{\tv \is \gt} \th \c}
\end{mathpar}

Application constraints $\capp \x \t$ are interpreted by checking that $\t$
belongs to the set of types mapped to $\x$ in $\semenv$, that is, $\semenv(\t)
\in \semenv(\x)$. Equivalently, if $\x$ is mapped to the interpretation
$\semenvp(\clam \tv \c)$ of the abstraction $\clam \tv \c$, then this
membership holds if and only if the body $\c$ is satisfied under the extended
environment $\semenvp\where{\tv \is \semenv(\t)}$ --- here, $\semenvp$ is the
environment at the binding site of $\x$ and thus serves as the closure of
$\clam \tv \c$.


\begin{mathparfig}[t]%
  {fig:constraint-semantics}%
  {Semantics of constraints (without suspended constraints)}
  \infer[True]
    {}
    {\semenv \th \ctrue}

  \infer[Conj]
    {\semenv \th \cone \\
     \semenv \th \ctwo}
    {\semenv \th \cone \cand \ctwo}

  \infer[Exists]
    {\semenv\where{\tv \is \gt} \vdash \c}
    {\semenv \th \cexists \tv \c}

  \infer[Forall]
    {\forall \gt, ~ \semenv\where{\tv \is \gt} \vdash \c}
    {\semenv \th \tfor \tv \c}

  \infer[Unif]
    {\semenv(\tone) = \semenv(\ttwo)}
    {\semenv \th \cunif \tone \ttwo}

  \infer[Let]
    {\semenv \vdash \exists \tv. \cone \\
     \semenv\where{\x \is \semenv(\cabs \tv \cone)} \th \ctwo}
    {\semenv \th \clet \x \tv \cone \ctwo}

  \infer[App]
    {\semenv(\t) \in \semenv(\x)}
    {\semenv \th \capp x \t}
\end{mathparfig}

% Why this semantics is useful

While this semantics feels a bit tautological, the rules above, which omit
suspended constraints, are straightforward. It is a useful exercise to ensure
that we can give an explanation of each constraint-former in our
mathematical meta-language that is reasonably simple and declarative.
This specification is essential for proving properties of type inference,
such as the soundness and completeness of the constraint generator---as well
as for reasoning about the correctness of the solver.

% Example

Closed constraints are either satisfiable in any semantic environment (\ie they are tautologies)
or unsatisfiable. For example, consider the constraint $\cexists
\tv {\cunif \tv \tint}$, its satisfiability is established by the following
derivation:
\begin{mathpar}
  \infer*[Right=Exists]
    {\infer*[Right=Unif]
      {\infer*{}{\tint = \tint}}
      {\semenv\where{\tv \is \tint} \vdash \cunif \tv \tint}}
  {\semenv \vdash \cexists \tv \cunif \tv \tint}
\end{mathpar}

% Equivalence and entailment

We write $\cone \centails \ctwo$ to express that $\cone$ \emph{entails} $\ctwo$,
meaning every solution $\semenv$ to $\cone$ is also a solution to $\ctwo$.
We write $\cone \cequiv \ctwo$ to indicate that $\cone$ and $\ctwo$ are equivalent,
that is, they have exactly the same set of solutions.

\subsection{Shapes
\label{sec/shapes}}

\parcomment {Definition of shape}

A shape $\Sh$ is a type with holes, written $\any \tvcs \t$, where $\tvcs$
denotes the set of type variables representing the holes, is exactly the
free variables of $\t$.  Hence, shaped are closed. They are treated up to
$\alpha$-conversion.  We write $\bot$ for the shape $\any \tvc \tvc$, which
we call the \emph{trivial} shape. We write $\Shapes$ the set of shapes and
$\Shapesz$ the subset of non trivial shapes.
%% and use letter $\Sh$ to range
%% over non trivial shapes.

Shapes are equipped with an ordering---that of the standard
instantiation ordering, defined by:
\begin{mathpar}
  \infer[Inst-Shape]
    {\bar \tvcs_2 \disjoint \any {\tvcs_1} \t}
    {\any {\tvcs_1} \t \preceq
     \any {\tvcs_2} \t \where {\tvcs_1 \is \tys_1}}
\end{mathpar}
When writing $\Sh \preceq \Shp$, we say that $\Sh$ is more general than
$\Shp$. When $\Sh$ and $\Shp$ are more general than one another, they are
actually equal. The trivial shape $\bot$ is the most general shape.

\parcomment {Define decomposition}

Given a shape $\any \tvcs \t$, we write $\deshaped [\tvcs] \t \tys$ for $\t
\where {\tvcs \is \tys}$. This is uniquely determined, since it is
independent of the choice of variables $\tvcs$ for representing the
shape.
%
A type $\t$ has a decomposition $\deshaped \Sh \tys$ iff $\t = \shapp \tys$;
we say that $\sh$ is \emph{a} shape of $\t$.  A decomposition is trivial if
the shape is trivial.

%% \Xgabriel{It is obvious that $\sh(\tys)$ is uniquely
%% determined in the paragraph above, but not completely obvious that the
%% decomposition of $\t$ as $\sh(\tys)$ is uniquely determined by
%% $\sh$.}\Xdidier {Why not?} \Xalistair{I also think it is fairly
%% obvious? To find $\tys$, just unify the shape with $\t$ treating
%% the variables as flexible unification variables.}

\begin{definition}
A non-trival shape $\Sh$ is the principal shape of the type $\t$ iff:
\begin{enumerate}
  \item
    $\t = \shapp[\Sh] \tys$
  \item
    $\forall \Shp \in \Shapesz, \t = \shapp[\Shp] \typs
    \implies \Sh \preceq \Shp$
\end{enumerate}
\end{definition}

\begin{theorem}[principal shapes]\label{th/shapes/principal}
Any nonvariable type $\t$ has a non-trivial principal shape $\Sh$.
\end{theorem}

\parcomment {Define canonical shape}

A principal shape $\any \tvcs \t$ is canonical if the sequence of its free
variables $\tvcs$ appear in the order in which the variables occur in
$\t$\footnote{This order is well-defned for principal shapes, but not always
well-defined for all shapes, for instance $\any {\tvca, \tvcb} (\tvca \to
\tvcb) \to (\tvcb \to \tvca)$.}. We write $\sh$ for canonical principal
shapes.

We write $\shape \t = \sh$ for the canoni cal principal shape of $\t$ (if
defined). Thus $\shape {\tys \Tapp}$ is $\any \tvcs \tvcs \Tapp$.
Canonical principal shapes can be seen as a generalization of type
constructors, capable of coping with polytypes.
For example, the polytype  $\tpoly {\all \tva
  {\parens{\tpoly {\all \tvb {\parens{\tvb \to \tint \tlist}} \tprod \tvb}
  \to \tva}
  \to \tva}}$  can be decomposed as:
\begin{mathpar}
\deshaped
  [\tvc]
  {\tpoly {\all \tva
     {\parens{\tpoly {\all \tvb \parens{\tvb \to \tvc} \tprod \tvb} \to \tva}
    \to \tva}}}
  {\parens{\tint \tlist}}
\end{mathpar}
The canonical principal shape of a type governs its decomposition. We write
$\decomp \t$ for the decomposition of $\t$ induced by its canonical
principal shape.

%\parcomment{Patterns and matching}
%
%Shapes and decompositions are used in suspended match constraints for describing the
%structure of types. We write $\cmatches \cpat {\shapp \tys} \theta$ to denote that the
%pattern $\cpat$ matches the principal decomposition $\shapp \tys$ of a type,
%producing a substitution $\theta$ for variables bound by the pattern.
%The matcing function $- \Matches \mathop{=}$ is partial: it is undefined when
%the pattern $\cpat$ does not match the given shape $\sh$. We introduce this
%function abstractly and defer its formal definition to \cref{sec:constraint-gen}
%along with the syntax of patterns, as it depends on the concrete grammar of types,
%given in \cref{sec:language}.
%

\TODO {Discuss and fix comments below}
\Xdidier {Too many
notations.  I replaced the canonical shape notation by forcing $\sh$ to only
range over principal shapes and introduced $\zeta$ (we could have used $s$
to range over any shape), or inline them. But it is reversible as I left the
macro $\pshapp$ in place, and just changed its definition.}\Xdidier {In
fact, I would prefer to invert the notation, use $\sh$ for any shape (if
need be) and use $\Sh$ for canonical shapes, since canonical shapes are
later use in place of type constructors and $\zeta$ looks better when seen
as a type constructor. Hence I would write $\Sh\; \tys$ rather then
$\shapp[\Sh] \tys$ for a type where $\Sh$ is either a canonical shape or a
type construtor $\F$, since they are isormophic to the nonpolytype shapes}
\Xalistair{I agree with the notation switch -- I also agree with the
suggestion to treat $\zeta$ more like a type constructor (though personally I
find $\sh$ more readable that $\zeta$ as a shape).}




\subsection{Suspended constraints}
\paragraph {An attempt}

To extend these semantics to our suspended constraints, a first natural idea
is to propose the following rule---henceforth referred to as the
\emph{natural semantics} of suspended constraints:
\begin{mathpar}
\infer[Susp-Nat]
  {\cmatches \cpati {\decomp {\semenv(\t)}} \theta \\
   \semenv \compose \theta \th \ci}
  {\semenv \vdash \cmatch \t {\cbranch {\bar \cpat} {\bar \c}}}
\end{mathpar}

\parcomment{Explain the rule}

This rule states that a suspended constraint is satisfied by $\semenv$ whenever
there exists a unique branch $\cbranch \cpati \ci$ whose pattern $\cpati$
matches the principal shape of the ground type $\semenv(\t)$\footnote{This is
guaranteed to be defined by Theorem ??.}. The match yields a substitution
$\theta$ that binds the subcomponents introduced by the pattern. The
corresponding branch constraint $\ci$ must then be satisfied under the extended
environment $\semenv \compose \theta$. In effect, the principal shape of
$\semenv(\t)$ provides the structural information needed to discharge the match
constraint, while $\theta$ ensures correct scoping of the extracted components.

\parcomment {Matching is unique and deterministic}

Suspended match constraints require that, if a pattern matches a given shape,
then the match is unique and unambiguous. However, we do not require the set of
branches to be exhaustive: if no pattern matches the shape, the constraint is
unsatisfiable by definition.

\parcomment {Matches predicate}

We have thus far left the syntax of shape patterns deliberately abstract, as
it is extension-specific. Accordingly, the matching function $\cmatches \cpat
{\pshapp \tys} \theta$ is also left unspecified. This partial function matches
a pattern $\cpat$ against a principal shape $\sh$ with components $\tys$,
yielding a substitution $\theta$ for any variables bound in the pattern.

\parcomment {Wildcard patterns}

For illustrative purposes, we define the trivial pattern $\cwild$, which matches
any shape and binds no variables. Its semantics are given by:
\begin{mathpar}
  \cmatches[\eqdef] \cwild {\pshapp \tys} \eset
\end{mathpar}

\parcomment {Good example}

Consider the constraint $\cexists \tv \cunif \tv \tint \cand \cmatch \tv
{\cbranch \cwild \ctrue}$. This is satisfiable under the current
semantics, as shown by the derivation:
\begin{mathpar}
\def \cmatchex {\cmatch \tv {\cbranch \cwild \ctrue}}
\def \semenvex {\semenv\where{\tv \is \tint}}
    \infer*[Right=Conj]
    {
     \infer*[Left=Unif]
      {\tint = \tint}
      % -------------------------------
      {\semenvex \vdash \cunif \tv \tint}
     \\
     \infer*[Right=Susp-Nat]
      {
	\cmatches \cwild {\pshapp[\tint]\cdot} \eset
	\\
	\infer*[Right=True]
	  { }
	  % ---------------------
	  {\semenvex \vdash \ctrue}
      }
      % ------------------------
      {\semenvex \vdash \cmatchex}
    \hspace{-2em}
}{% ---------------------
    \infer*[Right=Exists]
      {\semenvex \vdash \cunif \tv \tint \cand \cmatchex}
    % ------------------------------------------------------------
      {\semenv \vdash \cexists \tv \cunif \tv \tint \cand \cmatchex}
}
\end{mathpar}
In this case, the shape of $\tv$ is first determined by the unification with
$\tint$, allowing a solver to deduce that $\tv$'s shape is \emph{known}
from the surrounding context of the match constraint. This unlocks the
match constraint and permits the resolution of the corresponding branch
constraint ($\ctrue$)---precisely as intended.

\parcomment {The problem}

However, the semantics also permits less desirable behaviour. Consider the
constraint: $\cexists \tv \cmatch \tv {\cbranch \cwild {\cunif \tv \tint}}$.
Here, the shape of $\tv$ is unconstrained prior to solving the match branch,
suggesting that the constraint should be unsatisfiable. Yet under the
natural semantics, it is considered satisfiable:
\begin{mathpar}
\def \cmatchex {\cmatch \tv {\cbranch \cwild {\cunif \tv \tint}}}
\def \semenvex {\semenv\where{\tv \is \tint}}
    \infer*[Right=Susp-Nat]
    {
      \cmatches \cwild {\pshapp[\tint]\cdot} \eset
      \\
      \infer*[Right=Unif]
        {\tint = \tint}
	% -------------------------------
    {\semenvex \vdash \cunif \tv \tint}
}{% ---------------------------------
    \infer*[Right=Exists]
    {\semenvex \vdash \cmatchex}
  % -----------------------------------
  {\semenv \vdash \cexists \tv \cmatchex}
}
\end{mathpar}
In this case, the semantics can \emph{guess} the type of $\tv$
and use it to unlock the match constraint, rather than requiring it to be
known from the surrounding context. This does not match the intended meaning
of suspended match constraints, and raises several problems:
\begin{enumerate*}

  \item A reasonable solver---one that avoids guessing or backtracking---cannot
    be complete with respect to this semantics.

  \item This breaks the existence of principal solutions.
    Consider the function $\efun \x (\efield \x 2)$, which projects the second
    component of a tuple. Under the current semantics, the generated constraint
    permits us to guess any tuple type of arity at least two to be guessed for
$\x$. But there is no most general tuple type encompasing all such sizes---so
no principal type exists for $\x$. \end{enumerate*}

\paragraph {Contextual semantics}

To rule out guessing, we adopt a \emph{contextual} semantics in which
the shape of a type must be \emph{known} from the surrounding context
in order to satisfy a match constraint.
% Elaborated matches
First, we introduce the syntactic sugar $\cmatched \t \sh \cbrs$ for a match constraint
when the shape $\sh$ of the matchee $\t$ is already known:
\begin{mathpar}
  \cmatched \t {\any \tvcs \tp} {\cbranch \cpats \cs} \uad\eqdef\uad
    \cexists \tvcs \cunif \t \tp \cand \theta(\ci) \qquad \text{if } \cmatches \cpati {\shapp[\any \tvcs \tp] \tvcs} \theta
\end{mathpar}
This desugaring mirrors the premises of \Rule{Susp-Nat} rule, but differs in
how the shape is obtained. \Rule{Susp-Nat} ``guesses'' the shape of $\t$ using
the semenatic environment $\semenv$. In contrast, $\cmatched \t \sh \cbrs$
requires the shape \apriori. The first conjunct ensures that $\t$ indeed has
shape $\sh$, unifying the shape's parameters $\tvcs$ to the corresponding
components of $\t$. The second conjunct encodes the selected branch, just as in
\Rule{Susp-Nat}.

\parcomment {Contextual rule}

The key innovation of the contextual semantics lies in the following rule,
which is the only non-syntax-directed rule in our semantics:
\begin{mathpar}
  \infer[Susp-Ctx]
    {\Cshape \C \t \sh \\
      \semenv \th \C \where {\cmatched \t \sh \cbrs}
    }
    {\semenv \vdash \C \where {\cmatch \t \cbrs}}
\end{mathpar}
This rule lets us infer the shape $\sh$ of the matchee type $\t$,
provided the constraint context $\C$ determines $\t$
to have precisely the shape $\sh$.
%
\Xalistair{Should we rename this to the non-ambiguity condition?}
The premise $\Cshape \C \t \sh$ ensures this
precisely: it expresses that the context $\C$ constrains all the solutions
of $\t$ to have the \emph{same} principal shape $\sh$,
modulo $\alpha$-equivalence of shapes. The formal definition of this
predicate, which is somewhat technical, is given below.

\begin{definition}
  A type $\t$ has a \emph{uniquely known} principal shape within
  the context $\C\where{\square}$, written $\Cshape \C \t \sh$, iff for all
  assignments $\semenv$ and ground types $\gt$, then $\semenv \vdash
  \cerase {\C\where{\cunif \t \gt}}$ implies that the principal shape of $\gt$ is equal
  to $\sh$.
%
  In other words:
  \begin{mathpar}
    \Cshape \C \t \sh \Wide\eqdef \forall \semenv, \gt. \uad
      \semenv \vdash \cerase {\C\where{\cunif \t \gt}} \implies \shape \gt = \sh
  \end{mathpar}
\end{definition}

This condition ensures that we are not guessing a shape arbitrarily;
the shape must already be determined by the ambient constraint.

Here, $\cerase \cdot$ (defined in \cref{fig:constraint-erasure}) removes
all suspended match constraints. This reflects the fact that that such constraints
represent constraints that are only \emph{possibly} true in the future, and
thus should not inform what is known in the present. Implicitly, this induces a
linear partial ordering over suspended match constraints, reflecting \emph{temporal}
dependency: a match constraint may only be resolved once all of its dependencies
have been resolved.

% Unicity is only really interesting
Note that, if $\t$ is not a variable, then $\Cshape \square \t {~\shape \t}$ holds
trivially. The interesting cases arise when $\t$ is a type variable.

\begin{mathparfig}
  {fig:constraint-erasure}
  {The erasure of suspended match constraints}
\newcommand{\Erule}[2]{\cerase {#1} &\eqdef& {#2}}
  \begin{tabular}{RCL}
  \Erule{\ctrue}{\ctrue} \\
  \Erule{\cfalse}{\cfalse} \\
  \Erule{\cone \cand \ctwo}{\cerase \cone \cand \cerase \ctwo} \\
  \Erule{\cexists \tv \c}{\cexists \tv \cerase \c} \\
  \Erule{\cfor \tv \c}{\cfor \tv \cerase \c} \\
  \Erule{\cunif \tone \ttwo}{\cunif \tone \ttwo} \\
  \Erule{\clet \x \tv \cone \ctwo}{\clet \x \tv {\cerase \cone} {\cerase \ctwo}} \\
  \Erule{\capp \x \t}{\capp \x \t} \\
    \Erule{\cmatch \t {\cbranch {\bar \cpat} {\bar \c}}}{\ctrue} \\
\end{tabular}
\end{mathparfig}

\parcomment {Examples}

We illustrate the contextual semantics for suspended constraints
with a series of examples.
\begin{example}
Consider the two examples from above:
\begin{mathpar}
\cexists \tv \cunif \tv \tint
  \cand
  \cmatch \tv {\cbranch \cwild \ctrue}

  \cexists \tv \cmatch \tv {\cbranch \cwild {\cunif \tv \tint}}
\end{mathpar}
In the first example, we apply the contextual rule with the context $\C \is
(\exists \tv. \tv = \tint \cand \square)$. Any solution $\phi$ of this part
of the constraint necessarily satisfies $\tv = \tint$. Hence, the shape of
$\tv$ is uniquely determined. The uniqueness condition of \Rule{Susp-Ctx}
rule is therefore satisfied, and the suspended constraint can be resolved.

In constrast, the second example has no contextual information around
the suspended constraint ($\C \is \square$), so any solution
$\semenv$ satisfies it, and $\tv$ can take an arbitrary shape in this context.
Consequently, the uniqueness condition fails, the \Rule{Susp-Ctx} rule
cannot be applied, and the constraint remains unsatisfiable---as intended.
\end{example}
\begin{example}
Consider the more intricate example:
\begin{mathpar}
  \cexists {\tva \tvb}
  \Parens{\begin{array}{l}
    \quad \cmatch \tva {\cbranch \cwild {\cunif \tvb \tbool}} \\
    {} \cand \cmatch \tvb {\cbranch \cpatwild \ctrue} \\
    {} \cand \tva = \tint
  \end{array}}
\end{mathpar}

Suppose we attempt to apply \Rule{Susp-Ctx} to the suspension on $\tvb$ first.
This requires us to show that $\tvb$ has a uniquely determined shape in the
context $\C \is \cmatch \tv {\cbranch \cpatwild {\cunif \tvb \tbool}} \cand
\square \cand \cunif \tva \tint$. Erasing this context gives us $\cerase \C
= \ctrue \cand \square \cand \cunif \tva \tint$. From this, it is clear
that $\tvb$ is unconstrained, and thus the application of \Rule{Susp-Ctx}
fails.

Now consider instead applying \Rule{Susp-Ctx} to the suspension on $\tva$
first. To do, so, we must show that $\tva$ has a uniquely determined shape in
the context $\C \is \square \cand \cmatch \tvb {\cbranch \cpatwild \ctrue}
\cand \cunif \tva \tint$. The erasure of this context is $\cerase \C =
\square \cand \ctrue \cand \cunif \tva \tint$. With this context, $\tva$
clearly has the unique shape of $\tint$, thanks to the equality $\cunif \tva
\tint$.

We may now resolve the suspension on $\tva$, rewriting the constraint to
$\cmatch \tint {\cbranch \cpatwild {\cunif \tvb \tbool}} \cand \cmatch \tvb
{\cbranch \cpatwild \ctrue} \cand \cunif \tva \tint$. At this point, we can
safely apply \Rule{Susp-Ctx} to the remaining match constraint on $\tvb$.
This application succeeds now as the erasure of the context includes the
discharged match constraint $\cmatch \tint {\cbranch \cpatwild {\cunif \tvb
\tbool}}$, uniquely determining $\tvb$ to have the shape $\tbool$, thereby
eliminating the final suspended match.

This demonstrates that suspended match constraints must be resolved in a
dependency-respecting order: attempting to resolve a match
constraint too early may result in unsatisfiability.
\end{example}

\begin{example}
Let us consider a constraint with a cyclic dependency between match
constraints:
\begin{mathpar}
  \cexists {\tva \tvb}
  \left(\begin{array}{l}
    \quad \cmatch \tva {\cbranch \cwild {\cunif \tvb \tbool}} \\
    {} \cand \cmatch \tvb {\cbranch \cwild {\cunif \tva \tint}}
  \end{array}\right)
\end{mathpar}
This constraint can be proved satisfiable under the ``natural semantics'' introduced
earlier: by guessing the assignment $\tva \is \tint, \tvb \is
\tbool$, the two matches suceed and the constraint holds. However,
our solver fails to solve it, as does our contextual semantics.

Without loss of generality, suppose that we try to apply \Rule{Susp-Ctx} on
$\tva$ first: we must show $\Cshape \C \tva \tint$ for the context $\C :=
(\square \cand \cmatch \tvb {\cbranch \cwild {\cunif \tva \tint}})$. That is to
say, $\tva$ has the uniquely determined shape $\tint$ in every solution of the
erased context $\cerase \C$.
%
But this fails: the erasure $\cerase \C = \square \cand \ctrue$ imposes no
constraint on $\tva$. Hence, the shape of $\tva$ is unconstrainted, and we
cannot justify applying the \Rule{Susp-Ctx} rule.

This example illustrates a key distinction between the natural and
contextual semantics: while the former allows unconstrained guessing, the
latter requires well-foundedness in constraint dependencies, ensuring that
resolutions are guided by contextual information rather than arbitrary
choices.
\end{example}

\begin{example}
Considering the example \code{e_8} from \cref{sec/introduction}:
\begin{program}[input]
let e_8 r = let x = r.x in x + r.y
\end{program}
The simplified constraint generated when typing \code{e_8} is:
\begin{mathpar}
  \cexists \tv
    \clet x \tvb
      {\cmatch \tva \parens {\cbranch {(\wild \Tapp[t])} {\labenv(\x / t) \leq \tvb \to \tv}}}
      {\cinst x \tint \cand \cunif \tv {\mathsf{two}}}
\end{mathpar}
Here, $\tv$ stands for \code{r}'s type. The constraint remains
suspended until \code{r.y} forces \code{r}'s type to be \code{two}.

This constraint is satisfiable under our semantics. We apply the
\Rule{Susp-Ctx} rule with context $\C \is \clet \x \tvb \square \capp \x
\tint \cand \cunif \tv {\mathsf{two}}$. Although the context includes a
\code{let}-binding --- which in practice involves let-generalization --- we
can still deduce $\Cshape \C \tv {\mathsf{two}}$, since any solution to $\cerase \C$
requires $\tv$ to be \code{two} (thanks to the equality $\cunif \tv
{\mathsf{two}}$).

This example illustrates that our formulation of suspended constraints
interacts nicely with let-polymorphism. Although the two features are
specified in a modular fashion, they are carefully crafted to work together,
as we will further show in our next example.
\end{example}

\begin{example}
A further subtle---but crucial---feature of our semantics is its support for
\emph{backpropagation}. We illustrate this with the example \code{e_9}:
\begin{program}[input]
let e_9 = let getx r = r.x in getx { x = 1 }
\end{program}
\OCaml rejects this example, as it types the \code{let}-bound expression first
and fails to infer the unique type of \code{'a one} for  \code{r}.
%
In contrast, our approach accepts it. The constraint generated when typing
\code{e_9} is:
\begin{mathpar}
\begin{tabular}{L.L}
  \cexists \tv {}
  &\clet {getx} \delta
     {\cexists {\tvb, \tvc} \Parens {\strut
        \cunif \delta {\tvb \to \tvc} \cand
	\cmatch \tvb {\cbranch {(\wild \Tapp[t])} {\labenv(\x/t) \leq \tvc \to \tvb}}
        }}{}
    \\&\cinst {getx} {(\tint \ \mathsf{one} \to \tv)}
\end{tabular}
\end{mathpar}
The unicity predicate $\Cshape \C \tvb \sh$ can be used to show that no
other shape than $\sh$ equal to $\any \tvc {\parens {\tvc \; \mathsf{one}}}$
can be inferred for $\tvb$---without rendering the constraint
unsatisfiable. In particular, with the context $\C$ equal to $\clet {getx}
\delta {\cexists {\tvb, \tvc} \cunif \delta {\tvb \to \tvc} \cand \square}
{\capp {getx} {(\tint \ \mathsf{one} \to \tv)}}$, we have:
\begin{mathpar}
  \all {\semenv, \gt} \uad
    \semenv \th \cerase {\C\where{\cunif \tvb \gt}} \implies \shape \gt = \any \tvc \tvc \ \mathsf{one}
\end{mathpar}
Any attempt to assign a differently shaped type (\eg \code{two}) to $\tvb$
would cause the instantiation constraint to fail in the context $\C$.
%
This allows the unicity predicate to propagate shape information from
instantiation constraints \textbf{back} into the let-bound abstraction,
earning its name \emph{backpropagation}.
\end{example}

\paragraph{Well-foundedness}

The astute reader may have noticed a subtle compilication resulting
from our definition of the unicity predicate:
$\Cshape \C \tv \sh$ includes a negative occurrence of the
satisfiability judgement. This is essential for expressing that
$\sh$ is unique among all solutions of the ambient context $\C$.
%
However, this negative occurrence means that, \apriori, the rules
from \cref{fig:constraint-semantic} including \Rule{Susp-Ctx}
do not form an inductive definition in the usual syntactic sense.

This is not merely a technicality: if left unaddressed, it undermines
the well-foundedness of the semantics and the interpretation of our
rules as a proper inference system.

Fortunately, this issue can be cleanly resolved. Although the rules are not
structurally well-founded, they can be defined in a decreasing way by noting
that the conclusion of \Rule{Susp-Ctx} $\C\where{\cmatch \t \cbrs}$ is
structurally larger than the negatively-occurring judgement $\cerase {\C\where{\cunif
\tv \gt}}$: the former contains at least one suspended match constraint yet to be
discharged, whereas the latter contains no unresolved match constraints.
We formalize this decreasing measure in \Cref{appendix:wf}. This ensures that
the semantics is well-defined, even if not syntactically inductive.

\begin{restatable}{theorem}{satwf}
  The relation $\semenv \th \c$ is well-founded.
\end{restatable}


\paragraph{Summary}

To recap, suspended constraints provide a principled mechanism
for deferring constraint resolution until the structure of a type
is known---at which point a matching branch is selected, if one exists.
%
We formalize the notion of structure using \emph{shapes}, eqiupped with a
notion of principality that captures the most general decomposition of a
type.

Suspended constraints prove particularly useful in typing several
fragile \ML extensions:
\begin{enumerate*}
  \item semi-explicit first-class polymorphism,
  \item static overloading of record fields and datatype constructors, and
  \item structural tuple projections from \SML.
\end{enumerate*}

Their semantics are govered by three rules:
\begin{enumerate*}
  \item If the shape of the matchee is statically known, we use it
    directly via \Rule{Susp-Use};
  \item If not, we may guess the shape--but only when the context ensures
    the shape is unique, via the $\Cshape \C \tv \sh$ condition and apply
    \Rule{Susp-Ctx};
  \item If the shape cannot be uniquely inferred from the context, the constraint
    is unsatisfiable.
\end{enumerate*}

These rules, together with the base rules from
\cref{fig:constraint-semantics}, define the full semantics. For convenience,
we collect all the rules pertaining to the satisfiability judgement in
\cref{fig:contextual-semantics}.

\begin{mathparfig}[t]
  {fig:contextual-semantics}
  {Semantics of constraints including suspended constraints}
  \infer[True]
    { }
    {\semenv \th \ctrue}

  \infer[Conj]
    {\semenv \th \cone \\
     \semenv \th \ctwo}
    {\semenv \th \cone \cand \ctwo}

  \infer[Exists]
    {\semenv\where{\tv \is \gt} \th \c}
    {\semenv \th \cexists \tv \c}

  \infer[Forall]
    {\forall \gt, ~ \semenv\where{\tv \is \gt} \th \c}
    {\semenv \th \tfor \tv \c}

  \infer[Unif]
    {\semenv(\tone) = \semenv(\ttwo)}
    {\semenv \th \cunif \tone \ttwo}

  \infer[Let]
    {\semenv \th \exists \tv. \cone \\
     \semenv\where{\x \is \semenv(\cabs \tv \cone)} \th \ctwo}
    {\semenv \th \clet \x \tv \cone \ctwo}

  \infer[App]
    {\semenv(\t) \in \semenv(\x)}
    {\semenv \th \capp \x \t}

  \infer[Susp-Ctx]
    {\Cshape \C \t \sh \\
      \semenv \th \C\where{\cmatched \t \sh \cbrs}
    }
    {\semenv \th \C\where{\cmatch \t \cbrs}}
\\
\semenv(\cabs \tv \c) \Wide\eqdef \
  \set {\gt \in \Ground : \semenv\where{\tv \is \gt} \th \c}
\\
\Cshape \C \t \sh \Wide\eqdef \
  \forall \semenv, \gt. \uad
      \semenv \th \cerase {\C\where{\cunif \t \gt}} \implies \shape \gt = \sh
\end{mathparfig}

\section{The \OML calculus}
\label{sec:language}

\parcomment {Running example: tuple projection disambiguation}

\parcomment {We need a spec, but this itself is hard}

In order to show our approach is sound and complete with respect to our
constraint generation translation, we must first define a formal
specification in the form of a calculus and accompanying type
system. Surprisngly, identifying an appropriate declarative type system to
use as a specification is itself an interesting problem!

\parcomment {Why do naive approaches not guarantee principal types.}

Na\"ive specifications, though accessible, often lack principal types. Take
overloaded tuple projects \textit{\`a la \SML}: an expression $\efield e j$
governed by the rule:
\begin{mathpar}
  \infer
    {\G \th \e : \Pi\iton \ti \and 1 \leq j \leq n}
    {\G \th \efield \e j : \tj}
\end{mathpar}
admits many typings, as any tuple of at least size $j$ satisfies the
premise. This multiplicity undermines principality.

\parcomment {Partial annotations (shapes) to the rescue!}

Our first insight is that partial type annotations often suffices to
recover principality. For
example, explicitly annotating the tuple projection with its arity, as in
$\exfield \e n j$, disambiguates the expression:
\begin{mathpar}
   \inferrule*
      {\G \th \e : \Pi\iton \ti \\ 1 \leq j \leq n }
      {\G \th \exfield \e n j : \tj}
\end{mathpar}
Yet, requiring users to write such annotations manually is impractical.

\parcomment {Inference of shapes}

Our solution is to permit \textit{inference} of such information, provided
that the inferred annotation is \textit{uniquely determined by context}.  This
approach ensures principality by construction and yields a clear specification
with predictable annotability requirements for the everyday programmer.

\parcomment {How do we specify our intuition?}

Specifying the notion of unique inferrability from context is
tricky. Luckily, we can leverage many of the formal methods developed in the
previous section---in particular, the manipulation of contexts within the
derivation---to prove uniqueness of these partial annotations. Allowing us to
systematically replace the ambiguous constructs with their disambiguated
counterparts:
\begin{mathpar}
  \inferrule*
    {\eshape \E e {\any \tvcs \Pi\iton \tvcs} \\ \G \th E[\exfield \e n j] : \t}
    {\G \th \E[\efield \e j] : \t}
\end{mathpar}
The intuition here is that the context $E$ is sufficiently large to
constrain the shape of $e$'s type as a tuple of size $n$.

\parcomment {Limitations}

The chief limitation of our approach is that disambiguation can still
require explicit annotations in inherently ambiguous scenarios.  This is
fine. Another option would be the use of sensible ``defaults'', such as
resolving $\efield e j$ by assuming the tuple has arity $j$. While
appealing, such defaults compromise principality. We return to this
pragmatic tradeoff in \cref{sec:implementation}.

\subsection{Syntax}

\begin{bnffig}{fig/syntax}{Syntax of \OML}
\entry[Terms]{\e}{
  x \and
  () \and
  \efun x e \and
  \eapp \eone \etwo \and
  \elet x \eone \etwo \and
  \eannot \e \tvs \t \andcr
  \erecord {\overline{\el = \e} } \and
  \efield e \el \andcr
   (\eone, \ldots, \en) \and
   \efield e j \and
   \exfield e n j \andcr
   \epoly e \and
   \epoly[\exi \tvs \ts] e  \and
   \einst e \and
   \exinst e \tvs \ts
}\\
\entry[Labels]{l}{
  \elab \and \elab / \T
}\\[1ex]
\entry[Types]{\t}{
   \tv \and
   1 \and
   \tya \to \tyb \and
   \tys \T \and
   \Pi \iton \ti \and
   \tpoly \ts
}\\
\entry[Type schemes]{\ts}{
     \t \and
     \tfor \tv \ts
}\\
\entry[Contexts]{\G}{
   \eset \and
   \G, x : \ts
}\\
\end{bnffig}


In \cref {fig/syntax}, we give the grammar for our calculus. Terms include
all of the \ML calculus: variables $x$, the unit literal $\eunit$,
lambda-abstractions $\efun x e$, applications $\eapp \eone \etwo$,
annotations $\eannot \e \tvs \t$ and let-bindings $\elet x \eone \etwo$.
Our extensions include:
\begin{enumerate}
\item
  Constructor and record label disambiguation, modelled using record
  literals $\erecord { \ela = \eone; \ldots; \el_n = \en }$ and field
  projections $\efield e l$.

\item
  Tuples $(\eone, \ldots, \en)$ with overloaded tuple projections
  $\efield e j$.

\item
  For semi-explicit first-class polymorphism, we have the explicit and
    implicit boxing constructs
    $\expoly \e {\exi \tvs \ts}$, $\epoly \e$  and the unboxing construct $\einst e$.

\end{enumerate}
Each construct that endangers principality (written $\e^i$ or $\el^i$) has an
explicitly annotated counterpart (written $\e^x$ or $\el^x$) that is
$\eproj [n] \e j$, $\epoly [\exi \tvs \ts]
\e$, $\einst [\exi \tvs \ts] \e$, or $\elab / \T$ for record labels.


\Xalistair{We're now duplicating a bit of \cref{sec:constraints}.
I propose we cut this here. }
As usual, types are split into monotypes (or just types) and type schemes.
Types $\t$ include the variables $\tv$, the unit type $1$, function types
$\tone \to \ttwo$, $n$-ary product types $\Pi \iton \ti$ and nominal
record types $\tys \T$. Type schemes $\sigma$ extend monotypes allowing the
universal quantification of zero or more type variables $\all \tvs \t$. We
also have polytypes \textit{without the annotations} $[\ts]$ as monotypes.

Typing contexts $\Gamma$ are an ordered sequence of expression variable
typings $x : \sigma$.

\Xalistair{If we do end up cutting the above, where should we put?}
The structure of principal shapes $\sh$ induced by syntax of types given here
is a shape $\any \tvcs \t$ where
\begin{itemize}

\item $\tvcs$ are the linear free variables of $\t$ \ie each type variable
  $\tvc$ in $\tvcs$ occurs exactly once in $\t$

\item
  $\t$ is shallow, which means the following:
\begin{itemize}

\item
  when $\t$ is not a polytype, all subterms of $\t$ are variables \ie $\tvca
    \to \tvcb$, $\Pi\iton \tvci$, or $\tvcs \T$

\item
  when $\t$ is a polytype $\tpoly {\all \tvs \tsp}$, then all subterms of
  $\tsp$ that do not lead to a polymorphic variable $\tv$ in $\tvs$
  are a variable in $\tvcs$.

\end{itemize}
\end{itemize}


\subsection{Typing rules}
\label{sec/language/typing-rules}

As usual, the main typing judgment $\G \th \e : \ts$ states that in context
$\G$, expression $\e$ has type scheme $\ts$.  Typing rules are given on \cref
{fig/typing}.  They use auxiliary typing judgemnents $\G \th \elab = \e : \t$
and $\G \th \el : \t \to \tp$ for the typing of record assignments and
label instantiations respectively.

\begin{mathparfig}{fig/typing}{Typing rules of \OML}
  \inferrule[Var]
    {x : \sigma \in \G}
    {\G \th x : \sigma}

  \inferrule[Fun]
    {\G, x : \tone \th e : \ttwo }
    {\G \th \efun x e : \tone \to \ttwo}

  \inferrule[App]
    {\G \th \eone : \tone \to \ttwo \\
     \G \th \etwo : \tone}
    {\G \th \eapp \eone \etwo : \ttwo}

  \inferrule[Unit]
    {}
    {\G \th () : 1}

  \inferrule[Annot]
    {\G \th e : \t\where {\tvs \is \tys}}
    {\G \th (e : \exi \tvs \t) : \t\where {\tvs \is \tys}}

  \inferrule[Gen]
    {\G \th e : \sigma \\ \tv \disjoint \G}
    {\G \th e : \tfor \tv \sigma}

  \inferrule[Inst]
    {\G \th e : \tfor \tv \ts}
    {\G \th e : \tv \where{\tv \is \t}}

  \inferrule[Let]
    {\G \th \eone : \sigma \\
     \G, x : \sigma \th \etwo : \t}
    {\G \th \elet x \eone \etwo : \t}

  \inferrule[Tuple]
    {\parens{\G \th \ei : \ti}\iton}
    {\G \th (\eone, \ldots, \en) : \Pi\iton \ti}

  \inferrule[Proj-X]
    {\G \th \e : \Pi\iton \ti \\
     1 \leq j \leq n}
    {\G \th \exfield \e n j : \tj}

  \inferrule[Proj-I]
    {\eshape E e {\any \tvcs \Pi\iton \tvcs} \\
     \G \th E[\exfield e n j] : \t}
    {\G \th E[\efield e j] : \t}

  \inferrule [Poly-X]
    {\G \th \e : \ts\where {\tvs \is \tys}}
    {\G \th \epoly[\exi \tvs \ts] \e : \tpoly {\ts \where {\tvs \is \tys}}}

  \inferrule [Poly-I]
    {\Eshape \E \e {{\any \tvcs \tpoly \ts}} \\
     \G \th \E [\epoly[\exi \tvcs \ts] \e] : \t}
    {\G \th \E [\epoly \e] : \t}

  \inferrule [Use-X]
    {\G \th \e : \tpoly \ts \where {\tvs \is \tys}}
    {\G \th \exinst e \tvs \ts : \ts \where {\tvs \is \tys}}

  \inferrule [Use-I]
    {\eshape E  \e {\any \tvcs \tpoly \ts} \\
     \G \th E[\exinst e \tvcs \ts] : \t}
    {\G \th E[\einst e] : \t}

  \inferrule[Rcd-Assn]
    {\G \th \e : \t \\
     \G \th \el : \t \to \tp}
    {\G \th \el = \e : \tp}

  \inferrule[Rcd]
    {\parens{\G \th \eli = \ei : \t}\iton \\
     \G \th \bar \el \uni \t}
    {\G \th \erecord {\ela = \eone; \ldots; \el_n = \en} : \t}

  \inferrule[Rcd-Proj]
    {\G \th \e : \tp \\
     \G \th \el : \t \to \tp \\
     \G \th \el \uni \t }
    {\G \th \efield \e \el : \t}

  \inferrule[Lab-X]
    {\Omega(\elab / \T) = \tfor \tvs \t \to \tvs \T }
    {\G \th \elab / \T : \tys\where{\tvs \is \tys} \to \tys \T}

  \inferrule[Lab-I]
    {\Lshape \Lab \elab \T \\
      \G \th \Lab[\elab / \T] : \t}
    {\G \th \Lab[\elab] : \t}

  \inferrule[Lab-!]
    {\bar \el \uni \T \in \labenv}
    {\G \th \bar \el \uni \tys \T}

  \inferrule[Lab-?]
    {\G \th \t}
    {\G \th \bar \el \uni \t}
\end{mathparfig}

\begin{version}{}
\begin{bnffig}{fig/types/bnf}{aaa}
\entry[Types]{\t}{
    \tv \and
    \tunit \and
    \t \to \t \and
    \Pi \parens \t\iton \and
    \tys \T \and
    \tpoly \ts
}
\end{bnffig}

\begin{mathparfig}
  {fig/types/wf}
  {Well-formedness of types}
  \inferrule[Var-Wf]
    {\tv \in \G}
    {\G \th \tv}

  \inferrule[Unit-Wf]
    {}
    {\G \th \tunit}

  \inferrule[Arr-Wf]
    {\G \th \t \\ \G \th \tp}
    {\G \th \t \to \tp}

  \inferrule[Prod-Wf]
    {(\G \th \ti)\iton}
    {\G \th \Pi\iton \ti}

  \inferrule[Rcd-Wf]
    {(\G \th \ti)\iton \\
     \T \in \dom \Omega}
    {\G \th \tys \T}

  \inferrule[Poly-Wf]
    {\G \th \ts}
    {\G \th \tpoly \ts}

  \inferrule[Forall-Wf]
    {\G, \tv \th \ts}
    {\G \th \tfor \tv \ts}
\end{mathparfig}
\end{version}


\parcomment {Simple typing rules explained}

Rule \Rule{Var} retrieves the type scheme $\x : \ts$ from the context $\G$.
Function types are introduced via lambda abstractions: in Rule \Rule{Fun}, the
system guesses a well-formed type $\tone$ for the type of $x$, typechecks the
body $e$ is under the extended context $\G, \x : \tya$ producing the return
type $\tyb$, and assigns the abstraction the function type $\tya \to \tyb$.
Conversely, function types are eliminated by applications; in Rule \Rule{App},
the type of the argument must match the function's parameter type $\tya$ and
application returns the type $\tyb$. Rule \Rule{Unit} asserts that $\eunit$ has
the unit type $\tunit$.

\parcomment {Gen/Inst explained}

Rules \Rule{Gen} and \Rule{Inst} correspond to implicit
\textit{generalization} and \textit{instantiation} respectively.
Generalization universally quantifies a type variable $\tv$, introducing it
as a fresh polymorphic variable in the typing context. In \Rule{Inst}, we
specialize a type scheme $\tfor \tv \ts$ to $\ts \where{\tv \is \t}$,
substituting $\tv$ for an arbitrary monotype $\t$.

\parcomment {Let rule}

Let-polymorphism is handled by the \Rule{Let} rule, where a
\textit{polymorphic} term can be bound. This allows a single definition to be
instantiated differently at each use site---an essential feature of \ML. In
this rule, the term $\eone$ has a polymorphic type scheme $\ts$, adds $\x :
\ts$ into the context $\G$ to typecheck $\etwo$.

\parcomment {Annotations}

Annotations $(e : \exi \tvs \t)$ ensures that the type of $e$ is (an instance
of) the type $\t$. The type variables $\tvs$ are \emph{flexibly} (or
existentially) bound in $\t$, meaning that $\tvs$ may be unified with some
types $\tys$ to produce a well-typed term. For instance, the term $(\efun x x
+ 1 : \exi \tv \tv \to \tv)$ is well-typed with $\tv := \tint$ in
\Rule{Annot}.

\parcomment {Contextual rules (Poly-*, Use-*, Proj-*)}

\paragraph{Polytypes and overloaded tuples}
The typing rules for fully annotated terms ($\e^x$) are unsurprising.
However, typing rules for terms with omitted type annotations are
non-compositional as they depend on a surrounding one-hole context
$\E$. Hence, they assert that the typability of the expression $\G \th \E
\where {\e^i}: \t$ where $\e^i$ is an expression with an implicit type
annotation.
%
We first request a typing for the expression with an explicit annotation $\G
\th \E \where {\e^x}: \t$ where $\e^x$ is a fully annotated variant of $\e^i$.
We then request that (the shape of) the annotation is fully determined from
context, either from the type of the expression, which we write $\eshape \E
\e \sh$, or from the type of the hole, which we write $\Eshape \E \e \sh$.

In order to describe the judgments $\eshape \E \e \sh$ and
$\Eshape \E \e \sh$, we introduce a cast operation $\ecast \e \t \tp$
that allows an expression $\e$ of type $\t$ to be seen with type $\tp$.
That is the typing rule for casts is:
\begin{mathpar}
  \inferrule[Cast]
    {\G \th e : \t}
    {\G \th \ecast e \t \tp : \tp}
\end{mathpar}
Casts expressions are not allowed on source terms and are just a device for
the definition of unavoidable shapes.  Finally, we define what it means for a
shape to be determined from the type of a context or an expression:
\begin{mathpar}
\def \Eqdef {&\eqdef&}
{\begin{tabular}{RCL}
\eshape E \e \sh \Eqdef
  \forall \G, \t, \gt, \gtp, \uad
  \G \th \E \where {\ecast \e \gt \gtp} : \t
      \wide\implies \shape \gt = \sh
\\[1ex]
\Eshape E \e \sh \Eqdef
  \forall \G, \t, \gt, \gtp, \uad
      \G \th \E\where{\ecast \e \gt \gtp} : \t
      \wide\implies \shape \gtp = \sh
\end{tabular}}
\end{mathpar}
These states that the shape $\sh$ of expression $\e$ in context $\E$ is
determined by the expression $\e$, in the former case, or by the context
$\E$ in the latter case.

%% Shapes are equal modulo alpha equivalence and the removal of useless
%% polymorphic type variables. They do not have useless existential variables.

% Expression-based implicit rules

The implicit rule \Rule{Proj-I} types the projection $\eproj \e j$ provided the
context $\E$ \emph{infers} that the shape of $\e$ must be a tuple with arity $n$.
Similarly, \Rule{Use-I} permits instantiating a polytype in $\einst e$ if
the context $\E$ infers that the type of $\e$ must be a polytype with shape
$\any \tvcs \tpoly \ts$. The rule \Rule{Poly-I} types the implicit boxing
construct $\epoly \e$ by \emph{checking} the expected type of $\epoly \e$ in the
context $\E$ is a polytype with the shape $\any \tvcs \tpoly \ts$. This rule
differs from the previous two as the shape is determined by the expected type
within the context as opposed to the inferred type of $\e$.


% Labels

\paragraph{Overloaded record labels}
% Contextual rules
We adopt a similar non-compositional approach for elaborating overloaded
labels, whether in record projection ($\efield e \elab$) or record
construction ($\erecord {\overline{\elab = \e}}$), although the definitions
are slighly more involved.  Here, a one-hole label context $\Lab$ provides the
surrounding context in which a label $\elab$ may appear:
\begin{mathpar}
\begin{bnfgrammar}
\entry [Label contexts]{\Lab}{
    \E \where {\e.\square} \and
    \E \where
         {\erecord
            {\ela = \eone; \ldots; \square = \ei ; \ldots; \el_n = \en}
         }
}
\end{bnfgrammar}
\end{mathpar}

As with our contextual rules for expressions, we define two rules for labels.
\Rule{Lab-X} handles explicitly annotated labels $\elab / \T$ by instantiating
the type scheme $\tfor \tvs \t \to \tvs \T$ associated with $\elab$ in label
environment $\labenv$. \Rule{Lab-I} handles unannotated labels by elaborating
$\elab$ to $\elab / \T$ if the context $\Lab$ uniquely infers the record type
$\T$ for $\elab$ and the resulting elaboration is well-typed.

The unicity of the inferred record type is captured by the judgement
$\Lshape \Lab \elab \T$. The definition fits into the framework we established
for expressions above by introducing a label cast operator $\elcast \elab \t$,
analogous to the cast operator for expressions, which asserts that the
label is instantiated to the type $\tp \to \t$ for any $\tp$.
\begin{mathpar}
  \infer[Lab-Cast]
    {}
    {\G \th \elcast \elab \t : \tp \to \t}
\\
\Eshape \Lab \elab \T \Wide\eqdef
   \forall \G, \t, \gt , \uad
     \G \th \Lab[\elcast \elab \gt] : \t
	\implies \shape \gt= \any \tvcs \tvcs \T
\end{mathpar}

% Rules
\Rule{Rcd} types a record $\erecord {\overline{\el = \e}}$ as a record type
$\t$ provided that each field assignment $\el = \e$ can be assigned the record
type $\t$.
\Rule{Rcd-Assn} checks that $\e$ has the appropriate field type in $\el = \e$
and returns the instantiated record type $\tp$ for the label $\el$.
\Rule{Rcd-Proj} types the projection $\efield \e \el$ by checking that the
type of $\e$ matches the record type associated with label $\el$, returning
the field type $\t$.

% Closed world reasoning
Both \Rule{Rcd} and \Rule{Rcd-Proj} impose additional constraints on their
record types to support \emph{closed-world} reasoning. These constraints
exploit the uniqueness of type definitions in the global label environment
$\labenv$ to resolve overloaded labels:
\begin{enumerate*}
\item
  in a record projection $\efield \e \elab$, if the label $\elab$ is not
  overloaded, then the global record typing context $\labenv$ assigns a
  unqiue record type $\T$ to $\elab$;

\item
  in a record expression $\erecord {\ela = \eone; \ldots; \el_n =
  \en}$, if the set of labels ${ \ela, \ldots, \el_n }$ uniquely
  identifies a record type $\T$ in the typing context $\labenv$, then
  we can assign this type to the record expression.
\end{enumerate*}

We formalize this with the judgement $\G \th \bar \el \uni \t$, which
either:
\begin{enumerate*}
  \item enforces $\t$ to be of the form $\tys \T$ if the labels $\bar \el$
    uniquely identify a nominal record type $\T$ in $\labenv$ (\Rule{Lab-!}),
    or
  \item imposes no constraint on $\t$ in the ambiguous case
    (\Rule{Lab-?}).
\end{enumerate*}

Label declarations in $\labenv$ have the form $\elab : \tfor \tvs \tp \to \tvs
\T$, assigning labels to field types and record types\footnote{For a given
record type $\T$, we assume each label associated with it is unique.}. We
write $\elab / \T \in \labenv$ if such a declaration of $\elab$ exists for the
record type $\T$. This membership relation extends to explicitly annotated and
casted labels:
\begin{mathpar}
  \infer[Lab-$\in$X]
    {\elab / \T \in \labenv}
    {(\elab / \T) / \T \in \labenv}

  \infer[Lab-$\in$Cast]
    {\elab / \T \in \labenv}
    {\elcast \elab \t / \T \in \labenv}
\end{mathpar}
We then define the uniqueness predicate $\bar \el \uni \T \in \labenv$ as:
\begin{mathpar}
  \infer[Lab-U]
    {\bar \el / \T \in \labenv \\
     \all {\T'} \uad\bar \el / \T' \in \labenv \implies \T = ~\T'}
    {\bar \el \uni \T \in \labenv}
\end{mathpar}
This states that the set of labels $\bar \el$ determines a unique nominal type
$\T$ in $\labenv$ if no other type $\T'$ can be associated with the same label
set.

\subsection {Examples of typings}

The following lemma shows that we can always take a larger context
$\E$ or $\Lab$ for implicit rules \Rule {Proj-I}, \Rule {Use-I}, \Rule {Poly-I}
and \Rule{Lab-I}.
That is, there is always a derivation using only toplevel contexts.
\begin{lemma}
\label{lem/context/largest}
\newcommand {\Eab}{\parens{\Ea\where \Eb}}
Assume $\eshape \Eb \e \sh$ and $\G \th \Ea \Where {\Ga \th \Eb \where
{\e^x} : \tya} \t$, then $\eshape \Eab \e \sh$ and $\G \th \Eab\where {\e^i}
: \t$.  Similarly, for label contexts, assuming $\Lshape \Lab \elab \T$ and
$\G \th \E [\Ga \th \Lab[\elab] : \tya] : \t$, then $\Lshape {(\E[\Lab])}
\elab \T$ and $\G \th (\E[\Lab])[\elab] : \tau$.
\end{lemma}
\begin{proof}[Proof Sketch]
Formally, can be proved by induction on $\Ea$ and $\E$, respectively.
\end{proof}

% Examples
We now illustrate the typing of implicit constructs with a few examples.
\begin{example}
To illustrate a simple case of non-typability, we show that the expression $e$
equal to $\efun \x {\eproj \x k}$ is ambiguous, \ie that it does not
typecheck.
%
%% Let $e_n$ be the explicitly annotated version $\efun r
%% {\eproj[n] \x i}$. for $n \le k$.
If there is a derivation of $\efun \x
{\eproj \x k}$ then there must be one of the form:
\begin{mathpar}
\infer*[Right=Proj-I]{
                  \eshape \E \x {\any \tvcs \Pi\iton \tvcs} \\
                \eset \th \E \where {\eproj[n] \x k} : \t
}{%             -------------------------------------------
                  \eset \th \E \where {\eproj \x k} : \t
}
\end{mathpar}
where $E$ is the term $\efun \x \ehole$, which is the largest possible
context, thanks to~\cref {lem/context/largest}.
%
Let $\t$ be $\Pi\iton \ti \to \t_k$ for some $n \geq k$.  We have the
following derivation:
\begin{mathpar}
\infer* [Right=Fun]{
          \infer*[Right=Proj-X]
                {\x : \Pi\iton \ti \th \x : \Pi\iton \ti}
                {\x : \Pi\iton \ti \th \eproj[n] \x k : \t_k}
}{%      ----------------------------------------------------------
         \eset \th \E \where{\eproj[n] \x k} : \t
}
\end{mathpar}
Unfortunately, $\eshape \E  \x {\any \tvcs \Pi\iton \tvcs}$ does not hold.
Indeed, we have $\eset \th \E \where {\ecast \x {\gt_n} {\gt_k}} : \t$
for any $\gt_n$ and $\gt_k$ assuming $\t$ is of the form $\gt_n \to \gt_k$.
Hence, $\any \tvcs \Pi\iton[n] \tvcs$ and $\any \tvcs \Pi\iton[n+1] \tvcs$
are two possible shapes for the type of $\x$.
\end{example}

\begin{example}
\locallabelreset
We now illustrate a non-ambiguous example, showing that the
expression $e$ equal to $\th \eapp {(\efun \x {\eproj
\x  k})} {(1, 2)} : \tint$.
%
Let $k$ and $n$ be $1$ and $2$, respectively.
%
Let $\E$ be the context $\th \eapp {(\efun \x \ehole)} {(1, 2)} : \tint$.  We
have the derivation:
\begin{mathpar}
\infer* [Right=Proj-I]{
                \eshape \E \x {\any \tvcs \Pi\iton \tvcs} \\
                \eset \th \E \where {\eproj[n] \x k} : \tint
}{%             -------------------------------------------
                  \eset \th \E \where {\eproj \x k} : \tint
}
\end{mathpar}
We have $\eset \th \E \where {\eproj[n] \x k} : \tint$, indeed. Therefore, it
just remains to show $\eshape \E \x {\any \tvcs \Pi\iton \tvcs}$~\llabel C.
Assume $\eset \th \E \where{\ecast \x \gt \gtp} : \t$. Since $\x : \Pi\iton
(\tint, \tint)$ \Xalistair{Should we relax the notation here a a bit and use
$\tint \tprod \tint$ instead?} is bound in the context at the hole in $\E$,
  there is n other no choice but take $\gt$ equal to $\Pi\iton (\tint, \tint)$,
hence $\shape \gt = \any \tvcs \Pi\iton \tvcs$, which proves~\lref C.
\end{example}

The following example of non-typability illustrates how the typing rules
still forces to reject typing of some expressions whose elaboration would be
unambiguous. This is intended, to prevent us from having to focus at several
terms simultaneously. Our typing rules enforce the resolution of
shape inference, locally, one at a time.

\begin{example}
\newcommand{\tyid}{\ty_{\kwd{id}}}
  \newcommand{\eid}{\efun z z}
\newcommand {\epid}[1][]{\epoly[#1]{\eid}}
Let $\tyid$ be $\tpoly{\all \tv \tv \to \tv}$.
%
We show that the expression $e$ equal to $\elet \x {\epoly {\efun z z}}
{(\eapp {\einst \x} 1, \eapp {\einst \x} \eunit)}$ is rejected as ambiguous.
Let $\tyid$ be $\tpoly {\all \tv \tv \to \tv}$.  Clearly, we have $\elet \x
{\epoly [\tyid] {\efun z z}} {(\eapp {\einst[\tyid] \x} 1, \eapp
{\einst[\tyid] \x} \eunit)}$.  This is actually the only possible fully
annotated derivation.
%
To show that $e$ is typable, we must be able to make all annotations
optional, sequentially.  Therefore, the final step, which will eliminate the
last annotation has a single point of focus of the form $\E\where{e^i}$,
where $\e^i$ can be any of the three positions with a missing annotation.  We
consider each case independently, and show that it is actually not typable.
  \begin{itemize}
\proofcase
{$\E$ is $\elet \x \ehole (\eapp {\einst \x} 1, \eapp {\einst \x}\eunit)$}
%
If this holds, we should have a derivation that ends with
  \Xalistair{Should we add a $\any$-binder here? Or should we
  adopt the convention that if a shape has no variables, the binder
  is dropped.}
\begin{mathpar}
\infer*[Right=Poly-I]{
		  \Eshape \E \eid {\tpoly \tyid} \\
                  \eset \th \E \where {\epid [\tyid]}: \t
}{%               ---------------------------------------
                       \eset \th \E \where \epid : \t
}
\end{mathpar}
However, $\Eshape \E \eid {{\tpoly \tyid}}$ does not hold.
Indeed, the following judgment
$\eset \th \E \where {\ecast \eid \wild \tpoly \ts} : \t$ holds, where
$\ts$ is either $\tfor \tv \tv \to \tv$ or $\tfor \tv \tv \to
\tv\to\tv$. Hence, the shape of the type of $\eid$ is not uniquely
determined and this case cannot occur.

\proofcase
{$\E$ is
 $\elet \x \epid (\eapp {\einst \ehole} 1, \eapp {\einst \x} \eunit)$}
%
The derivation must end with:
\begin{mathpar}
\infer*[Right=Proj-X]{
		  \eshape \E \x {\tpoly \tyid} \\
                \eset \th \E \where {\einst[\tyid] \x} : \t
}{%             -------------------------------------------
                    \eset \th \E \where {\einst \x} : \t
}
\end{mathpar}
However, $\eshape \E \x \tyid$ does not hold (the proof is similar to the
previous case).

\proofcase {$\E$ is  $\elet \x \epoly {\efun z z} (\eapp {\einst \ehole} 1, \eapp
{\einst \x} \eunit)$} This is symmetric to the previous case, which cannot
hold either.
  \end{itemize}
\end{example}

\begin{example}
Let $\e$ be $\elet f {\efun \x {\eproj \x 1}} {\eapp f (1, 2)}$.
$\e$ is well-typed using \emph{backpropagation}.
$\e$ is of the form $\E \where {\x}$ where  $\E$ is the context $\elet f
{\efun \x \ehole} {\eapp f (1, 2)}$.
We have $\eset \th \E \where {\eproj[2] \x 1} : \tint$.
Let us show that $\eshape \E \x {\Pi\iton[2](\tint, \tint)}$.
%
Assume $\eset \th \E \where {\ecast \x \gt \gtp} : \t$. As $\gt$ is a ground
type, the type $\gt$ of $\x$ is not a variable.  Then, $\gt$ cannot be that
of an arbitrary sized tuple, since there is not such type for a tuple of
arbitrary size. Hence, $\gt$ must be a tuple $\Pi\iton \tys$ for some size
$n$. Since the codomain of $f$ must be a tuple of size~$2$ (for $\eapp f (1,
2)$ to be well-typed), then $n$ must also be $2$. This shows that $\eshape \E
\x {\any \tvcs \Pi\iton[2] \tvcs}$.
%% \begin{mathpar}
%%   \infer
%%     {
%%     \infer
%%       {
%% 	\infer
%% 	  {
%% 	    \infer
%% 	      {
%% 		\infer
%% 		  {}
%% 		  {\tva, \tvb, x : \tva \th x : \tva}}
%% 	      {\tva, \tvb, x : \tva \th \ecast x \tva \tvb : \tvb}}
%% 	  {\tva, \tvb \th \efun x {\ecast x \tva \tvb : \tva \to \tvb}}}
%%       {\emptyset \th \efun \x \ecast \x \tva \tvb : \tfor {\tva, \tvb} \tva \to \tvb} \\
%%     \infer
%%       {\ldots}
%%       {f : \tfor {\tva, \tvb} \tva \to \tvb \th \eapp f (1, 2) : \tunit}}
%%     {\emptyset \th \elet f {\efun \x {\ecast \x \tva \tvb}} {\eapp f (1, 2)} : \tunit}
%% \end{mathpar}
\end{example}


\subsection{Constraint generation}
\label{sec:constraint-gen}

% Intro
We now present the formal translation from terms $\e$ to constraints $\c$,
such that the resulting constraint is satisfiable if and only if the term is
well typed. The translation is defined as a function $\cinfer \e \t$, where $\e$
is the term to be translated and $\t$ is the expected type of $\e$.

% Explanation of expected type
The expected type $\t$ is permitted to contain type variables, which can be
existentially bound in order to perform type inference. The models of constraint
$\cinfer \e \t$ interpret the free variables of $\t$ such that
$\t$ becomes a valid type of $\e$. For example, to infer the entire type of $\e$
we may pick a fresh type variable $\tv$ for $\t$.
\paragraph{Pattern constraints}

Thus far, our formal presentation of constraint patterns has remained
abstract, deliberately leaving the syntax and semantics of patterns unspecified to
accommodate a range of language features. We now concretize this by specifying
the patterns used in \OML (See \cref{fig:patterns-oml}), and introducing the
corresponding constraints for the variables they bind.
%
Patterns include:
\begin{enumerate*}

  \item Tuple patterns $\cpatprod \tv j$, matching a tuple type $\Pi\iton
    \tys$ of arity $n \geq j$, and binding the $j$-th component to $\tv$.

  \item Nominal patterns $\cpatrcd \ct$, binding the name of a nominal type
    $\tys \Tapp$ to the nominal variable $\ct$.

  \item Polytype patterns $\cpatpoly \cscm$ matching a polytype $\tpoly \ts$ and
    binding the resulting scheme to the variable $\cscm$.

\end{enumerate*}

Each new constraint has an unsubstituted form ($\cscm \leq \t, \x \leq \cs,$
\etc), whose semantics is defined via substitution into a sugared form ($\ts
\leq \t, \x \leq \ts,$ \etc). Semantic environments $\semenv$ are extended to
interpret nominal variables $\ct$ as names $\T$ and scheme variables $\cscm$ as
ground type schemes $\gscm$, that is type schemes with no unbound variables
(\ie $\tfor {\fvs \t} \t$).

\begin{mathparfig}
  {fig:patterns-oml}
  {Patterns for \OML}
  \begin{bnfgrammar}
   \entry[Patterns]{\cpat}{
      \cpatprod \tv j
      \and \cpatrcd \ct
      \and \cpatpoly \cscm
    } \\
    \entry[Constraints]{\c}{
      \dots
      \and \labenv(\elab/\ct) \leq \tone \to \ttwo
      \and \labenv(\elab/\T) \leq \tone \to \ttwo
      \andcr \cscm \leq \t
      \and \ts \leq \t
      \andcr \x \leq \cscm
      \and \x \leq \ts
    } \\
    \entry[Semantic environments]{\semenv}{
      \dots
      \and \semenv, \ct := ~\T
      \and \semenv, \cscm := \gscm
    }
  \end{bnfgrammar}
  \\
  \newcommand{\Mrule}[4][]{{#2} \Matches {#3} &\eqdef& {#4} & #1}
  \begin{tabular}{RCLL}
    \Mrule[\text{if } n \geq j]
      {\cpatprod \tv j}
      {\shapp[\any \tvcs \Pi\iton \tvcs] \tys}
      {[\tv \is \ty_j]}
    \\[1ex]
    \Mrule
      {\cpatrcd \ct}
      {\shapp[\any \tvcs \tvcs \Tapp] \tys}
      {[\ct \is ~ \T]}
    \\[1ex]
    \Mrule
      {\cpatpoly \cscm}
      {\shapp[\any \tvcs \tpoly \ts] \tys}
      {[\cscm \is \ts \where{\tvcs \is \tys}]}
  \end{tabular}
  \\
  \inferrule[Lab-Inst]
    {\semenv \th \labenv(\elab/\semenv(\ct)) \leq \tone \to \ttwo}
    {\semenv \th \labenv(\elab/\ct) \leq \tone \to \ttwo}

  \inferrule[Scm-Inst]
    {\semenv \th \semenv(\cscm) \leq \t}
    {\semenv \th \cscm \leq \t}

  \inferrule[Abs-Inst]
    {\semenv \th \x \leq \semenv(\cscm)}
    {\semenv \th \x \leq \cscm}
  \\
  \newcommand{\Srule}[3][]{{#2} &\eqdef& {#3} & {#1}}
  \begin{tabular}{RCLL}
    \Srule[\text{if } \labenv(\elab/\T) = \tfor \tvs \t \to \tvs \Tapp]
      {\labenv(\elab/\T) \leq \tone \to \ttwo}
      {\cexists \tvs \cunif \tone \t \cand \cunif \ttwo {\tvs \Tapp}}
    \\[1ex]
    \Srule
      {(\tfor \tvs \tp) \leq \t}
      {\cexists \tvs \cunif \tp \t}
    \\[1ex]
    \Srule
      {\x \leq (\tfor \tvs \t)}
      {\cfor \tvs \capp \x \t}
  \end{tabular}

\end{mathparfig}


% Explanation of constraint gen cases
% Simple constraint gen

\paragraph{Constraint generation}

\begin{mathparfig}
  {fig:constraint-gen}
  {The constraint generation translation for \OML}
\newcommand {\Crule}[2]{#1 &\eqdef& #2}
\def \arraystretch{1.2}%4
\begin{tabular}{LCL}
\Crule
   {\cinfer x \t}
   {\cinst x \t}
\\
\Crule
  {\cinfer {()} \t}
  {\cunif \t \tunit}
\\
\Crule
  {\cinfer {\efun \x \e} \t}
  {\cexists {\tva, \tvb} \cunif \t {\tva \to \tvb}
    \cand \clet \x \tvc {\cunif \tvc \tva} {\cinfer \e \tvb}}
\\
\Crule
  {\cinfer {\eapp \eone \etwo} \t}
  {\cexists {\tva} \cinfer \eone {\tva \to \t} \cand \cinfer \etwo \tva}
\\
\Crule
  {\cinfer {\elet \x \eone \etwo} \t}
  {\clet \x \tva {\cinfer \eone \tva} {\cinfer \etwo \t}}
\\
\Crule
  {\cinfer {\eannot \e \tvs \tp} \t}
  {\cexists \tvs \cunif \t \tp \cand \cinfer \e \tp}
\\
\Crule
  {\cinfer {\etuple {\eone, \ldots, \en}} \t}
  {\cexists \tvs \cunif \t {\Pi\iton \tvs}
    \cand \cAnd \iton \cinfer \ei {\tv_i}}
\\
\Crule
  {\cinfer {\exfield \e j n} \t}
  {\cexists {\tvbs}
    \cinfer \e {\Pi\iton \tvbs}
    \cand \cunif \t {\tvb_j}}
\\
\Crule
  {\cinfer {\efield \e j} \t}
  {\cexists \tv \cinfer \e \tv
    \cand \cmatch \tv {\cbranch {\cpatprod \tvb j} {\cunif \t \tvb}}}
\\
\Crule
  {\cinfer {\expoly \e {\exi \tvs \ts}} \t}
  {\cexists {\tvs}
    \cinfer \e \ts
    \cand \cunif \t {\tpoly \ts}}
\\
\Crule
  {\cinfer {\exinst \e \tvs \ts} \t}
  {\cexists {\tvs}
    \cinfer \e {\tpoly \ts}
    \cand \ts \leq \t}
\\
\Crule
  {\cinfer {\einst \e} \t}
  {\cexists \tva
    \cinfer \e \tva
    \cand \cmatch \tva {\cbranch {\cpatpoly \cscm} \cs \leq \t}}
\\
\Crule
  {\cinfer {\epoly \e} \t}
  {\clet \x \tv {\cinfer \e \tv}
    {\cmatch \t {\cbranch {\cpatpoly \cscm} {\x \leq \cs}}}}
\\
\Crule
  {\cinfer {\efield \e \el} \t}
  {\cexists \tv \cinfer \e \tv
    \cand \cinferlabuni \el \tv
    \cand \cinferlab \elab \t \tv}
\\
\Crule
  {\cinfer {\erecord {\overline{\el = \e}}} \t}
  {\cinferlabuni {\bar \el} \t
    \cand \cAnd \iton \cinferassn \eli \ei \t}
\\
\Crule
  {\cinfer {(\ecast \e \tone \ttwo)} \t}
  {\cexists \tv \cinfer \e \tv \cand \cunif \tv \tone \cand \cunif \t \ttwo}
\\
\Crule
  {\cinfer \e {\tfor \tvs \t}}
  {\cfor \tvs \cinfer \e \t}
\\ \\
\Crule
  {\cinferassn \el \e \t}
  {\cexists \tv \cinfer \e \tv
    \cand \cinferlab \el \tv \t}
\\
\Crule
  {\cinferlab \elab \tone \ttwo}
  {\cmatch \ttwo {\cbranch {\cpatrcd \ct} {\labenv(\elab/\ct) \leq \tone \to \ttwo}}}
\\
\Crule
  {\cinferlab {\elab/\T} \tone \ttwo}
  {\labenv(\elab/\T) \leq \tone \to \ttwo}
\\
\Crule
  {\cinferlab {\elcast \elab \t} \tone \ttwo}
  {\cunif \t \ttwo}
\\
\Crule
  {\cinferlabuni {\bar \el} \t}
  {\begin{cases}
    \cexists \tvs \cunif \t {\tvs \Tapp} &\text{if } \bar \el \uni \T \in \labenv \\
    \ctrue &\text{otherwise}
   \end{cases}}
\\ \\
\Crule
  {\csem {\enil \th \e : \t}}
  {\cinfer \e \t}
\\
\Crule
  {\csem {\tv, \G \th \e : \t}}
  {\call \tv {\csem {\G \th \e : \t}}}
\\
\Crule
  {\csem {x : \ts, \G \th \e : \t}}
  {\clet \x \tv {\ts \le \tv} {\csem {\G \th \e : \t}}}
\\
\end{tabular}
\end{mathparfig}


The function $\cinfer - {\mathop{=}}$ is defined in \cref{fig:constraint-gen}.
All generated type variables are fresh with respect to the expected type $\t$,
ensuring capture-avoidance.
%
Unsurprisingly, variables generate an instantiation constraint. Unit $()$
requires the type $\t$ to be $\tunit$. A function generates a constraint that
binds two fresh flexible type variables for the argument and return types.  We
use a $\Let$ constraint to bind the argument in the constraint generated for
the body of the function. The $\Let$ constraint is monomorphic since $\tvc$ is
fully constrained by type variables defined outside the abstraction's scope
and therefore cannot be generalized. Applications introduce a fresh flexible
type variable for the argument type and ensures $\t$ is the return type of the
function. Let-bindings generates a polymorphic let constraint; $\cabs \tv
{\cinfer \e \tv}$ is a principal constraint abstraction for $\e$: its intended
interpretation is the set of all types that $\e$ admits.

% New constraint gen cases
% Annotations, tuples
Annotations bind their flexible variables and enforce the equility of
the annotated type $\tp$ and the expected type $\t$. Tuples introduce
fresh variables for each component and unify their product with $\t$.
Explicit projections ensure $\e$ has a tuple type $\Pi\iton \tvbs$
and extract the $j$-th component $\tvb_j$, unifying it with $\t$.
Implicit projections defer this via a suspended match constraint, until
the shape of $\e$'s expected type is known to be a tuple, extracting the
$j$-th component with the pattern $\cpatprod \tvb j$,

% Polytypes
For polytypes, boxing asserts that $\e$ has the polymorphic type $\ts$ (using
universal quantification) and that the expected type is the polytype $\tpoly
\ts$. Unboxing suspends until the inferred type of $\e$ is known to be a
polytype, captured by the pattern $\cpatpoly \cscm$, at which point we require
$\t$ to be an instance of $\cscm$. Explicit unboxing is analogous, but uses an
explicit scheme $\ts$ and therefore does not require a suspended match
constraint. Implicit boxing infers the principal type for $\e$ using a $\Let$
constraint and suspends until the expected type of the entire term is known to
be a polytype, bound to $\cscm$. We then assert that the principal type of $\e$
is at least as general as $\cscm$, via the constraint $\x \leq \cs$.


% Records
Record projections generate a fresh variable for the nominal record type,
constraining $\e$ to this type, and use the auxiliary function $\cinferlab \el
\tone \ttwo$ to instantiate the label. The function $\cinferlabuni {\bar \el}
\t$ checks whether a label sequence $\bar \el$ uniquely determines a record
type, unifying $\t$ with $\tvs \Tapp$ if so, or leaving it unconstrained if
ambiguous. This function enables closed-world reasoning for both projections
and constructions, and corresponds to the judgement $\G \th \bar \el \uni \t$
judgement defined in \cref{sec/language/typing-rules}.

Record construction checks label uniqueness and generates a per-field
constraint $\eli = \ei$, introducing a fresh variable $\tv$ for each
field's type and ensuring that $\e$ has this type and the label $\el$
instantiates to $\tv \to \t$.

Label instantiation constraints $\cinferlab \elab \tone \ttwo$ suspend
until $\ttwo$ is known to be a record type; once resolved, the label type is
looked up in $\labenv$ and instantiated. Explicit instantiations bypass
suspension and directly instantiate the label's type.

% Other cases
The remaining (greyed) cases \TODO{Make the cases grey} correspond to internal
constructs used in \OML's typing rules and are included for completeness.

% Soundness/completeness of constraint gen

The translation is sound and complete with respect to the typing judgment.
That is to say, the term $e$ is typable with $\ts$ if and only if
$\cinfer \e \ts$ is satisfiable.
%
\begin{theorem}{(Constraint generation is sound and complete)}
$\G \th \e : \ts$ iff\/
$\th \csem {\G \th \e : \ts}$.
\end{theorem}

\subsection{Metatheory}
\label{sec:constraint-prop}


\paragraph{Stability by program transformations}

A well-known property of \ML is to admit principal types---and the design of
fragile \ML extensions is all about the preservation of principal types.
However, core \ML has several other key properties:
\SetLabelAlign{mydesc}{#1:\hfill}
\begin{description}[font=\it,align=mydesc,topsep=1ex,itemsep=1ex,leftmargin=0ex]
\newcommand {\eswap}{\mathprefix  {swap}}

\item [Compositionality]
  If $\G \th \E \where \e : \t$ then there exists $\Gp$ and $\tp$ such that
  $\Gp \th \e : \tp$ and for all term $\ep$ such that $\Gp \th \ep : \tp$,
  then $\G \th \E \where \ep : \t$.

\item [Factorization]
  If $\G \th \e \where {\x \is \ez} : \t$ and $\G \th \ez : \ts$ then
  $\G \th \elet \x \ez \e : \t$.

%% \item [Inlining]
%%   If $\G \th \elet \x \ez \e : \t$ then $\G \th \e \where {\x \is \ez} : \t$

\item [Application equitypability]
  The expressions $\eappp f \ea \eb$ and $\eappp {\eswap f} \eb \ea$ are
  equitypable where $\eswap$ is $\efun f {\efun \xa {\efun \xb {\eappp f \xb
  \ea}}}$.  Thanks to a few other properties, this implies in turn that
  $\eapp f \ea$ and $\eApp f \ea$ and $\eb \ePipe \ea$ are themselves
  equi-typable where are the application function $\efun f \efun \x \eapp f
  \x$ and the reverse application function $\efun \x \efun f \eapp f \x$,
  respectively.

\end{description}
It is well-known that bidirectional types inference breaks application
equi-typability. However, both \Geninst-directional and omnidirectional type
inference preserve it.

In core \ML, Factorization is a consequence of principal types and
compositionality.  It is definitely broken by overloading, since the inlined
version may has several overloading sites that may be resolved differently.
However, we may wonder about linear factorization, \ie when $\x$ occurs
exactly once in~$\e$.  This is again broken by bidirectional type inference,
but preserved by both \Geninst-directional and omnidirectional type inference,
although for different reasons: for \Geninst-directional type inference, it
follows from the limited use of contextual type information; for
omnidirectional type inference, it follows by backpropagation\Xdidier{I
think this is not the right term}.

\Xdidier {How formal should we be? Should we justify these claims?}

\section{Solving constraints}
\label{sec:solving}

% Intro
We now present a machine for solving constraints in our language. The solver
operates as a rewriting system on constraints $\c \csolve \cp$. Once no further
transitions are applicable, \ie $\c \cnsolve$, the constraint $\c$ is either in
solved form---from which we can read off a most general solution---or the
solver becomes stuck, indicating that $\c$ is unsatisfiable.

% Contexts
% Treatment of $alpha$-equivalence in contexts
% Membership of constraints

% Unification
\subsection{Unification}
%
Our constraints ultimately reduce to equations between types, which we solve
using first-order unification. Like our solver, we specify unification as a
non-deterministic rewriting relation between \emph{unification problems} $\upa
\unif \upb$.

\begin{bnffig}
  {fig:unification-syntax}
  {Syntax of unification problems. Constraints are also extended with the
  administrative multi-equation construct.}

  \entry[Unification problems]{\up}{
    \ctrue \and \cfalse \and \upa \cand \upb \and \cexists \tv \up \and \ueq
  } \\
  \entry[Multi-equations]{\ueq}{
    \eset \mid \cunif \t \ueq
  } \\
  \entry[Constraints]{\c}{
    \dots \and \ueq
  }
\end{bnffig}

% Multi-equations

Unification problems $\up$ are a restricted subset of constraints.
To enable an efficient presentation of unification, we adopt
\emph{multi-equations} \citep{Pottier-Remy/emlti}---a multi-set of types
considered equal. These generalize binary equalities and their semantic
interpretation is given by:
\begin{mathpar}
  \infer[Multi-Unif]
    {\all {\t \in \ueq}\, \semenv(\t) = \gt}
    {\semenv \vdash \ueq}
\end{mathpar}
That is, $\semenv$ satisfies $\ueq$ if all members of $\ueq$ are mapped to a
single ground type $\gt$ by $\semenv$. We consider multi-equations equal
modulo permutation of their members. \Xdidier{Then, we could also
identify $\t = \eset$ with $\t$.}

% The spec

The unification rules are listed in
\cref{fig:omni-unification-algorithm}. Rewriting proceeds modulo
$\alpha$-equivalence, as well as associativity and commutativity of
conjuctions, and takes place under an arbitrary unification problem context
$\Up$.
%
Our algorithm is largely standard \cite{Pottier-Remy/emlti} but replaces
type constructors with \emph{canonical principal shapes}, enabling a uniform
treatment of monotypes and polytypes within unification, \Xdidier[avoiding
the need for specialised ]{simplifying the} handling of polytypes, as found
in \citep{Garrigue-Remy/poly-ml}.
\Xdidier{Not quite: we still need to turn a type scheme into a polytype,
and require explicit polymorphism, which \ML does not need. }

\TODO{Example of unifying polytypes?}

% Explaination of rules

We briefly summarize the purpose of each rule below: Ruke \Rule{U-Exists}
lifts existential quantifiers to the top of the unification problem,
enabling applications of rules \Rule{U-Merge} and \Rule{U-Cycle} as all
multi-equations eventually part of a single conjunction. Rule \Rule{U-Merge}
combines mutli-equations sharing a common variable. Rule \Rule{U-Stutter}
remxoves duplicate occurrences of a variable. Rule \Rule{U-Decomp}
decomposes equal types with matching shapes into equalities between their
subcomponents. Rule \Rule{U-Clash} complements
Rule \Rule{U-Decomp}, handling shape mistmatches that result in failure.
Rule \Rule{U-Name} introduces a fresh variable to expose a subcomponent of a shape,
ensuring unification over \emph{shallow terms}, making sharing of type
variables explicit and avoids the need for copying types in rules such as
\Rule{U-Decomp}. Rules \Rule{U-True} and \Rule{U-Trivial} eliminate trivial
constraints. The latter occurs when a multi-equation $\ueq$ is trivial, that
is, when it is either empty ($\eset$) or contains only a single type ($\cunif
\t \eset$).


Rule \Rule{U-Cycle} implements the \emph{occurs check}, ensuring that a type
variable does not occur in the type it is being unified with. This is a
necessary condition for unification, as it would otherwise lead to infinite
types\footnote{We discuss relaxing this constraint in \cref{sec/rec-types}.}
is defined by the relation $\tv \prec_\up \tvb$ indicating that $\tv$ occurs
in a type assigned to $\tvb$ in $\up$. A unification problem is cyclic,
written $\cyclic \up$, if $\tv \prec_\up^* \tv$ for some $\tv$.

\begin{mathparfig}[t]
  {fig:omni-unification-algorithm}
  {Unification algorithm as a series of rewriting rules
   $\upa \unif \upb$. All shapes are principal.}
   \rewrite[U-Exists]
      {(\cexists \alpha \upa) \cand \upb \\ \tv \disjoint \upb}
      {\cexists \tv {\upa \cand \upb}}

    \rewrite[U-Cycle]
      {\up \\ \cyclic \up}
      {\cfalse}

    \rewrite[U-True]
      {\up \cand \ctrue}
      {\up}

    \rewrite[U-Merge]
      {\cunif \tv \ueqa \cand \cunif \tv \ueqb}
      {\cunif \tv {\cunif \ueqa \ueqb}}

    \rewrite[U-Stutter]
      {\cunif \tv {\cunif \tv \ueq}}
      {\cunif \tv \ueq}

    \rewrite[U-Name]
      {\cunif {\pshapp \tys[\ti]} \ueq \\ \tv \disjoint \tys, \ueq }
      {\cexists \tv {\cunif \tv \ti \cand \cunif {\pshapp \tys[\tv] } \ueq}}

    \rewrite[U-Decomp]
      {\cunif {\pshapp \tvs} {\cunif {\pshapp \tvbs} \ueq}}
      {\cunif {\pshapp \tvs} \ueq \cand \cunif \tvs \tvbs}

    \rewrite[U-Clash]
      {\cunif {\pshapp \tvs} {\cunif {\pshapp[\shp]\tvbs } \ueq }\\
       \sh \neq \shp}
      {\cfalse}

    \rewrite[U-Trivial]
      {\trivial \ueq}
      {\ctrue}
\end{mathparfig}


\subsection{Solving rules}

% What we do (introduce / explain the solver)

We now introduce the rules of the constraint solver itself
(\cref{fig:omni-solver})\Xdidier {The is not such figure: the rules are
split in several parts}. These rules define a non-deterministic rewriting
system, operating modulo $\alpha$-equivalence and the associativity and
commutativity of conjunction. Rewriting is performed under an arbitrary
one-hole constraint context $\C$.
% Solved forms
A constraint $C$ is satisfiable if it can be rewritten into a \emph{solved
form}:
\begin{mathpar}
  \hat{\up} \uad\triangleq\uad \cexists \tvs \cAnd \iton \ueqi
\end{mathpar}
where each $\ueqi$ contains at most one non-variable type,
variables do not occur in multiple equations, and the constraint is acyclic.
From such a form, a most general solution (\ie a unifier $\vartheta$) can be
directly read off.

% Common rule descriptions

\paragraph{Basic rules}

Rule \Rule{S-Unif} invokes the unification algorithm to the
current unification problem. The unification algorithm itself is treated as a
black box by the solver, allowing the solver to be parameterized over the
equational theory of types implemented by the unifier.

\begin{bnffig}[t]
  {fig:constraint-syntax-extension}
  {Syntax of region-based $\Let$ constraints and partial applications}
  \entry[Constraints]{\c}{
    \dots \and \cletr \x \tv \tvs \ca \cb \and \cpapp \x \ren \ueqs \t
  } \\
  \entry[Semantic environment]{\semenv}{
    \dots \and \semenv, \x := \gabsr \tv \tvs
  } \\
  \entry[Renaming]{\ren}{
    \eset \and \rho[\tv := \tvb]
  }
\end{bnffig}

In general, existential quantifiers $\cexists \tv \c$ are lifted to the
nearest enclosing $\Let$, if any, or otherwise to the top of the constraint.
We refer to the resulting existential prefix $\exists \tvs$ as a
\emph{region}. To make regions explicit, we introduce the syntax $\cletr \x
\tv \tvs \ca \cb$, where $\tv$ is the \emph{root} of the region and $\tvs$ are
auxiliary existential variables. Both $\tv, \tvs$ are bound in $\ca$ but they
may also appear in $\cb$ but only in a partial application of $\x$.  In
particular, $\tvs$ cannot appear in $\cb$ when $\x$ does not appear in $\cb$.
The order of $\tvs$ is immaterial, and regions are considered equal up to
permutation of these variables.

The satisfiability of regional $\Let$-constraints is defined by:
\begin{mathpar}
  \infer[LetR]
    {\semenv \th \cexists {\tv, \tvs} \ca \\
     \semenv, \x \is \semenv(\cabsr \tv \tvs \ca) \th \cb}
    {\semenv \th \cletr \x \tv \tvs \ca \cb}

  \infer[AppR]
    {\semenv(\x) = \gabsr \tv \tvs \\
     \semenv(\t) \in \glam}
    {\semenv \th \capp \x \t}
\\
  \semenv(\cabsr \tv \tvs \c) \uad\eqdef\uad \gabsr[\set {\gt \in \Ground :
  \semenv, \tv \is \gt, \tvs \is \bar \gt \th \c}] \tv \tvs
\end{mathpar}
The semantic interpretation of an abstraction with a region, written
$\semenv(\cabsr \tv \tvs \c)$, is a set of ground types $\glam \subseteq
\Ground$ for which the applications are satisfiable with the region
$\tv\;\where\tvs$. Region-based $\Let$-constraints
strictly generalize ordinary constraint abstractions:
\begin{mathpar}
  \clet \x \tv \ca \cb \cequiv \cletr \x \tv \eset \ca \cb
\end{mathpar}
In particular, Rule \Rule{S-Let} rewrites the usual let constraints $\clet
\x \tv \ca \cb$ into region form.

\begingroup
\sloppy Rule \Rule{S-Exists-Conj} lifts existentials across
conjunctions, while rules \Rule{S-Let-ExistsLeft} and \Rule{S-Let-ExistsRight}
lift existentials into or across let-binders.
%
Rules \Rule{S-Let-ConjLeft} and
\Rule{S-Let-ConjRight} hoist constraints out of let-binders when they do not
depend on locally bound variables. Collectively, these lifting rules
normalize the structure of each region into a block of existentially bound
variables, comprising set of solved multi-equations (from unification) and
residual unsolved constraints (\ie applications, let-bindings and suspended
constraints).
\par
\endgroup

\begin{mathparfig}[t]
  {fig:solver-basic}
  {Basic rewriting rules $\ca \csolve \cb$}
  \rewrite[S-Unif]
    {\upa \\ \upa \unif \upb}
    {\upb}

  \rewrite[S-Let]
    {\clet \x \tv \ca \cb}
    {\cletr \x \tv \eset \ca \cb}

  \rewrite[S-Exists-Conj]
    {(\cexists \alpha \ca) \cand \cb \\
     \tv \disjoint \cb}
    {\cexists \tv {\ca \cand \cb}}

  \rewrite[S-Let-ExistsLeft]
    {\cletr \x \tv \tvs {\cexists \tvb \ca} \cb \\
     \tvb \disjoint \tv, \tvs}
    {\cletr \x \tv {\tvs, \tvb} \ca \cb}

  \rewrite[S-Let-ExistsRight]
    {\cletr \x \tv \tvs \ca {\cexists \tvb \cb} \\
     \tvb \disjoint \tv, \tvs, \cb}
    {\cexists \tvb {\clet \x \tvs \ca \cb}}

  \rewrite[S-Let-ConjLeft]
    {\cletr \x \tv \tvs {\ca \cand \cb} \cc \\
     \ca \disjoint \tv, \tvs}
    {\ca \cand \cletr \x \tv \tvs \cb \cc}

  \rewrite[S-Let-ConjRight]
    {\cletr \x \tv \tvs \ca (\cb \cand \cc) \\
     \x \disjoint \cc}
    {\cc \cand \Clet \x \tv \ca \cb}
\end{mathparfig}


Remaining basic constraint-formers, such as label and polytype instantiation
constraints, introduced in \cref{sec/TODO}, are handled by rewriting them once
their left-hand side becomes concrete. For instance, an instantiation
constraint $s \leq \t$\Xdidier {What is $s$, where are such constaints
defined?} is handled once $s$ is subsitituted by a match constraint,
yielding $\ts \leq \t$, which is then solved using the syntactic sugar
introduced in \cref{sec:constraints}. Similarly, label instantiation
constraints of the form $\Omega(\elab/t) \leq \t$ are resolved once $t$ is
substituted for some concrete $\T$.

\paragraph{Suspended match constraints}

\parcomment{S-Susp-Use}

Rule \Rule{S-Susp-Use} solves suspended match constraints whose scruintee
has a locally known shape---either statically, or as a result of appplying
Rule \Rule{S-Susp-Ctx}. The rule selects a unique matching branch based on
the shape of the scruitinee and applies the generated substitution to the
branch. If no branch matches, the rule is stuck, indicating that the
constraint is unsatisfiable.

\begin{mathparfig}
  {fig:solver-susp}
  {Rewriting rules for suspended match constraints.}
  \rewrite[S-Susp-Use]
    {\cmatch \t {\cbranch {\bar \cpat} {\bar \c}} \\
     \shape \t \Defined \\
     \cmatches \cpati {\decomp \t} \theta}
    {\theta(\ci)}

  \rewrite[S-Susp-Ctx]
    {\C\where{\cmatch \tv \cbrs} \\
     \cunif \tv {\cunif \t \ueq} \in \C \\
     \shape \t = \any \tvcs \tp}
    {\C\where{\cexists \tvcs  \cunif \tv \tp \cand \cmatch \tp \cbrs}}
\end{mathparfig}
\Xdidier {Where is ``$\cmatches \cpati {\decomp \t} \theta$'' defined?}




\parcomment {S-Susp-Ctx}

When the solver encounters a suspended constraint with an unknown shape, it
cannot proceed immediately. Instead, it must wait until the surrounding
context proves that the scruintee $\tv$ is unified with a type $\t$ whose
shape is defined. This enables the suspended match to be rewritten, according
to \Rule{Susp-Ctx}, thereby exposing the shape required to continue solving in
\Rule{S-Susp-Use}.

We decide whether the context $\C$ proves an equality (or more generally),
a multi-equation $\ueq$, by finding contexts $\Ca, \Cb$ such that
$\C = \Ca[\ueq \cand \Cb]$ and $\fvs \ueq \disjoint \Cb$ \ie $\Cb$ does not
bind the free variables of $\ueq$.

\paragraph{Let constraints}

% Let-constraint solving is generalization

Application constraints can be solved by copying constraints:
\begin{mathpar}
  \rewrite[S-Let-App-Beta]
    {\cletr \x \tv \tvs \ca {\C\where{\capp \x \t}} \\ \tv, \tvs \disjoint \t \\ x \disjoint \C}
    {\clet \x \tv \ca {\C\where{\cexists {\tv, \tvs} \cunif \tv \t \cand \ca}}}
\end{mathpar}
This is similarly to $\beta$-reduction, except that the original constraint
is kept around.
While obviously correct, this na\"ive strategy may duplicate constraint solving
work across applications of the same abstraction.

\parcomment{Background on efficient solving of applications (aka generalization)}

A more efficient approach first solves the abstraction once---\eg reducing it
to $\cabsr \tv \tvs \ueqs$, where $\tvs$ are generalizable variables---and
then reuses the result by copying only the solved constraint body $\ueqs$ at
each application site, only copying the solved constraints. Concretly, this
corresponds to solving $\ca$ to $\hat\up$ and identifying the generalizable
variables $\tvs$ and equations $\ueqs$ in $\hat\up$.

\parcomment{Where is this formalized?}

This connection between constraint abstractions and \ML type schemes is
formalized by Pottier and R\'emy \citet{Pottier-Remy/emlti}, who show that the
solved $\cabsr \tv \tvs \ueqs$ is equivalent to $\tfor {\tvs} \theta(\tv)$
where $\theta$ is the most general unifier of $\ueqs$. Consequently, efficient
implementations of \HM inference, such as that of \OCaml, implement
instantiation by copying the generalized constraint body $\ueqs$ with fresh
variables for $\tvs$.

\parcomment{Generalization with suspended constraints is hard}

However, suspended constraints complicate generalization.
To illustrate this, let us examine:
\begin{program}[input]
  type three = {x : int; y : int} °\ocamlcomment {OCaml - typechecks}°
  let e$_{10}$ r = let y = r.y in y + r.x
\end{program}
The generated constraint\footnote{Simplified for readability.} is of the
form:
\begin{mathpar}
  \cexists \tv
    \clet y \tvb
      %% {\cmatchdots \tva}
      {\cmatch \tvb {\cbranch {(\wild \Tapp[t])} {\C\where {t, \tva,\tvb}}}}
      {\cinst y \tint \cand \cunif \tv {\mathsf{three}}}
\end{mathpar}
\begin{version}{}
where $\C\where{t,\tv,\tvb}cbr$ is ${\Omega(\elab / t) \leq \tva \to \tvb}$
\end{version}
Here, $\tv$ stands for \code{r}'s type. The constraint remains
suspended until \code{r.y} forces \code{r}'s type to be
\code{three}.\Xdidier {I don't understand the discourse. First, we do not
know what are the overloaded labels. Then the suspended constaints if for
$r.y$, so the expression that could unfreeze it is $r.x$ not $r.y$.}
Cruicially, the variable $\tvb$ (introduced inside the abstraction for the
type of \code{y}) is captured by the suspended match constraint that is
not yet resolved at the point of generalizing \code{y}.

\parcomment {Partial type schemes}

Nonetheless, to continue solving the let-body, we must assign a scheme to
\code{y}. We na\"ively pick $\tfor \tvb \tvb$. This appears unsound, since
$\tvb$ will later unify with $\tint$ once the match constraint is discharged.
But it would be incomplete to lower $\tvb$ as a monomorphic variable.
%
This motivates, \emph{partial type schemes}, our second novel mechanism for
omnidirectional inference, Partial type shemes are type schemes that delay
commitment to certain quantifications (\eg $\tvb$). Such \emph{partially
generalized} variables are treated as generalized, but can still be refined
in future as suspended constraints are discharged.

\parcomment {Intro partial applications}

To support this, we extend the language of constraints with \emph{partial
application constraints} $\cpapp \x \ren \ueqs \t$, representing a partially
solved application $\capp \x \t$. The renaming $\ren$ map $\x$'s regional
variables to fresh copies, and $\ueqs$ accumulates the solved equations copied
so far. This enables efficient, incremental instantiation of constraint
abstractions: solved parts are reused immediately, while unresolved
constraints (\ie suspended constraints) can be solved later, further refining
the abstraction and propagation additional equations to the application sites.

\begin{mathparfig}[t]
  {fig:solver-schemes}
  {Rewriting rules for let-bindings and applications.}
  \rewrite[S-Let-App]
    {\cletr \x \tv \tvs \ca \C\where{\capp \x \t} \\
     \tvc \disjoint \t \\
     \x \disjoint \C}
    {\cletr \x \tv \tvs \ca \C\where{\cexists \tvc \cunif \tvc \t
                               \cand \cpapp \x \eset \eset \tvc }}

  \rewrite[S-Papp-Exists]
    {\cletr \x \tv {\tvs, \tvb} \c \C\where{\cpapp \x \ren \ueqs \tvc} \\
     \tvb \notin \dom \ren \\
     \tvbp \disjoint \ren, \ueqs, \tvc \\
     \x \disjoint \C}
    {\cletr \x \tv {\tvs, \tvb} \c
      \C\where{\cexists \tvbp \cpapp \x {\ren \where {\tvb \is \tvbp}} \ueqs \tvc}}

  \rewrite[S-Papp-Unif]
    {\cletr \x \tv \tvs {\c \cand \ueq} {\C\where{\cpapp \x \ren \ueqs \tvc}} \\
     \ren : \tvs \\
     \ueqs \nvDash \ueq \\
     \x \disjoint \C}
    {\cletr \x \tv \tvs {\c \cand \ueq}
      \C\where{\cpapp \x \ren {\ueqs, \ueq} \tvc
	 \cand \ueq[\ren\where{\tv \is \tvc}}]}

  \rewrite[S-Papp-Solve]
    {\cletr \x \tv \tvs {\ueqs'} {\C\where{\cpapp \x \ren \ueqs \tvc}} \\
     \ren : \tvs \\
     \ueqs \vDash \ueqs' \\
     \x \disjoint \C}
    {\cletr \x \tv \tvs {\ueqs'} {\C\where{\ctrue}}}

  \rewrite[S-Let-Solve]
    {\cletr \x \tv \tvs \ueqs \c \\ \x \disjoint \c \\
     \cexists {\tv, \tvs} \ueqs \cequiv \ctrue}
    {\c}

  \rewrite[S-Exists-Lower]
    {\cletr \x \tv {\tvas, \tvbs} \c
     {\C\where{\overline{\cpapp \x \ren \ueqs \tvc}}} \\
     \cdetermines {\cexists {\tv, \tvas} \c} \tvbs \\
     \tvbs \subseteq \dom \bar \ren
     \Xdidier[was]{\dom \bar \ren \subseteq \tvbs}\\
     \x, \tvbs \disjoint \C
     }
    {\cexists \tvbs
      \cletr \x \tv \tvas \c
	{\C\where{{\overline{\cpapp \x {\ren \setminus \tvbs} \ueqs
			 \cand \cunif {\ren(\tvbs)} \tvbs}}}}}
\end{mathparfig}


% Semantics to partial applications
We assign the following semantics to partial application constraints:
\begin{mathpar}
\infer[Papp]{
   \semenv(\x) = \gabsr \tv \tvs \\
   \dom \ren \subseteq \tvs \\
   \semenv, \tv \is \semenv(\t) \th \ueqs [\ren] \implies
   \semenv(\t) \in \glam                             \\
}{% -------------------------------------------------------
   \semenv \th \cpapp \x \ren \ueqs \t
}
\end{mathpar}
Informally, this states that a solution $\semenv$ to a partial application
constraint $\cpapp \x \ren \ueqs \t$ must also be a solution to the full
application $\capp \x \t$, provided the copied equations $\ueqs$ are
satisfiable under the renaming.
\parcomment{Treatment of alpha-renaming}
The semantics enforces that the domain of the renaming $\ren$ is a subset of
the regional variables $\tvs$ of $\x$---a cruicial property for treating these
variables modulo $\alpha$-equivalence. As mentioned above, $\tvs$ are bound not
only in the body of the abstraction $\ca$, but also in the
constraint $\cb$, where they may appear in partial applications of $\x$ via
renamings---and only there. Hence, when they cannot appear in $\ca$ when
(the corresponding variable) $\x$ does not itself appear in $\ca$.

\begin{remark}
  The satisfiability judgement in \Rule{Papp} occurs in a negative position.
  This does not threaten well-foundness, as the conclusion of this rule is
  strictly larger than the negatively occuring judgement. See Appendix ??.
\end{remark}

Partial application constraints are solved using the following rules:
\begin{enumerate}

\item
  Rule \Rule{S-Papp-Exists} allocates fresh existential variables at the
  call site that are mapped to uninstantiated variables within the
  abstraction.  We write $\ren : \tvs$ for $\dom \ren = \tvs$.
  \Xdidier {Why not inline it? already too many notations...}

\item
  Rule \Rule{S-Papp-Unif} copies multi-equations from the abstraction to the
  call site, provided we have already introduced the renamings by Rule \Rule
  {S-Papp-Exits} and we have not copied them previously.
  \Xdidier {$\ueqs \nvDash \ueq$ is not formally defined, which is non
  obvious because of renamings.}

\end{enumerate}
\parcomment{Cleaning up partial applications and let constraints}
Rule \Rule{S-Papp-Solve} removes partial applications once all necessary
constraints have been copied---that is, when the copied equations entail
the abstraction's body. \Rule{S-Let-Solve} remove a $\Let$ constraint when
the bound term variable is unused and the abstraction is satisfiable.

\parcomment{Lowering}

Rule \Rule{S-Exists-Lower} implements the non-trivial case of lowering
existentials across $\Let$-binders. It identifies a subset of variables in
the region of a $\Let$ constraint that are unified with variables from
outside the region. Such variables are considered monomorphic and thus
cannot be generalized; they can instead be safely lowered to the outer
scope.
\Xdidier{The condition $\x, \tvbs \disjoint \C$ in \Rule {S-exists-Lower}
prevents the simplicication when there are several occurrences of
$\x$ in $\C$ as they cannot be eliminated}


\parcomment {Determines}

This is the case when the types of $\tvbs$ are \emph{determined} in a unique
way. In short, $\c$ determines $\tvbs$ if and only if the solutions for
$\tvbs$ are uniquely fixed by the solutions to other variables in $\c$.

\begin{definition}
  $\cdetermines \c \tvbs$ if and only if every ground assignments
  $\semenv$ and $\semenvp$ that satisfy $\c$ and coincide outside of $\tvb$
  concide on $\tvbs$ as well.
  \begin{mathpar}
    \cdetermines \c \tvb \uad\eqdef\uad \all {\semenv, \semenvp} \uad
      \semenv \th \c
      \wedge \semenvp \th \c
      \wedge \semenv =_{\setminus \tvbs} \semenvp
      \implies
      \semenv = \semenvp
  \end{mathpar}
\end{definition}

\parcomment {How the determines relation corresponds to ML}
Conceptually, this corresponds to the negation of the generalization condition
in \ML: a type variable cannot be generalized if it appears in the typing
context. In the constraint setting, it cannot be generalized if it depends on
variables from outside the region.

% How to decide the relation
To decide when $\cdetermines {\cexists \tvs \c} \tvbs$ holds for $\tvbs
\disjoint \tvs$, we search for a multi-equation $\ueq$ in $\c$ of the form:
\begin{enumerate*}
  \item $\cunif \tvc \ueq'$ where $\tvc \disjoint \tvs, \tvbs$ and
    $\tvbs \subseteq \fvs {\ueq'}$, or
  \item $\cunif \tvbs {\cunif \t \ueq'}$ where $\fvs \t \disjoint
    \tvs, \tvbs$.
\end{enumerate*}
For instance, $\cexists \tvba \cunif \tv {\tvba \to \tvbb}$ determines
$\tvbb$, as $\tvbb$ is free. \cref{sec:implementation} discusses how we
efficiently decide determinability.

\parcomment{Why we lower?}

Lowering such variables improves solver efficiency. It avoids unnecessary
duplication of work that would otherwise occur via \Rule{S-Papp-Exists}, which
allocates fresh copies of all regional variables at each application site. By
reducing the number of variables that need to be copied, lowering directly
reduces instantiation overhead.

\parcomment{Updating partial applications}

However, sometimes \Rule{S-Papp-Exists} must copy a variable before it can be
lowered, for instance, in the constraint $\cexists \tvc \cletr \x \tva \tvb
{\cunif \tva \tvb \cand \cmatch \tvb {\cbranch \cwild {\cunif \tvb \tvc}}}
{\capp \x \tint}$ requires us to instantiate $\x$ before we can make any
progress on lowering $\tvb$. In this case, when we eventually lower the
variable, we must also update any partial applications that previously copied
it, ensuring their local copies are unified with the new, lowered variables
$\tvbs$.


\TODO{Compression}

\TODO{Should we mention backpropagation prior to here?}

\TODO{Forall constraints -- this should be the same from EMLTI}

\paragraph{Backpropagation}

The interaction that forces partial application to be useful\footnote{We
could in theory re-order instantiations in any way, delaying until the
abstraction is fully solved} is
\emph{backpropagation}, the mechanism that allows type information from use sites
to refine matched variables inside generalised abstractions.

For example, in:
\begin{program}[input]
  let e$_{10}$ = let f r = r.y in f {x = 1; y = 1}
\end{program}
\OCaml rejects this, as \geninst-directional inference cannot propagate the known
type \code{three} back to \code{f}'s parameter.
The (simplified) constraint generated when typing \code{e}$_{10}$ is:
\begin{align*}
  \cexists \tv
  &\clet f \delta {\cexists {\tvb, \tvc}
    \cunif \delta {\tvb \to \tvc} \cand
    \cmatch \tvb
       {(\cbranch {\wild \Tapp[t]} {\Omega(y / t) \leq \gamma \to \beta})}} \\
  &\capp f {(\mathsf{three} \to \tv)}
\end{align*}
At the use site, the abstraction is applied with a type of known shape
(\code{three}).  Rule \Rule{S-BackProp} propagates this shape back into the
suspendede match inside the abstraction by unifying it with the variable
$\tvb$. This is sound: the unicity predicate $\Cshape \C \tv \sh$ ensures
that $\tvb$'s shape is \code{three} provided the context $\C$ include the
application constraint.
\Xdidier {This rule should be in \cref  {fig:solver-schemes}}
\begin{mathpar}
  \rewrite[S-BackProp]
    {\C\where
       {\cletr \x \tv \tvs {\Ca\where{\cmatch \tvp \cbrs}}
                           {\Cb\where{\cpapp \x \ren \ueqs \tvc}}} \\
     \tvp \in \dom \ren \\
     \C\where{\Cb} \th \theta(\tv) = \t \\
     \shape \t = \any \tvcs \tp}
    {\C\where{\clet \x \tvs {\Ca[\cexists \tvcs \cunif \tv \tp
                           \cand \cmatch \tp \cbrs}}
		      {\Cb[x[\theta \th U]]}]}
\end{mathpar}


\subsection{Metatheory}
% Properties

\begin{theorem}[Progress]
  If $\cdot \th \c$ and $\c$ is not solved, then there exists a $\cp$
  such that $\c \csolve \cp$.
\end{theorem}

\begin{theorem}[Termination]
  The constraint solver terminates on all inputs.
\end{theorem}

\begin{theorem}[Preservation]
  If $\ca \csolve \cb$, then $\ca \cequiv \cb$.
\end{theorem}



\section{HM Prototype and discussion}
\label{sec:implementation}

\parcomment {Generalization trees}

% Ranks
In practice, this
check is efficiently implemented using \emph{ranks} -- where each regional
$\Let$ constraint and type variable is allocated an integer rank, which
informs us the depth of the region within the constraint. type variables of
rank $0$ are bound at the top-level region, and type variables of rank $r \geq
1$ are bound in the region of $\Let$ constraint at depth $r$. Ranks were
initially described by R\'emy \cite{TODO} for efficient generalization.
In practice, the unification algorithm is aware of ranks and lowers them
accordingly when unifying types.


\parcomment {Lazy generalization}

\parcomment {Schedulers}

\parcomment {Partial generics and instances}

\paragraph{Interaction with let-polymorphism}
\Xgabriel{This was moved from the introduction, it's related to ``choice
points'' below.}

\parcomment{Our intuition is not entirely correct here.}

While the above constraint generation already improves on
OCaml's current inference approach, it is not powerful enough to capture the
simple idea that to resolve an ambiguous constructor we must use contextual
information to show there is a unique type constructor $\F$ for the
application.

We demonstrate this is with the following example:
\begin{program}
let foo =
  let f x = match x with L -> 1 in
  f (L : m)
\end{program}
With the above contraint generation, we would keep the type of \code{x}
as a generalizable variable, thus the application of \code{f} would not
resolve this ambiguity, requiring an annotation at the definition.

We require some way of splitting the head of the type from the type itself,
treating the head of the variable monomorphically and the rest
polymorphically.
\Xalistair{An explaination of kinded(1) types here }

\subsection{Static overloading and variational types}

We applied omnidirectional type inference to three features that have
already been used in some dialect of \ML.  But applications are not limited
to those.

In particular, overloading of nominal record fields (or data-consttructors)
is a very specific case of overloading.  Omnidirectional type inference can
also be used for a general forms of static overloading.

Following~\cite{Leijen-Ye/prefix@pldi2025},
we may allow identifiers $\M.\x$ to be prefixed by a
disambiguation name $\M$ and let the prefix be optional in expressions.
When absent, such expressions are then overloaded and the prefix must be
resolved before the program may be compiled.

In this setting an overlaoded symbol $\x$ may have two (or more) definitions
$\Ma.\x$ an $\Mb.\x$ of respective types $\tya$, $\tyb$, which may have very
litte in common. In particular, $\tya$ and $\tyb$ may share the same prefix
an only differ from their leaves.

The framework we presented for \OML may only suspend a constraint on the
shape of a variable, that is roughtly on the toplevel symbol.  While it
would be possible to extend the framework to alow more general shapes, we
can actually encode general overloading without such an extension.
We present a solution below based on variational types, but other variants
are possible.

\paragraph{Variational types}

\begin{version}{}
\color{red}
Variational types are a mean to factor a tuple of types into a single one so
as to shape the common prefixes.

The syntax of variational type just extends simple types with a special form
of n-ary products $\varpi (\ti)\iton$, which however distributes other type
symbols. For example, $\vty {\tint \to \tint \to \tbool \vor \tbool \to
\tbool \to \tbool}$ is a 2-variational type $\t$ that represents both the type
$\tint \to \tint \to \tbool$ and $\tbool \to \tbool \to \tbool$.  However,
the interest of variational types is to be able to push them down the leaves
and equivalently write $\vty {\tint \vor \tbool} \to \vty {\tint \vor
\tbool} \to \tbool$ for $\t$ so as to share the common prefix of all types.
We may thus maintained variational types in such canonical form.  If $\vty
{\ti}\iton$ is in canonical form, then at least two $\tyi$ and $\tyj$ have
different shapes.  The arity of avariational typ must be known from context
since in the pathological case where all types agrees, its canonical form is
$\t$.

An n-variational type may be projected on any index of its domain: $\t/1$
means $\tint \to
\tint \to \tbool$.

For overloading of two defintions $\Ma.\x$ and $\Mb.\x$ of types $\tya$ and
$\tyb$, we may assign $\x$ the variational type $\vty {\tya \vor \tyb}$.
\end{version}

\paragraph {Opaqueness of suspended constraints}

Suspended constraints are opaque, \ie the solve may not learn anything form
suspended constraints until uniqueness of the shape the control them allows
to discharge them.

For example, this prevents typing of example \ocaml{e_9}, which we repeat
below:
\begin{program}
let e9 r = (r.x : bool)
\end{program}
Hence, the constraint type of \ocaml{r.x} is frozen until the record type
$r$ can be resolved. Hence, the overloading resolution ignores that the
return type of \ocaml{r.x} is \ocaml{bool} and fails. While, if we were
able to take it into account, then the only possibility would be that
\ocaml{r} has type \ocaml{bool one}---in the closed world view.


constaint that the return type of
\ocaml{r.x} is not taken into account in the overloading resolution.


While sometimes there is obvious information that we could learn from them,
especially by merging constraints on the same variable.

For example,


\paragraph {Variational types}

\begin{version}{\color{blue}\Draft}
Title to adjust.
This section is to explain
\begin{itemize}

\item
  that there are possible variants on static overloading.

\item
  The main idea of omnidirectional type inference is to collect as
  many constraints that can help resolve overloading, statically.
  Hence, we may be more aggressive, in some cases,

\item
  Variational types in general---but the have a cost

\item
  Using rows in nomimal records to merge contraints on the same record.
\end{itemize}


\end{version}

\Xdidier [From 2.1]{Then, it seems that we cannot solve
$\efun r {r.x + r.y}$, since the two accesses $r.x$ and $r.y$ will both wait
for the type of $r$ to be known independently of the other.
Since we could collect the information that $r$ must have two fields $x$
and $y$ and there is a unique solution. In fact, an approach based on
qualified types would solve this example statically.
Nominal records are an example where we should allow to combine information
from two different use points---of the same type. That is several matches on
the same variable should be combined. I cannot either for the moment, but at
some point I wanted to merge overloaded constraint on the same variable to
take take the intersection of their head constructors. Still planing to do
that, which would solve this example}



\subsection{Default rules}

Type inference may failed either because of a typing error (the constraint
if of the form $\C \where \cfalse$), or because some choice point cannot be
resolved---a stuck constraint contains a suspended match constraint.
%
In the later case, we may point the user to at least one choice point that
could not be solved and invite him to provide additional type annotations.

In fact \OCaml uses default rules in case an overloaded constructor or a record
field could not be solved, then selecting the most recently defined type.

While, we could also introduce similar default rules in our proposal, they
would likely break the properties of the type system.

One option is not to integrate default rules in omnidirectional type
inference, and instead combine omnidirectional type inference with another
external external algorithm that can suggest extra type annotations and
calls back type inference, or rather, resume type inference from its
previous state.  In this view, we preserve the properties in
in the absence of uses of default rules, but give up any property
as default rule have been used.

Hence, it is also appealing to attend to formalize default rules.  In order
to avoid choices, one option may be to fire all default rules at once and
independently of one another.  This however may loose opportunities to learn
useful information after firing one default rule so as to not have to used
other default rules.

Another track is to computer dependencies between unsolved constraints---and
solve them in inverse order of dependencies.

One the strategy of when firing default rules, the behavior of default rules
is quite dependent on the feature.  While, the reasonable default for
overloading of record fields and data constructors is to giving priority to
the most recent definition, as in \OCaml, there is not obvious choice for
structural tuples, for which the default should probably remain a failure.

For polytypes, there are actually to opposite meaningful choices, but
opposite of one another. One is to fallback to a monomorphic polytype.  The
other one is to pick the principal type scheme of the expression with an
unresolved polytype.  Of course, there are examples that favor one choice
and other examples that favor the other.

While default rules may be convenient in practice, they remain unprincipled
and may break properties of omnidirectional type infernce.  The strategy of
when firing them should be precautionary to limit what may look like
arbitrary or unpredictable choices.

\subsection{Equi-recursive types}
\label {sec/rec-types}

For sake of simplicity, we have taken finite trees for ground types, that
is, for the semantics of constraints.  Iso-recursive types can easily be
added as in \ML, using a new datatype definition where  a record label
or datatype constructor is used to fold or unfold the recursive definition.

\OCaml also allows equi-recursive types, which can be modeled by taking
regular trees instead of tree for ground types.  Doing this change would
preserve the main metatheoretical properties, as in~\cite
{Pottier-Remy/emlti}, as we never rely on finiteness of ground types.  This
would allow type inference with equi-recursive types.

Technically, we need to extend the syntax of types with
a new introduction form $\trec \tv \t$ with the condition that $\t$ is
constructive, \ie a nonvariable type.  Internally, we never manipulate
recursive types but equations. The change, is a remove
\Rule {U-Cycle} and consistently allow canonical forms to contain cycles,
as they now admit regular tree solutions.

Similarly, shapes may be recursive, but only minimal shapes of polytypes may
be recursive. All types still have unique minimal shapes where equality of
shapes is taken up to equi-recursion, indeed.  While equality of shapes is
syntactical in the absence of recursive types, this is no longer the
case---but this does not raise any issue.

\Xdidier{I line notes}
\begin{version}{}
I did not see any difficult with equi-recursive types.
I am not even sure we need to mention~\cite
{Gauthier-Pottier/numbering@icfp04}.
Ths provides a cannonical representation, generalizing de Bruin indicies so
that second-order equality of terms amount to fisrt-order equality.
The canonical representation useing shapes is simiular.
\end{version}


\Xdidier {How much more should we say?}

\Xdidier {Should we give the change in unification rules?}

\section{Related work}
\label{sec:related-work}

Should we cite \cite{Leijen-Ye/prefix@pldi2025} ?

\subsection{Qualified types}


\Xdidier {The following paragaph is just take from the old introduction}

Qualified types~\citep*{TODO} represent additional knowledge on a type. They
are used in particular in Haskell type-classes, where a constraint
$\mathsf{Show}~\alpha$ represents the fact that a part of the inferred term
needs to print values of type $\alpha$. A constraint on a ground type such
as $\mathsf{Show}~\mathsf{Int}$ can be resolved to a known printer. But if
the undetermined variable $\alpha$ becomes generalizable in a type $\tau$,
we get a type-scheme $\tfor{(\alpha \mid \mathsf{Show}~\alpha)}{\tau}$ that
also includes the type-class constraint.

DRAFT: Type-classes let each use-site choose a different typeclass instance
-- but this implies dictionary-passing or specialization. Sometimes we want
the choice to be shared by all use-sites:


\subsection{Suspended constraints in \textsc{OutsideIn}}

\Xalistair{They first solve simple constraints (existentials,
unification). Then they solve ``... constraints'', with implication
constraints, which corresponds to the case of GADT matches. Crucially, they
abandon local let generalization.}

\subsection{Suspended constraints in dependent-type systems}


\subsection{Bi-directional type inference}

\Xgabriel{Our approach should have better properties for disambiguation, but
which ones?}

In the simply-typed case our system works better. But with generalization
you can have more issues.

\Xdidier{Should we try to extend what we did to predicative polymorphism?}

\Xalistair{Not ready yet and would probably need too much space.}

\Xgabriel{CoreML + bidirectional disambiguation of constructors?}

\TODO
{do we understand what to say precisely about bidirectional type inference?}

\subsection{Principality tracking in \OCaml}

\Xdidier{The point of that is to enforce a directional type inference that
is based on let-bindings. When we check that the level is generic, we check
that we already ``closed'' this thing, it is an earlier 'let'
binding. Because we are omni-directional, we don't have principality issues
anymore -- except with default rules. We are principal by construction, we
never make any choice.}

\Xdidier{Principality tracking is making the choice that we are going to
make a directional let-binding-based type inference. We get rid of that, we
are omni-directional, and don't have any principality issues.}

\Xgabriel{We should not claim too much if we don't understand default
clauses well enough. It could people the impression that we hide the issue
under the carpet.}

\Xdidier{First a declarative/principal system, and then non-principal
heuristics to refine it, a two-phase process. It's fine.}

\section{Future work}
\label{sec:future-work}

\Xdidier{How would we solved example $e_9$ as announce in \cref
{sec/introduction}?}

% \begin{acks}
% \end{acks}


%% \bibliographystyle{ACM-Reference-Format}
\bibliography{suspended}

\newpage
\appendix

\section{Figures}

This section contains supplementary material to the main paper, including a
list of figures and definitions. Some of them are repeated from the main paper.

\TODO{Write these here}

\judgbox{\c \simple}{The constraint $\c$ is simple.}
\begin{mathparfig}
  {fig:defn-simple}
  {Simple constraints.}

  \inferrule[Simple-True]
    {}
    {\ctrue \simple}

  \inferrule[Simple-False]
    {}
    {\cfalse \simple}

  \inferrule[Simple-Conj]
    {\cone \simple \\ \ctwo \simple}
    {\cone \cand \ctwo \simple}

  \inferrule[Simple-Exists]
    {\c \simple}
    {\cexists \tv \c \simple}

  \inferrule[Simple-Forall]
    {\c \simple}
    {\cfor \tv \c \simple}

  \inferrule[Simple-Unif]
    {}
    {\cunif \tone \ttwo \simple}

  \inferrule[Simple-Let]
    {\cone \simple \\ \ctwo \simple}
    {\clet \x \tv \cone \ctwo \simple}

  \inferrule[Simple-App]
    {}
    {\capp \x \t \simple}

  \inferrule[Simple-LetR]
    {\cone \simple \\ \ctwo \simple}
    {\cletr \x \tv \tvs \cone \ctwo \simple}

  \inferrule[Simple-Papp]
    {}
    {\cpapp \x \ren \ueqs \simple}
\end{mathparfig}

\judgbox{\C \simple}{The constraint context $\C$ is simple.}
\begin{mathparfig}
  {fig:defn-ctx-simple}
  {Simple constraint contexts.}
  \inferrule[Simple-Ctx-Hole]
    {}
    {\square \simple}

  \inferrule[Simple-Ctx-Conj-Left]
    {\C \simple \\ \c \simple}
    {\C \cand \c \simple}

  \inferrule[Simple-Ctx-Conj-Right]
    {\C \simple \\ \c simple}
    {\c \cand \C \simple}

  \inferrule[Simple-Ctx-Exists]
    {\C \simple}
    {\cexists \tv \C \simple}

  \inferrule[Simple-Ctx-Forall]
    {\C \simple}
    {\cfor \tv \C \simple}

  \inferrule[Simple-Ctx-Let-Abs]
    {\C \simple \\ \c \simple}
    {\clet \x \tv \C \c \simple}

  \inferrule[Simple-Ctx-Let-In]
    {\c \simple \\ \C \simple}
    {\clet \x \tv \c \C \simple}
\end{mathparfig}

\judgbox{\semenv \Th \c}
  {Under the semantic environment $\semenv$,
   the constraint $\c$ is canonically satisfiable.}
\begin{mathparfig}
  {fig:defn-canonical-sat-deriv}
  {Canonical satisfiability derivations}

  \inferrule[Can-Simple]
    {\semenv \th \c \\ \c \simple}
    {\semenv \Th \c}

  \inferrule[Can-Susp-Ctx]
    {\Cshape \C \t \sh \\ \semenv \Th \C\where{\cmatched \t \sh \cbrs}}
    {\semenv \Th \C\where{\cmatch \t \cbrs}}
\end{mathparfig}


\section{Properties of the constraint language}

\subsection{Principality of shapes}


\Cref {th/shapes/principal} states that any non variable type $\t$ has a
principal shape. We show that this is indeed the case.

\medskip

When $\t$ is not a polytype, it has a toplevel constructor $c$ of
arity $n$, which in our setting may be the nullary $\tunit$, the binary
arrow, the n-ary product, or a $n$-ary nominal type. In all these
cases, the shape of $\t$ is $\any \tvcs \tc \tvcs$ where $\tvcs$ is a
sequence of $n$ distinct type variables.

\medskip

It only remains to check that a polytype $\tpoly {\all \tvs \t}$ also has a
unique shape. We may assume \Wlog that each variable of $\tvs$ occurs free in
$\t$.
%
Let $(\pi_i)\iton$ be the sequence of shortest paths in $\t$ that cannot be
extended to reach a (polymorphic) variable in $\tvas$, in lexicographic
order and $\tvcs$ be a sequence $(\tvci)\iton$ of distinct variables that do
not appear in~$\t$.
%
Let $\tyz$ be $\t \where {\pi_i \is \tvci}\iton$, \ie the term $\t$ where each
path $\pi_i$ has been substituted by the variable $\tvci$.  Let $\Sh$ be the
shape $\any \tvcs {\tpoly {\all \tvs \tyz}}$.
We claim that $\Sh$ is actually the principal shape of $\tpoly {\all \tvs
\t}$.

\medskip
\locallabelreset

By construction, $\t$ is equal to $\shapp[\Sh] \tys$~\llabel 1.
where $\tys$ is the sequence composed of $\ti$ equal to $\t/\pi_i$
for $i$ ranging from $1$ to $n$.
%
Indeed, by
definition, $\shapp[\Sh] \tys$ is equal to $(\t\where {\pi_i \is \tvci}\iton)
\where {\tvci \is \ti}$ which is obviously equal to $\t$.
The remaining of the proof checks that $\Sh$ is minimal~\llabel 2, that is,
we assume that $\Sh'$ is another shape such that $\tpoly {\all\tvs\t}$ is
equal to $\shapp [\Shp] \typs$ for some $\typs$~\llabel H and show that $\Sh
\preceq \Shp$~\llabel C.

\medskip

It follows from~\lref H that
  $\Shp$ must be a polytype shape, \ie of the form $\any \tvcps {\tpoly
  {\all \tvbs \typ}}$ and
  $\tpoly {\all \tvs \t}$ is equal to $\tpoly {\all\tvbs \tp} \where {\tvcps
  \is \typs}$~\llabel{P}.
\relax
We may assume \Wlog that $\tvbs$ and $\tvcps$ are disjoint, that
$\tvcps$ does not contain useless variables, \ie
that they all appear in $\tp$ and that they actually appear in lexicographic
order.
\relax
Now that never term contains useless variables, \lref P implies that the
sequences $\\tvas$ and $\tvbs$ can be put in one-to-one correspondances.
Besides, since they all ordered in the order of appearance in terms, they
the correspondance respects the ordering. Hence, the subsitution $\where
{\tvbs \is \tvas}$ is a renaming. Therefore, we can assume \Wlog that
$\tvbs$ is $\tvas$,
\relax
That is, \lref P becomes that $\tpoly {\all \tvs \t}$ is equal to $\tpoly
{\all \tvs \typ \where {\tvcps \is \typs}}$, which given that they $\tvs$
apprear in the same order in both terms, implies that $\t$ is equal to $\typ
\where {\tvcps \is
\typs}$~\llabel T.

\relax

\medskip

Since $\typs$ does not contain any variable in $\tvs$, every path $\pi_i$
is a path in $\typ$. Thus, we may write $\typ$ as
\relax $\typ \where {\pi_i \is \tyi''}\iton$ where $\tyi''$ is $\typ/\pi_i$.
This is also equal to
\relax $(\typ \where {\pi_i \is \tvci}\iton) \where {\tvci \is \tyi''}\iton$,
that is $\tyz\where {\tvci \is \tyi''}\iton$.
%
In summary, we have $\typ$ is equal to
\relax $\tyz \where {\tvci \is \tyi''}\iton$,
which implies that
\relax  $\tpoly {\all \tvs \typ}$ is equal to
\relax  $\tpoly {\all \tvs {\tyz \where {\tvci \is \tyi''}\iton}}$, \ie
\relax  $\tpoly {\all \tvs \tyz} \where {\tvci \is \tyi''}\iton$~\llabel E.
%
By Rule \Rule {Inst-Shape}, we have
\begin{mathpar}[inline]
\any \tvcs  \tpoly {\all \tvs \tyz} \preceq
\any \tvcps\tpoly {\all \tvs \tyz} \where {\tvci \is \tyi''}\iton,
\end{mathpar}
which, given~\lref E, is exactly~\lref C.



\subsection{Well-foundedness of satisfiability}
\label{appendix:sat-wf}

In this appendix, we give the full details of the well-foundedness of the
semantics of constraints, that is the satisfiability judgement $\semenv \th
\c$.

%\satwf
\newcommand{\cnmatches}[1]{\#\Match #1}
\newcommand{\csize}[1]{|#1|}
\newcommand{\cmeasure}[1]{{\| #1 \|}}

\begin{proof}
  For the relation $\semenv \th \c$, the following measure on such judgements is
  adequate to prove well-foundedness:
  \begin{mathpar}
    \cmeasure \c \uad\eqdef\uad \angles{\cnmatches \c, \csize \c}
  \end{mathpar}
  where $\angles \ldots$ denotes a pair with lexicographic ordering, and:
  \begin{enumerate}

    \item $\cnmatches \c$ is the number of $\cmatch \t \cbrs$ constraints in
      $\c$.

    \item the last component $\csize \c$ is a structural measure of constraints \ie a
      conjunction $\cone \cand \ctwo$ is larger than the two conjuncts $\cone,
      \ctwo$.

  \end{enumerate}
We will now show that every rule uses a premise whose measure is smaller than
the conclusion.
\begin{itemize}
  \proofcasederivation
      {True}
      {}
      {\semenv \th \ctrue}

      \begin{llproof}
	No premises.
      \end{llproof}

  \proofcasederivation
      {Conj}
      {\semenv \th \cone \\ \semenv \th \ctwo}
      {\semenv \th \cone \cand \ctwo}

      \begin{llproof}
	\gtPf{\csize {\cone \cand \ctwo}}{\csize \cone, \csize \ctwo}{By definition}
	\eqPf{\cnmatches {\cone \cand \ctwo}}{\cnmatches \cone + \cnmatches \ctwo}{By definition}
	\eqPf{\cmeasure \cone}{\angles{\cnmatches \cone, \csize \cone}}{By defintion}
\Hand 	\continueltPf{\cmeasure {\cone \cand \ctwo}}{Above}
	\eqPf{\cmeasure \ctwo}{\angles{\cnmatches \ctwo, \csize \ctwo}}{By defintion}
\Hand   \continueltPf{\cmeasure {\cone \cand \ctwo}}{\ditto}
      \end{llproof}

  \proofcasederivation
      {Exists}
      {\semenv\where{\tv \is \gt} \th \c}
      {\semenv \th \cexists \tv \c}

      \begin{llproof}
	\gtPf{\csize {\cexists \tv \c}}{\csize \c}{By definition}
	\eqPf{\cnmatches {\cexists \tv \c}}{\cnmatches \c}{By definition}
	\eqPf{\cmeasure \c}{\angles {\cnmatches \c, \csize \c}}{By definition}
\Hand 	\continueltPf{\cmeasure {\cexists \tv \c}}{Above}
      \end{llproof}

  \proofcasederivation
      {Forall}
      {\forall \gt,\, \semenv\where{\tv \is \gt} \th \c}
      {\semenv \th \cfor \tv \c}

      \begin{llproof}
	Similar to the \Rule{Exists} case.
      \end{llproof}

  \proofcasederivation
      {Unif}
      {\semenv(\tone) = \semenv(\ttwo)}
      {\semenv \th \cunif \tone \ttwo}

      \begin{llproof}
	No non-trivial premises.
      \end{llproof}

  \proofcasederivation
      {Let}
      {\semenv \th \cexists \tv \cone \\ \semenv\where{\x \is \semenv(\cabs \tv \c)} \th \ctwo}
      {\semenv \th \clet \x \tv \cone \ctwo}

      \begin{llproof}
	\gtPf{\csize {\clet \x \tv \cone \ctwo}}{\csize{\cexists \tv \cone}, \csize{\ctwo}}{By definition}
	\eqPf{\cnmatches {\clet \x \tv \cone \ctwo}}{\cnmatches \cone + \cnmatches \ctwo}{By definition}
	\eqPf{\cmeasure {\cexists \tv \cone}}{\angles {\cnmatches {\cexists \tv \cone}, \csize {\cexists \tv \cone}}}{By definition}
\Hand   \continueltPf{\cmeasure {\clet \x \tv \cone \ctwo}}{Above}
	\eqPf{\cmeasure \ctwo}{\angles {\cnmatches \ctwo, \csize \ctwo}}{By definition}
\Hand   \continueltPf{\cmeasure {\clet \x \tv \cone \ctwo}}{\ditto}
	\eqPf{\semenv(\cabs \tv \cone)}{\set {\gt \in \Ground : \semenv\where{\tv \is \gt} \th \cone}}{By definition}
	\gtPf{\csize {\cexists \tv \cone}}{\csize \cone}{By definition}
	\eqPf{\cnmatches {\cexists \tv \cone}}{\cnmatches \cone}{By definition}
	\eqPf{\cmeasure \cone}{\angles {\cnmatches \cone, \csize \cone}}{By definition}
	\continueltPf{\cmeasure {\cexists \tv \cone}}{Above}
\Hand   \continueltPf{\cmeasure {\clet \x \tv \cone \ctwo}}{Transitivity}
      \end{llproof}

  \proofcasederivation
      {App}
      {\semenv(\t) \in \semenv(\x)}
      {\semenv \th \capp \x \t}

      \begin{llproof}
	No non-trivial premises.
      \end{llproof}

  \proofcasederivation
      {Susp-Ctx}
      {\Cshape \C \t \sh \\ \semenv \th \C\where{\cmatched \t \sh \cbrs}}
      {\semenv \th \C\where{\cmatch \t \cbrs}}

      \begin{llproof}
	&$\Cshape \C \t \sh$ $=$\, &$\forall \semenvp, \gt.\, \semenvp \th \cerase {\C\where{\cunif \t \gt}}$ & By definition \\
	&&\qquad\qquad $\implies \shape \gt = \sh$ \\
	\eqPf{\cnmatches {\cerase {\C\where{\cunif \t \gt}}}}{0}{Erasure removes all matches}
	\continueltPf{1}{}
	\continueleqPf{\cnmatches {\C\where{\cmatch \t \cbrs}}}{}
	\eqPf{\cmeasure {\cerase {\C\where{\cunif \t \gt}}}}{\angles {0, \csize {\cerase {\C\where{\cunif \t \gt}}}}}{}
\Hand 	\continueltPf{\cmeasure {\C\where{\cmatch \t \cbrs}}}{Above}
	\decolumnizePf
	\eqPf{\cnmatches {\C\where{\cmatched \t \sh \cbrs}}}{\cnmatches \C}{By definition}
	\continueltPf{1 + \cnmatches \C}{}
	\continueeqPf{\cnmatches {\C\where{\cmatch \t \cbrs}}}{By definition}
	\eqPf{\cmeasure {\C\where{\cmatched \t \sh \cbrs}}}
	  {\angles {\cnmatches \C, \csize {\C\where{\cmatched \t \sh \cbrs}}}}
	  {}
\Hand 	\continueltPf{\cmeasure {\C\where{\cmatch \t \cbrs}}}{Above}
    \end{llproof}

  \proofcasederivation
      {Multi-Unif}
      {\all {\t \in \ueq} \semenv(\t) = \gt}
      {\semenv \th \ueq}

      \begin{llproof}
	No non-trivial premises.
      \end{llproof}

  \proofcasederivation
      {LetR}
      {\semenv \th \cexists {\tv, \tvs} \cone \\ \semenv\where{\x \is \semenv(\cabsr \tv \tvs \ctwo)} \th \ctwo}
      {\semenv \th \cletr \x \tv \tvs \cone \ctwo}

      \begin{llproof}
	Similar to the \Rule{Let} case.
      \end{llproof}

  \proofcasederivation
      {AppR}
      {\semenv(\x) = \gabsr \tv \tvs \\ \semenv(\t) \in \glam}
      {\semenv \th \capp \x \t}

      \begin{llproof}
	No non-trivial premises.
      \end{llproof}


  \proofcasederivation
      {Papp}
      {\semenv(\x) = \gabsr \tv \tvs \\ \dom \ren \subseteq \tvs \\ \semenv\where{\tv \is \semenv(\t)} \th \ueqs\where\ren \implies \semenv(\t) \in \glam}
      {\semenv \th \cpapp \x \ren \ueqs \t}

      \begin{llproof}
	\eqPf{\csize {\ueqs\where\ren}}{\csize \ueqs}{Renaming preserves size}
	\eqPf{\cnmatches {\cpapp \x \ren \ueqs \t}}{0}{By definition}
	\continueeqPf{\cnmatches {\ueqs\where\ren}}{Multi-equations do not contain matches}
	\ltPf{\csize \ueqs}{\csize {\cpapp \x \ren \ueqs \t}}{By definition}
	\eqPf{\cmeasure {\ueqs\where\ren}}{\angles {0, \csize {\ueqs\where\ren}}}{By definition}
	\continueltPf{\cmeasure {\cpapp \x \ren \ueqs \t}}{}
      \end{llproof}
\end{itemize}
\end{proof}

\subsection{Canonicalization of satisfiability}

This section aims at proving the canonicalization of satisfiability, that is,
for any $\semenv \th \c$, there is a canonical derivation $\semenv \Th \c$.
%
We begin by proving some auxillary lemmas regarding inversion and
entailment in our system.

\begin{lemma}
  \label{lem:match-tv-is-not-simple}
  For any constraint context $\C\where{\square}$,
  the constraint $\C\where{\cmatch \t \cbrs}$ is not simple.
  \begin{proof}
    Structural induction on $\C$.
  \end{proof}
\end{lemma}

\newcommand{\simplePf}[2]{\Pf{}{}{#1 \simple}{#2}}
\newcommand{\nsimplePf}[2]{\Pf{}{\neg}{#1 \simple}{#2}}
\newcommand{\shapePf}[4]{\Pf{}{}{\Cshape {#1} {#2} {#3}}{#4}}

\begin{lemma}[Simple inversion]
  Given $\semenv \th \c$ and $\c \simple$. Then:
  \begin{enumerate}[(\roman*)]
    \item If $\c = \cunif \tone \ttwo$, then $\semenv(\tone) = \semenv(\ttwo)$.
    \item If $\c = \capp \x \t$, then $\semenv(\t) \in \semenv(\x)$.
    \item If $\c =  \cpapp \x \ren \ueqs$, then $\semenv(\x) = \gabsr \tv \tvs$, $\dom \ren \subseteq \tvs$, and $\semenv\where{\tv \is \semenv(\t)} \th \ueqs\where\ren \implies \semenv(\t) \in \glam$.
    \item If $\c = \cone \cand \ctwo$, then $\semenv \th \cone$ and $\semenv \th \ctwo$.
    \item If $\c = \cexists \tv \c$, then $\semenv\where{\tv \is \gt} \th \c$ for some $\gt$.
    \item If $\c = \cfor \tv \c$, then $\semenv\where{\tv \is \gt} \th \c$ for all $\gt$.
    \item If $\c = \clet \x \tv \cone \ctwo$, then $\semenv \th \cexists \tv \cone$ and $\semenv\where{\x \is \semenv(\cabs \tv \cone)} \th \ctwo$.
  \end{enumerate}
  \begin{proof}~
    \begin{enumerate}[(\roman*)]
      \item Case analysis on the given derivation $\semenv \th \cunif \tone \ttwo$.
	There is a unique case for the atomic constraint $\cunif \tone \ttwo$:
	\begin{itemize}
	    \proofcasederivation
	      {Unif}
	      {\semenv(\tone) = \semenv(\ttwo)}
	      {\semenv \th \cunif \tone \ttwo}

	    \begin{llproof}
\Hand 		\eqPf{\semenv(\tone)}{\semenv(\ttwo)}  {Premise}
	    \end{llproof}
	\end{itemize}

      \item Similar to \Rule{Unif} case.
      \item Similar to \Rule{Unif} case.

      \item Case analysis on the given derivation $\semenv \th \cone \cand \ctwo$.
      \begin{itemize}
	\proofcasederivation
	  {Conj}
	  {\semenv \th \cone \\ \semenv \th \ctwo}
	  {\semenv \th \cone \cand \ctwo}

	\begin{llproof}
\Hand 	  \vdashPf{\semenv}{\cone} {Premise}
\Hand     \vdashPf{\semenv}{\ctwo} {Premise}
	\end{llproof}

	\proofcasederivation
	  {Susp-Ctx}
	  {\Cshape \C \tv \sh \\ \semenv \th \C\where{\cmatchesz \tv \sh \cbrs}}
	  {\semenv \th \C\where{\cmatch \tv \cbrs}}

	\begin{llproof}
	  \eqPf{\c}{\C\where{\cmatch \tv \cbrs}} {Given}
	  \simplePf{\C\where{\cmatch \tv \cbrs}} {\ditto}
	  \nsimplePf{\C\where{\cmatch \tv \cbrs}} {By \cref{lem:match--tv-is-not-simple}}
\Hand 	  \contraPf{\semenv \th \cone, \semenv \th \ctwo}


	\end{llproof}

      \end{itemize}

      \item Similar to \Rule{Conj} case.
      \item Similar to \Rule{Conj} case.
      \item Similar to \Rule{Conj} case.
    \end{enumerate}
  \end{proof}
\end{lemma}

\begin{lemma}[Simple congruence]
  Given simple constraints $\cone, \ctwo$ and simple context $\C$.
  If \\$\cone \centails \ctwo$, then $\C\where{\cone} \centails \C\where{\ctwo}$.
  \begin{proof}
    Induction on the derivation of $\C \simple$.
  \end{proof}
\end{lemma}



\begin{lemma}[Composability of unicity]
  If $\Cshape \Ca \t \sh$, then $\Cshape {\Cb\where\Ca} \t \sh$.
  \begin{proof}
    \TODO{This proof needs doing}
  \end{proof}
\end{lemma}

\begin{lemma}[Decanonicalization]
  If $\semenv \Th \c$, then $\semenv \th \c$.
  \begin{proof}
    Induction on the given derivation $\semenv \Th \c$
  \end{proof}
\end{lemma}

\newcommand{\VdashPf}[3]{\Pf{#1}{\Vdash}{#2}{#3}}
\begin{theorem}[Canonicalization]
  If $\semenv \th \c$, then $\semenv \Th \c$.
  \begin{proof}
  We proceed by induction on the height of the derivation $\deriv :: \semenv \th \c$.
    \TODO{This induction hypothesis is too weak, we likely need a measure on the height
    of the derivation + num of match constraints}
  \begin{itemize}
    \proofcasederivation
      {True}
      {}
      {\semenv \th \ctrue}

      \begin{llproof}
	\simplePf{\ctrue}{By definition}
\Hand 	\VdashPf{\semenv}{\ctrue}{By \Rule{Can-Base}}
      \end{llproof}
    \proofcasederivation
      {Unif}
      {\semenv(\tone) = \semenv(\ttwo)}
      {\semenv \th \cunif \tone \ttwo}

      \begin{llproof}
	Similar to the \Rule{True} case.
      \end{llproof}
    \proofcasederivation
      {Conj}
      {\semenv \th \cone \\ \semenv \th \ctwo}
      {\semenv \th \cone \cand \ctwo}

      \begin{llproof}
	\vdashPf{\semenv}{\cone} {Premise}
	\vdashPf{\semenv}{\ctwo} {Premise}
	\VdashPf{\semenv}{\cone} {By \ih}
	\VdashPf{\semenv}{\ctwo} {By \ih}
	\decolumnizePf
	\casesPf{\semenv \Th \cone, \semenv \Th \ctwo}
      \end{llproof}

      \begin{itemize}
	\proofcasederivationdouble
	  {Can-Base}
	  {\semenv \th \cone \\ \cone \simple}
	  {\semenv \Th \cone}
	  {Can-Base}
	  {\semenv \th \ctwo \\ \ctwo \simple}
	  {\semenv \Th \ctwo}

	  \begin{llproof}
	    \simplePf{\cone}{Premise}
	    \simplePf{\ctwo}{Premise}
	    \simplePf{\cone \cand \ctwo}{By \Rule{Simple-Conj}}
\Hand 	    \VdashPf{\semenv}{\cone \cand \ctwo}{By \Rule{Can-Base}}

	  \end{llproof}

	\proofcasederivationdouble
	  {Can-Susp-Ctx}
	  {\Cshape \C \t \sh \\ \semenv \Th \C\where{\cmatched \t \sh \cbrs}}
	  {\semenv \Th \underbrace{\C\where{\cmatch \t \cbrs}}_\ca}
	  {}
	  {}
	  {\semenv \Th \cb}

	  \begin{llproof}

	    \VdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs}} {Premise}
	    \vdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs}} {Lemma XXX}
	    \vdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs} \cand \cb}{By \Rule{Conj}}
 	    \VdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs} \cand \cb}{By \ih}
	    \Pf{}{}{\Cshape \C \tv \sh}{Premise}
 	    \Pf{}{}{\Cshape {\parens {\C \cand \cb}} \tv \sh}{Lemma XXX}
\Hand 	    \VdashPf{\semenv}{\C\where{\cmatch \t \cbrs}}{By \Rule{Con-Susp-Ctx}}
	  \end{llproof}

	\proofcasederivationdouble
	  {}
	  {}
	  {\semenv \Th \ca}
	  {Can-Susp-Ctx}
	  {\Cshape \C \t \sh \\ \semenv \Th \C\where{\cmatched \t \sh \cbrs}}
	  {\semenv \Th \underbrace{\C\where{\cmatch \t \cbrs}}_\cb}

	  \begin{llproof}
	    \Pf{}{}{}{Symmetric to the above case.}
	  \end{llproof}
      \end{itemize}

      \proofcasederivation
	{Exists}
	{\semenv\where{\tv \is \gt} \th \c}
	{\semenv \th \cexists \tv \c}

	\begin{llproof}
	  \vdashPf{\semenv\where{\tv \is \gt}}{\c}{Premise}
	  \VdashPf{\semenv\where{\tv \is \gt}}{\c}{By \ih}
	  \casesPf{\semenv\where{\tv \is \gt} \Th \c}
	\end{llproof}

	\begin{itemize}

	    \proofcasederivation
	      {Can-Base}
	      {\semenv\where{\tv \is \gt} \th \c \\ \c \simple}
	      {\semenv\where{\tv \is \gt} \Th \c}

	      \begin{llproof}
		\simplePf{\c}{Premise}
		\simplePf{\cexists \tv \c}{By \Rule{Simple-Exists}}
\Hand 		\VdashPf{\semenv}{\cexists \tv \c}{By \Rule{Can-Base}}
	      \end{llproof}


	      \proofcasederivation
		{Can-Susp-Ctx}
		{\Cshape \C \t \sh \\ \semenv\where{\tv \is \gt} \Th \C\where{\cmatched \t \sh \cbrs}}
		{\semenv \Th \underbrace{\C\where{\cmatch \t \cbrs}}_\c}

		\begin{llproof}
		  \VdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatched \t \sh \cbrs}}{Premise}
		  \vdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatched \t \sh \cbrs}}{Lemma XXX}
		  \vdashPf{\semenv}{\cexists \tv \C\where{\cmatched \t \sh \cbrs}}{By \Rule{Exists}}
		  \VdashPf{\semenv}{\cexists \tv \C\where{\cmatched \t \sh \cbrs}}{By \ih}
		  \Pf{}{}{\Cshape \C \t \sh}{Premise}
		  \Pf{}{}{\Cshape {\parens {\cexists \tv \C}} \t \sh}{Lemma XXX}
\Hand             \VdashPf{\semenv}{\cexists \tv \C\where{\cmatch \t \cbrs}}{By \Rule{Can-Susp-Ctx}}
		\end{llproof}
	\end{itemize}

	\proofcasederivation
	  {Forall}
	  {\forall \gt,~ \semenv\where{\tv \is \gt} \th \c}
	  {\semenv \th \cfor \tv \c}

	  \begin{llproof}
	    Similar to the \Rule{Exists} case.
	  \end{llproof}

	\proofcasederivation
	  {Let}
	  {\semenv \th \cexists \tv \cone \\ \semenv\where{\x \is \semenv(\cabs \tv \cone)} \th \ctwo}
	  {\semenv \th \clet \x \tv \cone \ctwo}

	  \begin{llproof}
	    \vdashPf{\semenv}{\cexists \tv \cone}{Premise}
	    \VdashPf{\semenv}{\cexists \tv \cone}{By \ih}
	    \vdashPf{\semenv\where{\x \is \semenv(\cabs \tv \cone)}}{\ctwo}{Premise}
	    \VdashPf{\semenv\where{\x \is \semenv(\cabs \tv \cone)}}{\ctwo}{By \ih}
	    \decolumnizePf
	    \casesPf{\semenv \Th \cexists \tv \cone, \semenv\where{\x \is \semenv(\cabs \tv \cone)} \Th \ctwo}
	  \end{llproof}

	  \begin{itemize}
	    \proofcasederivationdouble
	      {Can-Base}
	      {\semenv \th \cexists \tv \cone \\ \cexists \tv \cone \simple}
	      {\semenv \Th \cexists \tv \cone}
	      {Can-Base}
	      {\semenv\where{\x \is \semenv(\cabs \tv \cone)} \th \ctwo \\ \ctwo \simple}
	      {\semenv\where{\x \is \semenv(\cabs \tv \cone)} \Th \ctwo}

	      \begin{llproof}
		\simplePf{\cexists \tv \cone}{Premise}
		\simplePf{\cone}{Inversion of \Rule{Simple-Exists}}
		\simplePf{\ctwo}{Premise}
		\simplePf{\clet \x \tv \cone \ctwo}{By \Rule{Simple-Let}}
\Hand		\VdashPf{\semenv}{\clet \x \tv \cone \ctwo}{By \Rule{Can-Base}}
	      \end{llproof}

	    \proofcasederivationdouble
	      {Can-Susp-Ctx}
	      {\Cshape {\parens {\cexists \tv \cone}} \t \sh \\ \semenv \Th \cexists \tv \C\where{\cmatched \t \sh \cbrs}}
	      {\semenv \Th \cexists \tv \underbrace{\C\where{\cmatch \t \cbrs}}_\ca}
	      {}
	      {}
	      {\semenv\where{\x \is \semenv(\cabs \tv \cone)} \Th \ctwo}

	      \begin{llproof}
		\shapePf{\parens {\cexists \tv \C}}{\t}{\sh}{Premise}
		\shapePf{\C}{\t}{\sh}{Lemma XXX}
		\VdashPf{\semenv}{\cexists \tv \C\where{\cmatched \t \sh \cbrs}}{Premise}
		\vdashPf{\semenv}{\cexists \tv \C\where{\cmatched \t \sh \cbrs}}{Lemma XXX}
		\eqPf{\semenv(\cabs \tv \cone)}{\semenv(\cabs \tv \C\where{\cmatched \t \sh \cbrs})}{Lemma XXX}
		\vdashPf{\semenv}{\clet \x \tv {\C\where{\cmatched \t \sh \cbrs}} \ctwo}{By \Rule{Let}}
		\VdashPf{\semenv}{\clet \x \tv {\C\where{\cmatched \t \sh \cbrs}} \ctwo}{By \ih}
		\shapePf{\parens{\clet \x \tv \C \ctwo}}{\t}{\sh}{Lemma XXX}
\Hand 		\VdashPf{\semenv}{\clet \x \tv {\C\where{\cmatch \t \cbrs}} \ctwo}{By \Rule{Can-Susp-Ctx}}
	      \end{llproof}

	    \proofcasederivationdouble
		{}
		{}
		{\semenv \Th \cexists \tv \cone}
		{Can-Susp-Ctx}
		{\Cshape \C \t \sh \\ \semenv\where{\x \is \semenv(\cabs \tv \cone)} \Th \C\where{\cmatched \t \sh \cbrs}}
		{\semenv\where{\x \is \semenv(\cabs \tv \cone)} \Th \underbrace{\C\where{\cmatch \t \cbrs}}_\cb}

		\begin{llproof}
		  \shapePf{\C}{\t}{\sh}{Premise}
		  \shapePf{\parens{\clet \x \tv \cone \C}}{\t}{\sh}{Lemma XXX}
		  \VdashPf{\semenv\where{\x \is \semenv(\cabs \tv \cone)}}{\C\where{\cmatched \t \sh \cbrs}}{Premise}
		  \vdashPf{\semenv\where{\x \is \semenv(\cabs \tv \cone)}}{\C\where{\cmatched \t \sh \cbrs}}{Lemma XXX}
		  \vdashPf{\semenv}{\clet \x \tv \cone {\C\where{\cmatched \t \sh \cbrs}}}{By \Rule{Let}}
		  \VdashPf{\semenv}{\clet \x \tv \cone {\C\where{\cmatched \t \sh \cbrs}}}{By \ih}
\Hand 		  \VdashPf{\semenv}{\clet \x \tv \cone {\C\where{\cmatch \t \sh}}}{By \Rule{Can-Susp-Ctx}}
		\end{llproof}
	  \end{itemize}

      \proofcasederivation
	{App}
	{\semenv(\t) \in \semenv(\x)}
	{\semenv \th \capp \x \t}

      \begin{llproof}
	Similar to the \Rule{True} case.
      \end{llproof}
  \end{itemize}
  \end{proof}
\end{theorem}


\section{Examples of suspended match constraints}

\Xgabriel{We have a problem in this definition, due to the fact that $\phi$ also contains polymorphic schemes, which are not necessarily the same as the one at the point where we use the \Rule{Susp-Ctx} rule. For example when the current environment $\phi$ has $x : \forall \alpha. \tint$, one would expect that $\phi \vdash \capp x \alpha \cand \cmatch \alpha \dots$ is satisfiable as $\capp x \alpha$ is morally equivalent to $\alpha = \tint$, but technically it is not because we can pick $\phi' := [x := \forall \alpha. \tbool]$.}
\Xalistair{Actually it's okay if this example fails, the ``fix'' is to use a wider $\C$ that contains the $\mathsf{let}~ x$ definition as part of the constraint.}
\Xgabriel{This example/discussion should go in the Unicity Testsuite Appendix.}

%
%\section{Well-foundedness of satisfiability}

%\section{Well-foundedness of \OML typing rules}
%
%\Xalistair{The same problem of well-foundedness comes up
%with the \OML typing rules. Should we have a separate
%section? Or deal with it in the above section (A single
%section for well-foundedness concerns)}
%
%\section{Ordered substitutions and unifiers}
%
%An ordered substitution $\sub$ is a refinement on substitutions, which
%defines the scope of existential variables in solutions and controls the free
%variables of their solutions.
%
%\begin{mathpar}
%  \begin{bnfgrammar}
%    \entry[Ordered substitution]{\sub}{
%      \cdot
%      \and \sub, \tv
%      \and \sub, \tv := \t
%      \and \sub, \x := \cabs \tv \c
%    }
%  \end{bnfgrammar}
%\end{mathpar}
%Like typing contexts $\G$, substitutions $\sub$ are ordered and contain
%delcarations of polymorphic variables ($\tv$), they also provide term variable
%bindings ($\x \is \cabs \tv \c$). Unlike typing contexts, ordered substitutions
%$\sub$ also contain declarations of existential (flexible) type variables with
%solutions ($\tv \is \t$). We write $\dom \sub$ for the sequence of type
%variables and term variables defined in $\sub$.
%
%The well-formedness of substitutions $\sub$, written $\th \sub$ and defined
%below, enforces an order: if $\sub = \sub_L, \tv \is \t, \sub_R$, the solution
%$\t$ must be well-formed under $\sub_L$.
%
%\begin{mathpar}
%  \infer[Sub-Emp-Wf]
%    {}
%    {\th \eset}
%
%  \infer[Sub-TyVar-Wf]
%    {\th \sub}
%    {\th \sub, \tv}
%
%  \infer[Sub-TyAssn-Wf]
%    {\th \sub \\ \sub \th \t}
%    {\th \sub, \tv \is \t}
%
%  \infer[Sub-Var-Wf]
%    {\th \sub \\ \dom \sub \th \cabs \tv \c}
%    {\th \sub, \x \is \cabs \tv \c}
%\\
%  \infer[S-Var-Wf]
%    {\tv \in \dom \sub}
%    {\sub \th \tv}
%
%  \infer[S-Unit-Wf]
%    {}
%    {\sub \th \tunit}
%
%  \inferrule[S-Arr-Wf]
%    {\sub \th \t \\ \sub \th \tp}
%    {\sub \th \t \to \tp}
%
%  \inferrule[S-Prod-Wf]
%    {(\sub \th \ti)\iton}
%    {\sub \th \Pi\iton \ti}
%
%  \inferrule[S-Rcd-Wf]
%    {(\sub \th \ti)\iton \\
%     \T \in \dom \Omega}
%    {\sub \th \tys \T}
%
%  \inferrule[S-Poly-Wf]
%    {\sub \th \ts}
%    {\sub \th \tpoly \ts}
%
%  \inferrule[S-Forall-Wf]
%    {\sub, \tv \th \ts}
%    {\sub \th \tfor \tv \ts}
%
%\end{mathpar}
%Ordered substitutions $\sub$ can be viewed as parallel substitutions on types,
%substitutiong solved existential variables. We write $\sub(\t)$ for $\sub$
%applied as a substitution to type $\t$:
%\begin{mathpar}
%  \begin{tabular}{RCLL}
%    \sub(\tv) &\eqdef&
%      \begin{cases}
%	\theta(\t) &\text{if } \tv \is \t \in \theta \\
%	\tv &\text{otherwise}
%      \end{cases}\\
%    \sub(\tunit) &\eqdef& \tunit \\
%    \sub(\t \to \tp) &\eqdef& \sub(\t) \to \sub(\tp) \\
%    \sub(\Pi\iton \ti) &\eqdef& \Pi\iton \sub(\ti) \\
%    \sub(\tys \Tapp) &\eqdef& \sub(\tys) \Tapp \\
%    \sub(\tpoly \ts) &\eqdef& \tpoly {\sub(\ts)} \\
%    \sub(\tfor \tv \ts) &\eqdef& \tfor \tv \sub(\ts) &\text{if } \tv \disjoint
%    \sub
%  \end{tabular}
%\end{mathpar}
%
%We can interpret $\sub$ as a set of semantic environments, written $\csem
%\sub$.
%\TODO{Semantic environments should not be ordered}
%\begin{mathpar}
%  \begin{tabular}{RCL}
%      \csem \cdot &\eqdef& \set {\cdot} \\
%      \csem {\sub, \tv} &\eqdef& \set{\semenv[\tv \is \gt] : \semenv \in \csem
%      \sub} \\
%      \csem {\sub, \tv \is \t} &\eqdef& \set{\semenv[\tv \is \semenv(\t)] :
%	\semenv \in \csem \sub} \\
%      \csem {\sub, \x \is \cabs \tv \c} &\eqdef& \set{\semenv[\x \is
%      \semenv(\cabs \tv \c)] : \semenv \in \csem \sub}
%  \end{tabular}
%\end{mathpar}
%
%We say that $\sub$ is a \emph{unifier} of $\c$ iff $\all {\semenv } \semenv
%\in \csem \sub \implies \semenv \th \c$.
%
%\begin{lemma}
%  If $\sub$ is unifier of $\cexists \tv \c$, there exists type $\t$ such that
%  $\sub \th \t$ and $\sub, \tv \is \t$ is a unifier of $\c$. Conversely,
%  if $\sub, \tv \is \t$ is a unifier of $\c$, then $\sub$ is a unifier of
%  $\cexists \tv \c$.
%
%
%\end{lemma}
%
%\TODO{Add some more stuff on ordered substitutions and unifiers (probably on
%an as need basis)}
%
%\section{Proofs for \cref{sec:constraint-gen}}
%
%In this appendix, we give the details for proving the soundness and completeness
%of the constraint generator, that is $\G \th \e : \ts$ if and only if
%$\cdot \th \cinfer {\G \th \e} \ts$. We begin by reformulating this statement using
%unifiers.
%%
%We write $\csem \G$ for the set of semantic environments induced by $\G$:
%\begin{mathpar}
%  \begin{tabular}{RCL}
%    \csem \cdot &\eqdef& \set \cdot \\
%    \csem {\G, \tv} &\eqdef& \set{\semenv[\tv \is \gt] : \semenv \in \csem \G} \\
%    \csem {\G, \x : \ts} &\eqdef& \set{\semenv[\x \is \semenv(\cabs \tv \ts \leq \tv)] : \semenv \in \csem \G}
%  \end{tabular}
%\end{mathpar}
%
%\begin{lemma}
%  $\cdot \th \csem{\G \th \e : \ts}$ if and only if $\csem \G \Vdash \cinfer \e \ts$
%  \begin{proof}
%    Induction on $\G$.
%  \end{proof}
%\end{lemma}
%
%We also relate $\G$ and ordered substitutions with the translation $\pparens \G$:
%\begin{mathpar}
%  \begin{tabular}{RCL}
%    \pparens \cdot &\eqdef& \cdot \\
%    \pparens {\G, \tv} &\eqdef& \pparens \G, \tv \\
%    \pparens {\G, \x : \ts} &\eqdef& \pparens \G, \x \is \cabs \tv \ts \leq \tv
%  \end{tabular}
%\end{mathpar}
%
%\begin{lemma}
%  $\csem \G = \csem {\pparens \G}$.
%  \begin{proof}
%    Induction on $\G$.
%  \end{proof}
%\end{lemma}
%
%We can now reformulate soundness and completeness as:
%$\G \th \e : \ts$ if and only if $\pparens \G$ is a
%unifier of $\cinfer \e \ts$.
%
%
%
%\begin{lemma}[X-soundness and completeness]
%  For the explicit term $\e$, we have
%  $\G \th \e : \ts$ if and only if $\pparens \G$ is a unifier of $\cinfer \e \ts$.
%  \begin{proof}
%    Structural induction on $\e$.
%  \end{proof}
%\end{lemma}
%
%\pagebreak
%\section{Unicity properties}
%
%\newcommand{\cscmmatch}[2]{\angles{#1}#2}
%\newcommand{\cscmmatchsub}[3]{\angles{#1 \is #2}#3}
%\newcommand{\Csshape}[4]{{#1}\where{\cscmmatch{#2}{#3} \uni #4}}
%\newcommand{\Cscshape}[7]{{#1}\where{\cscmmatch{#2}{#3} \uni {#4} \mid \csmatch{#5}{#6} \uni {#7}}}
%\newcommand{\cbrsp}{\cbrs'}
%
%In this section, we give details of the unicity predicate along with our main result: \emph{inversion of suspension}.
%We recall the following definition of unicity:
%
%\begin{definition}[Unicity]
%  The type variable $\tv$ has a uniquely known principal shape $\sh$ in the context $\C$,
%  written $\Cshape \C \tv \sh$ (or $\Csshape \C \tv \cbrs \sh$), iff for all assignments
%  $\semenv$ and ground types $\gt$, then $\C\where{\cunif \tv \gt}$ implies that the
%  principal shape of $\gt$ is equal to $\sh$:
%  \begin{mathpar}
%    \Csshape \C \tv \cbrs \sh \uad\eqdef\uad \all {\semenv, \gt} \; \semenv \th \C\where{\cunif \tv \gt} \implies \shape \gt = \sh
%  \end{mathpar}
%\end{definition}
%
%We introduce the notation $\Csshape \C \tv \cbrs \sh$ to be more consistent with our later notation on
%\emph{joint} and \emph{conditional} unicity.
%
%\begin{lemma}
%  If $\Csshape \Cb \tv \cbrs \sh$, then $\Csshape {\parens {\Ca\where\Cb}} \tv \cbrs \sh$.
%  \begin{proof}
%    Induction on $\Ca$.
%  \end{proof}
%\end{lemma}
%
%\begin{definition}[Conditional unicity] For two type variables $\tv, \tvp$, $\tv$ has the conditionally
%  known shape $\sh$ given that $\tvp$ has the shape $\shp$
%  within the match $\cscmmatch \tvp \cbrsp$, written
%  $\Cscshape \C \tv \cbrs \sh \tvp \cbrsp \shp$, is defined as:
%  \begin{mathpar}
%    \Cscshape \C \tv \cbrs \sh \tvp \cbrsp \shp \uad\eqdef\uad \Csshape {\parens{\C\where{\square, \cscmmatchsub \tvp \shp \cbrsp}}} \tv \cbrs \sh
%  \end{mathpar}
%
%  Here $\C$ is a two-hole context and $\C\where{\square, \cscmmatchsub \tvp \shp \cbrsp}$ is a one-hole context used in
%  the unicity predicate.
%\end{definition}
%
%
%\begin{theorem}[Bayes' theorem]
%  \begin{mathpar}
%    \Cscshape \C \tv \cbrs \sh \tvp \cbrsp \shp \wedge \Csshape {\parens{\C\where{\cscmmatch \tv \cbrs, \square}}} \tvp \cbrsp \shp \\
%    \iff \\
%    \Cscshape \C \tvp \cbrsp \shp \tv \cbrs \sh \wedge \Csshape {\parens{\C\where{\square, \cscmmatch \tvp \cbrsp}}} \tv \cbrs \sh
%  \end{mathpar}
%  \begin{proof}
%    ??
%  \end{proof}
%\end{theorem}
%
%
%\begin{theorem}[Inversion of suspension]
%  $\semenv \th \C\where{\cmatch \tv \cbrs}$ if and only if
%  $\Cshape \C \tv {\any \tvcs \t}$ and $\semenv \th \C\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs}$ for some $\tvcs, \t$.
%  \begin{proof}
%    The backwards direction is trivial, using \Rule{Susp-Ctx}.
%    We now consider the forwards direction, by induction on the given derivation.
%
%    \proofcase{\Rule{True}, \Rule{Multi-Unif}, \Rule{App}, \Rule{Susp-Use}, \Rule{AppR}, \Rule{Papp}} Impossible.
%
%    \proofcase{\Rule{Conj}}
%      \begin{mathpar}
%	\infer[Conj]
%	  {\semenv \th \cone \\ \semenv \th \ctwo}
%	  {\semenv \th \cone \cand \ctwo}
%      \end{mathpar}
%      We have $\C\where{\cmatch \tv \cbrs} = \cone \cand \ctwo$. Consider
%      cases on $\C$:
%      \begin{itemize}
%	\item \proofcase{$\C = \Cp \cand \ctwo$}
%	  So we have $\semenv \th \Cp\where{\cmatch \tv \cbrs}$.
%	  By induction, we have $\Cshape \Cp \tv {\any \tvcs \t}$ and
%	  $\semenv \th \Cp\where{\cexists \tvcs \cunif \tv \tvcs \cand \cmatch \t \cbrs}$.
%	  By Lemma ??, we have $\Cshape {\parens {\Cp \cand \ctwo}} \tv {\any \tvcs \t}$.
%	  By \Rule{Conj}, we have
%	  \begin{mathpar}
%	    \infer[Conj]
%	      {\semenv \th \Cp\where{\cexists \tvcs \cunif \tv \tvcs \cand \cmatch \t \cbrs} \\
%	       \semenv \th \ctwo}
%	      {\semenv \th \parens{\Cp \cand \ctwo}\where{\cexists \tvcs \cunif \tv \tvcs \cand \cmatch \t \cbrs}}
%	  \end{mathpar}
%	\item \proofcase{$\C = \cone \cand \Cp$}
%	  Symmetric.
%      \end{itemize}
%
%    \proofcase{\Rule{Let}}
%      \begin{mathpar}
%	\infer[Let]
%	  {\semenv \th \cexists \tvb \cone \\
%	   \semenv, \x \is \semenv(\cabs \tvb \cone) \th \ctwo}
%	  {\semenv \th \clet \x \tvb \cone \ctwo}
%      \end{mathpar}
%      We have $\C\where{\cmatch \tv \cbrs} = \clet \x \tv \cone \ctwo$.
%      Consider cases on $\C$:
%      \begin{itemize}
%	\item \proofcase{$\C = \clet \x \tvb \Cp \ctwo$}
%	  So we have $\semenv \th \cexists \tvb \Cp\where{\cmatch \tv \cbrs}$ (1)
%	  and $\semenv, \x \is \semenv(\cabs \tvb \Cp\where{\cmatch \tv \cbrs}) \th \ctwo$ (2).
%
%	  By induction (1), we have $\cexists \tvb \Cshape \Cp \tv {\any \tvcs \t}$ and $\semenv \th \cexists \tvb
%	  \Cp\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs}$. By Lemma ??, we have $\Cshape \Cp \tv {\any \tvcs \t}$.
%
%	  We now claim that $\semenv(\cabs \tvb \Cp\where{\cmatch \tv \cbrs}) = \semenv(\cabs \tvb \Cp\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs})$.
%	  That is $\semenv, \tvb \is \gt \th \Cp\where{\cmatch \tv \cbrs} \iff \semenv, \tvb \is \gt \th \Cp\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs}$.
%	  This follows directly from induction, as we have $\Cshape \Cp \tv {\any \tvcs \t}$.
%
%	  So we have $\semenv, \x \is \semenv(\cabs \tvb \Cp\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs}) \th \ctwo$ from (2).
%	  Applying Lemma ??, we have $\Cshape {\parens {\clet \x \tvb \Cp \ctwo}} \tv {\any \tvcs \t}$, and applying the \Rule{Let} rule
%	  gives us:
%	  \begin{mathpar}
%	    \infer[Let]
%	      {\semenv \th \cexists \tvb \Cp\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs} \\
%	       \semenv, \x \is \semenv(\cabs \tvb \Cp\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs}) \th \ctwo}
%	      {\semenv \th \parens {\clet \x \tvb \Cp \ctwo} \where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs} }
%	  \end{mathpar}
%
%
%
%
%	\item \proofcase{$\C = \clet \x \tvb \cone \Cp$}
%	  Similiar to the \Rule{Conj} case.
%
%      \end{itemize}
%
%
%    \proofcase{\Rule{Exists}}
%      \begin{mathpar}
%	\infer[Exists]
%	  {\semenv, \tvb \is \gt \th \c}
%	  {\semenv \th \cexists \tvb \c}
%      \end{mathpar}
%
%      We have $\C\where{\cmatch \tv \cbrs} = \cexists \tvb \c$.
%      Hence $\C = \cexists \tvb \Cp$ and $\Cp\where{\cmatch \tv \cbrs} = \c$.
%
%      By induction, we have $\Cshape \Cp \tv {\any \tvcs \t}$
%      and $\semenv, \tvb \is \gt \th \Cp\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs}$.
%
%      By Lemma ??, we have $\Cshape {\parens {\cexists \tvb \Cp}} \tv {\any \tvcs \t}$.
%      Applying \Rule{Exists} gives us:
%      \begin{mathpar}
%	\infer[Exists]
%	  {\semenv, \tvb \is \gt \th \Cp\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs}}
%	  {\semenv \th \cexists \tvb \Cp\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs}}
%      \end{mathpar}
%
%
%    \proofcase{\Rule{Forall}} Similiar to the \Rule{Exists} case.
%
%    \proofcase{\Rule{Susp-Ctx}}
%      \begin{mathpar}
%	\infer[Susp-Ctx]
%	  {\Cshape \Cp \tvp {\any \tvcs' \typ} \\
%	   \semenv \th \Cp\where{\cexists {\tvcs'} \cunif \tvp \typ \cand \cmatch \typ \cbrs'}}
%	  {\semenv \th \Cp\where{\cmatch \tvp \cbrs'}}
%      \end{mathpar}
%
%      Consider whether $\C = \Cp$:
%      \begin{itemize}
%	\item \proofcase{$\C = \Cp$} Trivial
%	\item \proofcase{$\C \neq \Cp$}
%	  Bayes' theorem + induction
%      \end{itemize}
%  \end{proof}
%\end{theorem}
%
%%
%%We write $\e^i$ for an \emph{implicit} term, which is either: $\eproj \e j$, $\einst \e$, $\epoly \e$.
%%Let us define $x(\e^i, \sh)$ for the explicit elaboration of an implicit term $\e^i$ using the
%%shape $\sh$:
%%\begin{align*}
%%  x(\eproj \e j, \any \tvcs \Pi\iton \tvcs) &= \eproj[n] \e j \\
%%  x(\einst \e, \any \tvcs \tpoly \ts) &= \exinst \e \tvcs \ts \\
%%  x(\epoly \e, \any \tvcs \tpoly \ts) &= \expoly \e {\exi \tvcs \ts}
%%\end{align*}
%%
%%\begin{theorem}
%%  $\G \th \E\where{\e^i} : \ts$ if and only if
%%  $\E\where{\e \mathop{\triangleleft\triangleright} \sh}$ and $\G \th \E\where{x(\e^i, \sh)} : \ts$ where
%%  $\decomp {\e^i} = \e, \triangleleft\triangleright$
%%  \begin{proof}
%%    \TODO{Unable to prove the hard cases yet (\eg \Rule{Proj-I}) --- this theorem is quite strong, }
%%  \end{proof}
%%\end{theorem}
%
%%% Below this line will is a draft
\Draft{}{\end{document}}\color{blue}

\section{DRAFT: a later TODO  list}

Problems to solve or leave unsolved:
\begin{itemize}

\item
  Overloading of the bracket notation for context filling and polytypes,
  as in $E\where{\epoly \e}$.

  A possibility would be to use braces for either one. Although they are
  used for record expressions, I would say the overlapping with either
  polytypes (they never appear simultaneously) or context (idem, since we
  put label accesses but not records in contexts.

  Alternatively, we could use $\ceils \e$ for polytypes---and then $\floors
  \e$ for the projections.


\end{itemize}


\end{document}

% LocalWords:  omnidirectional typecheck polymorphism Hindley Milner kinded
% LocalWords:  GADTs typechecked codomain typechecking subexpressions Bodin
% LocalWords:  monomorphic subexpression Dunfield Riboulet jfla subtyping
% LocalWords:  greek Chargueraud typable monotype polytype Garrigue Remy th
% LocalWords:  impredicative polytypes minimality RCL ary Proj toplevel
% LocalWords:  typability backpropagation arity Compositionality equi
% LocalWords:  equitypable compositionality inlined equitypability nullary
% LocalWords:  metatheoretical finiteness nonvariable
