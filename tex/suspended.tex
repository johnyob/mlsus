%; whizzy section

%% Leave the above line for didier
%% No macros before \documentclass

\documentclass[acmsmall,screen,nonacm,review]{acmart}

\input{suspended.cfg}
\newcommand{\acmart}{\True}
\usepackage{suspended}

%% \Xfirstname defined in {mycomments}
%% Use either
%%   \Xfistname[text to comment]{your comment on the text}
%% or
%%   \Xfirstname{free comment}
%% Uncomment this line to hide all comments.
% \UNXXX{}

\usepackage{marginnote}

\title{Omnidirectional type inference for \ML: principality any way}

\begin{document}

\begin{abstract}

We propose a new concept of \emph{omnidirectional} type inference: the
ability to resolve \ML-style typing constraints in disorder. In contrast,
all known existing implementations which typically infer the types of
let-bound expressions before typechecking their use sites.
%
This relies on two technical devices: \emph{suspended match constraints}, which
suspend the resolution of some constraints until the context has more
information about a type variable; and \emph{partial type schemes}, which allow
taking instances of partially solved type scheme containing suspended
constraints, with a
mechanism to incrementally update instances as the scheme is refined.

The benefits of omnidirectional type inference are striking for several
advanced \ML extensions, typically those that rely on optional type
annotations where principality is fragile. We illustrate them with \OCaml's
static overloading of record labels and datatype constructors, semi-explicit
first-class polymorphism, and tuple projections \ala \SML.
\end{abstract}
\maketitle

\section{Introduction}
\label{sec/introduction}

\parcomment {Introduction (ML, principality)}

The Damas-Hindley-Milner (\HM) \citep*{Damas-Milner/W@popl82} type system has
long occupied a sweet spot in the design space of strongly typed programming
languages, as it enjoys the \emph{principal types property}: every well-typed
expression $\e$ has a most general type $\ts$ from which all other valid
types for $\e$ are instances of $\ts$. For example, the identity function
$\efun \x \x$ has the principal type $\tfor \tv \tv \to \tv$, generalizing
types like $\tint \to \tint$ and $\tbool \to \tbool$.

\parcomment {Benefits of principality}

This property ensures predictable and efficient inference. Local typing
decisions are always optimal, yielding most general types without guessing or
backtracking. As a result, inference of subexpressions can proceed in any
order, and well-typedness is preserved under common program transformations
such as let-contraction and argument reordering.

\parcomment {Extensions often break pincipality}

Over the years, many extensions of \ML have been proposed. Some of
them, such as extensible records with row-polymorphism, higher-kinded
types, or dimensional types, fit perfectly into the \ML
framework. Others such as GADTs, higher-rank polymorphism, or static
overloading, are \emph{fragile}, as they sometimes require explicit
type annotations. The return type of overloaded datatype constructors may
be annotated; polymorphic expressions can be annotated with a type
scheme; and for GADTs, the type of the \texttt{match} scrutinee and return
type can be annotated to a rigid type which will be refined by type
equalities in each branch. Those type annotations may sometimes---but
not always---be omitted.

Consider impredicative higher-rank polymorphism for instance:
\begin{program}[input]
let self f = f f
\end{program}
With higher-rank types, one could \emph{guess} the type of \code{f} to be
either $\tfor \tv \tv \to \tv$ or $\tfor \tv \tv \to \tv \to \tv$ in order
to typecheck \code{self}---neither of which is more general than the other,
violating principality.

\parcomment {Current approaches are kinda bad}

To fix this, inference algorithms require a minimal amount of
\emph{known} type information to restore principality; in this example
the binding of \code{f} should be annotated with a polymorphic type
scheme. Yet specifying such requirements declaratively is
difficult. As a result, the specifications are often twisted with some
direct or indirect algorithmic flavor in order to preserve
principality and completeness.
%
Moreover, these (more or less) ad-hoc restrictions commonly reject examples
whose type could easily be guessed. For instance, \MLF~\citep*{LeBotlan-Remy/recasting-mlf} accepts
or rejects the following expression, depending on the position of the
annotation (using a traffic-light scheme: green and red indicate typechecking success
and failure; orange signals a warning):
\begin{program}[input]
let self' (f : $\forall$'a. 'a -> 'a) = if true then f f else f $
$   °\Ocamlcomment{\ocamlFlag {\MLF}0}°
let self' f = if true then f f else (f : $\forall$'a. 'a -> 'a) $
$   °\Ocamlcomment{\ocamlFlag {\MLF}1}°
\end{program}

\parcomment {Annotations fixes all the issues (but they're problematic)}

\subsection{Directional type inference}

Each fragile construct admits
a robust counterpart where the type annotation is mandatory. While
robust constructs fit perfectly into the \ML framework, they are
significantly more cumbersome to use, as they always require explicit type
annotations. Fragile constructs can be defined by elaboration into their
robust counterpart.
%
% The elaboration determines which annotations can be
% omitted and rebuilt from context, a point of view already taken by~\citet*
% {Pottier-Regis-Gianas/stratified@popl06} in their work on stratified type
% inference.
%
The difficulty lies in finding a specification
that is sufficiently expressive, principled, intuitive for the user,
and for which we have a complete and effective elaboration algorithm.

The solutions proposed so far all enforce some ordering in which type
inference is performed, which can then be used to propagate both inferred
types and user-provided type annotations as \emph{known} types that can be
used for disambiguation and enable the omission of some annotations.


\paragraph{\Geninst-directional type inference}

\parcomment{Introduce the order}

Most \ML inference algorithms enforce a fixed order when typechecking
let-bindings $\elet \x \ea \eb$: first typecheck the definition $\ea$, then
the body $\eb$. \OCaml leverages this ordering to resolve overloaded or
ambiguous constructs in a \emph{principal} way: polymorphic types
are treated as \emph{known} and may guide disambiguation, whereas monomorphic
types are considered not-yet-known and cannot be relied on for disambiguation.

\parcomment{What is it, and what does it solve}

We call this \textbf{\geninst}-directional (read as
``\textbf{pi}-directional'') type inference, to mean that \textbf{p}olymorphic
expressions must be typed before their \textbf{i}nstances. This strategy
ensures principality for fragile constructs, but can lead to counter-intuitive
behavior.

\parcomment{An instance of the problem (implementation directionality in inference)}

To illustrate the problem, consider the following two record types
with overlapping field names:
\begin{program}[input]
type 'a one = {x : 'a; y : int}
type two = {x : int; z : int}
\end{program}
In \OCaml, both definitions are in scope, and the compiler must
statically disambiguate field usage. The expression \ocaml!{x = 1; z = 1}! can
only be \code{two}, and \code{r.y} necessarily infers \code{one} for \code{r}.
But field accesses such as \code{r.x} are ambiguous unless the type of \code{r} is
\emph{known}. Consider:
\begin{program}[input]
let ex_1 r = r.x                         	°\ocamlflags 21°
let ex_2 = let r = {x = 1; y = 1} in r.x        °\ocamlflags 00°
let ex_3 = (fun r -> r.x) {x = 1; y = 1}        °\ocamlflags 10°
\end{program}
In \ocaml{ex_1}, the type of \code{r} is unconstrained, so disambiguation
fails\footnote {In fact, \OCaml uses a default
resolution strategy instead of failing when the type is ambiguous,
  which is to emit a warning and use the last definition in scope. To
  check these examples, you should use the options
  \texttt{-principal -w +41}, which enforce principality checks and enables
  the warning on default resolution.}.
\relax
At first glance, \code{ex_2} and \code{ex_3} appear equivalent: in both,
the expression \code{r.x} can only refer to the field from type \code{int one}.
Yet \OCaml accepts \code{ex_2} and rejects \code{ex_3}.
This is because the \code{let}-binding in \code{ex_2} allows \code{r} to be
treated polymorphically, and thus its type is considered \emph{known}--enabling
disambiguation. In \code{ex_3}, by contrast, \code{r} is monomorphic at the point of
projection, and disambiguation is therefore forbidden.

To emphasize that this behavior is specification-drive and not an
artifact of \OCaml's inference algorithm, consider two equivalent versions of
\ocaml{ex_3}, where \texttt{@@} and \ocaml{|>} are the application and reverse application
functions:
\begin{program}[input]
let ex_3_2 = (fun r -> r.x) @@ {x = 1; y = 1}   °\ocamlflags 10°
let ex_3_3 = {x = 1; y = 1} |> (fun r -> r.x)   °\ocamlflags 20°
\end{program}
While these terms are semantically equivalent, they highlight a potential hazard:
their typability would vary under a directionally biased inference algorithm,
depending on whether the function or argument is typed first.
To avoid such implementation-dependent behavior, \OCaml chooses to infer
all subexpressions \emph{simultaneously}, until they are \code{let}-bound.

Consequently, \OCaml does not make any difference between \ocaml[indices]{ex_3},
\ocaml[indices]{ex_3_2}, or \ocaml[indices]{ex_3_3}; in all cases, disambiguation
is disallowed, and they are ill-typed.
%
This criterion also
warns on the following example, where \code{r} has a monomorphic type:
\begin{program}[input]
let ex_4 p r = if p then r.x else (r : 'a one).x °\ocamlflags 20°
\end{program}
Warning here is preferable to silently accepting or rejecting the program based
on the inference order between the \code{if} branches.

\Geninst-directional inference offers a way to specify and implement principal
type inference for fragile features, aligning with the implicit inference order
present in most \ML-like typecheckers.
%
This mechanism was originally proposed by~\citet*{Garrigue-Remy/poly-ml} for
semi-explicit first-class polymorphism, and used in \MLF. It has since been
adopted in \OCaml for features such as polymorphic object methods and the
overloading of record fields and variant constructors. More generally, \OCaml
uses \geninst-directionality whenever the typechecker disambiguates on type
information.

\paragraph{Bidirectional type inference}

Bidirectional type inference is a standard alternative to unification for
propagating type information. It is typically formulated by splitting
typing rules into two modes: \emph{checking mode}, which typechecks a term
$\e$ against a \emph{known} type $\t$ in a given context, and \emph{inference mode}
which infers $\e$ from the context alone.

For example, the type system designer can decide to typecheck function
applications $\eapp \ea \eb$ by first \emph{inferring} that $\ea$ has some
function type $\t \tarrow \tp$, and then \emph{checking} $\eb$ against $\t$.
This is not the only possible choice: bidirectional type inference is a
framework that must be instantiated by assigning modes---checking or
inference---to each language construct. There is usually no optimal assignment
of modes: for any choice of modes, some programs will typecheck successfully,
while others will fail unnecessarily. Yet the typing rules must irrevocably
commit to a fixed set of modes. After which, principal types often exist, but
only with respect to a specification that made non-principal choices to begin with.

Bidirectional type inference has been largely used for languages with
higher-rank polymorphism, dependent types, or subtyping.  Still, both \OCaml
and \Haskell only use a limited form of bidirectional type checking with an
underlying first-order unification-based type inference engine, that limits
the downsides of bidirectional type inference.


\paragraph{Limitations of directional type inference}

Bidirectional type inference is lightweight, practical, and well-suited for
complex language features. It supports the propagation of type information with
minimal annotations. Its main downside lies in the need to fix an often
arbitrary flow of type information---as in the case of function applications
discussed above.

On the other hand, \emph{\Geninst-directional} type inference appears better
suited for \ML, relying on polymorphism, the essence of \ML. But it remains
surprisingly weak in some cases: it does not even allow the propagation of
user-provided type annotations from a function to its argument! For example,
the following would be rejected as ambiguous with \geninst-directional type
inference alone:
\begin{program}[input]
let g (f : two -> int) : int = f {x = 1; z = 1} in g (fun r -> r.x)$
$ °\ocamlflags 00°
\end{program}

\OCaml uses \geninst-directional type inference as its primary mechanism, alongside
a weak form of bidirectional propagation. In this example the type
of the argument of \code{g} is known \Geninst-directionally, but \OCaml then
propagates this expected type within the function definition in bidirectional
fashion, so that this example may be considered non-ambiguous.

Besides, the implementation of \geninst-directional type inference has an
algorithmic cost. For technical reasons, type annotations must unshare
types (from acyclic graphs as naturally produced by unification to trees),
which may increase the size of types and the cost of type inference. For
that reason, the implementation of \OCaml cheats and is incomplete by
default. The user must explicitly pass the \texttt{\small -principal} flag to
require the more expensive computation when desired.

\subsection{Omnidirectional type inference}

In absence of \emph{implicit} polymorphism, type inference is solely based
on unification constraints which can be solved in any order;
omnidirectional inference is then natural and easy to implement.  The
difficulty originates from \ML \emph{implicit} let-polymorphism for which all known
implementations follow the \geninst-order: first typing the binding,
generalizing it into a type scheme, and finally typing the body under the extended
typing environment that binds the generalized scheme.
The Hindley-Milner algorithm $\mathcal{J}$, one of
its variant $\mathcal{W}$ or $\mathcal{M}$~\citep*
{Lee_Yi/algoM@toplas1998}, or more flexible constraint-based type
inference implementations~\citep* {Remy/mleth,Remy/thesis,
Odersky-Sulzmann-Wehr@tpos, Pottier-Remy/emlti} all follow this strategy, to
the best of our knowledge. However, this state of affairs is not a
necessity.

To efficiently achieve omnidirectional type inference for fragile \ML
extensions:
\begin{enumerate}

\item
  We introduce \emph{suspended match constraints} as a way to suspend
  ambiguity resolution until sufficient information has been found from
  context so that they can be discharged.

\item
  We work with \emph{partial types schemes}, \ie with the ability to
  instantiate type
  schemes that are not yet fully determined and consequently revisit their
  instances when they are being refined, incrementally. This allows
  inferring parts of a \texttt{let}-body to disambiguate its definition,
  without duplicating constraint-solving work.

\end{enumerate}

These technical devices are introduced once and for all---in a general
framework of constraint-based type inference. Each fragile \ML construct can
then be implemented by suspended constraints that expand to its robust
counterpart once the annotation has been inferred. This generality comes at
a cost, which is that everything is hard:
\begin{enumerate}

\item
  Giving an adequate semantics for suspended constraints is hard, as we
  must capture declaratively the intuition that some type information must be
  \emph{known} rather than \emph{guessed}.

\item
  Implementing partial types schemes is also hard.

\end{enumerate}
In return, the techniques we developed for the semantics
also help provide declarative typing rules for each fragile
construct, for which the generated constraints are correct and
complete.

\paragraph{Illustrative examples}

Examples \code{ex_2} to \code{ex_4} are all typable with omnidirectional
inference, as indicated by the green traffic light labeled \OML---the
calculus formalized in this paper.

%
In contrast, both bidirectional and \Geninst-directional inference
rely on specifications that include choices that are subjective
and somewhat arbitrary. As a result, they reject programs
that have a unique well-typed solution. We now turn to
further examples that illustrate such failures:
%
\locallabelreset
%
\begin{program}[input]
let ex_6 r = (r.x, r.y)                          	°\ocamlflags 10°
let ex_7 r = let x = r.x in x + r.y              	°\ocamlflags 10°
let ex_8 = let getx r = r.x in getx {x = 1; y = 1}      °\ocamlflags 10°
let ex_9 r = (r.x : bool)                        	°\ocamlflags 11°
let ex_1_0 r = r.x.x                              	°\ocamlflags 11°
\end{program}
All are arguably unambiguous; \OCaml accepts none of them, \OML accepts the first three.

In \ocaml{ex_6}, \ocaml{r} can only be of type \ocaml{'a one}. Indeed,
considering the second projection first, we should learn that
\ocaml{r} is of type \ocaml{'a one} and since it is $\lambda$-bound, this
should then make the first projection unambiguous. Disambiguating this example is a matter
of solving the typing constraints in the right order.

A similar failure occurs in \ocaml{ex_7}, where the type of the
$\lambda$-bound variable \code{r} is initially ambiguous and
unknown. It is only upon typing the projection \code{r.y} that
\code{r} is forced to have the type \ocaml{'a one}; this requires
inferring the $\Let$-body to disambiguate the $\Let$-definition.
%
In \code{ex_8}, disambiguation information flows from an instance to
back the definition, opposite to the \Geninst-order; we call this
\emph{backpropagation}.

The example \ocaml{ex_9} can be disambiguated from the return type of
the projection, rather than from the type of \code{r}. The typing rules for
records that we present in this work restrict disambiguation to the
record type alone, and thus rejects this example. Alternative typing rules
using omnidirectional type inference could support this example as
well.

Finally, \ocaml{ex_1_0} is an example where none of the field
projections has enough type information to be disambiguated on its own, but the
constraints they impose can be combined to deduce that the type of
\ocaml{r} must be \ocaml{one}, as the \code{x} field of \code{two}
does not have a record type. This lies outside the framework of
omnidirectional type inference, in which suspended constraints must be
discharged one by one in some order, independently of other
still-suspended constraints.
%
We believe that this restriction is necessary for effective type inference,
since the complexity of general overloading without this restriction is
NP-hard, even in the absence of let-polymorphism, as shown by an encoding of
3-SAT problem by~\citet*
{Chargueraud-Bodin-Dunfield-Riboulet/jfla2025}.

\subsubsection* {Plan}

The paper is organized as follows:
\begin{enumerate*}[label={}]

\item
  In \cref{sec:constraints}, we give an overview of suspended constraints
  and their application to three extensions for \ML of various kind.

\item
  In \cref{sec:semantics}, we describe suspended match constraints and their semantics.

\item
  In \cref{sec:language}, we define \OML, an extension of \ML featuring static
    overloading of record labels, overloaded tuple projections, and
    semi-explicit first-class polymorphism. We sketch its typing rules and
    state the theorems of soundness and completeness for constraint generation,
    as well as principality. By lack of space, detailed typing rules and constraint
    generation are postponed to \cref {app:oml-calculus}.

\item
  In \cref{sec:solving}, we provide a formal definition of our constraint
  solver as a series of non-deterministic rewriting rules and state the main
  theorems for correctness.

\item
  In \cref{sec:implementation}, we describe an efficient implementation
    of suspended constraints and partial type schemes.

\item
  In \cref{sec:related-work}, we compare with related work,
  and in \cref{sec:future-work}, we conclude with a discussion of future work,
  including prototyped extensions whose theory is less clear.

\end{enumerate*}
Appendix \cref{appendix:figures} contains a complete technical reference,
collecting key definitions and figures for convenient lookup. All proofs are
postponed to appendices.

\subsubsection* {Our contributions}

Our contributions are:
\begin{enumerate*}
\item
  A novel \emph{omnidirectional} type inference framework for
  extensions of \ML with advanced features, based on two new devices,
  suspended constraints and partial type schemes;

\item A declarative semantics of suspended constraints that captures the
  idea that they wait on information that must be propagated from the
  context, not \emph{guessed}.

  This includes, in particular, a new declarative characterization of
  \emph{known} type information.

\item
  A complete yet efficient constraint-solving type inference algorithm.

\item
  Three instantiation of our framework that give new declarative type
  systems and their implementation using suspended constraints for tuple
  projection in the style of \SML, static overloading of record fields and
  datatype constructors, and for semi-explicit first-class polymorphism.

\end{enumerate*}

\section{Suspended constraints: an overview}
\label{sec:constraints}

\begin{bnffig}[t]%
  {fig:constraint-syntax}%
  {Syntax of types and constraints.}
\entryset[Type variables]{\tva, \tvb, \tvc}{\TyVars}{}
\\
%% \entryset[Types]{\t}{\Types}\\
\entry[Types]{\t}{
    \tv \and
    \tunit \and
    \ta \to \tb \color{gray} \and
    \Pi\iton \ti \and
    \T \tys \and
    \tpoly \ts
}\\
\entry[Type schemes]{\ts}{
    \t \and
    \all \tv \ts
}\\[1ex]
\entry[Constraints]{\c}{
        \ctrue
  \and  \cfalse
  \and  \ca \cand \cb
  \and  \cexists \tv \c
  \and 	\cfor \tv \c
  \and  \cunif \ta \tb
  \nextline
  \and  \clet \x \tv \ca \cb
  \and  \capp \x \t
  \nextline
  \and  \cmatch \t \cbrs
}\\[1ex]
\entry[Branches]{\cbr}{\cbranch \cpat \c} \\
\entry[Patterns]{\cpat}{}{} \\[1ex]
\entry[Constraint contexts]{\C}{
  \square
  \and \C \cand \c
  \and \c \cand \C
  \and \cexists \tv \C
  \and \cfor \tv \C
  \nextline
  \and \clet \x \tv \C \c
  \and \clet \x \tv \c \C
} \\
\entry[Shapes] {\Sh} {} {}
\\
\entry[Canonical principal shapes] {\sh} {} {}
\end{bnffig}

\parcomment{Syntax!}

The syntax of types and constraints is given
in~\Cref{fig:constraint-syntax}. Monotypes (or just types) include, as
usual, type variables $\tv$, the unit type $\tunit$, arrow types, but
also\footnote{These are grayed, as they which will be introduced in the
following subsections.}  structural tuples $\Pi\iton \ti$, nominal
types\footnote {Type constructors are prefixed, except in \OCaml code, where
they are postfixed.}  $\T \tys$, and polytypes $\tpoly \ts$.  Type schemes
$\ts$ are of the form $\all \tvs \t$, they are equal up to the reordering of
binders and removal of useless variables. We write $\TyVars$ the set of type variables.

Building atop the constraint-based type inference framework of
\citet*{Pottier-Remy/emlti}, we adopt a constraint language that includes both
term and type variables.
%
The language (in \cref{fig:constraint-syntax}) contains tautological ($\ctrue$) and
unsatisfiable ($\cfalse$) constraints, conjunctions
($\ca \cand \cb$). The constraint form $(\cexists \tv \c)$ binds an
existentially quantified type variable $\tv$ in $\c$, while the
constraint $(\cfor \tv \c)$ binds $\tv$ universally. The constraint form
$(\cunif \ta \tb)$ asserts that the types $\ta$ and $\tb$ are
equal.
%
When $\ts$ is a polymorphic type scheme $\tfor \tvs \tp$, we use the
notation $(\cleq \ts \t)$ as syntactic sugar for the instantiation
constraint $\cexists \tvs \cunif \tp \t$.

\parcomment{Constraint abstractions}

Two constructs deal with the introduction and elimination of
constraint abstractions. A constraint abstraction $\cabs \tv \c$ can
simply be seen as a function which when applied to some type $\t$
returns $\c \where {\tv \is \t}$. Constraint abstractions are
introduced by a let construct $(\clet \x \tv \ca \cb)$ which binds
the constraint abstraction to the term variable $\x$ in
$\cb$---additionally ensuring the abstraction is satisfiable. They
are eliminated using the application constraint $(\capp \x \t)$ which
applies the type $\t$ to the abstraction constraint bound to $x$.

\parcomment {Suspended match constraints}

Finally, we introduce \textit{suspended match constraints} $(\cmatch \t \cbrs)$.
%% \footnote
%% {Previously dubbed `frozen constraints'.
%% %in \citep{TODO} % this would be a de-anonymizing citation, silence it for now
%% }
These constraints are \emph{suspended} until
the \textit{shape} of $\t$, such as its top-level constructor,
is known. Then they are \emph{discharged}: a unique branch is selected
and its associated constraint has to be solved. A match constraint
that is never discharged is considered unsatisfiable.

More precisely:
\begin{enumerate}

\item
  The matchee $\t$ is a type. The constraint remains suspended
  while $\t$ is a type variable, that is,
  until the shape of $\t$ is determined.

\item
  $\cbrs$ is a list of branches of the form $\cbranch \cpat \c$,
  where $\cpat$ is a shape pattern. For example, the pattern
  $\tva \to \tvb$ matches function types, binding its domain and
  codomain to $\tva$ and $\tvb$, respectively. The constraint $\c$
  is then solved in the extended context.
  %
  To ensure determinism, the set of patterns $\bar \cpat$ must be
  \emph{disjoint}---that is, no shape may be matched by more
  than one pattern in the list.

\end{enumerate}

We keep the grammar of shapes and patterns abstract in this section,
to explain the general framework of suspended constraints. Shapes are
formalized in \cref{sec:semantics}.

\parcomment {Constraint contexts}

Throughout this paper, we will find it convenient to work with
\emph{constraint contexts}. A constraint context is simply a constraint with
a \emph{hole}, analogous to evaluation contexts $\E$ used extensively in
operational semantics. We write $\C\where{\c}$ to denote filling the hole of
the context $\C$ with the constraint $\c$. Hole filling may capture
variables, so we frequently require explicit side conditions when
variable capture must be avoided. We write $\bvs \C$ for the set of
variables bound at the hole in $\C$.

\paragraph{Suspended constraints in action}

The remainder of this section illustrates the role of suspended constraints
in supporting \emph{fragile} language features as defined above.
These include:
\begin{enumerate}
  \item Semi-explicit first-class polymorphism;
  \item Constructor and record label overloading for nominal algebraic
  datatypes;
  \item Overloaded tuple projection in the style of \SML.
\end{enumerate}
We demonstrate how the typability of each of these features can be elaborated
into constraints, formalized using a constraint generation function of the
form $\cinfer \e \tv$, which, given a term $e$ and expected type $\tv$,
produces a constraint $\c$ which is satisfiable if and only if $\e$ is
well-typed.
%

\subsection{Semi-explicit first-class polymorphism}
\label {sec/constraints/polytypes}

\parcomment {Intro (and annotations)}
Semi-explicit first-class polymorphism \citet*{Garrigue-Remy/poly-ml} uses
\textit{annotated types} to track the origins of polymorphic types.
%
The type constructor $\tapoly \ts \av$ boxes a polymorphic type scheme
$\ts$, turning it into a \textit{polytype} annotated with the annotation
variable $\av$.  Once boxed, the polytype $\tapoly \ts \av$ is considered
a monotype, thereby enabling impredicative polymorphism. Annotation variables
may themselves be generalized, yielding type schemes such as
$\tfor \av {\tapoly \ts \av}$.

\parcomment {Boxing}

The introduction form for polytypes is a boxing operator $\expoly
\e \tvs \ts$ with an explicit polytype annotation $\exi \tvs \ts$
where the $\tvs$ are all the type variables that are free in
$\ts$.
%
The resulting expression has type $\tapoly {\ts \where {\tvs \is \tys}} \av$
where $\av$ is an arbitrary (typically fresh) annotation variable and $\tys$
are arbitrary types that replace the free variables $\tvs$.
The annotation variable $\av$ can thus be generalized.  That is $\expoly \e
\tvs \ts$ can also be assigned the type scheme $\all \av {\tapoly {\ts
\where {\tvs \is \tys}} \av}$.

\parcomment {Unboxing (principality restriction and \geninst-directionality)}

Conversely, to instantiate a polytype expression, one must use an explicit
unboxing operator $\einst \e$, which requires no accompanying type
annotation. However, the operator requires $\e$ to have a polytype scheme of
the form $\tfor \av {\tapoly \ts \av}$ and then assigns $\einst \e$ a type
$\t$ that is an instance of $\ts$. If, by contrast, $\e$ has the type
$\tapoly \ts \av$ for some non-generalizable annotation variable $\av$, then
$\e$ is considered of a not-yet-known polytype, and therefore $\einst \e$ is
ill-typed. This mechanism precisely captures \geninst-directionality: it is
the polymorphism of $\av$ that ensures that marks the type as \emph{known},
rather than still being inferred---the very purpose of annotation variables
is to make this distinction explicit.

\parcomment {Example ill-typed term}

For example, the expression $\efun \x {\einst \x}$ is not
typable. Indeed, the $\lambda$-bound variable $\x$ is assigned
a monotype. The only admissible type for $\x$ is $x : \tapoly \ts \av$
for some $\ts$ and $\av$.  Since $\av$ is bound in the surrounding
context at the point of typing $\einst \x$, it cannot be generalized
prior to unboxing, rendering the term ill-typed.

\parcomment {Annotations}

However, type annotations can be used to freshen annotation variables.
We usually omit annotation variables in annotations, since we can
implicitly introduce fresh ones in their place. For example,
$\efun {\x : \tapoly \ts {}} {\einst \x}$---which is syntactic sugar
for $\efun \x {\elet \x {(\x : \tapoly \ts {})} {\einst \x}}$---is
well-typed because the explicit annotation introduces a fresh
variable annotation $\ava$, which can then be generalized, yielding
$\tfor \ava {\tapoly \ts \ava}$.

\parcomment {Shortcomings of annotation variables}

This behavior can be counter-intuitive: type information that has
just been inferred must still be considered as yet-unknown until its
generalization. It also makes the system sensitive to the placement of type annotations, an
artifact of the fixed directionality of generalization in \geninst-directional
inference. For instance, the following two terms differ only in the position of
the annotation, yet only the one on the left-hand side is well-typed.
\begin{mathpar}
 \efun f {\eapp {\einst {(f : \tpoly {\tfor \tv {\tv \to \tv}})}} f}

\efun f {\eapp {\einst f} {(f : \tpoly {\tfor \tv {\tv \to \tv}})}}
\end{mathpar}
The difference lies in how generalization and annotation variables interact.
In the first term, the annotation occurs in an unboxing operator introducing
fresh annotation variables and may therefore be generalized to the type
scheme $\tfor \av {\tapoly {\tfor \tv {\tv \to \tv}} \av}$, enabling
unboxing to proceed. Whereas the second term applies the annotation to the
argument $f$, which fixes $f$'s type to the monotype $\tapoly {\tfor \tv
{\tv \to \tv}} \ava$ for some fresh annotation variable $\ava$. Because this
type is assigned to $f$ at its binding site, $\ava$ is bound in the context
when typing $\einst f$ and cannot be generalized, so the second term is
ill-typed despite the annotation.

\parcomment {Suspended match constraints fixes this}

Suspended match constraints eliminate this sensitivity to directionality
when typechecking $\einst e$. If $\e$ is already known to have the type
$[\ts]$, then we can simply
instantiate it.  However, if the type of $\e$ is not yet known---\ie  it is a
(possibly constrained) type variable $\tv$---then we must defer until more
information is available. We capture this behavior with a suspended match
constraint:
\begin{mathpar}
\cinfer {\einst \e} \tva \Wide\eqdef
    \cexists \tvb \cinfer \e \tvb
\cand
    \cmatch  \tvb {\parens {\cbranch {\tpoly s} s \leq \tva}}
\end{mathpar}
The match constraint is suspended until $\tvb$ is resolved to a polytype
$\tpoly \ts$ matching the pattern $\tpoly s$, which binds the type scheme
$\ts$ to the scheme variable $s$. The selected branch then performs the
instantiation $\cleq s \tva$, that is $\cleq \ts \tva$.
%
% If $\tvb$ is already known to be a polytype, the constraint discharges
% immediately and behaves like a standard instantiation constraint $\cleq \ts
% \tva$.
%
By waiting for the type of $e$ to be \emph{known}, we ensure principal types
without annotation variables.

\subsection{Static overloading of constructors and record labels}
\label{sec:constraints:overloading}

% What do we mean by static overloading?

\emph{Static overloading} denotes a form of overloading in which resolution is
performed entirely at compile time, enabling the compiler to select a unique
implementation without relying on runtime information---in contrast to
\emph{dynamic overloading}, which defers resolution to runtime via
mechanisms such as dictionary-passing or dynamic dispatch.

\parcomment {Other languages}

Many languages offer statically resolved overloading to avoid the overhead
of dynamic dispatch. C++ and Java resolve overloaded functions through
compile-time specialization based on argument types. Conversely, languages
like Rust and Haskell primarily employ dynamic overloading via traits and
type classes, respectively, which can incur runtime overhead unless
optimized away by monomorphization and aggressive inlining.

\parcomment {\OCaml and \OCaml's approach (PI-directionality)}

As noted in the introduction, \OCaml supports a limited yet useful form of
static overloading for record labels and datatype constructors. When
encountering overloaded labels or constructors, \OCaml resolves ambiguity
using local type information, guided by \geninst-directional
inference. Nominal types $\Tapp \tys$ carry annotation variables $\av$,
written $\Tapp^\av \tys$. As discussed in \cref{sec/constraints/polytypes},
this mechanism allows one to deduce that types polymorphic over their
annotation variable $\tfor \av {\Tapp^\av \tys}$ are \emph{known}.

\parcomment {A note on bidirectional expected type propagation}

Because static overloading involves more intricate flows of information than
polytype inference, \OCaml supplements \geninst-directionality with a limited,
ad-hoc form of bidirectional type inference. This mechanism is folklore; no
formal account has been given.

\parcomment {Closed-world reasoning and default rules}


Beyond propagation, \OCaml also exploits \emph{closed-world reasoning} to
resolve ambiguities in record types. For instance:
\begin{program}[input]
let ex_1_1 = {x = 42; z = 1337} °\ocamlflags 00°
\end{program}
Here, \code{x} and \code{y} appear together only in the type \code{two},
allowing the type checker to unambiguously infer the type of \ocaml{e$_{11}$} as
\code{two}.
%
If local type information and closed-world reasoning are insufficient,
\OCaml falls back to a syntactic default: it selects the most recently
defined compatible type. For example:
\begin{program}[input]
let getx r = r.x         °\ocamlflags 21°
\end{program}
The expression is compatible with both \code{one} and \code{two},
since each defines a field \code{x}. But \code{two} is chosen simply
because it appears later in the source.
We do not treat this behavior as principal; accordingly, we provide
no formalization of such ``default'' rules, though their implementation is
discussed further in \cref{sec:discussion}.
%
This fallback mechanism highlights the directionality of \OCaml inference.
Once the compiler selects a type, it commits to it---even if that choice
causes errors downstream. Consider \code{ex_7} from \cref{sec/introduction}:
\begin{program}[input]
let ex_7 r = let x (* infers [two] *) = r.x in x + r.y °\ocamlflags 10°
\end{program}
Here, \OCaml defaults to \code{two} for \code{r} when typing \code{r.x},
but then fails to type \code{r.y}, as this default choice is fixed---even
though \code{one} would have satisfied both projections.

\parcomment {Record field disambiguation in suspended constraints}

We assume a global typing environment $\labenv$ mapping labels to type
schemes, written $\elab : \tfor \tvs \t \to \Tapp \tys \in \labenv$. A given
label $\elab$ may be defined several times in $\labenv$, but at most once at
a given record type~$\T$. We write $\labenv(\elab / \T)$ for the type scheme
of $\elab$ in $\T$ when it exists.

We propose an alternative account of static overloading using suspended
match constraints.  For example, in the case of an ambiguous record
projection $\efield \e \elab$, we generate the typing constraint:
\begin{mathpar}
\cinfer {\efield \e \elab} \tva \wide\eqdef
  \cexists \tvb \cinfer \e \tvb
  \cand
  \cmatch \tvb
      {\cbranch {\cpatrcd \ct}
	{\parens {\labenv(\elab / \ct) \leq \tva \to \tvb}}
      }
\end{mathpar}
This constraint suspends resolution of the return type $\alpha$ until the
record type $\tvb$ of $\e$ is known. Its branch matches against the nominal
type pattern $\cpatrcd t$, binding the type constructor name to~$t$. Using
this, the appropriate type scheme for $\elab$ is retrieved from
$\labenv(\elab/t)$, instantiated, and the resulting constraints are imposed
on the domain and codomain of the field-access type.

\parcomment{Suspended constraints are better}

\OCaml programs that do not use the default rule are accepted by this
approach. Certain expressions, such as \code{e}$_{12}$ are well-typed under
our account but rejected by \OCaml's current type checker.

\parcomment {Constructor disambiguation in suspended constraints}

Our approach also applies to overloaded datatype constructors. Since
the formal treatment is analogous to that of record fields, we focus only
on fields in this work. However, our prototype implementation of \OML
supports both.

\subsection{Tuple projections \`a la \SML}

\SML supports positional projections from tuples using expressions of the form
\ocaml{#$j$ e} to extract the $j$-th component of the tuple \code{e}.
%
Internally, tuples in \SML are treated as structural records with numeric
labels, so \ocaml{(#$j$ e)} desugars into a structural record field access
\ocaml{e.$j$}: if $\e$ has the type $\tsrecord {j = \tj; \varrho}$, where
$\varrho$ is a row describing the remaining tuple fields, then $\eproj \e j$
has type $\tj$.

\SML enforces an additional restriction: the tail $\varrho$ must be
fully determined (\ie it cannot be a polymorphic row variable).  This
ensures that the arity of the tuple is \emph{known} statically from
the surrounding context, thereby avoiding the need for row
polymorphism. However, this restriction is not expressed in the typing
rules themselves, but is specified operationally as part of the
type inference process.

\parcomment {Tuple projection is statically overloaded}

From a typing perspective, tuple projection in \SML behaves like a form
of static overloading: the expression $\eproj \e j$ is valid only when $\e$ is
known to be an $n$-ary tuple for some fixed $n \geq j$.

\parcomment {We can precisely specify this with suspended constraints}

We can capture the typing of tuple projections precisely using suspended
constraints. For the projection $\eproj \e j$, we generate the following
constraint:
\begin{mathpar}
  \cinfer {\eproj \e j } \tv \wide\eqdef
  \cexists \tvb
    \cinfer \e \tvb
    \cand \cmatch \tvb {\cbranch {\cpatprod \tvc j} {\cunif \tva \tvc}}
\end{mathpar}
\parcomment{Tuple patterns}
The suspended constraint $(\cmatch \tvb {\cbranch {\cpatprod \tvc j} {\cunif
\tva \tvc}})$ blocks until the shape of $\e$ ($\tvb$) is known to be a tuple
of sufficient arity. The pattern $\cpatprod
\tvc j$ matches only tuple types $\tProd \ti$, where $n \geq j$, binding the
$j$-th component to $\tvc$, which is then unified with the expected result type
$\tva$.

\paragraph{Comparison to \SML}

Our understanding is that \SML typecheckers implement row-polymorphic records
under the hood, but they never generalize row variables, rejecting any
declaration that leaves a row variable undetermined. This is a neat approach,
and we conjecture that it accepts the same programs as our implementation of
overloaded tuples using suspended constraints. On the other hand, it only works
for structural types. It cannot be applied to disambiguate between
nominal records or variants that share field or constructor names, particularly
when some field projections or constructors need non-uniform typing rules,
such polymorphic fields or GADT constructors.


\begin{mathparfig}[htpb!]%
  {fig:constraint-semantics}%
  {Semantics of constraints (without suspended constraints).}
  \begin{bnfgrammar}
     \entry[Semantic environments]{\semenv}
     {\emptyset \and \semenv\where{\tv \is \gt} \and
      \semenv\where{\x \is \gabs}}
   \end{bnfgrammar}
   \par
  \infer[True]
    { }
    {\semenv \th \ctrue}

  \infer[Conj]
    {\semenv \th \ca \\
     \semenv \th \cb}
    {\semenv \th \ca \cand \cb}

  \infer[Exists]
    {\semenv\where{\tv \is \gt} \th \c}
    {\semenv \th \cexists \tv \c}

  \infer[Forall]
    {\forall \gt, ~ \semenv\where{\tv \is \gt} \th \c}
    {\semenv \th \tfor \tv \c}

  \infer[Unif]
    {\semenv(\ta) = \semenv(\tb)}
    {\semenv \th \cunif \ta \tb}

  \infer[Let]
    {\semenv \th \exists \tv. \ca \\
     \semenv\where{\x \is \semenv(\cabs \tv \ca)} \th \cb}
    {\semenv \th \clet \x \tv \ca \cb}

  \infer[App]
    {\semenv(\t) \in \semenv(\x)}
    {\semenv \th \capp x \t}

  \let \Eqdef\eqdef \def \eqdef {&\Eqdef&}
  \begin{tabular}[c]{.R.C;.L.}
  %%\semenv &::=&
  %%  \emptyset \mid
  %%  \semenv\where{\tv \is \gt} \mid
  %%  \semenv\where{\x \is \gabs}
  %%\\
  \semenv(\cabs \tv \c) \eqdef
    \set {\gt \in \Ground : \semenv\where{\tv \is \gt} \th \c}
  \\
  \ca \centails \cb \eqdef
    \forall \semenv,\ \semenv \th \ca \implies \semenv \th \cb
  \\
  \ca \cequiv \cb   \eqdef
    (\ca \centails \cb) \wide\wedge   (\ca \centails \cb)
  %% \forall \semenv,\ \semenv \th \ca \iff \semenv \th \cb
  \end{tabular}
\end{mathparfig}

\section{Semantics of constraints}
\label{sec:semantics}

To implement a typechecker using constraint-based type inference, it
suffices to generate constraints from terms and to solve them. To study the
meta-theory of this approach, we follow the standard
approach of assigning a \emph{semantics} for our constraints---as declaratively as
possible. The existence of well-defined declarative semantics provides
a foundation for reasoning about correctness and validates the design of the
constraint language.


In our work on suspended constraints, defining a satisfying semantics was the
most challenging aspect. The key difficulty lies in capturing what it means for
type information to be \emph{known}. Our semantics is declarative, but not
syntax-directed unlike the standard constraint semantics of
\citet*{Pottier-Remy/emlti}. This lack of syntax-directness complicates
reasoning and proofs. On the upside, the semantics directly
  suggest declarative typing rules for the surface language.

\parcomment {Judgment shape}

The semantics of constraints follows the standard form of
a satisfiability judgment $\semenv \th \c$. The semantic environment
$\semenv$ contains a ground assignment for each free variable of $\c$
(type and term variable), and $\semenv \th \c$ states that these
assignments indeed satisfy $\c$. Let us write $\Ground$ for the set of
\emph{ground} types, types without free variables\footnote{Ground
  types are thus finite trees, assuming the existence
%
of some base types such as $\tint$. In \cref{sec/rec-types}, we
discuss the alternative choice of regular trees for the set of ground
types that models equirecursive types.}. $\semenv$ maps each type
variable $\tv$ to a ground types $\gt \in \Ground$, and each term
variable $x$ to sets of ground types $\gabs \subseteq \Ground$
(the set of ground instances of a type scheme for $\x$).
%
We write $\semenv\where{\tv \is \gt}$ and $\semenv\where{\x \is \gabs}$ for
the extension of $\semenv$ with a new binding. For a type $\t$, we write
$\semenv(\t)$ for the ground type obtained by substitution.

\parcomment {Definition exampled}

The judgment is defined in \cref{fig:constraint-semantics} for all
constraint formers except suspended constraints; its definition on
this fragment is standard and somewhat tautological. The constraint
$\ctrue$ is satisfied by any environment, and $\cfalse$ by none. An
environment $\semenv$ satisfies $\ca \cand \cb$ if it satisfies both
$\ca$ and $\cb$. Satisfying $\cexists \tv \c$ requires finding
a witness $\gt$ for $\tv$.  The universal constraint $\cfor \tv \c$ is
satisfiable if $\c$ is satisfiable for any binding of $\tv$. The
unification constraint $\cunif \ta \tb$ is satisfied when
$\semenv(\ta)$ and $\semenv(\tb)$ are equal.

The rule for $\clet \x \tv \ca \cb$ states that $\ca$ must satisfied under
\emph{some} instantiation of its bound variable, and that $\cb$ must be
satisfiable when $\x$ is bound to $\cabs \tv \ca$, or rather to its semantic
interpretation as a set of ground types.

An application constraint $\capp \x \t$ is interpreted by checking that $\t$
belongs to the set of types mapped to $\x$ in $\semenv$, that is, $\semenv(\t)
\in \semenv(\x)$. Note that when $\semenv(\x)$ is of the form
$\semenvp(\cabs \tv \c)$, where $\semenvp$ is the environment at the binding
site of $\x$, then $\semenv(\t) \in \semenv(x)$ holds iff
$\semenvp\where{\tv \is \semenv(\t)} \th \c$, which corresponds to the
intuition that the application $\capp {(\cabs \tv \c)} \t$ should be
equivalent to $\c \where {\tv \is \t}$.


\begin{wraphbox}{0.2}{0.6}
\begin{mathpar}[inline]
\infer*[right=Exists]
    {\infer*[Right=Unif]
      {\infer*{}{\tint = \tint}}
      {\semenv\where{\tv \is \tint} \th \cunif \tv \tint}}
  {\semenv \th \cexists \tv \cunif \tv \tint}
\end{mathpar}
\end{wraphbox}
Closed constraints are either satisfiable in any semantic environment (\ie
they are tautologies) or unsatisfiable. For example, the satisfiability of
the constraint $\cexists \tv {\cunif \tv \tint}$ is established by the
derivation on the right-hand side.


% Equivalence and entailment

We write $\ca \centails \cb$ to express that $\ca$ \emph{entails} $\cb$,
meaning every solution $\semenv$ to $\ca$ is also a solution to $\cb$.
We write $\ca \cequiv \cb$ to indicate that $\ca$ and $\cb$ are equivalent,
that is, they have exactly the same set of solutions.

\subsection{Shapes
\label{sec/shapes}}

\parcomment {Why shapes?}

We introduce \emph{shapes} as a generalization of type constructors for
suspended match constraints. They provide a uniform treatment of both
constructors and polytypes, and are useful in defining polytype
unification (\Cref{sec:implementation}).

\parcomment {Definition of shape}

A shape $\Sh$ is a type with holes, written $\any \tvcs \t$, where $\tvcs$
denotes the set of type variables representing the holes.  By construction,
we require $\tvcs$ to be \emph{exactly} the free variables of $\t$.  Hence,
shapes are closed and do not contain useless binders.  We consider shapes up
to $\alpha$-conversion.  When $\t$ is a ground type, we omit the binder and
write simply $\t$.
%
We write $\bot$ for the shape $\any \tvc \tvc$, which we call the
\emph{trivial} shape. We write $\Shapesz$ the
set of non-trivial shapes.
%% and use letter $\Sh$ to range
%% over non trivial shapes.

\begin{wraphbox}{}{}
\begin{mathpar}[inline]
  \infer[Inst-Shape]
    {\tvcs_2 \disjoint \any {\tvcs_1} \t}
    {\any {\tvcs_1} \t \preceq
     \any {\tvcs_2} \t \where {\tvcs_1 \is \tys_1}}
\end{mathpar}
\end{wraphbox}
Shapes are equipped with the standard instantiation ordering,
defined by \Rule{Inst-Shape}.
%
When writing $\Sh \preceq \Shp$, we say that $\Sh$ is more general than
$\Shp$. When $\Sh$ and $\Shp$ are more general than one another, they are
actually equal. The trivial shape $\bot$ is the most general shape.
%
If $\Sh$ is $\any \tvcs \t$, the shape application $\shapp[\Sh] \tys$ is
defined as $\t \where {\tvcs \is \tys}$. We say that $\Sh$ is a shape of
$\t$ when there exists $\tys$ such that $\t = \shapp[\Sh] \tys$; in this
case we write that the pair $(\Sh, \tys)$ is a decomposition of $\t$.

\begin{definition}
A non-trivial shape $\Sh \in \Shapesz$ is the principal shape of the type
$\t$ iff:
\begin{enumerate}
  \item
    $\exists \typs,\ \t = \shapp[\Sh] \typs$
  \item
    $\forall \Shp \in \Shapesz, \forall \typs,\ \t = \shapp[\Shp] \typs
    \implies \Sh \preceq \Shp$
\end{enumerate}
\end{definition}

\begin{restatable}[Principal shapes]{theorem}{principalShapes}
  \label{thm:principal-shapes}
Any non-variable type $\t$ has a non-trivial principal shape $\Sh$.
\end{restatable}

There is an equivalent direct description of principal shapes
$\sh$. They are precisely the shapes $\any \tvcs \t$ satisfying two conditions:
\begin{enumerate*}
  \item
    $\tvcs$ must be linear in $\t$ \ie each variable $\tvc$ in $\tvcs$
    occurs exactly once in $\t$.

  \item
    The type $\t$ must be shallow, meaning that its structure is limited in
    the following way.  When $\t$ is not a polytype, all of its subterms must
    be variables. Shapes of this form are $\tunit$, $\tvca \to \tvcb$, and
    $\tProd \tvci$, or $\T \tvcs$.
    When $\t$ is a polytype $\tpoly {\all \tvs \tsp}$, the only subterms
    of $\tsp$ that do not contain one of the polymorphic variables $\tvs$ must be variables in $\tvcs$.
\end{enumerate*}

\parcomment {Define canonical shape}

A principal shape $\any \tvcs \t$ is \emph{canonical} if its free variables
appear in the sequence $\tvcs$ in the order in which they occur in $\t$.  We
write $\sh$ for canonical principal shapes.
%
Each non-variable type $\t$ has a unique canonical principal shape, which we
write $\shape \t$. For example, $\shape {\Tapp \tys}$
is $(\any \tvcs \Tapp \tvcs)$.

\parcomment {Polytypes are constructors}

Polytypes are particularly interesting in this setting because they can be
decomposed into shapes and treated analogously to type constructors.
\begingroup
\newcommand {\tsh}[1]%
  {\def \tsi {\all \tvb {{\parens{\tvb \to #1}}} \tprod \tvb}
  \tpoly {\all \tva {\parens {\tpoly \tsi} \to \tva} \to \tva}}%
For instance, the polytype $\tsh {\tint \tlist}$ has the principal
shape $\sh \is \any \tvc {\tsh \tvc}$. The original polytype can thus
be represented as the shape application $\shapp (\tint \tlist)$.
\endgroup

\subsection{Suspended constraints}

We have left the syntax of shape patterns deliberately abstract. We also
assume a matching relation:
% mathpar instead of mathline since spacing was odd. If spacing is fixed, use mathline
\begin{mathpar}
  \cmatches \cpat \sh \tvcs \theta
\end{mathpar}
This partial function matches a pattern $\cpat$ against a principal
shape $\sh$ opened with shape names $\tvcs$ (which must have the same
arity as $\sh$), yielding a substitution $\theta$. The substitution
binds the pattern variables to shape components, that may contain
occurrences of the shape variables $\tvcs$.
%
For our examples we define the trivial pattern $\cpatwild$ which matches
any shape and binds nothing:
\begin{mathpar}
  \cmatches[\eqdef] \cpatwild \sh \tvcs \eset
\end{mathpar}

\begin{definition}[Discharged match constraint]
  Given a suspended constraint $(\cmatch \t \cbrs)$ and a canonical shape
  $\sh$, we introduce the syntactic sugar $(\cmatched \t \sh \cbrs)$ for the
  \emph{discharged match constraint} that selects the branch in $\cbrs$ that matches
  $\sh$:
\begin{mathpar}
  \cmatched \t \sh {\cbranch \cpats \cs} \uad\eqdef\uad
  \begin{cases}
    \cexists \tvs \cunif \t \shapp \tvs \cand \theta(\ci) & \text{if } \cmatches \cpati \sh \tvs \theta\\
    \cfalse & \text{otherwise}
  \end{cases}
\end{mathpar}
The first conjunct ($\tau = \shapp \tvs$) ensures that $\sh$ is indeed the
canonical shape of $\t$, and the second conjunct is the selected branch
constraint $\ci$ under the appropriate substitution. Since the syntax of
suspended match constraints requires that branch patterns are
non-overlapping, the matching branch $\cbranch \cpati \ci$ is uniquely
determined; but it may not exist as branches need not be exhaustive, in
which case the discharged constraint is $\cfalse$.
\end{definition}

\paragraph {A natural attempt}

To provide semantics for our suspended constraints, a first idea
is to propose the following rule---henceforth referred to as the
\emph{natural semantics} of suspended constraints.
\begin{mathpar}
  \infer[Susp-Nat]
  {\sh = \shape {\semenv(\t)} \\ \semenv \th \cmatched \t \sh \cbrs}
  {\semenv \th \cmatch \t \cbrs}
\end{mathpar}
%
This rule states that a suspended constraint is satisfied by $\semenv$ whenever
the corresponding discharged constraint holds for the canonical shape $\sh$ of
$\t$ in the semantic environment $\semenv$. If $\sh$ matches no branch in
$\cbrs$, then the discharged constraint is not defined, so this rule cannot be
applied, and the suspended constraint is unsatisfiable.

\parcomment {The problem}

This semantics rule is nicely declarative, but unfortunately accepts too
many constraints. For example, $\cexists \tv \cmatch \tv {\cbranch
\cpatwild {\cunif \tv \tint}}$ is satisfiable under this natural
semantics:

\begin{mathpar}
\def \cmatchex {\cmatch \tv {\cbranch \cpatwild {\cunif \tv \tint}}}
\def \semenvex {\semenv\where{\tv \is \tint}}
    \infer*[Right=Susp-Nat]
    {
      \cmatches \cpatwild \tint \eset \eset
      \\
      \infer*[Right=Unif]
        {\tint = \tint}
	% -------------------------------
    {\semenvex \th \cunif \tv \tint}
}{% ---------------------------------
    \infer*[Right=Exists]
    {\semenvex \th \cmatchex}
  % -----------------------------------
  {\semenv \th \cexists \tv \cmatchex}
}
\end{mathpar}
The semantics can \emph{guess} the type of $\tv$ and use it to unlock the match
constraint, rather than requiring it to be \emph{known} from the surrounding
context. One could call the guess of $\cunif \tva \tint$ an ``out of thin air''
behavior. This does not match the intended meaning of suspended match
constraints, and raises several problems:
\begin{enumerate*}
  \item a reasonable solver---one that avoids guessing or backtracking---cannot
    be complete with respect to this semantics;

  \item this breaks the existence of principal solutions.
    Consider the function $\efun \x (\efield \x 2)$, which projects the second
    component of a tuple. The natural semantics lets us guess for $\x$ any
    tuple type of arity at least $2$; so there is no principal type
    for~$\x$.
\end{enumerate*}

\paragraph {Contextual semantics}

\begin{version}{}
\begin{wraphbox}{}{}
\begin{mathpar}[inline]
  \infer[Susp-Ctx]
    {\Cshape \C \t \sh \\\\
      \semenv \th \C \where {\cmatched \t \sh \cbrs}
    }
    {\semenv \th \C \where {\cmatch \t \cbrs}}
\end{mathpar}
\end{wraphbox}
\end{version}
To rule out guessing, we instead adopt a \emph{contextual} semantics: a
match constraint is satisfiable only if the shape of the type is determined
by the surrounding context. The corresponding rule for suspended
constraints, \Rule {Susp-Ctx} in \cref {fig:contextual-semantics}, is the
only non-syntax-directed rule in our semantics.
%
In this rule, the shape $\sh$ is not guessed from $\semenv$, but it must be
recovered from the constraint context $\C$. The \emph{unicity} condition
$\Cshape \C \t \sh$ (defined below) ensures that $\sh$ is uniquely determined by $\C$.

\begin{definition}[Erasure]
  \label{def:erasure}
  The erasure $\cerase \c$ of a constraint $\c$ is defined as the constraint
  obtained by replacing suspended match constraints in $\c$ with $\ctrue$.
\end{definition}

\begin{definition}[Simple constraints]
  We say that $\c$ is \emph{simple} if it contains no suspended match
  constraints. We write $\semenv \thsimple \c$ for a derivation of $\semenv \th
  \c$ that only uses the rules listed in \cref{fig:constraint-semantics},
  without using \Rule{Susp-Ctx}. This judgment coincides with $\semenv \th \c$
  on simple constraints.
\end{definition}

\begin{definition}[Unicity]
  We define the unicity condition $\Cshape \C \t \sh$, which states that $\t$
  has a unique canonical shape $\sh$ within the context $\C$ as:
  \begin{mathpar}[inline]
    %% \Cshape \C \t \sh \Wide\eqdef
    \forall \semenv, \gt. \uad
      \semenv \thsimple \cerase {\C\where{\cunif \t \gt}} \implies
          \shape \gt = \sh
  \end{mathpar}.
\end{definition}

\begin{mathparfig}[htpb!]
  {fig:contextual-semantics}
  {Semantics of suspended constraints.}
\infer[Susp-Ctx]
    {\Cshape \C \t \sh \and
      \semenv \th \C\where{\cmatched \t \sh \cbrs}
    }
    {\semenv \th \C\where{\cmatch \t \cbrs}}
\hfill
\begin{array}{.l.}
\Cshape \C \t \sh \eqdef
\\[.6ex]\quad
\forall \semenv, \gt. \uad
      \semenv \thsimple \cerase {\C\where{\cunif \t \gt}} \implies
         \shape \gt = \sh
\end{array}
\end{mathparfig}

The use of erasure $\cerase {\C\where{\cunif \t \gt}}$ in the definition of
$\Cshape \C \t \sh$ ensures that the unicity of $\sh$ is determined only by the
constraints that have already been discharged in $\C$; it excludes suspended
match constraints, which may be discharged in the future. Implicitly, this
induces a linear partial order between the suspended match constraints within a
constraint, reflecting a \emph{temporal} dependency: a match constraint may only
be discharged once all of its dependencies have been discharged.

The erasure $\cerase{\C\where{\cunif \t \gt}}$ is simple, so the use of
$\thsimple$ avoids well-foundedness issues that would arise from
a negative occurrence of $(\th)$ in a premise of \Rule{Susp-Ctx}.
%
Note that, when $\t$ is not a variable, then $\Cshape \square \t \sh$
holds trivially for $\sh = \shape \t$. Likewise, when $\C$ is unsatisfiable,
then $\Cshape \C \tv \sh$ holds vacuously for any $\sh$. The interesting cases
arise when $\t$ is a type variable and $\C$ is satisfiable.

We summarize the definition of the unicity condition and \Rule{Susp-Ctx} in
\cref{fig:contextual-semantics}. Together with the rules of
\cref{fig:constraint-semantics}, this forms the complete semantics of our
constraint language.


\parcomment {Examples}

\begin{example}
Consider the two examples from above:
\begin{mathpar}
\cexists \tv \cunif \tv \tint
  \cand
  \cmatch \tv {\cbranch \cpatwild \ctrue}

  \cexists \tv \cmatch \tv {\cbranch \cpatwild {\cunif \tv \tint}}
\end{mathpar}
In the first example, we apply the contextual rule with the context
\relax $\C \is \cexists \tv \cunif \tv \tint \cand \square$.
Any solution $\semenv$ of this context necessarily satisfies
\relax $\cunif \tv \tint$, so we have
\relax $\Cshape \C \tv \tint$ and the suspended constraint can be discharged.
%
By contrast, the second example has no contextual information around the
suspended constraint: $\C \is \square$. So any solution $\semenv$ satisfies
it, allowing $\semenv(\tv)$ to have an arbitrary shape (\eg $\tint$,
$\tbool$,
  \etc). As a result, the uniqueness condition $\Cshape \C \tv \sh$ never holds
  and the constraint is unsatisfiable as intended.

\end{example}
\begin{example}
Consider the more intricate example:
\begin{mathpar}
  \cexists {\tva \tvb}
  {\def \EX
     {\cmatch \tva {\cbranch \cpatwild {\cunif \tvb \tbool}} \and
      \cmatch \tvb {\cbranch \cpatwild \ctrue} \and
      \cunif \tva \tint}
    \False%\True
      {\def \and{\\{}\cand}\Parens
         {\begin{array}{;l}
            \quad \EX
          \end{array}}}
      {\def \and{)\wide\wedge(}\parens{\EX}}
  }
\end{mathpar}
Suppose we attempt to apply \Rule{Susp-Ctx} to the match on $\tvb$ first.
We want to show $\Cshape \C \tvb \tbool$ for the context
$\C$ equal to
\begin{mathpar}[inline]
  \cmatch \tv {(\cbranch \cpatwild {\cunif \tvb \tbool})} \cand
  \square \cand
  \cunif \tva \tint
\end{mathpar}.
Its erasure is
\relax $\cerase \C = \ctrue \cand \square \cand \cunif \tva \tint$.
In this constraint $\tvb$ is unconstrained, so for example
\relax $\cerase {{\C\where{\cunif \tvb \tint}}}$ and
\relax $\cerase {\C\where{\cunif \tvb \tbool}}$
are both satisfiable: unicity does not hold and \Rule{Susp-Ctx} cannot be
applied.

Now consider instead applying \Rule{Susp-Ctx} to the match on $\tva$
first. To do so, we must show that $\tva$ has a uniquely determined shape in
the context $\C$ equal to
\begin{mathpar}[inline]
  \square \cand
  \cmatch \tvb {\cbranch \cpatwild \ctrue} \cand
  \cunif \tva \tint
\end{mathpar}.
Its erasure $\cerase \C$ is
\relax $\square \cand \ctrue \cand \cunif \tva \tint$.
Since $\tva$ is unified with $\tint$ in the erasure, we have $\Cshape \C
\tva \tint$.
%
We may now discharge the match on $\tva$, rewriting it as
\begin{mathpar}[inline]
(\cmatched \tva \tint {\cbranch \cpatwild {\cunif \tvb \tbool}})
\end{mathpar},
that is, $(\tva = \tint \cand \cunif \tvb \tbool)$. Substituting back, we
are left to satisfy the constraint $\C \where {\tva = \tint \cand \cunif
\tvb \tbool}$, that is,
\begin{mathpar}[inline]
\parens {
  \cunif \tva \tint \cand \cunif \tvb \tbool \cand
  \cmatch \tvb {\cbranch \cpatwild \ctrue} \cand
  \cunif \tva \tint
}
\end{mathpar}.

At this point, we can safely
apply \Rule{Susp-Ctx} to the remaining match constraint on $\tvb$.  The
unicity condition now holds, as the erasure of the context includes the
discharged constraint $\cunif \tvb \tbool$, allowing us to eliminate the
final match constraint.

This demonstrates that suspended match constraints must be resolved in a
dependency-respecting order: attempting to resolve a match
constraint too early may result in unsatisfiability.
\end{example}

\begin{example}
Let us consider a constraint with a cyclic dependency between match
constraints:
\begin{mathpar}
  \cexists {\tva \tvb}
  {\def \EX
     {\cmatch \tva {\cbranch \cpatwild {\cunif \tvb \tbool}} \and
      \cmatch \tvb {\cbranch \cpatwild {\cunif \tva \tint}}}
    \False%\True
      {\def \and{\\{}\cand}\Parens
         {\begin{array}{;l}
            \quad \EX
          \end{array}}}
      {\def \and{)\wide\wedge(}\parens{\EX}}
  }
\end{mathpar}
This constraint can be proved satisfiable under the ``natural semantics'' introduced
earlier: by guessing the assignment $\tva \is \tint, \tvb \is
\tbool$, the two match constraints succeed. However, our solver
and the contextual semantics reject it.

Without loss of generality, suppose we attempt to apply \Rule{Susp-Ctx} on
$\tva$ first. We must show $\Cshape \C \tva \tint$ where $\C$ is
\begin{mathpar}[inline]
    \square \cand \cmatch \tvb {\cbranch \cpatwild {\cunif \tva \tint}}
\end{mathpar}
But the erasure $\cerase \C$ is $\square \cand \ctrue$ imposes no constraint
on $\tva$, so unicity fails, and \Rule{Susp-Ctx} cannot be applied.
\end{example}

\begin{example}
Considering the example \code{ex_7} from \cref{sec/introduction}:
\begin{program}[input]
let ex_7 r = let x = r.x in x + r.y °\ocamlflags 10°
\end{program}
The typing constraint generated for \code{ex_7} contains the following, where $\tv$ stands for the type of \code{r}:
\begin{mathpar}
  \cexists {\tv, \tvc}
    \clet x \tvb
      {(\cmatch \tva \dots)}
      {\cinst x \tint \cand \cunif \tv {\Tapp[\mathsf{one}] \tvc}}
\end{mathpar}
The suspended constraint can be discharged under our semantics, as
intended. We apply the \Rule{Susp-Ctx} rule with context
$\C$ equal to
\begin{mathpar}[inline]
  \clet \x \tvb \square \capp \x \tint \cand
  \cunif \tv {\Tapp[\mathsf{one}] \tvc}
\end{mathpar}.
Although the context includes a \code{let}-binding---which in practice
involves \code{let}-generalization---we can still deduce $\Cshape \C \tv
{\any \tvcp \Tapp[\mathsf{one}] \tvcp}$, since the erased context $\cerase \C$ contains the
unification $\cunif \tv {\Tapp[\mathsf{one}] \tvc}$.

This example illustrates that our formulation of suspended constraints
interacts nicely with \code{let}-polymorphism. Although the two features are
specified in a modular fashion, they are carefully crafted to work together,
as we will further show in our next example.
\end{example}

\begin{example}\label{ex:backprop}
A subtle yet crucial feature of our semantics is its support for
\emph{backpropagation}:
\begin{program}[input]
let ex_8 = let getx r = r.x in getx {x = 1; y = 1}  °\ocamlflags 10°
\end{program}
As in the previous example, the type of \code{r} cannot be disambiguated in the
\code{let}-definition alone. In the previous example, this type was unified
to a known shape in the \code{let}-body. Here, this is more subtle: an
\emph{instance} of the type scheme is taken, which is only well-typed if
\code{r} has a variable type or a type of the form
\ocaml{'a one}. The projection \code{r.x} would be
forbidden if \code{r} had a variable type, so
\code{'a one} is the unique solution. We call this flow of
information from instances back to definitions \emph{backpropagation}.

The constraint generated when typing
\code{ex_8} is:
\begin{mathpar}
\begin{tabular}{L.L}
  \cexists \tv {}
  &\clet {getx} \tvd
     {\cexists {\tvb, \tvc} \Parens {\strut
        \cunif \tvd {\tvb \to \tvc} \cand
	\cmatch \tvb \dots
        }}{}
    \cinst {getx} {(\tint \ \mathsf{one} \to \tv)}
\end{tabular}
\end{mathpar}
With the context $\C$ equal to $\clet {getx}
\tvd {\cexists {\tvb, \tvc} \cunif \tvd {\tvb \to \tvc} \cand \square}
{\capp {getx} {(\tint \ \mathsf{one} \to \tv)}}$, we can show the unicity predicate $\Cshape \C \tvb \sh$ for the shape $\sh = (\any \tvc {\tvc~\mathsf{one}})$.
%% That is:
%% \begin{mathpar}
%%   \all {\semenv, \gt} \uad
%%     \semenv \th \cerase {\C\where{\cunif \tvb \gt}} \implies \shape \gt = \sh
%% \end{mathpar}
For any $\semenv, \gt$, the erasure $\cerase {\C \where {\cunif \tvb \gt}}$
is
\begin{mathpar}[inline]
\clet {getx}
\tvd {\cexists {\tvb, \tvc} \cunif \tvd {\tvb \to \tvc} \cand \cunif \tvb \gt}
{\capp {getx} {(\tint \ \mathsf{one} \to \tv)}}
\end{mathpar}.
Since $getx$ is bound to the constraint abstraction
\relax $\cabs \tvd \exists \tvc.\uad \cunif \delta {(\gt \to \gamma)}$,
the instantiation
\relax $\capp {getx} (\tint \ \mathsf{one} \to \tv)$
can only be satisfied when
\relax $\gt = \tint\ \mathsf{one}$. This proves unicity,
hence \code{ex_7} is accepted by our semantics.
\end{example}


\section{The \OML calculus}
\label{sec:language}

\parcomment {Running example: tuple projection disambiguation}

\parcomment {We need a spec, but this itself is hard}

To prove correctness of constraint generation, we must first define a surface
language and its type system. Surprisingly, identifying an appropriate
declarative type system to use as a specification is itself an interesting
problem! In particular, na\"ive specifications often fail to ensure principal types.

\parcomment {Why do naive approaches not guarantee principal types.}

%\begin{wraphbox}[11em]{}{}
%\mprset{sep=1em}
%\begin{mathpar}[inline]
%   \inferrule*
%      {\G \th \e : \Pi\iton \ti \\ 1 \leq j \leq n }
%      {\G \th \exfield \e n j : \tj}
%\end{mathpar}
%\end{wraphbox}
Take overloaded tuple projections \ala \SML. We can ask the user to provide the
length of the tuple explicitly, via an annotated syntax $\exfield \e n j$,
which has a simple typing rule (\Rule{Proj-X}).
\begin{mathpar}
  \infer[Proj-X]
    {\G \th \e : \Pi\iton \ti \\ 1 \leq j \leq n}
    {\G \th \exproj \e j n : \tj }

  \infer[Proj-I-Nat]
    {\G \th \e : \Pi\iton \ti \\ 1 \leq j \leq n}
    {\G \th \efield \e j : \tj}
\end{mathpar}
%
%\begin{wraphbox}[11em]{}{}
%\mprset{sep=1em}
%\begin{mathpar}[inline]
%  \infer
%    {\G \th \e : \Pi\iton \ti \\ 1 \leq j \leq n}
%    {\G \th \efield \e j : \tj}
%\end{mathpar}
%\end{wraphbox}
%
On the other hand, the natural typing rule for the fragile construct $\eproj e
j$ breaks principality (\Rule{Proj-I-Nat}). The term $\eproj \e j$ admits
infinitely many typings for $\e$, provided the tuple is of sufficient length.
%
%\begin{wraphbox}[11em]{}{}
%\mprset{sep=1em}
%\begin{mathpar}[inline]
%\infer
%  {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\\\
%   \G \th E[\exfield \e n j] : \t}
%  {\G \th \E[\efield \e j] : \t}
%\end{mathpar}
%\hfil
%\end{wraphbox}
This is the exact same issue we had with the na\"ive semantics of suspended
constraints, and in fact we solve it in the same way, with a unicity
condition and a contextual rule (\Rule{Proj-I}) that transforms the fragile, implicit
construct into the robust, explicit counterpart:
\begin{mathpar}
  \infer[Proj-I]
  {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\
   \G \th \E[\exfield \e n j] : \t}
  {\G \th \E[\efield \e j] : \t}
\end{mathpar}

\subsection{Syntax}

\begin{bnffig}[t]{fig/syntax}{Syntax of \OML.}
\entry[Terms]{\e}{
  x \and
  () \and
  \efun x e \and
  \eapp \ea \eb \and
  \elet x \ea \eb \and
  \eannot \e \tvs \t \and%\andcr
  \erecord {\overline{\el = \e} } \and
  \efield e \el \andcr%\and
   (\ea, \ldots, \en) \and
   \efield e j \and
   \exfield e n j \and%\andcr
   \epoly e \and
   \expoly e \tvs \ts \and
   \einst e \and
   \exinst e \tvs \ts
}
%% \\
%% \entry[Labels]{l}{
%%   \elab \and \elab / \T
%% }
\\[1ex]
\entry[Types]{\t}{
   \tv \and
   1 \and
   \tya \to \tyb \and
   \T \tys \and
   \Pi \iton \ti \and
   \tpoly \ts
}\\
\entry[Type schemes]{\ts}{
     \t \and
     \tfor \tv \ts
}\\
\entry[Contexts]{\G}{
   \eset \and
   \G, x : \ts
}\\
\end{bnffig}

In \cref {fig/syntax}, we give the grammar for our calculus. Terms include
all of the \ML calculus: variables~$\x$, the unit literal $\eunit$,
lambda-abstractions $\efun \x \e$, applications $\eapp \ea \eb$,
annotations $\eannot \e \tvs \t$ and let-bindings $\elet x \ea \eb$.
Our extensions include:
\begin{enumerate}
\item
  Overloaded variant constructors and record labels, modeled using record
  literals $\erecord { \ela = \ea; \ldots; \el_n = \en }$ and field
  projections $\efield \e l$. Variant constructors are not treated formally in \OML, but
    behave analogously in practice.
\item
  Tuples $(\ea, \ldots, \en)$ with implicit projections
  $\efield \e j$ and explicit projections $\exproj \e j n$.

\item
  For semi-explicit first-class polymorphism, we have implicit and explicit
    introduction and elimination forms: boxing $\epoly \e$ and $\expoly
    \e \tvs \ts$, and unboxing $\einst \e$ and $\exinst \e \tvs \ts$.

\end{enumerate}
We use the metavariable $\e^i$ to range over the
fragile/implicit constructions, and $\e^x$ to range over their
explicit counterpart.

\subsection{Typing rules and unicity}

We have detailed typing rules for the full \OML calculus, but unfortunately
they do not fit in the margins of the 25 pages of this document. We moved them
all, along with detailed examples, in Appendix \cref{app:oml-calculus}.

Our typing rules $\G \th \e : \ts$ are mostly standard, except for
the rules governing implicit (or fragile) constructs $\e^i$. These
rules are inspired by our contextual constraint semantics (\Cref{sec:semantics}):
each is a contextual typing rule paired with a unicity condition and
an elaboration into an explicit form.

The unicity condition requires that the shape $\sh$ is fully determined by the
surrounding term context $\E$, including any subexpressions (\eg $\e$ in
$\eproj \e j$). They are analogous to the unicity condition $\Cshape \C \t \sh$
for constraints, though the analogy is not exact. Different fragile features
require slightly different formulations, depending on whether they infer a
unique shape for a subexpression $\eshape \E \e \sh$ or for the expected type
of the context $\Eshape \E \e \sh$.

\begin{wraphbox}{}{}
\begin{mathpar}[inline]
  \inferrule[Magic]
    {\G \th \e : \t}
    {\G \th \emagic \e : \tp}
\end{mathpar}
\end{wraphbox}
In order to define the unicity conditions, we introduce \emph{typed holes}
$\emagic \e$, which allow any well-typed term $\e$ to be treated as
if it had any type (via \Rule{Magic}). Types holes are forbidden in
the source language---they are a device solely used to define unicity conditions.
%
We also introduce an erasure function $\eerase \e$, the term counterpart of constraint erasure
$\cerase \c$, which erases all not-yet-elaborated implicit constructs
$\e^i$ in $\e$ with typed holes around their subterms. This ensures the
subterms---such as type annotations---remain present, so that any constraints
they introduce can still contribute to unicity.
For example, $\eerase {\efield \e j}$ is $\emagic {\cerase \e}$.
The full definition is given in Appendix \cref{appendix:figures}.

We can now formalize the two unicity conditions:
\begin{mathpar}
\def \Eqdef {&\eqdef&}
{\begin{tabular}{RCL}
\eshape \E \e \sh \Eqdef
  \forall \G, \t, \gt, \uad
  \G \th \eerase {\E \where {\emagic {\eannot \e {} \gt }}} : \t
      \wide\implies \shape \gt = \sh
\\[1ex]
\Eshape \E \e \sh \Eqdef
  \forall \G, \t, \gt, \uad
      \G \th \eerase {\E\where{\eannot {\emagic \e} {} \gt}} : \t
      \wide\implies \shape \gt = \sh
\end{tabular}}
\end{mathpar}
We use the unicity condition
$\eshape \E \e \sh$ when we disambiguate using the type of a subterm,
as in overloaded tuple projections, record projections, and polytype
unboxing. Conversely, we use $\Eshape \E \e \sh$ for polytype boxing and
overloaded records, where we disambiguate them using the expected type of
the context.

\begin{example}
Let $\e$ be $\elet f {\efun \x {\eproj \x 1}} {\eapp f (1, 2)}$.
$\e$ is well-typed using \emph{backpropagation}.
$\e$ is of the form $\E \where {\x}$ where  $\E$ is the context $\elet f
{\efun \x \ehole} {\eapp f (1, 2)}$.
We have $\eset \th \E \where {\eproj[2] \x 1} : \tint$.
Let us show that $\eshape \E \x {\any {\tvca, \tvcb} \tvca \tprod \tvcb}$.
%
Assume $\eset \th \E \where {\emagic {\eannot \x {} \gt} } : \t$. As $\gt$ is a ground
type, the type $\gt$ of $\x$ is not a variable.  Then, $\gt$ cannot be that
of an arbitrary sized tuple, since there is no such type for a tuple of
arbitrary size. Hence, $\gt$ must be a tuple $\Pi\iton \tys$ for some size
$n$. Since the codomain of $f$ must be a tuple of size~$2$ (for $\eapp f (1,
2)$ to be well-typed), then $n$ must also be $2$. This shows that $\eshape \E
\x {\any {\tvca, \tvcb} \tvca \tprod \tvcb}$.
%% \begin{mathpar}
%%   \infer
%%     {
%%     \infer
%%       {
%% 	\infer
%% 	  {
%% 	    \infer
%% 	      {
%% 		\infer
%% 		  { }
%% 		  {\tva, \tvb, x : \tva \th x : \tva}}
%% 	      {\tva, \tvb, x : \tva \th \ecast x \tva \tvb : \tvb}}
%% 	  {\tva, \tvb \th \efun x {\ecast x \tva \tvb : \tva \to \tvb}}}
%%       {\emptyset \th \efun \x \ecast \x \tva \tvb : \tfor {\tva, \tvb} \tva \to \tvb} \\
%%     \infer
%%       {\ldots}
%%       {f : \tfor {\tva, \tvb} \tva \to \tvb \th \eapp f (1, 2) : \tunit}}
%%     {\emptyset \th \elet f {\efun \x {\ecast \x \tva \tvb}} {\eapp f (1, 2)} : \tunit}
%% \end{mathpar}
\end{example}



\subsection{Metatheory}
\label{sec:constraint-prop}

Constraint generation is sound and complete with respect to the typing judgment.
That is to say, the term $\e$ is typable with $\t$ if and only if
$\cinfer \e \tv$ is satisfiable when $\tv$ is $\t$.
%
\begin{theorem}[Constraint generation is sound and complete]
  \label{thm:constraint-gen-is-sound-and-complete}
Given a closed term $\e$ and type $\t$. Then for any $\tv \disjoint \t$,
$\th \e : \t$ iff\/
$\cunif \tv \t \centails \csem {\e : \tv}$.
\end{theorem}

\begin{restatable}[Principal types]{theorem}{principalTypes}
\label{thm:principal-types}
For any well-typed closed term $\e$, there exists a type $\t$, which we call
principal, such that:
\begin{enumerate*}[(\roman*)]
\item
  $\th \e : \t$.
\item
  For any other typing $\th \e : \tp$, then $\tp = \theta(\t)$ for some
  substitution $\theta$.
\end{enumerate*}
\end{restatable}
It is also interesting to discuss the stability of typing by common program
transformations.

\paragraph{Application equi-typability does hold}

\newcommand {\eswap}{{\mathprefix {swap}}}
The expressions $\eappp f \ea \eb$ and $\eappp {\eswap f} \eb \ea$ are
equitypable where $\eswap$ is
$\efun f {\efun \xa {\efun \xb {\eappp f \xb \ea}}}$. We also have
that $\eapp f \e$ and $\eappp {\mathsf{app}} f \e$ and
$\eappp {\mathsf{rev\_app}} \e f$ are equitypable, where
$\mathsf{app}$ and $\mathsf{rev\_app}$ are the application function
$\efun f \efun \x \eapp f \x$ and the reverse application function
$\efun \x \efun f \eapp f \x$, respectively. It is well-known that
bidirectional types inference breaks application
equitypability. Both \Geninst-directional and omnidirectional
type inference preserve it.

\paragraph{Factorization does not hold} If $\G \th \e \where {\x \is {\e_0}}
: \t$ with $\x$ appearing in $\e$, we do not necessarily have $\G \th \elet \x
\ez \e : \t$. This is not a defect of our system, but a general property of
all systems that support static overloading: the expanded term $\e \where {x
\is \e_0}$ can pick a different overloading choice for each occurrence of
$\e_0$, and if they are incompatible the factored form may not typecheck.

\paragraph{Inlining does not hold} If $\G \th \elet \x \ez \e : \t$, we do
not necessarily have $\G \th \e \where {\x \is {\e_0}} : \t$. This is
specific to our support for \emph{backpropagation}: the $\Let$-form will
use information from all occurrences of $\x$ in $\e$ to resolve fragile
constructs in $e_0$, but in the inlined form each copy of $\e$ must resolve
its implicit constructs independently, and it has access to less information to
establish unicity. As a result, the implicit \OML calculus does not preserve typability
in its operational semantics.

\section{Solving constraints}
\label{sec:solving}

\parcomment{Intro}
We now present a machine for solving constraints in our language. The solver
operates as a rewriting system on constraints $\c \csolve \cp$. Once no further
transitions are applicable, \ie $\c \cnsolve$, the constraint $\c$ is either in
solved form---from which we can read off a most general solution---or the
solver becomes stuck, indicating that $\c$ is unsatisfiable.

\begin{definition}[Solved form $\hat\up$]
  \label{def:solved-form}
  A solved form is a constraint $\hat\up$ of the form $\cexists \tvs \cAnd
\iton \ueqi$, where:
\begin{enumerate*}
  \item each $\ueqi$ contains at most one non-variable type;
  \item head variables do not occur in multiple equations;
  \item the constraint is acyclic.
\end{enumerate*}
\end{definition}

\subsection{Unification}
%
Our constraints ultimately reduce to equations between types, which we solve
using first-order unification. Like our solver, we specify unification as a
non-deterministic rewriting relation between \emph{unification problems} $\upa
\unif \upb$, that eventually reduces to a solved form $\hat\up$ or to $\cfalse$.

\begin{mathparfig}[htpb!]
  {fig:unification-syntax-and-semantics}
  {Syntax and semantics of unification problems.
   %Constraints are also extended with the administrative multi-equation construct.
  }
\begin{minipage}[c]{0.7\textwidth}
\begin{bnfgrammar}
  \entry[Unification problems]{\up}{
    \ctrue \and \cfalse \and \upa \cand \upb \and \cexists \tv \up \and \ueq
    \uad\strut
  } \\
  \entry[Multi-equations]{\ueq}{
    \eset \mid \cunif \t \ueq
  } \\
  \entry[Constraints]{\c}{
    \dots \and \ueq
  }
\end{bnfgrammar}
\end{minipage}
\hfill
\vcenter{\hbox{
  \infer[Multi-Unif]
    {\all {\t \in \ueq}\, \semenv(\t) = \gt}
    {\semenv \th \ueq}
}}
\end{mathparfig}

\parcomment{Unification problems and multi-equations}

Unification problems $\up$
(\cref{fig:unification-syntax-and-semantics}) are a restricted subset
of constraints, extended with \emph{multi-equations}
\citep*{Pottier-Remy/emlti}---a multi-set of types considered
equal. These generalize binary equalities: $\semenv$ satisfies
a multi-equation $\ueq$ if all of its members are mapped to a single
ground type $\gt$ (\Rule{Multi-Unif}). Multi-equations are
considered equal modulo permutation of their members.

Our algorithm is largely standard, with it main novelty being the use
of \emph{canonical principal shapes} in place of type constructors. This
uniform treatment of monotypes and polytypes simplifies unification and improves
on the previous treatment of polytype unification \citep{Garrigue-Remy/poly-ml}.
For a detailed discussion of the unification rules, see
\cref{app:unification} (appendix).

\subsection{Solving rules}

% What we do (introduce / explain the solver)

We now gradually introduce the rules of the constraint solver itself
(\cref {fig:solver-basic,fig:solver-susp,fig:solver-schemes}).
These rules define a non-deterministic rewriting
system, operating modulo $\alpha$-equivalence, and the associativity and
commutativity of conjunction. Rewriting takes place under an arbitrary
one-hole constraint context $\C$.
%
% Solved forms
A constraint $\c$ is satisfiable if it rewrites to a solved form
$\hat\up$ (\cref{def:solved-form}); otherwise it gets
stuck.

\begin{mathparfig}[htpb!]
  {fig:solver-basic}
  {Basic rewriting rules $\ca \csolve \cb$}
  \rewrite[S-Unif]
    {\upa}
    {\upa \unif \upb}
    {\upb}

  \rewrite[S-False]
    {\C\where\cfalse}
    {\C \neq \square}
    {\cfalse}

  \rewrite[S-Let]
    {\clet \x \tv \ca \cb}
    {}
    {\cletr \x \tv \eset \ca \cb}

  \rewrite[S-Exists-Conj]
    {(\cexists \alpha \ca) \cand \cb}
    {\tv \disjoint \cb}
    {\cexists \tv {\ca \cand \cb}}

  \rewrite[S-Let-ExistsLeft]
    {\cletr \x \tv \tvs {\cexists \tvb \ca} \cb}
    {\tvb \disjoint \tv, \tvs, \cb}
    {\cletr \x \tv {\tvs, \tvb} \ca \cb}

  \rewrite[S-Let-ExistsRight]
    {\cletr \x \tv \tvs \ca {\cexists \tvb \cb}}
    {\tvb \disjoint \tv, \tvs, \ca}
    {\cexists \tvb {\clet \x \tvs \ca \cb}}

  \rewrite[S-Let-ConjLeft]
    {\cletr \x \tv \tvs {\ca \cand \cb} \cc}
    {\ca \disjoint \tv, \tvs}
    {\ca \cand \cletr \x \tv \tvs \cb \cc}

  \rewrite[S-Let-ConjRight]
    {\cletr \x \tv \tvs \ca (\cb \cand \cc)}
    {\x \disjoint \cc}
    {\cc \cand \Clet \x \tv \ca \cb}
\end{mathparfig}

\paragraph{Basic rules}

\parcomment{Unification}

\Rule{S-Unif} invokes the unification algorithm to the
current unification problem. The unification algorithm itself is treated as a
black box by the solver, so the system could be extended with any
equational theory of types implemented by the unification algorithm.
\begin{mathparfig}[htpb!]
  {fig:constraint-let-regions}
  {Syntax and semantics of region-based $\Let$ constraints.}
 \begin{bnfgrammar}
  \entry[Constraints]{\c}{
     \dots \and \cletr \x \tv \tvs \ca \cb
   }
 \end{bnfgrammar}\\
\begin{tabular}{R;;C;;L}
%%\c &::=& \ldots \mid \cletr \x \tv \tvs \ca \cb \\
\semenv(\cabsr \tv \tvs \c) &\eqdef&
  \set{\greg \tv {\semenv\where{\tv \is \gt, \tvs \is \gts}}
       \in \GroundRegion : \semenv\where{\tv \is \gt, \tvs \is \gts} \th \c}
\end{tabular}
\\
  \infer[LetR]
    {\semenv \th \cexists {\tv, \tvs} \ca \\
     \semenv\where{\x \is \semenv(\cabsr \tv \tvs \ca)} \th \cb}
    {\semenv \th \cletr \x \tv \tvs \ca \cb}

  \infer[AppR]
    {\greg \tv \semenvp \in \semenv(\x) \\
     \semenv(\t) = \semenvp(\tv) }
    {\semenv \th \capp \x \t}
\end{mathparfig}

\parcomment{Regional let constraints}

In general, existential quantifiers $\cexists \tv \c$ are lifted to the nearest
enclosing $\Let$, if one exists, or otherwise to the top of the constraint. The
resulting existential prefix $\exists \tvs$ is called a \emph{region}. To make
regions explicit, we introduce the syntax $\cletr \x \tv \tvs \ca \cb$, where
$\tv$ is the \emph{root} of the region and $\tvs$ are auxiliary existential
variables. The order of $\tvs$ is immaterial; regions are considered equal up
to permutation of these variables.

Satisfiability of regional $\Let$-constraints is defined in
\cref{fig:constraint-let-regions}. The semantics of an
abstraction with a region, written $\semenv(\cabsr \tv \tvs \c)$, is a set of
\emph{ground regions} that satisfy $\c$. A ground region is a satisfying
interpretation for the region $\semenvp$ with a designated \emph{root} variable
$\tv$, written $\greg \tv \semenvp$. Regional $\Let$-constraints strictly
generalize ordinary constraint abstractions, as captured by the equivalence:
\begin{mathline}
  \clet \x \tv \ca \cb \Wide\cequiv \cletr \x \tv \eset \ca \cb
\end{mathline}

\parcomment{Explanation of rules}

Rule \Rule{S-Let} rewrites let constraints into regional form.
%
\Rule{S-Exists-Conj} lifts existentials across conjunctions;
\Rule{S-Let-ExistsLeft} and \Rule{S-Let-ExistsRight} lift existentials across
let-binders; \Rule{S-Let-ConjLeft}, \Rule{S-Let-ConjRight} hoist
constraints out of let-binders when they are independent of the local
variables.
%
Collectively, these lifting rules normalize the structure of each
region into a block of existentially bound variables, whose body
consists of a conjunction of solved multi-equations followed by
a residual constraint---typically an application, let-binding, or
suspended constraint.


\parcomment{\OML constraints do not need dedicated rules}

\OML-specific constraints, such as the label and polytype instantiations from
\cref{sec/constraints/polytypes} and \cref{sec:constraints:overloading}, require no
special treatment in our solver. Once their pattern variables are
substituted---after solving a match constraint---they are desugared into
constraints already handled by the solver.

\paragraph{Suspended match constraints}

\begin{mathparfig}[htpb!]
  {fig:solver-susp}
  {Rewriting rules for suspended match constraints.}
  \rewrite[S-Match-Type]
    {\cmatch \t \cbrs}
    {\t \notin \TyVars }
    {\cmatched \t {\shape \t} \cbrs}

  \rewrite[S-Match-Var]
    {\C\where{\cmatch \tv \cbrs}}
    {\cunif \tv {\cunif \t \ueq} \in \C}
    {\C\where{\cmatched \tv {\shape \t} \cbrs}}
\end{mathparfig}

\parcomment{S-Match-Type}

\Rule{S-Match-Type} solves suspended match constraints whose scrutinee is
a non-variable type $\t$ by rewriting them using the sugar $(\cmatched \t
{\shape \t} \cbrs)$, introduced in \cref{sec:constraints}.

\parcomment {S-Match-Var}

\Rule{S-Match-Var} applies when the scrutinee is a variable $\tv$ and
the context $\C$ proves that $\tv$ is equal to some non-variable type
$\t$, which establishes the unicity property
$\Cshape \C \t {~\shape \t}$.
%
To check whether a context $\C$ proves an equality---or more generally,
a multi-equation $\ueq$---we search for a decomposition $\C = \Ca\where{\ueq \cand \Cb}$
where $\fvs \ueq$ is disjoint from the binders of $\Cb$.

\paragraph{Let constraints}

% Let-constraint solving is generalization

\parcomment{Background on efficient solving of applications (aka generalization)}

Application constraints can be solved by copying constraints:
\begin{mathpar}
  \rewrite[S-Let-App-Beta]
    {\cletr \x \tv \tvs \ca {\C\where{\capp \x \t}}}
    {\tv, \tvs \disjoint \t \\ x \disjoint \bvs \C}
    {\clet \x \tv \ca {\C\where{\cexists {\tv, \tvs} \cunif \tv \t \cand \ca}}}
\end{mathpar}
This resembles $\beta$-reduction, except that the original abstraction is
retained. While correct for \emph{simple} constraints, it may duplicate solving work
across applications of the same abstraction.
%
A more efficient approach first solves the abstraction once---\eg reducing it
to $\cabsr \tv \tvs \ueqs$, where $\tvs$ are generalizable variables---and then
reuses the result at each application site by only copying the solved
constraint $\ueq$. This mirrors \ML generalization and instantiation, a
connection formalized by \citet*{Pottier-Remy/emlti}, where $\cabsr \tv \tvs
\ueqs$ corresponds to the type scheme $\tfor \tvs {\sub(\tv)}$ and $\sub$ is
the \mgu of $\ueqs$. This optimization underlies efficient implementations of
\HM inference, such as \OCaml's.

\parcomment{Generalization with suspended constraints is hard}

However, this approach \emph{does not} extend to suspended constraints. To illustrate
this, let us examine \ocaml{ex_7} (from \cref{sec/introduction}):
\begin{program}[input]
  let ex_7 r = let x = r.x in x + r.y °\ocamlflags10°
\end{program}
The generated typing constraint contains:
\begin{mathpar}
  \cexists {\tv, \tvc}
    \clet x \tvb
      {\cmatch \tvb {\cbranch {(\cpatrcd \ct)} {\C\where {\ct,\tva,\tvb}}}}
      {\cinst x \tint \cand \cunif \tv {\Tapp[\mathsf{one}] \tvc}}
\end{mathpar}
where $\C\where{\ct,\tv,\tvb}$ is ${\Omega(\elab / t) \leq \tva \to \tvb}$.
Here, $\tv$ stands for \code{r}'s type. The constraint remains suspended until
\code{r.y} forces \code{r}'s type to be \code{one}. Crucially, the variable
$\tvb$ (introduced inside the abstraction for the type of \code{y}) is captured
by the suspended match constraint that is not yet resolved at the point of
solving the $\Let$ constraint that binds \code{x}.

\parcomment {Partial type schemes}

Nonetheless, to continue solving the let-body, we must assign a scheme to
\code{x}. We na\"ively pick $\tfor \tvb \tvb$. This appears unsound, since
$\tvb$ will later unify with $\tint$ once the match constraint is discharged.
But it would be incomplete to lower $\tvb$ as a monomorphic variable.
%
This motivates \emph{partial type schemes}, our second novel mechanism for
omnidirectional inference. Partial type schemes are type schemes that delay
commitment to certain quantifications (\eg $\tvb$). Such \emph{partially
generalized} variables are treated as generalized, but can be incrementally
refined in future as suspended constraints are discharged.

\begin{mathparfig}[t]
  {fig:constraint-partial-app}
  {The syntax and semantics of partial instantiations.}
\begin{minipage}[b]{0.5\hsize}
  \indent
  \begin{bnfgrammar}
    \entry[Constraints]{\c}{
      \dots
      \and \cexistsi \inst \x \c
      \and \cpinst \inst \tv \t
    } \\
    \entry[Semantic environments]{\semenv}{
      \dots
      \and \semenv\where{\inst := \semenvp}
    }
  \end{bnfgrammar}
\end{minipage}
\hfill
\infer[Exists-Inst]
  {\greg \tv\semenvp \in \semenv(\x) \\\\
   \semenv\where{\inst \is \semenvp} \th \c}
  {\semenv \th \cexistsi \inst \x \c}

\infer[Partial-Inst]
  {\semenv(\inst)(\tv) = \semenv(\t) }
  {\semenv \th \cpinst \inst \tv \t}
\end{mathparfig}


\parcomment {Intro partial applications}

To support this, we extend the constraint language with \emph{partial
instantiation constraints}. Instead of duplicating an abstraction at each
application site, we introduce:
\begin{enumerate*}
  \item
    $\cexistsi \inst \x \c$, which binds a fresh instantiation $\inst$ of $\x$'s
    region within $\c$, and
  \item
    $\cpinst \inst \tv \t$, which asserts that the copy of $\tv$ in $\inst$
    equals~$\t$.
\end{enumerate*}
%
The instantiation variable $\inst$ is required to ensure all partial
instantiations $\cpinst \inst \tv \t$ are solved uniformly. Within the
solver, we view partial instantiations as markers indicating which parts of
the abstraction still need to be copied.

Partial instantiations enables efficient incremental instantiation of
constraint abstractions: solved parts are reused immediately, while
suspended constraints can be solved later, further refining the
abstraction and propagation additional equations to the application
sites.

\parcomment{Semantics of partial applications}

The semantics of the existential constraint $\cexistsi \inst \x \c$
(\Rule{Exists-Inst}) introduces the fresh instantiation~$\inst$ by ``guessing''
a region $\semenvp$ that satisfies the regional constraint abstraction bound to
$\x$.
%
Partial instantiations (\Rule{Partial-Inst}) equate the copy of $\tv$ in
$\inst$ with $\t$.
%
The domain of partial instantiation constraints must lie within the closure of
the abstraction or among the regional variables of $\x$. Consequently, the
variables $\tv, \tvs$ bound by the $\Let$-constraint $\cletr \x \tv \tvs \ca
\cb$ are bound not only in the body of the abstraction $\ca$, but also in the
constraint $\cb$, where they may appear in partial instantiations of $\x$ via
renamings---and only there. Hence, they cannot appear in $\cb$ when the
corresponding variable $\x$ does not itself appear in $\cb$.

\parcomment{Solving partial instantiations}

Partial instantiation constraints are reduced using the following rules:
\begin{enumerate}

\item
  \Rule{S-Inst-Copy} copies the shape of a type to the instantiation site,
    introducing fresh variables for each subcomponents and marking them with
    corresponding instantiation constraints.
    %
    We write $\cpapp \x \tv \t \inst$ as a shorthand for $\cpinst \inst \tv \t$
    when $\inst$ is bound with $\exists \inst^\x$ in the context. To ensure
    termination, the abstraction must contain acyclic types.

  \item \Rule{S-Inst-Unify} unifies two instantiations if they refer to the
    same source variable.
\end{enumerate}
There are three cases in which an instantiation constraint is eliminated:
\begin{enumerate}
  \item
    A nullary shape is copied and no further instantiations are needed
    (\Rule{S-Inst-Copy}).

  \item
    The copied variable $\tvb$ is polymorphic, and thus the instantiation
    constraint imposes no restriction (\Rule{S-Inst-Poly}), provided no
    other instantiations of $\tvb$ remain (if not, then apply
    \Rule{S-Inst-Unify}).

  \item
    The copy is monomorphic and in scope, so we unify it directly
    (\Rule{S-Inst-Mono}).
\end{enumerate}


%% Uncomment to restore the old style
%% \let \rewrite \hrewrite
\begin{mathparfig}[t]
  {fig:solver-schemes} {Select rewriting rules for let-bindings and
  applications.}
  \rewrite[S-Exists-Lower]
    {\cletr \x \tv {\tvas, \tvbs} \ca \cb\\}
    {\cdetermines {\cexists {\tv, \tvas} \ca} \tvbs}
    {\cexists \tvbs \cletr \x \tv \tvas \ca \cb}

  \rewrite[S-Let-AppR]
    {\cletr \x \tv \tvs \c {\C\where{\capp \x \t}}}
    {\tvc \disjoint \t \\
     \x \disjoint \bvs \C}
    {\cletr \x \tv \tvs \c
       {\C\where{\cexistsi {\tvc, \inst} \x
                {\cunif \tvc \t \cand \cpinst \inst \tv \tvc}}}}

  \rewrite[S-Inst-Copy]
    {\cletr \x \tv \tvs {\c}
      \C\where{\cpapp \x \tvp \tvc \inst}}
     {\c = \cp \cand \cunif \tvp {\cunif {\shapp \tvbs} \ueq}\\\\
      \tvp \in \reg \tv \tvs \\
      \neg \cyclic {\c} \\
     \tvbs' \disjoint \tvp, \tvc, \tvbs \\
     \x \disjoint \bvs \C}
    {\cletr \x \tv \tvs {\c}
      \C\where{\cexists {\tvbs'}
          \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}}

  \rewrite[S-Inst-Unify]
    {\cpinst \inst \tv \tvca \cand \cpinst \inst \tv \tvcb}
    {}
    {\cpinst \inst \tv \tvca \cand \cunif \tvca \tvcb}

  \rewrite[S-Inst-Poly]
    {\cletr \x \tv {\tvs} {\ueqs \cand \c}
        {\C\where{\cpapp \x \tvp \tvc \inst}}}
    {\\\cfor \tvp \cexists {\tv, \tvs \setminus \tvp} {\ueqs} \cequiv \ctrue \\
      \tvp \in \reg \tv \tvs \\\\
     \tvp \disjoint \c \\ \inst.\tvp \disjoint \insts \C \\
     \x \disjoint \bvs \C}
    {\cletr \x \tv {\tvs} {\ueqs \cand \c} {\C\where\ctrue}}

  \rewrite[S-Inst-Mono]
    {\cletr \x \tv \tvs \c {\C\where{\cpapp \x \tvb \tvc \inst}}\\}
   {\tvb \notin \reg \tv \tvs \\
     \x, \tvb \disjoint \bvs \C}
    {\cletr \x \tv \tvs \c {\C\where{\cunif \tvb \tvc}}}

  \rewrite[S-Let-Solve]
    {\cletr \x \tv \tvs \ueqs \c\\}
    {\cexists {\tv, \tvs} \ueqs \cequiv \ctrue \\
     \x \disjoint \c}
    {\c}

  \rewrite[S-Compress]
    {\cletr \x \tv {\tvs, \tvb} {\ca \cand \cunif \tvb {\cunif \tvc \ueq}} {\cb}}
    {\tvb \neq \tvc}
    {\cletr \x \tv {\tvs}
       {\ca\where{\tvb \is \tvc} \cand
        \cunif \tvc {\ueq\where{\tvb \is \tvc}}} {\cb\where{\x.\tvb \is \tvc}}}

  \rewrite[S-BackProp]
    {\C\where
       {\cletr \x \tv {\tvs} {\Ca\where{\cmatch \tvp \cbrs}}
                           {\Cb\where{\cpapp \x \tvp \tvc \inst}}}}
    {\tvp \in \reg \tv \tvs \\
     \cunif {\tvp} {\cunif \t \ueq} \in \C\where\Cb \\
     \x \disjoint \bvs \Cb}
    {\C\where{\cletr \x \tv {\tvs} {\Ca\where{\cmatched \tvp {\shape \t} \cbrs}}
		      {\Cb\where{\cpapp \x \tvp \tvc \inst}}}}
\end{mathparfig}


\parcomment{Cleaning up partial applications and let constraints}

\Rule{S-Let-Solve} remove a $\Let$ constraint when the bound term
variable is
unused and the abstraction is satisfiable. \Rule{S-Compress} determines that a
regional variable $\tvb$ is an an alias for $\tvc$. We replace every free
occurrence of $\tvb$ with $\tvc$---\emph{including} the domains of any partial
instantiation constraints, written as the substitution $\where{\x.\tvb \is
\tvc}$. We view this as an analogous copy rule for variables.

\parcomment{Lowering}

\Rule{S-Exists-Lower} implements the non-trivial case of lowering
existentials across $\Let$-binders. It identifies a subset of variables in
the region of a $\Let$ constraint that are unified with variables from
outside the region. Such variables are considered monomorphic and thus
cannot be generalized; they can instead be safely lowered to the outer
scope.

\parcomment {Determines}

This is the case when the types of $\tvbs$ are \emph{determined} in a unique
way. In short, $\c$ determines $\tvbs$ if and only if the solutions for
$\tvbs$ are uniquely fixed by the solutions to other variables in $\c$.

\begin{definition}
  $\cdetermines \c \tvbs$ if and only if every ground assignments
  $\semenv$ and $\semenvp$ that satisfy (the erasure of) $\c$ and coincide outside of $\tvbs$
  coincide on $\tvbs$ as well.
  \begin{mathpar}
    \cdetermines \c \tvb \uad\eqdef\uad \all {\semenv, \semenvp} \uad
      \semenv \th \cerase \c
      \wedge \semenvp \th \cerase \c
      \wedge \semenv =_{\setminus \tvbs} \semenvp
      \implies
      \semenv = \semenvp
  \end{mathpar}
\end{definition}

\parcomment {How the determines relation corresponds to ML}

Conceptually, this corresponds to the negation of the generalization condition
in \ML: a type variable cannot be generalized if it appears in the typing
context. In the constraint setting, it cannot be generalized if it depends on
variables from outside the region.

\parcomment{How to decide the relation}

To decide when $\cdetermines {\cexists \tvs \c} \tvbs$ holds for $\tvbs
\disjoint \tvs$, we search for a multi-equation $\ueq$ in $\c$ of the form:
\begin{enumerate*}
  \item $\cunif \tvc \ueq'$ where $\tvc \disjoint \tvs, \tvbs$ and
    $\tvbs \subseteq \fvs {\ueq'}$, or
  \item $\cunif \tvbs {\cunif \t \ueq'}$ where $\fvs \t \disjoint
    \tvs, \tvbs$.
\end{enumerate*}
For instance, $\cexists \tvba \cunif \tv {\tvba \to \tvbb}$ determines
$\tvbb$, as $\tvbb$ is free.

\parcomment{Why we lower?}

Lowering such variables improves solver efficiency. It avoids unnecessary
duplication of work that would otherwise occur via \Rule{S-Inst-Copy}. By
reducing the number of variables that need to be copied, lowering directly
reduces instantiation overhead.

\paragraph{Backpropagation}

Finally, \Rule{S-BackProp} expresses \emph{backpropagation}, previously
illustrated in \cref{ex:backprop}. In particular, the shape of a regional
variable can sometimes be determined from its instantiations. If an abstraction
contains a suspended match constraint on a regional variable $\tvp$, and the
constraint context includes a partial instantiation $\cpapp \x \tvp \tvc \inst$
together with a multi-equation constraining the copy of $\tvp$ ($\tvc$)
to a non-variable type $\t$, then $\shape \t$ must be the unique shape of
$\tvp$. Any other shape would render the instantiation unsatisfiable.

% Properties

\begin{restatable}[Progress]{theorem}{progress}
  \label{thm:progress}
  If constraint $\c$ cannot take a step $\c \csolve \cp$, then either:
  \begin{enumerate}[(\roman*)]
    \item $\c$ is solved.
    \item $\c$ is stuck, it is either:
      \begin{enumerate*}
      \item
        $\cfalse$;
      \item
        $\hat\C\where{\capp \x \t}$ where $\x \disjoint \hat\C$;
      \item
        $\hat\C\where{\cpapp \x \tv \tvc \inst}$ where
        $\x \disjoint \hat\C$ and $\inst.\tv \disjoint \insts {\hat\C}$;
      \item
        for every match constraint $\hat\C\where{\cmatch \tv \cbrs}$ in
        $\c$, $\Cshape {\hat\C} \tv \sh$ does not hold for any $\sh$.

      \end{enumerate*}
     Here, $\hat\C$ is a normal context \ie such that no other
     rewrites can be applied.
  \end{enumerate}
\end{restatable}

\begin{restatable}[Termination]{theorem}{termination}
  \label{thm:termination}
  The constraint solver terminates on all inputs.
\end{restatable}

\begin{restatable}[Preservation]{theorem}{preservation}
  \label{thm:preservation}
  If $\ca \csolve \cb$, then $\ca \cequiv \cb$.
\end{restatable}

\section{Implementation}
\label{sec:implementation}

We have two working prototypes implementing the \OML language with suspended
match constraints and partial type schemes, in which we have reproduced the
various type-system features and examples presented in this work.  One closely
follows the constraint-based presentation described here\footnote{The other
prototype is a direct implementation of type inference based on
semi-unification. We mention it here only it indicate that we have explored
multiple implementation strategies leading to the same results.}. It is public
and open-source (link omitted for anonymity). Its implementation is inspired by
previous work such as \Inferno~\citep {Pottier/inferno@icfp2014,
Pottier/inferno@opam}.  It uses state-of-the-art implementation techniques for
efficiency, such as a Tarjan's union-find data structure for unification
\citep*{journals/jacm/Tarjan75} and \emph{ranks} (or \emph{levels}) for
efficient generalization \citep*{Remy/mleth}. Let us discuss a few salient
points.

\paragraph{Unification and scheduling}

Each unsolved unification variable maintains a \emph{wait list} of suspended
constraints that are blocked until the variable is unified with a concrete
type. When such a unification occurs, the wait list is flushed: the suspended
constraints are scheduled on the global constraint scheduler, which is
responsible for eventually solving them.

\paragraph{From a stack to a tree}

% To implement generalization (the \Rule{S-Lower-Exists} rule)
% efficiently, we follow the classic rank-based approach to
% generalization. Each $\Let$ constraint and type variable is allocated
% an integer \emph{rank}, which informs us the depth of the region
% within the constraint. Type variables of rank $0$ are bound at the
% top-level region, and type variables of rank $r \geq 1$ are bound in
% the region of $\Let$ constraint at depth $r$.

% As inference progresses, unification may widen the scope of variables,
% thereby lowering their rank. The set of variables eligible for
% generalization at a given region consists precisely of those
% whose rank remains equal to that of the region.

Many standard \ML implementations, for example \Inferno, represent the solver
state as a linear \emph{stack} of inference regions, from the outermost
variable scope to the current region. Unification associates
an integer \emph{rank} (or \emph{level}) for each variable, that indexes the
region in the stack to which it belongs.
%
This approach does not work for partial generalization. If
generalization at some region is suspended by a match constraint, the
region must remain alive while we continue inference in other
regions. However, later parts of the constraint may introduce a new
$\Let$-region at the same rank that is unrelated to the suspended one---neither its
ancestor nor its descendant---breaking the linear assumption of ranks.

Our implementation must instead use a \emph{tree} of nested
$\Let$-regions. Under this scheme, ranks no longer uniquely determine a
variable's region. Instead, we interpret a rank relative to a path in the
region tree from the root. When two variables are unified, they must always
lie on some shared path---by scoping invariants---so computing their minimum
rank (along this path) suffices to determine the lowered region: we keep
the efficient integer comparisons of generalization.

\paragraph{Partial generalization}

Partial generalization arises when a region cannot be fully
generalized due to suspended constraints that may still update
its variables. To manage this, we classify type variables
into four categories:
\begin{itemize}
  %% \let \\ \relax
  \let \Item \item
  \renewcommand \item [1][]{\Item[(\textbf{#1})]}
  \item[I] Variables are yet to be generalized. \\
    \emph{Introduced by instantiations or source types in constraints}

  \item[G] Variables that are generalized. \\
    \emph{Not accessible from any instance type. Treated polymorphically.}

  \item[PG] Variables that are partially generalizable. \\
    \emph{Generalizable variables mentioned by suspended match constraint or partial
    instantiations.}

  \item[PI] Variables that were previously partially generalized
    but have since been updated.  \\
    \emph{Awaiting re-generalization. Introduced by the unification of partial
    generics.}
\end{itemize}
At generalization time, we conservatively approximate whether a variable may be
updated in the future using \emph{guards}. A guard is a mark on a variable that
indicates the variable is captured by some suspended constraint that has not
yet been solved. Guarded variables are generalized as partial generics (\textbf{PG});
unguarded ones are fully generalized (\textbf{G}).

When an instance is taken from a partial generic, we retain a forward reference
from the partial generic (\textbf{PG}) to the instance. This enables the
generic to notify the instance that it has been updated, propagating the
updated type structure to all instances. This mirrors, in reverse, the way our
formalized solver uses partial instantiation constraints to track copies. In
addition, the instance remains guarded by the partial generic until the latter
is either lowered or fully generalized.

Once a suspended match constraint is solved, it removes the guards it
introduced. This may enable previously partial generics to become fully
generalizable. Conversely, if a partially generalized variable is lowered (\eg
by \Rule{S-Lower-Exists}), it must be unified with all its instances.

\paragraph{Lazy generalization} Repeatedly generalizing a region after every
update is expensive.  Instead we generalize on demand. We mark regions as
``stale'' when they may require re-generalization. When an instance is taken,
we re-generalize the stale descendants of the region in the region tree.

\section{Related work}
\label{sec:related-work}

\paragraph{Principality tracking in \OCaml}

\citet*{Garrigue-Remy/poly-ml} introduced an approach to principality tracking
for polytypes---what we now call \geninst-directional inference---in which
generalization and instantiation govern the flow of known type information.
This approach has since been extended to other features of the \OCaml language:
whenever the typechecker need to know if a type is known in a robust way, it
checks whether the type is generalizable. We compared their approach to ours in
\cref{sec/introduction} and \cref{sec/constraints/polytypes}.

\paragraph{Bidirectional type inference}

At the level of simply-typed
terms or \ML, we believe that omnidirectional inference works better
than bidirectional type inference: it can type more programs than
a given fixed bidirectional system, and has a more declarative
specification---we would say that it is ``more principal''.  In fact,
a direct inspiration for the present work was a user complaint in
\citet*{rossberg-wasm} on the type-based disambiguation of \OCaml: its
bidirectional logic propagates type information from patterns to
definitions in \code{let}-bindings, when the WebAssembly reference
implementation would sometimes prefer the other direction.
%
% De-anonymizing URL: https://github.com/ocaml/ocaml/issues/7389
%
On the other hand, bidirectional typing is known to scale to powerful
systems such as fully-implicit predicative
polymorphism~\citep*{dunfield-krishnaswami-bidirectional-poly} and we
have not considered scaling our approach to those systems yet.


\paragraph{Qualified types}

Qualified types~\citep*{jones-qualified-types}, most well-known via their usage
in Haskell type-classes, are related to our suspended match constraints as they
represent constraints on types or type variables. At generalization time, the
constraints on generalizable variables are kept as part of the generalized type
scheme, and they get copied during instantiation. This is much simpler to
implement than our partial type schemes, but it provides a different behavior
where each instance can choose independently how to resolve the constraint.
Qualified types are an excellent choice when this is the desired behavior,
typically for dynamic overloading. To handle cases that require a unique
resolution of the constraint across all instances---such as static
overloading---we require the more complex mechanism of partial generalization.

\paragraph{Suspended constraints in dependent-type systems}

Suspending the constraints that cannot be solved yet is not a novel idea: it
is a standard approach to implement unification dependently-typed
systems. This goes back to Huet's algorithm for higher-order
unification~\citep*{huet-unif} and pattern
unification~\citep*{Miller/pattern-unif@iclp91} where flexible-flexible
pairs are delayed until at least one side becomes rigid. The novelty of our
work lies in combining constraint suspension with \ML-style implicit
polymorphism---absent from most dependently-typed systems---and in the design
of a declarative constraint semantics used to establish principality.

%% \paragraph{Leijen et al. (TODO change paragraph naming)}
%% Should we cite \citet*{Leijen-Ye/prefix@pldi2025}?
%% \Xdidier{I'm volunteering to write this, but we are not sure we have to}.

\paragraph{\OutsideIn}

\OutsideIn~\citep*{conf/icfp/SchrijversJSV09} is a type system for GADTs that
introduces \emph{delayed implications} of the form $\where{\tvs}(\all \tvbs \ca
\Rightarrow \cb)$. Constraint solving for delayed implications proceeds in two
steps; solving simple constraints first and then solving delayed implications.
The deferral ensures that inference for GADT match branches occurs when more is
known about the scrutinee and expected return type from the context.
%
To ensure principality, \OutsideIn enforces an algorithmic
restriction: the variables $\tvs$ must already be instantiated to
concrete type constructors before they may be unified by the
implication's conclusion $\cb$. This ensures information only flows
from the outside into the implication's conclusion. They do not give
a declarative semantics for delayed implication that their solver
preserves. Moreover, later work on \OutsideIn argues
\citep*{Vytiniotis-Peyton-Jones-Schrijvers-Sulzmann/outsidein@jfp2011}
that delayed implication constraints make local let-generalization all
but unmanageable, both in theory and implementation. Their proposed fix
is to abandon local let-generalization altogether. We believe that we
have solved the troubling interactions between let-generalization and
suspended constraints in this work, and would be interested in
studying applications to GADT typing, which was also one of our
original motivations.

\section{Conclusions and future work}
\label{sec:discussion}
\label{sec:future-work}

In this work, we developed a constraint-based framework for omnidirectional
type inference, capable of supporting fragile features that would otherwise
break principality.
%
Central to our approach is a new declarative account of when type inference is
\emph{known} from the context, rather than \emph{guessed}.

Our constraint solver is omnidirectional: constraints may be solved in any
order, made possible by our introduction of \emph{partial type schemes}.
We formalized the solver as a non-deterministic, terminating rewrite system,
and implemented an efficient prototype to demonstrate its practicality.

Through three instantiations of our framework---static overloading of
tuples, nominal records and variant constructors, and semi-explicit
first-class polymorphism---we showed that our framework yields a sound and
complete inference algorithm and a principal type system. In short, it
appears principality holds \emph{anyway} from our approach.
%
Naturally, all this begs the question: what else can be done with
omnidirectional inference beyond the features of \OML?


\paragraph{Static overloading}

Our nominal records use a restricted form of overloading.  We have also
experimented with a more general overloading mechanism in which several
definitions may be bound to the same identifier ${\color{gray}\M.}\x$, but
prefixed with a namespace\footnote {Reusing the notation
of~\citet*{Leijen-Ye/prefix@pldi2025}.}~$\color{gray}\M$ used for
disambiguation: an implicit form $\x$ in the source is elaborated to an
explicit form~$\exover {{\color{gray}\M}} \x$.
%
Although implemented in a prototype, we have not yet
%% identified a satisfactory typing behavior or
formalized this feature.  Nevertheless, we conjecture
that it should be typable with our framework.

Modular implicits \citep*{White-Bour-Yallop/Modular_Implicits/ml2014} are a
proposed extension to \OCaml's module system, intended to support ad-hoc
polymorphism through type-directed implicit parameters. We believe
omnidirectional type inference could serve as a principled, constraint-based
approach foundation for resolving implicits in the presence of
let-generalization.
%
As future work, we aim to extend our constraint language to typecheck an
implicit-parameters calculus, similar to \COCHIS
\citep*{journals/jfp/SchrijversOWM19}, but with \ML polymorphism.


\paragraph{Higher-rank polymorphism}

In \cref{sec/introduction} and \cref{sec:related-work}, we compared
omnidirectional and bidirectional type inference in the context of static
overloading. While overloading is non-trivial, it poses little challenge for the
bidirectional framework, making the comparison somewhat limited. Bidirectional
typing is best known for its scalability to more complex settings, such as
higher-rank polymorphism. We are therefore interested in extending our
framework to support higher-rank polymorphism, in the style of
\citet*{dunfield-krishnaswami-bidirectional-poly}. This would provide a more
meaningful basis for understanding the trade-offs of omnidirectional and
bidirectional inference.

\MLF is an extension of \ML that support first-class polymorphism that
goes beyond the power of System $\F$, while retaining type inference.
It is a generalization of \OCaml's polytypes, relying on \geninst-directionality.
It would therefore be worth exploring whether omnidirectional type inference
could further empower \MLF.

\paragraph{Default rules}

% Default rules are useful
Some type systems disambiguate fragile constructs using known type information,
but fall back on default, non-principal choices when none is available. \OCaml
selects the most recent matching record type in scope for ambiguous field
names; \SML assigns default types to overloaded numeric
literals~\citep*[Section 5.8]{rossberg-hamlet}.

\parcomment {We tried, but failed}

We explored adding such \emph{default rules} to suspended match constraints,
allowing unresolved constraints to discharge with a default shape rather than
fail. While pragmatic, such rules are inherently non-principal and difficult to
reconcile with our framework.

\parcomment {Why did we fail}

In particular, they introduce subtle semantic complexities: if two suspended
constraints could unlock each other, then defaulting one over the other
may force an unsatisfiable branch to be taken.
% But we have a nifty prototype
The optimal or principled strategy for applying defaults in such cases
remains unclear.
Should we fire all default rules of all suspended constraints
that remain after the solver terminates, or in batches, restricted to connected
components of mutually dependent suspended constraints?
Our prototype opts for the latter, but this warrants further study.

%%\paragraph{Behavior of default rules} Giving priority to most recent
%%definitions is a possible default behavior for field and constructor
%%disambiguation. For structural tuples there is no reasonable default
%%rule.
%
%%For polytypes, one option is to fallback to a monomorphic polytype. The
%%other one is to pick the principal type scheme of the expression with an
%%unresolved polytype. Of course, there are examples that favor one choice
%%and other examples that favor the other.

\paragraph{Equi-recursive types}
\label {sec/rec-types}

\OCaml allows equi-recursive types to express recursive polymorphic variants
and objects types. Supporting such types is a necessary step towards integrating
our approach into \OCaml's typechecker.

In this work, for the sake of simplicity, we treat ground types as finite
trees. Supporting equi-recursive types amounts to using regular trees instead
\citep*{Pottier-Remy/emlti}. Our prototype already supports them,
but the formalization of our solver relies on acyclicity to ensure
termination.  Extending the formalization to accommodate cycles would
require some changes.  Following the implementation, incremental
instantiation might require to instantiate cycles atomically.

Shapes may also be equi-recursive, though only minimal shapes of polytypes
can be recursive. In the acyclic setting, shape equality is syntactic; with
cycles, this no longer holds---but we do not anticipate any fundamental issues.

% \begin{acks}
% \end{acks}

%% \bibliographystyle{ACM-Reference-Format}
\bibliography{suspended}

\newpage
\appendix

\section*{Organization of our appendices}
\label{app:outline}

\paragraph{Content appendices.} These appendices are intended to be
readable prose in the style of the rest of the paper.

\begin{itemize}
\item \cref{app:oml-calculus} presents and explains the typing rules for \OML;
  this is the long version of \cref{sec:language}.
\item \cref{app:unification} presents a relatively standard part of our constraint solver (\cref{sec:solving}),
  namely the unification rules.
%%\item \cref{app:more-discussion} contains topics of discussion that we
 %% did not have the space to include in \cref{sec:discussion}.
\end{itemize}

\paragraph{Reference appendix}
\begin{itemize}
\item \cref{app:full-reference} gives a full reference for all
  definitions, grammars and figures in the paper, including all cases
  (even those omitted from the main paper for reasons of space).
\end{itemize}

\paragraph{Proof appendices} These appendices contain proofs for the
formal claims in the article. They are typically written tersely.
\begin{itemize}
\item \cref{app:proofs-constraints} proves properties of the
  constraint language and its semantics. The main result is
  canonicalization, which morally establishes that uses of the
  contextual rule \Rule{Susp-Ctx} can be ``permuted down'' in the
  proof until they are all at the bottom of the derivation, followed
  by a proof on a simple constraint.
\item \cref{app:proofs-solving} proves the correctness of the
  constraint solver with respect to the semantics.
\item \cref{app:proofs-typing} proves the properties about the \OML
  type system, in particular the correctness of constraint generation.
\end{itemize}

\section{The \OML calculus: typing rules and constraint generation}
\label{app:oml-calculus}

\subsection{Typing rules}
\label{sec/language/typing-rules}

As usual, the main typing judgment $\G \th \e : \ts$ states that in context
$\G$, expression $\e$ has type scheme $\ts$.  Typing rules are given on \cref
{fig/typing}.  They use auxiliary typing judgments $\G \th \elab = \e : \t$
and $\el : \t \to \tp$ for the typing of record assignments and
label instantiations respectively.

\begin{mathparfig}{fig/typing}{Typing rules of \OML.}
  \inferrule[Var]
    {x : \sigma \in \G}
    {\G \th x : \sigma}

  \inferrule[Fun]
    {\G, x : \ta \th e : \tb }
    {\G \th \efun x e : \ta \to \tb}

  \inferrule[App]
    {\G \th \ea : \ta \to \tb \\
     \G \th \eb : \ta}
    {\G \th \eapp \ea \eb : \tb}

  \inferrule[Unit]
    { }
    {\G \th () : 1}

  \inferrule[Annot]
    {\G \th e : \t\where {\tvs \is \tys}}
    {\G \th (e : \exi \tvs \t) : \t\where {\tvs \is \tys}}

  \inferrule[Gen]
    {\G \th e : \sigma \\ \tv \disjoint \G}
    {\G \th e : \tfor \tv \sigma}

  \inferrule[Inst]
    {\G \th e : \tfor \tv \ts}
    {\G \th e : \tv \where{\tv \is \t}}

  \inferrule[Let]
    {\G \th \ea : \sigma \\
     \G, x : \sigma \th \eb : \t}
    {\G \th \elet x \ea \eb : \t}

  \inferrule[Tuple]
    {\parens{\G \th \ei : \ti}\iton}
    {\G \th (\ea, \ldots, \en) : \Pi\iton \ti}

  \inferrule[Proj-X]
    {\G \th \e : \Pi\iton \ti \\
     1 \leq j \leq n}
    {\G \th \exfield \e n j : \tj}

  \inferrule[Proj-I]
    {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\
     \G \th \E\where{\exfield \e n j} : \t}
    {\G \th \E\where{\efield \e j} : \t}

  \inferrule [Poly-X]
    {\G \th \e : \ts\where {\tvs \is \tys}}
    {\G \th \epoly[\exi \tvs \ts] \e : \tpoly {\ts \where {\tvs \is \tys}}}

  \inferrule [Poly-I]
    {\Eshape \E \e {{\any \tvcs \tpoly \ts}} \\
     \G \th \E \where{\epoly[\exi \tvcs \ts] \e} : \t}
    {\G \th \E \where{\epoly \e} : \t}

  \inferrule [Use-X]
    {\G \th \e : \tpoly \ts \where {\tvs \is \tys}}
    {\G \th \exinst e \tvs \ts : \ts \where {\tvs \is \tys}}

  \inferrule [Use-I]
    {\eshape \E  \e {\any \tvcs \tpoly \ts} \\
     \G \th \E\where{\exinst \e \tvcs \ts} : \t}
    {\G \th \E\where{\einst \e} : \t}

  \inferrule[Rcd-Assn]
    {\G \th \e : \t \\
     \el : \t \to \tp}
    {\G \th \el = \e : \tp}

  \inferrule[Rcd]
    {\parens{\G \th \eli = \ei : \t}\iton \\
     \bar \el \uni \t}
    {\G \th \erecord {\ela = \ea; \ldots; \el_n = \en} : \t}

  \inferrule[Rcd-Proj]
    {\G \th \e : \tp \\
     \el : \t \to \tp \\
     \el \uni \t }
    {\G \th \efield \e \el : \t}

  \inferrule[Lab-I]
    {\Lshape \Lab \elab \T \\
      \G \th \Lab[\elab / \T] : \t}
    {\G \th \Lab[\elab] : \t}

  \inferrule[Lab-X]
    {\Omega(\elab / \T) = \tfor \tvs \t \to \T \tvs }
    {\elab / \T : \tys\where{\tvs \is \tys} \to \T \tys}

  \inferrule[Lab-I]
    {\Lshape \Lab \elab \T \\
      \G \th \Lab[\elab / \T] : \t}
    {\G \th \Lab[\elab] : \t}

  \inferrule[Lab-!]
    {\bar \el \uni {\T} \in \labenv}
    {\bar \el \uni {\T} \tys}

  \inferrule[Lab-?]
    {}
    {\bar \el \uni \t}
\end{mathparfig}

%\TODO{We should consider handling the three features (tuples, records, polytypes) separately, one in each subsection.
%If we later run out of space budget it will be easier to move only some of those subsections to an appendix.
%Concrete proposal:
%\begin{itemize}
%\item one subsection at the beginning that only hints at the standard ML stuff:
%  show the syntax, hint at typing rules, show a short bit of constraint generation
%\item then each advanced feature (from the simplest to the more complex: tuples, polytypes, records)
%  show the typing rules, and examples, and its dedicated patterns, and its constraint generation
%\end{itemize}}
%
\begin{version}{}
\begin{bnffig}{fig/types/bnf}{aaa}
\entry[Types]{\t}{
    \tv \and
    \tunit \and
    \t \to \t \and
    \Pi \parens \t\iton \and
    \T \tys \and
    \tpoly \ts
}
\end{bnffig}

\begin{mathparfig}
  {fig/types/wf}
  {Well-formedness of types}
  \inferrule[Var-Wf]
    {\tv \in \G}
    {\G \th \tv}

  \inferrule[Unit-Wf]
    { }
    {\G \th \tunit}

  \inferrule[Arr-Wf]
    {\G \th \t \\ \G \th \tp}
    {\G \th \t \to \tp}

  \inferrule[Prod-Wf]
    {(\G \th \ti)\iton}
    {\G \th \Pi\iton \ti}

  \inferrule[Rcd-Wf]
    {(\G \th \ti)\iton \\
     {\T} \in \dom \Omega}
    {\G \th \T \tys}

  \inferrule[Poly-Wf]
    {\G \th \ts}
    {\G \th \tpoly \ts}

  \inferrule[Forall-Wf]
    {\G, \tv \th \ts}
    {\G \th \tfor \tv \ts}
\end{mathparfig}
\end{version}


\parcomment {Simple typing rules explained}

\Rule{Var} retrieves the type scheme $\x : \ts$ from the context $\G$.
Function types are introduced via lambda abstractions: in \Rule{Fun}, the
system guesses a well-formed type $\ta$ for the type of $\x$, typechecks the
body $e$ is under the extended context $\G, \x : \tya$ producing the return
type $\tyb$, and assigns the abstraction the function type $\tya \to \tyb$.
Conversely, function types are eliminated by applications; in Rule \Rule{App},
the type of the argument must match the function's parameter type $\tya$ and
application returns the type $\tyb$. \Rule{Unit} asserts that $\eunit$ has
the unit type $\tunit$.

\parcomment {Gen/Inst explained}

\Rule{Gen} and \Rule{Inst} correspond to implicit
\textit{generalization} and \textit{instantiation} respectively.
Generalization universally quantifies a type variable $\tv$, introducing it
as a fresh polymorphic variable in the typing context. In \Rule{Inst}, we
specialize a type scheme $\tfor \tv \ts$ to $\ts \where{\tv \is \t}$,
substituting $\tv$ for an arbitrary monotype $\t$.

\parcomment {Let rule}

Let-polymorphism is handled by the \Rule{Let} rule, where a
\textit{polymorphic} term can be bound. This allows a single definition to be
instantiated differently at each use site---an essential feature of \ML. In
this rule, the term $\ea$ has a polymorphic type scheme $\ts$, adds $\x :
\ts$ into the context $\G$ to typecheck $\eb$.

\parcomment {Annotations}

Annotations $\eannot \e \tvs \t$ ensures that the type of $\e$ is (an instance
of) the type $\t$. The type variables $\tvs$ are \emph{flexibly} (or
existentially) bound in $\t$, meaning that $\tvs$ may be unified with some
types $\tys$ to produce a well-typed term. For instance, the term $(\efun \x \x
+ 1 : \exi \tv \tv \to \tv)$ is well-typed with $\tv \is \tint$ in
\Rule{Annot}.

\parcomment {Contextual rules (Poly-*, Use-*, Proj-*)}

\paragraph{Polytypes and overloaded tuples}

The typing rules for fully annotated terms ($\e^x$) are unsurprising.
However, typing rules for terms with omitted type annotations are
non-compositional as they depend on a surrounding one-hole context
$\E$. Hence, they assert that the typability of the expression $\G \th \E
\where {\e^i}: \t$ where $\e^i$ is an expression with an implicit type
annotation.
%
We first request a typing for the expression with an explicit annotation $\G
\th \E \where {\e^x}: \t$ where $\e^x$ is a fully annotated variant of $\e^i$.
We then request that (the shape of) the annotation is fully determined from
context, either from the type of the expression, which we write $\eshape \E
\e \sh$, or from the type of the hole, which we write $\Eshape \E \e \sh$.

In order to describe the judgments $\eshape \E \e \sh$ and $\Eshape \E \e \sh$,
we introduce a \emph{typed hole} construct $\emagic \e$ that allows any
well-typed expression $\e$ to be treated as if it had any type. That is the
typing rule for holes is:
\begin{mathpar}
  \inferrule[Magic]
    {\G \th \e : \t}
    {\G \th \emagic \e : \tp}
\end{mathpar}
Typed holes are not allowed on source terms and are just a device for
the definition of non-ambiguous shapes.  Finally, we define what it means for a
shape to be determined from the type of a context or an expression:
\begin{mathpar}
\def \Eqdef {&\eqdef&}
{\begin{tabular}{RCL}
\eshape \E \e \sh \Eqdef
  \forall \G, \t, \gt, \uad
  \G \th \eerase {\E \where {\emagic {\eannot \e {} \gt }}} : \t
      \wide\implies \shape \gt = \sh
\\[1ex]
\Eshape \E \e \sh \Eqdef
  \forall \G, \t, \gt, \uad
      \G \th \eerase {\E\where{\eannot {\emagic \e} {} \gt}} : \t
      \wide\implies \shape \gt = \sh
\end{tabular}}
\end{mathpar}
These states that the shape $\sh$ of expression $\e$ in context $\E$ is
determined by the expression $\e$, in the former case, or by the context
$\E$ in the latter case. Just like constraints, we must erase implicit constructs
in the term that have not yet been elaborated, written $\eerase \e$ (defined in
\cref{app:full-reference}).

%% Shapes are equal modulo alpha equivalence and the removal of useless
%% polymorphic type variables. They do not have useless existential variables.

% Expression-based implicit rules

The implicit rule \Rule{Proj-I} types the projection $\eproj \e j$ provided the
context $\E$ \emph{infers} that the shape of $\e$ must be a tuple with arity $n$.
Similarly, \Rule{Use-I} permits instantiating a polytype in $\einst e$ if
the context $\E$ infers that the type of $\e$ must be a polytype with shape
$\any \tvcs \tpoly \ts$. The rule \Rule{Poly-I} types the implicit boxing
construct $\epoly \e$ by \emph{checking} the expected type of $\epoly \e$ in the
context $\E$ is a polytype with the shape $\any \tvcs \tpoly \ts$. This rule
differs from the previous two as the shape is determined by the expected type
within the context as opposed to the inferred type of $\e$.


% Labels

\paragraph{Overloaded record labels}
% Contextual rules
We adopt a similar non-compositional approach for elaborating overloaded
labels, whether in record projection ($\efield e \elab$) or record
construction ($\erecord {\overline{\elab = \e}}$), although the definitions
are slightly more involved.  Here, a one-hole label context $\Lab$ provides the
surrounding context in which a label $\elab$ may appear:
\begin{mathpar}
\begin{bnfgrammar}
\entry [Label contexts]{\Lab}{
    \E \where {\e.\square} \and
    \E \where
         {\erecord
            {\ela = \ea; \ldots; \square = \ei ; \ldots; \el_n = \en}
         }
}
\end{bnfgrammar}
\end{mathpar}

As with our contextual rules for expressions, we define two rules for labels.
\Rule{Lab-X} handles explicitly annotated labels $\elab / \T$ by instantiating
the type scheme $\tfor \tvs \t \to \T \tvs$ associated with $\elab$ in label
environment $\labenv$. \Rule{Lab-I} handles unannotated labels by elaborating
$\elab$ to $\elab / \T$ if the context $\Lab$ uniquely infers the record type
$\T$ for $\elab$ and the resulting elaboration is well-typed.

The unicity of the inferred record type is captured by the judgment $\Lshape
\Lab \elab \T$. The definition fits into the framework we established for
expressions above by introducing analogous annotation and hole constructs for
labels.
\begin{mathpar}
  \infer[Lab-Magic]
    { }
    {\G \th \elmagic \elab : \tp \to \t}

  \infer[Lab-Annot]
    {\G \th \el : \tp \to \t\where{\tvs \is \tys}}
    {\G \th \elannot \el \tvs \t : \tp \to \t\where{\tvs \is \tys}}

\\
\Lshape \Lab \elab \T \Wide\eqdef
   \forall \G, \t, \gt , \uad
     \G \th \eerase {\Lab[\elannot {\elmagic \elab} {} \gt]} : \t
	\implies \shape \gt= \any \tvcs {\tvcs \T}
\end{mathpar}

% Rules
\Rule{Rcd} types a record $\erecord {\overline{\el = \e}}$ as a record type
$\t$ provided that each field assignment $\el = \e$ can be assigned the record
type $\t$.
\Rule{Rcd-Assn} checks that $\e$ has the appropriate field type in $\el = \e$
and returns the instantiated record type $\tp$ for the label $\el$.
\Rule{Rcd-Proj} types the projection $\efield \e \el$ by checking that the
type of $\e$ matches the record type associated with label $\el$, returning
the field type $\t$.

% Closed world reasoning
Both \Rule{Rcd} and \Rule{Rcd-Proj} impose additional constraints on their
record types to support \emph{closed-world} reasoning. These constraints
exploit the uniqueness of type definitions in the global label environment
$\labenv$ to resolve overloaded labels:
\begin{enumerate*}
\item
  in a record projection $\efield \e \elab$, if the label $\elab$ is not
  overloaded, then the global record typing context $\labenv$ assigns a
  unique record type $\T$ to $\elab$;

\item
  in a record expression $\erecord {\ela = \ea; \ldots; \el_n =
  \en}$, if the set of labels ${ \ela, \ldots, \el_n }$ uniquely
  identifies a record type $\T$ in the typing context $\labenv$, then
  we can assign this type to the record expression.
\end{enumerate*}

We formalize this with the judgment $\bar \el \uni \t$, which
either:
\begin{enumerate*}
  \item enforces $\t$ to be of the form $\T \tys$ if the labels $\bar \el$
    uniquely identify a nominal record type $\T$ in $\labenv$ (\Rule{Lab-!}),
    or
  \item imposes no constraint on $\t$ in the ambiguous case
    (\Rule{Lab-?}).
\end{enumerate*}

Label declarations in $\labenv$ have the form $\elab : \tfor \tvs \tp \to \T
\tvs$, assigning labels to field types and record types\footnote{For a given
record type $\T$, we assume each label associated with it is unique.}. We
write $\elab / {\T} \in \labenv$ if such a declaration of $\elab$ exists for the
record type $\T$. This membership relation extends to explicitly annotated and
casted labels:
\begin{mathpar}
  \infer[Lab-inX]
    {\elab / {\T} \in \labenv}
    {(\elab / \T) / {\T} \in \labenv}

  \infer[Lab-inMagic]
    {\elab / {\T} \in \labenv}
    {\elmagic \elab / {\T} \in \labenv}

  \infer[Lab-inAnnot]
    {\el / {\T} \in \labenv}
    {\elannot \el \tvs \t / {\t} \in \labenv}
\end{mathpar}
We then define the uniqueness predicate $\bar \el \uni {\T} \in \labenv$ as:
\begin{mathpar}
  \infer[Lab-U]
    {\bar \el / {\T} \in \labenv \\
     \all {\T'} \uad\bar \el / {\T'} \in \labenv \implies {\T} = \T'}
    {\bar \el \uni {\T} \in \labenv}
\end{mathpar}
This states that the set of labels $\bar \el$ determines a unique nominal type
$\T$ in $\labenv$ if no other type $\T'$ can be associated with the same label
set.

\subsection {Examples of typings}

The following lemma shows that we can always take a larger context
$\E$ or $\Lab$ for implicit rules \Rule {Proj-I}, \Rule {Use-I}, \Rule {Poly-I}
and \Rule{Lab-I}.
That is, there is always a derivation using only toplevel contexts.
\begin{lemma}
\label{lem/context/largest}
\newcommand {\Eab}{\parens{\Ea\where \Eb}}
If $\eshape \Eb \e \sh$, then $\eshape \Eab \e \sh$. Similarly, for label
contexts, if $\Lshape \Lab \elab \T$, then \\$\Lshape {(\E[\Lab])} \elab \T$.
\end{lemma}

% Examples
We now illustrate the typing of implicit constructs with a few examples.
\begin{example}
To illustrate a simple case of non-typability, we show that the expression $e$
equal to $\efun \x {\eproj \x k}$ is ambiguous, \ie that it does not
typecheck.
%
%% Let $e_n$ be the explicitly annotated version $\efun r
%% {\eproj[n] \x i}$. for $n \le k$.
If there is a derivation of $\efun \x
{\eproj \x k}$ then there must be one of the form:
\begin{mathpar}
\infer*[Right=Proj-I]{
                  \eshape \E \x {\any \tvcs \Pi\iton \tvcs} \\
                \eset \th \E \where {\eproj[n] \x k} : \t
}{%             -------------------------------------------
                  \eset \th \E \where {\eproj \x k} : \t
}
\end{mathpar}
where $E$ is the term $\efun \x \ehole$, which is the largest possible
context, thanks to~\cref {lem/context/largest}.
%
Let $\t$ be $\Pi\iton \ti \to \t_k$ for some $n \geq k$.  We have the
following derivation:
\begin{mathpar}
\infer* [Right=Fun]{
          \infer*[Right=Proj-X]
                {\x : \Pi\iton \ti \th \x : \Pi\iton \ti}
                {\x : \Pi\iton \ti \th \eproj[n] \x k : \t_k}
}{%      ----------------------------------------------------------
         \eset \th \E \where{\eproj[n] \x k} : \t
}
\end{mathpar}
Unfortunately, $\eshape \E  \x {\any \tvcs \Pi\iton \tvcs}$ does not hold.
  Indeed, we have $\eset \th \E \where {\emagic {\eannot \x {} {\gt}}} : \t$
for any $\gt$ assuming $\t$ is of the form $\gt \to \tp$.
Hence, $\any \tvcs \Pi\iton[n] \tvcs$ and $\any \tvcs \Pi\iton[n+1] \tvcs$
are two possible shapes for the type of $\x$.
\end{example}

\begin{example}
\locallabelreset
We now illustrate a non-ambiguous example, showing that the
expression $e$ equal to $\th \eapp {(\efun \x {\eproj
\x  1})} {(1, 2)} : \tint$.
%
%
Let $\E$ be the context $\eapp {(\efun \x \ehole)} {(1, 2)}$.  We
have the derivation:
\begin{mathpar}
\infer* [Right=Proj-I]{
		\eshape \E \x {\any {\tvca, \tvcb} \tvca \tprod \tvcb} \\
                \eset \th \E \where {\eproj[2] \x 1} : \tint
}{%             -------------------------------------------
                  \eset \th \E \where {\eproj \x 1} : \tint
}
\end{mathpar}
We have $\eset \th \E \where {\eproj[2] \x 1} : \tint$, indeed. Therefore, it
just remains to show $\eshape \E \x {\any {\tvca, \tvcb} \tvca \tprod \tvcb}$~\llabel C.
Assume $\eset \th \E \where{\emagic {\eannot \x {} \gt}} : \t$. Since $\x : \tint \tprod \tint$
is bound in the context at the hole in $\E$,
there is no other choice but take $\gt$ equal to $\tint \tprod \tint$,
hence $\shape \gt = \any {\tvca, \tvcb} \tvca \tprod \tvcb$, which proves~\lref C.
\end{example}

The following example of non-typability illustrates how the typing rules
still forces to reject typing of some expressions whose elaboration would be
unambiguous. This is intended, to prevent us from having to focus at several
terms simultaneously. Our typing rules enforce the resolution of
shape inference, locally, one at a time.

\begin{example}
\newcommand{\tyid}{\ty_{\kwd{id}}}
  \newcommand{\eid}{\efun z z}
\newcommand {\epid}[1][]{\epoly[#1]{\eid}}
Let $\tyid$ be $\tpoly{\all \tv \tv \to \tv}$.
%
We show that the expression $e$ equal to $\elet \x {\epoly {\efun z z}}
{(\eapp {\einst \x} 1, \eapp {\einst \x} \eunit)}$ is rejected as ambiguous.
Let $\tyid$ be $\tpoly {\all \tv \tv \to \tv}$.  Clearly, we have $\elet \x
{\epoly [\tyid] {\efun z z}} {(\eapp {\einst[\tyid] \x} 1, \eapp
{\einst[\tyid] \x} \eunit)}$.  This is actually the only possible fully
annotated derivation.
%
To show that $e$ is typable, we must be able to make all annotations
optional, sequentially.  Therefore, the final step, which will eliminate the
last annotation has a single point of focus of the form $\E\where{e^i}$,
where $\e^i$ can be any of the three positions with a missing annotation.  We
consider each case independently, and show that it is actually not typable.
\begin{proofcases}
\proofcase
{$\E$ is $\elet \x \ehole (\eapp {\einst \x} 1, \eapp {\einst \x}\eunit)$}
%
If this holds, we should have a derivation that ends with
\begin{mathpar}
\infer*[Right=Poly-I]{
		  \Eshape \E \eid {\tpoly \tyid} \\
                  \eset \th \E \where {\epid [\tyid]}: \t
}{%               ---------------------------------------
                       \eset \th \E \where \epid : \t
}
\end{mathpar}
However, $\Eshape \E \eid {{\tpoly \tyid}}$ does not hold.
Indeed, the following judgment
$\eset \th \E \where {\eannot {\emagic \eid} {} {\tpoly \ts}} : \t$ holds, where
$\ts$ is either $\tfor \tv \tv \to \tv$ or $\tfor \tv \tv \to
\tv\to\tv$. Hence, the shape of the type of $\eid$ is not uniquely
determined and this case cannot occur.

\proofcase
{$\E$ is
    $\elet \x {\epid} {\eapp {\einst \ehole} 1, \eapp {\einst \x} \eunit}$}
%
The derivation must end with:
\begin{mathpar}
\infer*[Right=Proj-X]{
		  \eshape \E \x {\tpoly \tyid} \\
                \eset \th \E \where {\einst[\tyid] \x} : \t
}{%             -------------------------------------------
                    \eset \th \E \where {\einst \x} : \t
}
\end{mathpar}
However, $\eshape \E \x \tyid$ does not hold (the proof is similar to the
previous case).

\proofcase {$\E$ is  $\elet \x \epid {(\eapp {\einst \x} 1, \eapp
  {\einst \ehole} \eunit)}$} This is symmetric to the previous case, which cannot
hold either.
  \end{proofcases}
\end{example}

\begin{example}
Let $\e$ be $\elet f {\efun \x {\eproj \x 1}} {\eapp f (1, 2)}$.
$\e$ is well-typed using \emph{backpropagation}.
$\e$ is of the form $\E \where {\x}$ where  $\E$ is the context $\elet f
{\efun \x \ehole} {\eapp f (1, 2)}$.
We have $\eset \th \E \where {\eproj[2] \x 1} : \tint$.
Let us show that $\eshape \E \x {\any {\tvca, \tvcb} \tvca \tprod \tvcb}$.
%
Assume $\eset \th \E \where {\emagic {\eannot \x {} \gt} } : \t$. As $\gt$ is a ground
type, the type $\gt$ of $\x$ is not a variable.  Then, $\gt$ cannot be that
of an arbitrary sized tuple, since there is no such type for a tuple of
arbitrary size. Hence, $\gt$ must be a tuple $\Pi\iton \tys$ for some size
$n$. Since the codomain of $f$ must be a tuple of size~$2$ (for $\eapp f (1,
2)$ to be well-typed), then $n$ must also be $2$. This shows that $\eshape \E
\x {\any {\tvca, \tvcb} \tvca \tprod \tvcb}$.
%% \begin{mathpar}
%%   \infer
%%     {
%%     \infer
%%       {
%% 	\infer
%% 	  {
%% 	    \infer
%% 	      {
%% 		\infer
%% 		  {}
%% 		  {\tva, \tvb, x : \tva \th x : \tva}}
%% 	      {\tva, \tvb, x : \tva \th \ecast x \tva \tvb : \tvb}}
%% 	  {\tva, \tvb \th \efun x {\ecast x \tva \tvb : \tva \to \tvb}}}
%%       {\emptyset \th \efun \x \ecast \x \tva \tvb : \tfor {\tva, \tvb} \tva \to \tvb} \\
%%     \infer
%%       {\ldots}
%%       {f : \tfor {\tva, \tvb} \tva \to \tvb \th \eapp f (1, 2) : \tunit}}
%%     {\emptyset \th \elet f {\efun \x {\ecast \x \tva \tvb}} {\eapp f (1, 2)} : \tunit}
%% \end{mathpar}
\end{example}


\subsection{Constraint generation}
\label{sec:constraint-gen}

% Intro
We now present the formal translation from terms $\e$ to constraints $\c$,
such that the resulting constraint is satisfiable if and only if the term is
well typed. The translation is defined as a function $\cinfer \e \tv$, where $\e$
is the term to be translated and $\tv$ is the expected type of $\e$.

\paragraph{Pattern constraints}

Thus far, our formal presentation of constraint patterns has remained
abstract, deliberately leaving the syntax and semantics of patterns unspecified to
accommodate a range of language features. We now concertize this by specifying
the patterns used in \OML (in \cref{fig:patterns-oml}), and introducing the
corresponding constraints for the variables they bind.
%
Patterns include:
\begin{enumerate*}

  \item Tuple patterns $\cpatprod \tv j$, matching a tuple type $\Pi\iton
    \tys$ of arity $n \geq j$, and binding the $j$-th component to $\tv$.

  \item Nominal patterns $\cpatrcd \ct$, binding the name of a nominal type
    $\Tapp \tys$ to the nominal variable $\ct$.

  \item Polytype patterns $\cpatpoly \cscm$ matching a polytype $\tpoly \ts$ and
    binding the resulting scheme to the variable $\cscm$.

\end{enumerate*}

Each new constraint has an unsubstituted form ($\cscm \leq \t, \x \leq \cscm$
\etc), whose semantics is defined via substitution into a sugared form ($\ts
\leq \t, \x \leq \ts,$ \etc). Semantic environments $\semenv$ are extended to
interpret nominal variables $\ct$ as names $\T$ and scheme variables $\cscm$ as
ground type schemes $\gscm$, that is type schemes with no unbound variables
(\ie $\tfor {\fvs \t} \t$).

\begin{mathparfig}
  {fig:patterns-oml}
  {Patterns for \OML.}
  \begin{bnfgrammar}
   \entry[Patterns]{\cpat}{
      \cpatprod \tv j
      \and \cpatrcd \ct
      \and \cpatpoly \cscm
    } \\
    \entry[Constraints]{\c}{
      \dots
      \and \labenv(\elab/\ct) \leq \ta \to \tb
      \and \labenv(\elab/\T) \leq \ta \to \tb
      \andcr \cscm \leq \t
      \and \ts \leq \t
      \andcr \x \leq \cscm
      \and \x \leq \ts
    }
 \end{bnfgrammar}
  \\
  \newcommand{\Mrule}[5][]{{#2} \Matches {(#3)} \; #4 &\eqdef& {#5} & #1}
  \begin{tabular}{RCLL}
    \Mrule[\text{if } n \geq j]
      {\cpatprod \tv j}
      {\any \tvcs \Pi\iton \tvcs} \tvbs
      {[\tv \is \tvb_j]}
    \\[1ex]
    \Mrule
      {\cpatrcd \ct}
      {\any \tvcs \Tapp} \tvbs
      {[\ct \is \T]}
    \\[1ex]
    \Mrule
      {\cpatpoly \cscm}
      {\any \tvcs \tpoly \ts} \tvbs
      {[\cscm \is \ts \where{\tvcs \is \tvbs}]}
  \end{tabular}
  \\
  \inferrule[Lab-Inst]
    {\semenv \th \labenv(\elab/\semenv(\ct)) \leq \ta \to \tb}
    {\semenv \th \labenv(\elab/\ct) \leq \ta \to \tb}

  \inferrule[Scm-Inst]
    {\semenv \th \semenv(\cscm) \leq \t}
    {\semenv \th \cscm \leq \t}

  \inferrule[Abs-Inst]
    {\semenv \th \x \leq \semenv(\cscm)}
    {\semenv \th \x \leq \cscm}
  \\
  \newcommand{\Srule}[3][]{{#2} &\eqdef& {#3} & {#1}}
  \begin{tabular}{RCLL}
    \Srule[\text{if } \labenv(\elab/\T) = \tfor \tvs \t \to \Tapp \tvs]
      {\labenv(\elab/\T) \leq \ta \to \tb}
      {\cexists \tvs \cunif \ta \t \cand \cunif \tb {\Tapp \tvs}}
    \\[1ex]
    \Srule
      {(\tfor \tvs \tp) \leq \t}
      {\cexists \tvs \cunif \tp \t}
    \\[1ex]
    \Srule
      {\x \leq (\tfor \tvs \t)}
      {\cfor \tvs \capp \x \t}
  \end{tabular}

\end{mathparfig}


% Explanation of constraint gen cases
% Simple constraint gen

\paragraph{Constraint generation}

\begin{mathparfig}
  {fig:constraint-gen}
  {The constraint generation translation for \OML.}
\newcommand {\Crule}[2]{#1 &\eqdef& #2}
\def \arraystretch{1.2}%4
\begin{tabular}{LCL}
\Crule
   {\cinfer x \tv}
   {\cinst x \tv}
\\
\Crule
  {\cinfer {()} \tv}
  {\cunif \tv \tunit}
\\
\Crule
  {\cinfer {\efun \x \e} \tv}
  {\cexists {\tvb, \tvc} \cunif \tv {\tvb \to \tvc}
    \cand \clet \x \tvbp {\cunif \tvbp \tvb} {\cinfer \e \tvc}}
\\
\Crule
  {\cinfer {\eapp \ea \eb} \tv}
  {\cexists {\tvb \tvc} \cunif \tvc {\tvb \to \tv} \cand \cinfer \ea {\tvc} \cand \cinfer \eb \tvb}\
\\
\Crule
  {\cinfer {\elet \x \ea \eb} \tv}
  {\clet \x \tvb {\cinfer \ea \tvb} {\cinfer \eb \tv}}
\\
\Crule
  {\cinfer {\eannot \e \tvs \t} \tv}
  {\cexists \tvs \cunif \tv \t \cand \cinfer \e \tv}
\\
\Crule
  {\cinfer {\etuple {\ea, \ldots, \en}} \tv}
  {\cexists \tvs \cunif \tv {\tProd \tvs}
    \cand \cAnd \iton \cinfer \ei {\tv_i}}
\\
\Crule
  {\cinfer {\exproj \e j n} \tv}
  {\cexists {\tvb, \tvbs}
    \cinfer \e \tvb
    \cand \cunif \tvb {\tProd \tvbs}
    \cand \cunif \tv {\tvb_j}}
\\
\Crule
  {\cinfer {\eproj \e j} \tv}
  {\cexists \tvb \cinfer \e \tvb
    \cand \cmatch \tvb {\cbranch {\cpatprod \tvc j} {\cunif \tv \tvc}}}
\\
\Crule
  {\cinfer {\expoly \e \tvs \ts} \tv}
  {\cexists {\tvs}
    \cinfer \e \ts
    \cand \cunif \tv {\tpoly \ts}}
\\
\Crule
  {\cinfer {\exinst \e \tvs \ts} \tv}
  {\cexists {\tvs, \tvb}
    \cinfer \e \tvb
    \cand \cunif \tvb {\tpoly \ts}
    \cand \ts \leq \tv}
\\
\Crule
  {\cinfer {\einst \e} \tv}
  {\cexists \tva
    \cinfer \e \tva
    \cand \cmatch \tva {\cbranch {\cpatpoly \cscm} \cscm \leq \tv}}
\\
\Crule
  {\cinfer {\epoly \e} \tv}
  {\clet \x \tvb {\cinfer \e \tvb}
    {\cmatch \tv {\cbranch {\cpatpoly \cscm} {\x \leq \cscm}}}}
\\
\Crule
  {\cinfer {\efield \e \el} \tv}
  {\cexists \tvb \cinfer \e \tvb
    \cand \cinferlabuni \el \tvb
    \cand \cinferlab \elab \tv \tvb}
\\
\Crule
  {\cinfer {\erecord {\overline{\el = \e}}} \tv}
  {\cinferlabuni {\bar \el} \tv
    \cand \cAnd \iton \cinferassn \eli \ei \tv}
\\
\Crule
  {\cinfer {\emagic \e} \tv}
  {\cexists \tvb \cinfer \e \tvb}
\\\\
\Crule
  {\cinfer \e \t}
  {\cexists \tv \cunif \tv \t \cand \cinfer \e \tv}
\\
\Crule
  {\cinfer \e {\tfor \tvs \t}}
  {\cfor \tvs \cinfer \e \t}
\\\\
\Crule
  {\cinferassn \el \e \tv}
  {\cexists \tvb \cinfer \e \tvb
    \cand \cinferlab \el \tvb \tv}
\\\\
\Crule
  {\cinferlab \elab \tva \tvb}
  {\cmatch \tb {\cbranch {\cpatrcd \ct} {\labenv(\elab/\ct) \leq \tva \to \tvb}}}
\\
\Crule
  {\cinferlab {\elab/\T} \tva \tvb}
  {\labenv(\elab/\T) \leq \tva \to \tvb}
\\
\Crule
  {\cinferlab {\elmagic \elab} \tva \tvb}
  {\ctrue}
\\
\Crule
  {\cinferlab {\elannot \el \tvs \t} \tva \tvb}
  {\cexists \tvs \cunif \tvb \t \cand \cinferlab \el \tva \tvb}
\\
\Crule
  {\cinferlabuni {\bar \el} \tv}
  {\begin{cases}
    \cexists \tvs \cunif \tv {\Tapp \tvs} &\text{if } \bar \el \uni {\T} \in \labenv \\
    \ctrue &\text{otherwise}
   \end{cases}}
\end{tabular}
\end{mathparfig}


The function $\cinfer - {\mathop{=}}$ is defined in \cref{fig:constraint-gen}.
All generated type variables are fresh with respect to the expected type $\tv$,
ensuring capture-avoidance.
%
Unsurprisingly, variables generate an instantiation constraint. Unit $\eunit$
requires the type $\tv$ to be $\tunit$. A function generates a constraint that
binds two fresh flexible type variables for the argument and return types.  We
use a $\Let$ constraint to bind the argument in the constraint generated for
the body of the function. The $\Let$ constraint is monomorphic since $\tvbp$ is
fully constrained by type variables defined outside the abstraction's scope
and therefore cannot be generalized. Applications introduce two fresh flexible,
one for the argument type and one for the type of the function, typing each
subterm with these, ensuring $\tv$ is the expected return type.
 Let-bindings generates a polymorphic let constraint; $\cabs \tv
{\cinfer \e \tv}$ is a principal constraint abstraction for $\e$: its intended
interpretation is the set of all types that $\e$ admits.

% New constraint gen cases
% Annotations, tuples
Annotations bind their flexible variables and enforce the equality of
the annotated type $\t$ and the expected type $\tv$. Tuples introduce
fresh variables for each component and unify their product with $\tv$.
Explicit projections ensure $\e$ has a tuple type $\Pi\iton \tvbs$
and extract the $j$-th component $\tvb_j$, unifying it with $\tv$.
Implicit projections defer this via a suspended match constraint, until
the shape of $\e$'s expected type is known to be a tuple, extracting the
$j$-th component with the pattern $\cpatprod \tvb j$,

% Polytypes
For polytypes, boxing asserts that $\e$ has the polymorphic type $\ts$ (using
universal quantification) and that the expected type is the polytype $\tpoly
\ts$. Unboxing suspends until the inferred type of $\e$ is known to be a
polytype, captured by the pattern $\cpatpoly \cscm$, at which point we require
$\tv$ to be an instance of $\cscm$. Explicit unboxing is analogous, but uses an
explicit scheme $\ts$ and therefore does not require a suspended match
constraint. Implicit boxing infers the principal type for $\e$ using a $\Let$
constraint and suspends until the expected type of the entire term is known to
be a polytype, bound to $\cscm$. We then assert that the principal type of $\e$
is at least as general as $\cscm$, via the constraint $\x \leq \cscm$.

% Records
Record projections generate a fresh variable for the nominal record type,
constraining $\e$ to this type, and use the auxiliary function $\cinferlab \el
\tva \tvb$ to instantiate the label. The function $\cinferlabuni {\bar \el}
\tv$ checks whether a label sequence $\bar \el$ uniquely determines a record
type, unifying $\tv$ with $\Tapp \tvs$ if so, or leaving it unconstrained if
ambiguous. This function enables closed-world reasoning for both projections
and constructions, and corresponds to the judgment $\bar \el \uni \t$
judgment defined in \cref{sec/language/typing-rules}.

Record construction checks label uniqueness and generates a per-field
constraint $\eli = \ei$, introducing a fresh variable $\tvb$ for each
field's type and ensuring that $\e$ has this type and the label $\el$
instantiates to $\tvb \to \tv$.
%
Label instantiation constraints $\cinferlab \elab \tva \tvb$ suspend
until $\tvb$ is known to be a record type; once resolved, the label type is
looked up in $\labenv$ and instantiated. Explicit instantiations bypass
suspension and directly instantiate the label's type.

\section{Unification}
\label{app:unification}

The unification rules are listed in \cref{fig:unification-algorithm}.
Rewriting proceeds under an arbitrary context $\Up$, modulo $\alpha$-equivalence
and associativity/commutativity of conjunctions.

Our algorithm is largely standard~\citep*{Pottier-Remy/emlti} but replaces type
constructors with \emph{canonical principal shapes}, enabling a uniform
treatment of monotypes and polytypes within unification compared to
prior formulations~\citep*{Garrigue-Remy/poly-ml}.

%


\begin{mathparfig}[htpb!]
  {fig:unification-algorithm}
  {Unification algorithm as a series of rewriting rules
   $\upa \unif \upb$. All shapes are principal.}
   \rewrite[U-Exists]
      {(\cexists \alpha \upa) \cand \upb }{ \tv \disjoint \upb}
      {\cexists \tv {\upa \cand \upb}}

    \rewrite[U-Cycle]
      {\up }{ \cyclic \up}
      {\cfalse}

    \rewrite[U-True]
      {\up \cand \ctrue}
      {}
      {\up}

    \rewrite[U-False]
      {\Up\where\cfalse }{ \Up \neq \square}
      {\cfalse}

    \rewrite[U-Merge]
      {\cunif \tv \ueqa \cand \cunif \tv \ueqb}
      {}
      {\cunif \tv {\cunif \ueqa \ueqb}}

    \rewrite[U-Stutter]
      {\cunif \tv {\cunif \tv \ueq}}
      {}
      {\cunif \tv \ueq}

    \rewrite[U-Name]
      {\cunif {\pshapp \parens{\tys, \ti, \typs}} \ueq }
      { \tv \disjoint \tys, \typs, \ueq \\ \ti \notin \TyVars}
      {\cexists \tv {\cunif \tv \ti \cand \cunif {\pshapp \parens{\tys, \tv, \typs}} \ueq}}

    \rewrite[U-Decomp]
      {\cunif {\pshapp \tvs} {\cunif {\pshapp \tvbs} \ueq}}
      {}
      {\cunif {\pshapp \tvs} \ueq \cand \cunif \tvs \tvbs}

    \rewrite[U-Clash]
      {\cunif {\pshapp \tvs} {\cunif {\pshapp[\shp]\tvbs } \ueq }}{
       \sh \neq \shp}
      {\cfalse}

    \rewrite[U-Trivial]
      {\ueq }
      {|\ueq| \leq 1}
      {\ctrue}
\end{mathparfig}


\parcomment{Explanation of the rules}

We briefly summarize the role of each rule. \Rule{U-Exists} lifts existential
quantifiers, enabling applications of \Rule{U-Merge} and \Rule{U-Cycle} since
all multi-equations eventually become part of a single conjunction.
\Rule{U-Merge} combines mutli-equations sharing a common variable and
\Rule{U-Stutter} removes duplicate variables. \Rule{U-Decomp} decomposes equal
types with matching shapes into equalities between their subcomponents, while
\Rule{U-Clash} detects shape mismatches that result in failure. \Rule{U-Name}
introduces fresh variable for subcomponents, ensuring unification operates on
\emph{shallow terms}, making sharing of type variables explicit and avoiding
copying types in rules such as \Rule{U-Decomp}. \Rule{U-True} and
\Rule{U-Trivial} eliminate trivial constraints, and \Rule{U-False} propagates
failure.
%
Finally, \Rule{U-Cycle} implements the \emph{occurs check}, ensuring that a
type variable does not occur in the type it is being unified with. This is a
necessary condition for unification, as it would otherwise lead to infinite
types\footnote{We discuss relaxing this constraint in \cref{sec/rec-types}.}.
This is formalized by the relation $\tv \prec_\up \tvb$ indicating that $\tv$
occurs in a type assigned to $\tvb$ in $\up$. A unification problem is cyclic,
written $\cyclic \up$, if $\tv \prec_\up^* \tv$ for some $\tv$.

\clearpage
\section{Full technical reference}
\label{appendix:figures}
\label{app:full-reference}

This section repeats all the technical definitions mentioned in the paper,
including the cases, rules, and definitions that were omitted from the main
paper to save space. It can serve as a useful cheatsheet to understand a
definition in full, or when studying the meta-theory of the system.

\begin{mathpar}
\begin{bnfgrammar}%
\entryset[Type variables]{\tva, \tvb, \tvc}{\TyVars}{}
\\
%% \entryset[Types]{\t}{\Types}\\
\entry[Types]{\t}{
    \tv \and
    \tunit \and
    \ta \to \tb \and
    \Pi\iton \ti \and
    \T \tys \and
    \tpoly \ts
}\\
\entry[Type schemes]{\ts}{
    \t \and
    \all \tv \ts
}\\[1ex]
\entry[Ground types]{\gt}{}{}\\
\entry[Ground type schemes]{\gscm}{}{}\\
  \entry[Ground region]{\gr}{\greg \tv \semenv}\\
\entry[Sets of ground types]{\gabs \subseteq \GroundRegion}{}{}\\
\entry[Sets of ground regions]{\gabsr \subseteq \Ground}{}\\
\entry[Constraints]{\c}{
        \ctrue
  \and  \cfalse
  \and  \ca \cand \cb
  \and  \cexists \tv \c
  \and 	\cfor \tv \c
  \and  \cunif \ta \tb
  \nextline
  \and  \clet \x \tv \ca \cb
  \and  \capp \x \t
  \nextline
  \and  \cmatch \t \cbrs
  \nextline
  \and \ueqs
  \and \cletr \x \tv \tvs \ca \cb
  \and \cexistsi \inst \x \c
  \and \cpinst \inst \tv \t
  \nextline
  \and \labenv(\elab/\ct) \leq \ta \to \tb
  \and \labenv(\elab/\T) \leq \ta \to \tb
  \nextline
  \and \cscm \leq \t \mid \ts \leq \t \mid \x \leq \cscm \mid \x \leq \ts
}\\[1ex]
\entry[Branches]{\cbr}{\cbranch \cpat \c} \\
\entry[Patterns]{\cpat}{
  \cpatwild \and \cpatprod \tv j \and \cpatrcd \ct \and \cpatpoly \cscm
} \\[1ex]
\entry[Semantic environment]{\semenv}{
  \eset \and \semenv\where{\tv := \gt}
  \and \semenv\where{\x := \gabs}
  \and \semenv\where{\x := \gabsr}
  \and \semenv\where{\inst := \semenvp}
  \nextline
  \and \semenv\where{\ct := \T}
  \and \semenv\where{\cscm := \gscm}
}\\
\entry[Unification problems]{\up}{
  \ctrue \and \cfalse \and \upa \cand \upb \and \cexists \tv \up \and \ueq
} \\
\entry[Multi-equations]{\ueq}{
  \eset \mid \cunif \t \ueq
} \\[1ex]
\entry[Constraint contexts]{\C}{
  \square
  \and \C \cand \c
  \and \c \cand \C
  \and \cexists \tv \C
  \and \cfor \tv \C
  \nextline
  \and \clet \x \tv \C \c
  \and \clet \x \tv \c \C
  \nextline
  \and \cletr \x \tv \tvs \C \c
  \and \cletr \x \tv \tvs \c \C
  \and \cexistsi \inst \x \C
} \\
\entry[Shapes] {\Sh} {
  \any \tvcs \t
}
\\
\entry[Canonical principal shapes] {\sh} {} {}\\
\entry[Terms]{\e}{
  x \and
  () \and
  \efun x e \and
  \eapp \ea \eb \and
  \elet x \ea \eb \and
  \eannot \e \tvs \t \andcr
  \erecord {\overline{\el = \e} } \and
  \efield e \el \andcr
   (\ea, \ldots, \en) \and
   \efield e j \and
   \exfield e n j \andcr
   \epoly e \and
   \expoly e \tvs \ts \and
   \einst e \and
   \exinst e \tvs \ts
   \nextline
   \and \emagic \e
}\\
\entry[Labels]{l}{
  \elab \and \elab / \T ~ \and \elmagic \elab \and \elannot \el \tvs \t
}\\[1ex]
\entry[Term contexts]{\E}{
  \square
  \and \eapp \E \e
  \and \eapp \e \E
  \and \elet \x \E \e
  \and \elet \x \e \E
  \and \eannot \E \tvs \t
  \andcr \erecord {\ela = \ea\; \ldots\; \eli = \E\; \ldots\; \el_n = \en}
  \and \efield \E \el
  \andcr (\ea, \ldots, \E, \ldots, \en)
  \and \eproj \E j
  \and \exproj \E j n
  \andcr \epoly \E
  \and \expoly \E \tvs \ts
  \and \einst \E
  \and \exinst \E \tvs \ts
  \andcr
  \emagic \E
}\\
\entry[Label contexts]{\Lab}{
    \E \where {\e.\square} \and
    \E \where
         {\erecord
            {\ela = \ea; \ldots; \square = \ei ; \ldots; \el_n = \en}
         }
  }\\[1ex]
\entry[Typing contexts]{\G}{
   \eset \and
   \G, x : \ts
}\\
\entry[Label environment]{\labenv}{
  \eset \and \labenv, \elab : \tfor \tvs \t \to \T \tvs
}
\end{bnfgrammar}
\end{mathpar}
\clearpage



\begin{judgboxmathpar}
  {\semenv \th \c}
  {Under the environment $\semenv$, the constraint $\c$ is satisfiable.}

  \infer[True]
    { }
    {\semenv \th \ctrue}

  \infer[Conj]
    {\semenv \th \ca \\
     \semenv \th \cb}
    {\semenv \th \ca \cand \cb}

  \infer[Exists]
    {\semenv\where{\tv \is \gt} \th \c}
    {\semenv \th \cexists \tv \c}

  \infer[Forall]
    {\forall \gt, ~ \semenv\where{\tv \is \gt} \th \c}
    {\semenv \th \tfor \tv \c}

  \infer[Unif]
    {\semenv(\ta) = \semenv(\tb)}
    {\semenv \th \cunif \ta \tb}

  \infer[Let]
    {\semenv \th \exists \tv. \ca \\
     \semenv\where{\x \is \semenv(\cabs \tv \ca)} \th \cb}
    {\semenv \th \clet \x \tv \ca \cb}

  \infer[App]
    {\semenv(\t) \in \semenv(\x)}
    {\semenv \th \capp \x \t}

  \infer[Susp-Ctx]
    {\Cshape \C \t \sh \\
      \semenv \th \C\where{\cmatched \t \sh \cbrs}
    }
    {\semenv \th \C\where{\cmatch \t \cbrs}}

  \infer[Multi-Unif]
    {\forall \t \in \ueq,~ \semenv(\t) = \gt}
    {\semenv \th \ueq}

  \infer[LetR]
    {\semenv \th \cexists {\tv, \tvs} \ca \\
     \semenv\where{\x \is \semenv(\cabsr \tv \tvs \ca)} \th \cb}
    {\semenv \th \cletr \x \tv \tvs \ca \cb}

  \infer[AppR]
    {\greg \tv \semenvp \in \semenv(\x) \\
     \semenv(\t) = \semenvp(\tv) }
    {\semenv \th \capp \x \t}

  \infer[Exists-Inst]
    {\greg \tv\semenvp \in \semenv(\x) \\
     \semenv\where{\inst \is \semenvp} \th \c}
    {\semenv \th \cexistsi \inst \x \c}

  \infer[Partial-Inst]
    {\semenv(\inst)(\tv) = \semenv(\t) }
    {\semenv \th \cpinst \inst \tv \t}

  \inferrule[Lab-Inst]
    {\semenv \th \labenv(\elab/\semenv(\ct)) \leq \ta \to \tb}
    {\semenv \th \labenv(\elab/\ct) \leq \ta \to \tb}

  \inferrule[Scm-Inst]
    {\semenv \th \semenv(\cscm) \leq \t}
    {\semenv \th \cscm \leq \t}

  \inferrule[Abs-Inst]
    {\semenv \th \x \leq \semenv(\cscm)}
    {\semenv \th \x \leq \cscm}
\\
  \newcommand{\Srule}[3][]{{#2} &\eqdef& {#3} & {#1}}
  \begin{tabular}{RCLL}
    \Srule[\text{if } \cmatches \cpati \sh \tvs \theta]{\cmatched \t \sh {\cbranch \cpat \cs}}
      {\cexists \tvs \cunif \t \shapp \tvs \cand \theta(\ci)}
    \\[1ex]
    \Srule[\text{if } \labenv(\elab/\T) = \tfor \tvs \t \to \Tapp \tvs]
      {\labenv(\elab/\T) \leq \ta \to \tb}
      {\cexists \tvs \cunif \ta \t \cand \cunif \tb {\Tapp \tvs}}
    \\[1ex]
    \Srule
      {(\tfor \tvs \tp) \leq \t}
      {\cexists \tvs \cunif \tp \t}
    \\[1ex]
    \Srule
      {\x \leq (\tfor \tvs \t)}
      {\cfor \tvs \capp \x \t}
  \end{tabular}
\\
  \semenv(\cabsr \tv \tvs \c) \uad\eqdef\uad \set{\greg \tv {\semenv\where{\tv \is \gt, \tvs \is \gts}} \in \GroundRegion :
    \semenv\where{\tv \is \gt, \tvs \is \gts} \th \c}
\\
\semenv(\cabs \tv \c) \Wide\eqdef \
  \set {\gt \in \Ground : \semenv\where{\tv \is \gt} \th \c}
\\
\Cshape \C \t \sh \Wide\eqdef \
  \forall \semenv, \gt. \uad
      \semenv \th \cerase {\C\where{\cunif \t \gt}} \implies \shape \gt = \sh
\end{judgboxmathpar}
\emph{Note: in most definitions, we ignore the additional  $\OML$ constraints, as they are not particularly interesting.} \\

\begin{judgboxmathpar}
  {\Sh \preceq \Shp}
  {The shape $\Shp$ is an instance of $\Sh$. Alternatively, $\Shp$ is more general than $\Sh$.}
  \infer[Inst-Shape]
    {\tvcs_2 \disjoint \any {\tvcs_1} \t}
    {\any {\tvcs_1} \t \preceq
     \any {\tvcs_2} \t \where {\tvcs_1 \is \tys_1}}
\end{judgboxmathpar}

\begin{definition}
A non-trivial shape $\Sh \in \Shapesz$ is the principal shape of the type
$\t$ iff:
\begin{enumerate}
  \item
    $\exists \typs,\ \t = \shapp[\Sh] \typs$
  \item
    $\forall \Shp \in \Shapesz, \forall \typs,\ \t = \shapp[\Shp] \typs
    \implies \Sh \preceq \Shp$
\end{enumerate}

A principal shape $\any \tvcs \t$ is \emph{canonical} if the sequence of its
free variables $\tvcs$ appear in the order in which the variables occur in
$\t$. $\shape \t$ is the canonical principal shape of $\t$.
\end{definition}

\begin{judgboxmathpar}
  {\cmatches \cpat \sh \tvs \theta}
  {The pattern $\cpat$ matches the shape $\sh$ with components $\tvs$ binding\\pattern variables in $\theta$.}
  \\
  \newcommand{\Mrule}[5][]{{#2} \Matches {(#3)} \; #4 &\eqdef& {#5} & #1}
  \begin{tabular}{RCLL}
    \Mrule[\text{if } n \geq j]
      {\cpatprod \tvb j}
      {\any \tvcs \Pi\iton \tvcs} \tvs
      {[\tvb \is \tv_j]}
    \\[1ex]
    \Mrule
      {\cpatrcd \ct}
      {\any \tvcs \Tapp} \tvs
      {[\ct \is \T]}
    \\[1ex]
    \Mrule
      {\cpatpoly \cscm}
      {\any \tvcs \tpoly \ts} \tvs
      {[\cscm \is \ts \where{\tvcs \is \tvs}]}
  \end{tabular}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\c \simple}
  {The constraint $\c$ is simple.}
  \label{fig:simple}
  \inferrule[Simple-True]
    { }
    {\ctrue \simple}

  \inferrule[Simple-False]
    { }
    {\cfalse \simple}

  \inferrule[Simple-Conj]
    {\ca \simple \\ \cb \simple}
    {\ca \cand \cb \simple}

  \inferrule[Simple-Exists]
    {\c \simple}
    {\cexists \tv \c \simple}

  \inferrule[Simple-Forall]
    {\c \simple}
    {\cfor \tv \c \simple}

  \inferrule[Simple-Unif]
    { }
    {\cunif \ta \tb \simple}

  \inferrule[Simple-Let]
    {\ca \simple \\ \cb \simple}
    {\clet \x \tv \ca \cb \simple}

  \inferrule[Simple-App]
    { }
    {\capp \x \t \simple}

  \inferrule[Simple-LetR]
    {\ca \simple \\ \cb \simple}
    {\cletr \x \tv \tvs \ca \cb \simple}

  \inferrule[Simple-Exists-Inst]
    {\c \simple}
    {\cexistsi \inst \x \c \simple}

  \inferrule[Simple-Partial-Inst]
    { }
    {\cpinst \inst \tv \t \simple}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\C \simple}
  {The constraint context $\C$ is simple.}
  \label{fig:simple-context}

  \inferrule[Simple-Ctx-Hole]
    { }
    {\square \simple}

  \inferrule[Simple-Ctx-Conj-Left]
    {\C \simple \\ \c \simple}
    {\C \cand \c \simple}

  \inferrule[Simple-Ctx-Conj-Right]
    {\C \simple \\ \c simple}
    {\c \cand \C \simple}

  \inferrule[Simple-Ctx-Exists]
    {\C \simple}
    {\cexists \tv \C \simple}

  \inferrule[Simple-Ctx-Forall]
    {\C \simple}
    {\cfor \tv \C \simple}

  \inferrule[Simple-Ctx-Let-Abs]
    {\C \simple \\ \c \simple}
    {\clet \x \tv \C \c \simple}

  \inferrule[Simple-Ctx-Let-In]
    {\c \simple \\ \C \simple}
    {\clet \x \tv \c \C \simple}

  \inferrule[Simple-Ctx-Exists-Inst]
    {\C \simple}
    {\cexistsi \inst \x \C \simple}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\cerase \c}
  {The erasure of $\c$.}
  \label{fig:erasure}
\newcommand{\Erule}[2]{\cerase {#1} &\eqdef& {#2}}
\begin{tabular}{RCL}
  \Erule{\ctrue}{\ctrue} \\
  \Erule{\cfalse}{\cfalse} \\
  \Erule{\ca \cand \cb}{\cerase \ca \cand \cerase \cb} \\
  \Erule{\cexists \tv \c}{\cexists \tv \cerase \c} \\
  \Erule{\cfor \tv \c}{\cfor \tv \cerase \c} \\
  \Erule{\cunif \ta \tb}{\cunif \ta \tb} \\
  \Erule{\clet \x \tv \ca \cb}{\clet \x \tv {\cerase \ca} {\cerase \cb}} \\
  \Erule{\capp \x \t}{\capp \x \t} \\
    \Erule{\cmatch \t {\cbranch {\bar \cpat} {\bar \c}}}{\ctrue} \\
  \Erule{\cletr \x \tv \tvs \ca \cb}{\cletr \x \tv \tvs {\cerase \ca} {\cerase \cb}} \\
  \Erule{\cexistsi \inst \x \c}{\cexistsi \inst \x \cerase \c}\\
  \Erule{\cpinst \inst \tv \t}{\cpinst \inst \tv \t}
\end{tabular}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\semenv \Th \c}
  {Under the semantic environment $\semenv$,
   the constraint $\c$ is canonically satisfiable.}
  \label{fig:canonical-sem}
  \inferrule[Can-Simple]
    {\semenv \thsimple \c}
    {\semenv \Th \c}

  \inferrule[Can-Susp-Ctx]
    {\Cshape \C \t \sh \\ \semenv \Th \C\where{\cmatched \t \sh \cbrs}}
    {\semenv \Th \C\where{\cmatch \t \cbrs}}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\el : \ta \to \tb}
  {The label $\el$ has the field type $\ta$ and record type $\tb$.}
  \infer[Lab-Magic]
    { }
    {\G \th \elmagic \elab : \tp \to \t}

  \infer[Lab-Annot]
    {\G \th \el : \tp \to \t\where{\tvs \is \tys}}
    {\G \th \elannot \el \tvs \t : \tp \to \t\where{\tvs \is \tys}}

  \inferrule[Lab-X]
    {\Omega(\elab / \T) = \tfor \tvs \t \to \T \tvs }
    {\G \th \elab / \T : \tys\where{\tvs \is \tys} \to \T \tys}
\end{judgboxmathpar}

\judgbox
  {\el / {\T} \in \labenv}
  {The label $\el$ belongs to the nominal record type $\T$ in $\labenv$.}

\judgbox
  {\bar\el \uni {\T} \in \labenv}
  {The set of labels $\bar\el$ belong to a unique nominal record type $\T$ in $\labenv$.}

\begin{judgboxmathpar}
  {\bar \el \uni \t}
  {The set of labels $\bar\el$ infer the possibly unique type $\t$.}
  \infer[Lab-inI]
    {\elab : \tfor \tvs \t \to \T \tvs \in \labenv}
    {\elab / {\T} \in \labenv}

  \infer[Lab-inX]
    {\elab / {\T} \in \labenv}
    {(\elab / \T) / {\T} \in \labenv}

  \infer[Lab-inMagic]
    {\elab / {\T} \in \labenv}
    {\elmagic \elab / {\T} \in \labenv}

  \infer[Lab-inAnnot]
    {\el / {\T} \in \labenv}
    {\elannot \el \tvs \t / {\T} \in \labenv}

  \infer[Lab-U]
    {\bar \el / {\T} \in \labenv \\
     \forall {\T'}, \uad\bar \el / \T' \in \labenv \implies {\T} = \T'}
    {\bar \el \uni {\T} \in \labenv}

  \inferrule[Lab-!]
    {\bar \el \uni {\T} \in \labenv}
    {\el \uni {\T \tys}}

  \inferrule[Lab-?]
    { }
    {\bar \el \uni \t}
\end{judgboxmathpar}


\judgbox
  {\G \th \el = \e : \t}
  {Under the typing context $\G$, the record assignment $\el = \e$ has the record type $\t$.}

\begin{judgboxmathpar}
  {\G \th \e : \ts}
  {Under the typing context $\G$, the term $\e$ is assigned the type $\ts$.}
  \inferrule[Var]
    {x : \sigma \in \G}
    {\G \th x : \sigma}

  \inferrule[Fun]
    {\G, x : \ta \th e : \tb }
    {\G \th \efun x e : \ta \to \tb}

  \inferrule[App]
    {\G \th \ea : \ta \to \tb \\
     \G \th \eb : \ta}
    {\G \th \eapp \ea \eb : \tb}

  \inferrule[Unit]
    { }
    {\G \th () : 1}

  \inferrule[Annot]
    {\G \th e : \t\where {\tvs \is \tys}}
    {\G \th (e : \exi \tvs \t) : \t\where {\tvs \is \tys}}

  \inferrule[Gen]
    {\G \th e : \sigma \\ \tv \disjoint \G}
    {\G \th e : \tfor \tv \sigma}

  \inferrule[Inst]
    {\G \th e : \tfor \tv \ts}
    {\G \th e : \tv \where{\tv \is \t}}

  \inferrule[Let]
    {\G \th \ea : \sigma \\
     \G, x : \sigma \th \eb : \t}
    {\G \th \elet x \ea \eb : \t}

  \inferrule[Tuple]
    {\parens{\G \th \ei : \ti}\iton}
    {\G \th (\ea, \ldots, \en) : \Pi\iton \ti}

  \inferrule[Proj-X]
    {\G \th \e : \Pi\iton \ti \\
     1 \leq j \leq n}
    {\G \th \exfield \e n j : \tj}

  \inferrule[Proj-I]
    {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\
     \G \th \E\where{\exfield \e n j} : \t}
    {\G \th \E\where{\efield \e j} : \t}

  \inferrule [Poly-X]
    {\G \th \e : \ts\where {\tvs \is \tys}}
    {\G \th \epoly[\exi \tvs \ts] \e : \tpoly {\ts \where {\tvs \is \tys}}}

  \inferrule [Poly-I]
    {\Eshape \E \e {{\any \tvcs \tpoly \ts}} \\
     \G \th \E \where{\epoly[\exi \tvcs \ts] \e} : \t}
    {\G \th \E \where{\epoly \e} : \t}

  \inferrule [Use-X]
    {\G \th \e : \tpoly \ts \where {\tvs \is \tys}}
    {\G \th \exinst e \tvs \ts : \ts \where {\tvs \is \tys}}

  \inferrule [Use-I]
    {\eshape \E  \e {\any \tvcs \tpoly \ts} \\
     \G \th \E\where{\exinst \e \tvcs \ts} : \t}
    {\G \th \E\where{\einst \e} : \t}

  \inferrule[Rcd-Assn]
    {\G \th \e : \t \\
     \el : \t \to \tp}
    {\G \th \el = \e : \tp}

  \inferrule[Rcd]
    {\parens{\G \th \eli = \ei : \t}\iton \\
     \bar \el \uni \t}
    {\G \th \erecord {\ela = \ea; \ldots; \el_n = \en} : \t}

  \inferrule[Rcd-Proj]
    {\G \th \e : \tp \\
     \el : \t \to \tp \\
     \el \uni \t }
    {\G \th \efield \e \el : \t}

  \inferrule[Lab-I]
    {\Lshape \Lab \elab \T \\
      \G \th \Lab[\elab / \T] : \t}
    {\G \th \Lab[\elab] : \t}

  \inferrule[Magic]
    {\G \th \e : \t}
    {\G \th \emagic \e : \tp}
\\
\def \Eqdef {&\eqdef&}
{\begin{tabular}{RCL}
\eshape E \e \sh \Eqdef
  \forall \G, \t, \gt, \uad
  \G \th \eerase {\E \where {\emagic {\eannot \e {} \gt }}} : \t
      \wide\implies \shape \gt = \sh
\\[1ex]
\Eshape E \e \sh \Eqdef
  \forall \G, \t, \gt, \uad
      \G \th \eerase {\E\where{\eannot {\emagic \e} {} \gt}} : \t
      \wide\implies \shape \gt = \sh
\\[1ex]
\Lshape \Lab \elab \T \Eqdef
   \forall \G, \t, \gt , \uad
     \G \th \eerase {\Lab[\elannot {\elmagic \elab} {} \gt]} : \t
	\implies \shape \gt= \any \tvcs {\tvcs \T}

\end{tabular}}
\end{judgboxmathpar}

\judgbox
  {\cinfer {\G \th \e} \t}
  {$\cinfer {\G \th \e} \t$ is satisfiable iff $\e$ has the expected \emph{known} type $\t$ under \emph{known} context $\G$.}

\judgbox
  {\cinferlabuni {\bar\el} \tv}
  {$\cinferlabuni {\bar\el} \tv$ is satisfiable iff $\bar\el$ has the possibly unique type $\tv$.}

\judgbox
  {\cinferlab \el \tva \tvb}
  {$\cinferlab \el \tva \tvb$ is satisfiable iff $\el$ has the record type $\tvb$ and field type $\tva$. }

\judgbox
  {\cinferassn \el \e \tv}
  {$\cinferassn \el \e \tv$ is satisfiable iff the record assignment $\el = \e$ has the record type $\tv$.}

\judgbox
  {\cinfer \e \ts}
  {$\cinfer \e \ts$ is satisfiable iff $\e$ has the expected \emph{known} type scheme $\ts$.}

\begin{judgboxmathpar}
  {\cinfer \e \tv}
  {$\cinfer \e \tv$ is satisfiable iff $\e$ has the expected type $\tv$.}

\newcommand {\Crule}[2]{#1 &\eqdef& #2}
\def \arraystretch{1.2}%4
\begin{tabular}{LCL}
\Crule
   {\cinfer x \tv}
   {\cinst x \tv}
\\
\Crule
  {\cinfer {()} \tv}
  {\cunif \tv \tunit}
\\
\Crule
  {\cinfer {\efun \x \e} \tv}
  {\cexists {\tvb, \tvc} \cunif \tv {\tvb \to \tvc}
    \cand \clet \x \tvbp {\cunif \tvbp \tvb} {\cinfer \e \tvc}}
\\
\Crule
  {\cinfer {\eapp \ea \eb} \tv}
  {\cexists {\tvb \tvc} \cunif \tvc {\tvb \to \tv} \cand \cinfer \ea {\tvc} \cand \cinfer \eb \tvb}\
\\
\Crule
  {\cinfer {\elet \x \ea \eb} \tv}
  {\clet \x \tvb {\cinfer \ea \tvb} {\cinfer \eb \tv}}
\\
\Crule
  {\cinfer {\eannot \e \tvs \t} \tv}
  {\cexists \tvs \cunif \tv \t \cand \cinfer \e \tv}
\\
\Crule
  {\cinfer {\etuple {\ea, \ldots, \en}} \tv}
  {\cexists \tvs \cunif \tv {\tProd \tvs}
    \cand \cAnd \iton \cinfer \ei {\tv_i}}
\\
\Crule
  {\cinfer {\exproj \e j n} \tv}
  {\cexists {\tvb, \tvbs}
    \cinfer \e \tvb
    \cand \cunif \tvb {\tProd \tvbs}
    \cand \cunif \tv {\tvb_j}}
\\
\Crule
  {\cinfer {\eproj \e j} \tv}
  {\cexists \tvb \cinfer \e \tvb
    \cand \cmatch \tvb {\cbranch {\cpatprod \tvc j} {\cunif \tv \tvc}}}
\\
\Crule
  {\cinfer {\expoly \e \tvs \ts} \tv}
  {\cexists {\tvs}
    \cinfer \e \ts
    \cand \cunif \tv {\tpoly \ts}}
\\
\Crule
  {\cinfer {\exinst \e \tvs \ts} \tv}
  {\cexists {\tvs, \tvb}
    \cinfer \e \tvb
    \cand \cunif \tvb {\tpoly \ts}
    \cand \ts \leq \tv}
\\
\Crule
  {\cinfer {\einst \e} \tv}
  {\cexists \tva
    \cinfer \e \tva
    \cand \cmatch \tva {\cbranch {\cpatpoly \cscm} \cscm \leq \tv}}
\\
\Crule
  {\cinfer {\epoly \e} \tv}
  {\clet \x \tvb {\cinfer \e \tvb}
    {\cmatch \tv {\cbranch {\cpatpoly \cscm} {\x \leq \cscm}}}}
\\
\Crule
  {\cinfer {\efield \e \el} \tv}
  {\cexists \tvb \cinfer \e \tvb
    \cand \cinferlabuni \el \tvb
    \cand \cinferlab \elab \tv \tvb}
\\
\Crule
  {\cinfer {\erecord {\overline{\el = \e}}} \tv}
  {\cinferlabuni {\bar \el} \tv
    \cand \cAnd \iton \cinferassn \eli \ei \tv}
\\
\Crule
  {\cinfer {\emagic \e} \tv}
  {\cexists \tvb \cinfer \e \tvb}
\\\\
\Crule
  {\cinfer \e \t}
  {\cexists \tv \cunif \tv \t \cand \cinfer \e \tv}
\\
\Crule
  {\cinfer \e {\tfor \tvs \t}}
  {\cfor \tvs \cinfer \e \t}
\\\\
\Crule
  {\cinferassn \el \e \tv}
  {\cexists \tvb \cinfer \e \tvb
    \cand \cinferlab \el \tvb \tv}
\\\\
\Crule
  {\cinferlab \elab \tva \tvb}
  {\cmatch \tb {\cbranch {\cpatrcd \ct} {\labenv(\elab/\ct) \leq \tva \to \tvb}}}
\\
\Crule
  {\cinferlab {\elab/\T} \tva \tvb}
  {\labenv(\elab/\T) \leq \tva \to \tvb}
\\
\Crule
  {\cinferlab {\elmagic \elab} \tva \tvb}
  {\ctrue}
\\
\Crule
  {\cinferlab {\elannot \el \tvs \t} \tva \tvb}
  {\cexists \tvs \cunif \tvb \t \cand \cinferlab \el \tva \tvb}
\\
\Crule
  {\cinferlabuni {\bar \el} \tv}
  {\begin{cases}
    \cexists \tvs \cunif \tv {\Tapp \tvs} &\text{if } \bar \el \uni {\T} \in \labenv \\
    \ctrue &\text{otherwise}
   \end{cases}}
\\ \\
\Crule
  {\csem {\eset \th \e : \t}}
  {\cinfer \e \t}
\\
\Crule
  {\csem {\x : \ts, \G \th \e : \t}}
  {\clet \x \tv {\ts \le \tv} {\csem {\G \th \e : \t}}}
\end{tabular}
\end{judgboxmathpar}


\begin{judgboxmathpar}
  {\e \simple}
  {The term $\e$ is simple.}
  \inferrule[Simple-Var]
    { }
    {\x \simple}

  \inferrule[Simple-Fun]
    {\e \simple}
    {\efun \x \e \simple}

  \inferrule[Simple-App]
    {\ea \simple \\ \eb \simple}
    {\eapp \ea \eb \simple}

  \inferrule[Simple-Unit]
    { }
    {\eunit \simple}

  \inferrule[Simple-Let]
    {\ea \simple \\ \eb \simple}
    {\elet \x \ea \eb \simple}

  \inferrule[Simple-Annot]
    {\e \simple}
    {\eannot \e \tvs \t \simple}

  \inferrule[Simple-Tuple]
    {\parens {\ei \simple}\iton}
    {\etuple {\ea, \ldots, \en} \simple}

  \inferrule[Simple-ProjX]
    {\e \simple}
    {\exproj \e j n \simple}

  \inferrule[Simple-PolyX]
    {\e \simple}
    {\expoly \e \tvs \ts \simple}

  \inferrule[Simple-UseX]
    {\e \simple}
    {\exinst \e \tvs \ts \simple}

  \inferrule[Simple-Rcd]
    {\parens {\eli = \ei \simple} \iton}
    {\erecord {\ela = \ea\; \ldots\; \el_n = \en}}

  \inferrule[Simple-Rcd-Assn]
    {\el \simple \\ \e \simple}
    {\el = \e \simple}

  \inferrule[Simple-Rcd-Proj]
    {\e \simple \\ \el \simple}
    {\efield \e \el \simple}

  \inferrule[Simple-Magic]
    {\e \simple}
    {\emagic \e \simple}

  \inferrule[Simple-Lab]
    { }
    {\elab / \T ~ \simple}

  \inferrule[Simple-Lab-Magic]
    { }
    {\elmagic \elab \simple}

  \inferrule[Simple-Lab-Annot]
    {\el \simple}
    {\elannot \el \tvs \t \simple}
\end{judgboxmathpar}

\judgbox
  {\eerase \el}
  {The erasure of $\el$.}

\begin{judgboxmathpar}
  {\eerase \e}
  {The erasure of $\e$.}
\newcommand{\Erule}[2]{\eerase {#1} &\eqdef& {#2}}
  \begin{tabular}{RCL}
  \Erule{\x}{\x} \\
  \Erule{\efun \x \e}{\efun \x \eerase \e} \\
  \Erule{\eapp \ea \eb}{\eapp {\eerase \ea} {\eerase \eb}} \\
  \Erule{\eunit}{\eunit} \\
  \Erule{\elet \x \ea \eb}{\elet \x {\eerase \ea} {\eerase \eb}} \\
  \Erule{\eannot \e \tvs \t}{\eannot {\eerase \e} \tvs \t} \\
  \Erule{\etuple {\ea, \ldots, \en}}{\etuple {\eerase \ea, \ldots, \eerase \en}} \\
  \Erule{\eproj \e j}{\emagic {\eerase \e}} \\
  \Erule{\exproj \e j n}{\exproj {\eerase \e} j n} \\
  \Erule{\expoly \e \tvs \ts}{\expoly {\eerase \e} \tvs \ts} \\
  \Erule{\epoly \e}{\emagic {\eerase \e}}\\
  \Erule{\einst \e}{\emagic {\eerase \e}}\\
  \Erule{\exinst \e \tvs \ts}{\exinst {\eerase \e} \tvs \ts}\\
  \Erule{\erecord {\ela = \ea\; \ldots\; \el_n = \en}}{\erecord {\eerase \ela = \eerase \ea\; \ldots\; \eerase {\el_n} = \eerase \en}}\\
  \Erule{\efield \e \el}{\efield {\eerase \e} {\eerase \el}}\\[1ex]
  \Erule{\elab/\T}{\elab/\T}\\
  \Erule{\elab}{\elmagic \elab}\\
  \Erule{\elannot \el \tvs \t}{\elannot {\eerase \el} \tvs \t}\\
  \Erule{\elmagic \elab}{\elmagic \elab}
\end{tabular}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\G \thsimplesd \e : \t}
  {Under the typing context $\G$, the simple term $\e$ has the type $\t$.}
\\
  \inferrule[Var-SD]
    {x : \tfor \tvs \t \in \G}
    {\G \thsimplesd x : \t\where{\tvs \is \tys}}

  \inferrule[Let-SD]
    {\G \thsimplesd \ea : \ta\\
     \tvs \disjoint \G \\
     \G, x : \tfor \tvs \ta \thsimplesd \eb : \tb}
    {\G \thsimplesd \elet x \ea \eb : \tb}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\Th \e : \t}
  {The term $\e$ canonically has the type $\t$.}
  \inferrule[Can-Base]
    {\eset \thsimplesd \e : \t}
    {\Th \e : \t}

  \inferrule[Can-Proj-I]
    {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\
     \Th \E\where{\exfield \e n j} : \t}
    {\Th \E\where{\efield \e j} : \t}

  \inferrule [Can-Poly-I]
    {\Eshape \E \e {{\any \tvcs \tpoly \ts}} \\
     \Th \E \where{\epoly[\exi \tvcs \ts] \e} : \t}
    {\Th \E \where{\epoly \e} : \t}

  \inferrule [Can-Use-I]
    {\eshape \E  \e {\any \tvcs \tpoly \ts} \\
     \Th \E\where{\exinst \e \tvcs \ts} : \t}
    {\Th \E\where{\einst \e} : \t}

  \inferrule[Can-Lab-I]
    {\Lshape \Lab \elab \T \\
      \Th \Lab[\elab / \T] : \t}
    {\Th \Lab[\elab] : \t}
\end{judgboxmathpar}


\label {app/rules/unif}
\begin{judgboxmathpar}
  {\up \unif \upp}
  {The unifier rewrites $\up$ to $\upp$.}
   \rewrite[U-Exists]
      {(\cexists \alpha \upa) \cand \upb }{ \tv \disjoint \upb}
      {\cexists \tv {\upa \cand \upb}}

    \rewrite[U-Cycle]
      {\up }{ \cyclic \up}
      {\cfalse}

    \rewrite[U-True]
      {\up \cand \ctrue}
      {}
      {\up}

    \rewrite[U-False]
      {\Up\where{\cfalse}}
      { \Up \neq \square}
      {\cfalse}

    \rewrite[U-Merge]
      {\cunif \tv \ueqa \cand \cunif \tv \ueqb}
      {}
      {\cunif \tv {\cunif \ueqa \ueqb}}

    \rewrite[U-Stutter]
      {\cunif \tv {\cunif \tv \ueq}}
      {}
      {\cunif \tv \ueq}

    \rewrite[U-Name]
      {\cunif {\pshapp \parens{\tys, \ti, \typs}} \ueq }
      {\tv \disjoint \tys, \typs, \ueq \\ \ti \notin \TyVars}
      {\cexists \tv
        {\cunif \tv \ti \cand
         \cunif {\pshapp \parens{\tys, \tv, \typs}} \ueq}}

    \rewrite[U-Decomp]
      {\cunif {\pshapp \tvs} {\cunif {\pshapp \tvbs} \ueq}}
      {}
      {\cunif {\pshapp \tvs} \ueq \cand \cunif \tvs \tvbs}

    \rewrite[U-Clash]
      {\cunif {\pshapp \tvs} {\cunif {\pshapp[\shp]\tvbs } \ueq }}{
       \sh \neq \shp}
      {\cfalse}

    \rewrite[U-Trivial]
      {\ueq}
      {|\ueq| \leq 1}
      {\ctrue}
\end{judgboxmathpar}


\begin{judgboxmathpar}
  {\c \csolve \cp}
  {The constraint solver rewrites $\c$ to $\cp$.}

  \rewrite[S-Unif]
    {\upa}
    {\upa \unif \upb}
    {\upb}

  \rewrite[S-True]
    {C \cand \ctrue}
    {}
    {C}

  \rewrite[S-False]
    {\C\where\cfalse}
    {\C \neq \square}
    {\cfalse}

  \rewrite[S-Let]
    {\clet \x \tv \ca \cb}
    {}
    {\cletr \x \tv \eset \ca \cb}

  \rewrite[S-Exists-Conj]
    {(\cexists \alpha \ca) \cand \cb }{
     \tv \disjoint \cb}
    {\cexists \tv {\ca \cand \cb}}

  \rewrite[S-Let-ExistsLeft]
    {\cletr \x \tv \tvs {\cexists \tvb \ca} \cb }{
     \tvb \disjoint \tv, \tvs, \cb}
    {\cletr \x \tv {\tvs, \tvb} \ca \cb}

  \rewrite[S-Let-ExistsRight]
    {\cletr \x \tv \tvs \ca {\cexists \tvb \cb} }{
     \tvb \disjoint \tv, \tvs, \ca}
    {\cexists \tvb {\clet \x \tvs \ca \cb}}

  \rewrite[S-Let-ConjLeft]
    {\cletr \x \tv \tvs {\ca \cand \cb} \cc }{
     \ca \disjoint \tv, \tvs}
    {\ca \cand \cletr \x \tv \tvs \cb \cc}

  \rewrite[S-Let-ConjRight]
    {\cletr \x \tv \tvs \ca (\cb \cand \cc) }{
     \x \disjoint \cc}
    {\cc \cand \Clet \x \tv \ca \cb}

  \rewrite[S-Match-Type]
    {\cmatch \t \cbrs }{ \t \notin \TyVars}
    {\cmatched \t {\shape \t} \cbrs}

  \rewrite[S-Match-Var]
    {\C\where{\cmatch \tv \cbrs} }{
     \cunif \tv {\cunif \t \ueq} \in \C}
    {\C\where{\cmatched \tv {\shape \t} \cbrs}}

   \rewrite[S-Inst-Name]
    {\cpinst \inst \tv \t}
    {\t \notin \TyVars}
    {\cexists \tvc \cunif \tvc \t \cand \cpinst \inst \tv \tvc}

  \rewrite[S-Let-AppR]
    {\cletr \x \tv \tvs \c {\C\where{\capp \x \t}}}
    {\tvc \disjoint \t \\ \x \disjoint \bvs \C}
    {\cletr \x \tv \tvs \c {\C\where{\cexistsi
      {\tvc, \inst} \x {\cunif \tvc \t \cand \cpinst \inst \tv \tvc}}}}

  \rewrite[S-Inst-Copy]
    {\cletr \x \tv \tvs {\c} \C\where{\cpapp \x \tvp \tvc \inst}}
    {\c = \cp \cand \cunif \tvp {\cunif {\shapp \tvbs} \ueq}\\
     \tvp \in \reg \tv \tvs \\\\
     \neg \cyclic {\c} \\
     \tvbs' \disjoint \tvp, \tvc, \tvbs \\
     \x \disjoint \bvs \C}
    {\cletr \x \tv \tvs {\c}
      \C\where{\cexists {\tvbs'}
         {\cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}}}

  \rewrite[S-Inst-Unify]
    {\cpinst \inst \tv \tvca \cand \cpinst \inst \tv \tvcb}
    {}
    {\cpinst \inst \tv \tvca \cand \cunif \tvca \tvcb}

  \rewrite[S-Inst-Poly]
    {\cletr \x \tv {\tvs} {\ueqs \cand \c}
        {\C\where{\cpapp \x \tvp \tvc \inst}}}
    {\cfor \tvp \cexists {\tv} {\ueqs} \cequiv \ctrue \\\\
     \tvp \in \reg \tv \tvs \\
     \tvp \disjoint \c \\
     \inst.\tvp \disjoint \insts \C \\
     \x \disjoint \bvs \C}
    {\cletr \x \tv {\tvs} {\ueqs \cand \c} {\C\where\ctrue}}

  \rewrite[S-Inst-Mono]
    {\cletr \x \tv \tvs \c {\C\where{\cpapp \x \tvb \tvc \inst}}}
    {\tvb \notin \reg \tv \tvs \\ \x, \tvb \disjoint \bvs \C}
    {\cletr \x \tv \tvs \c {\C\where{\cunif \tvb \tvc}}}

  \rewrite[S-Let-Solve]
    {\cletr \x \tv \tvs \ueqs \c}
    {\cexists {\tv, \tvs} \ueqs \cequiv \ctrue \\ \x \disjoint \c}
    {\c}

  \rewrite[S-Compress]
    {\cletr \x \tv {\tvs, \tvb}
       {\ca \cand \cunif \tvb {\cunif \tvc \ueq}} {\cb}}
    {\tvb \neq \tvc}
    {\cletr \x \tv {\tvs}
       {\ca\where{\tvb \is \tvc} \cand \cunif \tvc {\ueq\where{\tvb \is \tvc}}}
       {\cb\where{\x.\tvb \is \tvc}}}

  \rewrite[S-Gc]
    {\cletr \x \tv {\tvs, \tvb} {\ca \cand \cunif \tvb \ueq} \cb}
    {\tvb \disjoint \ca, \ueq, \cb}
    {\cletr \x \tv {\tvs} {\ca \cand \ueq} \cb}

  \rewrite[S-Exists-Lower]
    {\cletr \x \tv {\tvas, \tvbs} \ca \cb}
    {\cdetermines {\cexists {\tv, \tvas} \ca} \tvbs}
    {\cexists \tvbs \cletr \x \tv \tvas \ca \cb}

  \rewrite[S-BackProp]
    {\C\where
       {\cletr \x \tv {\tvs}
          {\Ca\where{\cmatch \tvp \cbrs}}
          {\Cb\where{\cpapp \x \tvp \tvc \inst}}}}
    {\tvp \in \reg \tv \tvs \\
     \cunif {\tvc} {\cunif \t \ueq} \in \C\where\Cb \\
     \x \disjoint \bvs \Cb}
    {\C\where
       {\cletr \x \tv {\tvs}
           {\Ca\where{\cmatched \tvp {\shape \t} \cbrs}}
	   {\Cb\where{\cpapp \x \tvp \tvc \inst}}}}

  \rewrite[S-Exists-Exists-Inst]
    {\cexistsi \inst \x \cexists \tv \c}
    {}
    {\cexists \tv \cexistsi \inst \x \c}

  \rewrite[S-Exists-Inst-Conj]
    {\cexistsi \inst \x \ca \cand \cb}
    {\inst \disjoint \ca}
    {\ca \cand \cexistsi \inst \x \cb}

  \rewrite[S-Exists-Inst-Let]
    {\cletr \x \tv \tvs \ca {\cexistsi \inst \xp \cb}}
    {\x \neq \xp}
    {\cexistsi \inst \xp \cletr \x \tv \tvs \ca \cb}

  \rewrite[S-Exists-Inst-Solve]
    {\cexistsi \inst \x \c}
    {\inst \disjoint \c}
    {\c}

  \rewrite[S-All-Conj]
    {\cfor \tvs {\cexists \tvbs {\ca \cand \cb}}}
    {\tvs, \tvbs \disjoint \ca}
    {\ca \cand \cfor \tvs {\cexists \tvbs \cb}}

  \rewrite[S-Exists-All]
    {\cfor \tvs {\cexists {\tvbs, \tvcs} \c}}
    {\cdetermines {\cexists {\tvs, \tvbs} \c} \tvcs}
    {\cexists \tvcs \cfor \tvs {\cexists \tvbs \c}}

  \rewrite[S-All-Escape]
    {\cfor {\tvs, \tv} {\cexists \tvbs {\c \cand \ueqs}}}
    {\tv \prec_{\ueqs}^* \tvc \\
     \tvc \disjoint \tv, \tvbs \\
     \tv \disjoint \tvbs}
    {\cfalse}

  \rewrite[S-All-Rigid]
    {\cfor {\tvs, \tv}
      {\cexists \tvbs \c \cand \cunif \tv {\cunif \t \ueq}}}
    {\t \notin \TyVars \\ \tv \disjoint \tvbs}
    {\cfalse}

  \rewrite[S-All-Solve]
    {\cfor \tvs \cexists \tvbs \ueqs}
    {\cexists \tvbs \ueqs \cequiv \ctrue}
    {\ctrue}
\end{judgboxmathpar}

\begin{definition}
  $\cdetermines \c \tvbs$ if and only if every ground assignments
  $\semenv$ and $\semenvp$ that satisfy (the erasure of) $\c$ and coincide outside of $\tvb$
  coincide on $\tvbs$ as well.
  \begin{mathpar}
    \cdetermines \c \tvb \uad\eqdef\uad \all {\semenv, \semenvp} \uad
      \semenv \th \cerase \c
      \wedge \semenvp \th \cerase \c
      \wedge \semenv =_{\setminus \tvbs} \semenvp
      \implies
      \semenv = \semenvp
  \end{mathpar}
\end{definition}

\begin{definition}
A context $\C$ proves a multi-equation $\ueq$, written $\ueq \in \C$,  if there exists a decomposition
  $\C = \Ca[\ueq \cand \Cb]$ such that $\fvs \ueq \disjoint \bvs \Cb$
\end{definition}



\begin{definition}[Measure]
  For the relation $\semenv \th \c$, the following measure enables a useful
  induction principle:
    \begin{mathpar}
    \cmeasure \c \uad\eqdef\uad \angles{\cnmatches \c, \csize \c}
  \end{mathpar}
  where $\angles \ldots$ denotes a pair with lexicographic ordering, and:
  \begin{enumerate}

    \item $\cnmatches \c$ is the number of $\cmatch \t \cbrs$ constraints in
      $\c$.

    \item the last component $\csize \c$ is a structural measure of constraints \ie a
      conjunction $\ca \cand \cb$ is larger than the two conjuncts $\ca,
      \cb$.

  \end{enumerate}
\end{definition}


\clearpage
\section{Properties of the constraint language}
\label{app:proofs-constraints}

This appendix establishes key properties of the constraint language. The first
is the principality of shapes \cref{thm:principal-shapes}: any non-variable type
$\t$ admits a non-trivial principal shape $\sh$.

The second is the canonicalization of satisfiability derivations $\semenv \th
\c$, which enables a simple induction principal for reasoning about unicity.
This canonical form for derivations is a crucial tool in our proof of
soundness and completeness in \cref{app:proofs-typing}.

\subsection{Principality of shapes}

\principalShapes
\begin{proof}
  Let us assume $\t$ is a non-variable type.

  \begin{proofcases}
    \proofcase{$\t$ is a type constructor $\tconstr \tys$}

    $\tconstr$ is a top-level type constructor of arity $n$, which in our
    setting may be the nullary $\tunit$, the binary arrow, the $n$-ary product,
    or a $n$-ary nominal type. In all these cases, the shape of $\t$ is $\any
    \tvcs \tconstr \tvcs$ where $\tvcs$ is a sequence of $n$ distinct type
    variables. This is clearly principal.

    \proofcase{$\t$ is a polytype $\tpoly {\tfor \tvs \t}$}

    We may assume \Wlog that each variable of $\tvs$ occurs free in
    $\t$.
    %
    Let $(\pi_i)\iton$ be the sequence of shortest paths in $\t$ that cannot be
    extended to reach a (polymorphic) variable in $\tvas$, in lexicographic
    order and $\tvcs$ be a sequence $(\tvci)\iton$ of distinct variables that do
    not appear in~$\t$.
    %
    Let $\tyz$ be $\t \where {\pi_i \is \tvci}\iton$, \ie the term $\t$ where each
    path $\pi_i$ has been substituted by the variable $\tvci$.  Let $\Sh$ be the
    shape $\any \tvcs {\tpoly {\all \tvs \tyz}}$.
    We claim that $\Sh$ is actually the principal shape of $\tpoly {\all \tvs
    \t}$.

    \medskip
    \locallabelreset

    By construction, $\t$ is equal to $\shapp[\Sh] \tys$~\llabel 1.
    where $\tys$ is the sequence composed of $\ti$ equal to $\t/\pi_i$
    for $i$ ranging from $1$ to $n$.
    %
    Indeed, by
    definition, $\shapp[\Sh] \tys$ is equal to $(\t\where {\pi_i \is \tvci}\iton)
    \where {\tvci \is \ti}$ which is obviously equal to $\t$.
    The remaining of the proof checks that $\Sh$ is minimal~\llabel 2, that is,
    we assume that $\Sh'$ is another shape such that $\tpoly {\all\tvs\t}$ is
    equal to $\shapp [\Shp] \typs$ for some $\typs$~\llabel H and show that $\Sh
    \preceq \Shp$~\llabel C.

    \medskip

    It follows from~\lref H that
      $\Shp$ must be a polytype shape, \ie of the form $\any \tvcps {\tpoly
      {\all \tvbs \typ}}$ and
      $\tpoly {\all \tvs \t}$ is equal to $\tpoly {\all\tvbs \tp} \where {\tvcps
      \is \typs}$~\llabel{P}.
    \relax
    We may assume \Wlog that $\tvbs$ and $\tvcps$ are disjoint, that
    $\tvcps$ does not contain useless variables, \ie
    that they all appear in $\tp$ and that they actually appear in lexicographic
    order.
    \relax
    Now that never term contains useless variables, \lref P implies that the
    sequences $\tvas$ and $\tvbs$ can be put in one-to-one correspondences.
    Besides, since they all ordered in the order of appearance in terms, they
    the correspondence respects the ordering. Hence, the substitution $\where
    {\tvbs \is \tvas}$ is a renaming. Therefore, we can assume \Wlog that
    $\tvbs$ is $\tvas$,
    \relax
    That is, \lref P becomes that $\tpoly {\all \tvs \t}$ is equal to $\tpoly
    {\all \tvs \typ \where {\tvcps \is \typs}}$, which given that variables
    $\tvs$ appear in the same order in both terms, implies that $\t$ is
    equal to $\typ \where {\tvcps \is
    \typs}$~\llabel T.

    \relax

    \medskip

    Since $\typs$ does not contain any variable in $\tvs$, every path $\pi_i$
    is a path in $\typ$. Thus, we may write $\typ$ as
    \relax $\typ \where {\pi_i \is \tyi''}\iton$ where $\tyi''$ is $\typ/\pi_i$.
    This is also equal to
    \relax $(\typ \where {\pi_i \is \tvci}\iton) \where {\tvci \is \tyi''}\iton$,
    that is $\tyz\where {\tvci \is \tyi''}\iton$.
    %
    In summary, we have $\typ$ is equal to
    \relax $\tyz \where {\tvci \is \tyi''}\iton$,
    which implies that
    \relax  $\tpoly {\all \tvs \typ}$ is equal to
    \relax  $\tpoly {\all \tvs {\tyz \where {\tvci \is \tyi''}\iton}}$, \ie
    \relax  $\tpoly {\all \tvs \tyz} \where {\tvci \is \tyi''}\iton$~\llabel E.
    %
    By \Rule {Inst-Shape}, we have
    \begin{mathpar}[inline]
    \any \tvcs  \tpoly {\all \tvs \tyz} \preceq
    \any \tvcps\tpoly {\all \tvs \tyz} \where {\tvci \is \tyi''}\iton,
    \end{mathpar}
    which, given~\lref E, is exactly~\lref C.

  \end{proofcases}
\end{proof}

\subsection{Canonicalization of satisfiability}

They key result in this section is that our semantic derivations $\semenv \th
\c$ can always be rewritten to only apply the rule \Rule{Susp-Ctx} at the very
bottom of the derivation, rather than in the middle of derivations. This
corresponds to explicitating the unique shapes of all suspended constraints (in
some order that respects the dependency between suspended constraints), and
then continuing with a syntax-directed proof of a fully-discharged constraint.

We did not impose this ordering in our definition of the semantics to make it
more flexible and more declarative, but the inversion principle that it
provides will be helpful when reasoning about the solver in
\cref{app:proofs-solving}.

We define in \cref{fig:simple} a formal judgment $\c \simple$ that says that
$\c$ does not contain any suspended match constraint, and extend it trivially
to constraint contexts: $\C \simple$. In particular, the erasure $\cerase \c$
of a constraint (\cref{def:erasure}) is always simple. We then introduce in
\cref{fig:canonical-sem} a ``canonical'' semantic judgment $\semenv \Th \c$
that enforces the structure we mentioned: its derivation starts by discharging
suspended constraints, until eventually we reach a simple constraint $\c$.
Below we prove that any semantic derivation $\semenv \th \c$ can be turned into
a canonical semantic derivation $\semenv \Th \c$.

We can think of this result as controlling the amount of non-syntax-directness in our rules: we need some of it, but it suffices to have it only at the outside, and it contains a more standard derivation that is easy to reason about.

\paragraph{Inversion} When $\c$ is simple, a derivation of $\semenv \th \c$
does not use the contextual rule (it is a derivation in $\semenv \thsimple
\c$), so it enjoys the usual inversion principle on syntax-directed judgments;
for example, if $\semenv \thsimple {\ca \cand \cb}$ then by inversion $\semenv
\thsimple \ca$ and $\semenv \thsimple \cb$, etc.

\paragraph{Congruence} Congruence does not hold in general in our system due to
the contextual rule. For example, $\ca \eqdef (\cmatch \tva {\cbranch \wild
\ctrue})$ is unsatisfiable so we have $\ca \cequiv \cfalse$, but for $\C \eqdef
(\cexists \tva \cunif \tva \tint \cand \square)$ we have $\C \where \ca \cequiv
\ctrue$ and $\C \where \cfalse \equiv \cfalse$. It holds simply for simple
constraints.

\begin{lemma}[Simple congruence]
  \label{lem:cong-simple}
  Given simple constraints $\ca, \cb$ and simple context $\C$.
  If \\$\ca \centails \cb$, then $\C\where{\ca} \centails \C\where{\cb}$.

  \begin{proof}
    Induction on the derivation of $\C \simple$.
  \end{proof}
\end{lemma}

\paragraph{Composability} The composability result below is an important test of our definition of the unicity condition $\Cshape \C \t \sh$, which is in part engineered for this lemma to be simple to prove. In the past we used a definition of unicity that also required $\C \where \ctrue$ to be satisfiable, which broke the composability property.
\begin{lemma}[Composability of unicity]
  \label{lem:compose-unicity}
  If $\Cshape \Ca \t \sh$, then $\Cshape {\Cb\where\Ca} \t \sh$.
  \begin{proof}
    Induction on the structure of $\Cb$.
    \begin{proofcases}
      \proofcase{$\square$}
        immediate.
      \proofcase{$\Cc \cand \c$}

	\begin{llproof}
	  \shapePf{\Ca}{\t}{\sh}{Premise}
	  \shapePf{\Cc\where\Ca}{\t}{\sh}{By \ih}
	  \ForallPf{\semenv, \gt}{}{Definition of $\Cshape {\parens{\Cc\where\Ca \cand \c}} \t \sh$}
	  \vdashPf{\semenv}{\cerase {\Cc\where\Ca\where{\cunif \t \gt}} \cand \cerase \c}{$\implies$I}
	  \vdashPf{\semenv}{\cerase {\Cc\where\Ca\where{\cunif \t \gt}}}{Simple inversion}
	  \eqPf{\shape \gt}{\sh}{$\implies$E on $\Cshape {\Cc\where\Ca} \t \sh$}
\Hand 	  \shapePf{\parens{\Cc\where\Ca \cand \c}}{\t}{\sh}{Above}
	\end{llproof}

      \proofcase{$\c \cand \Cc$}

	\begin{llproof}
	  Similar to the $\Cc \cand \c$ case.
	\end{llproof}

      \proofcase{$\cexists \tv \Cc$}

	\begin{llproof}
	  \shapePf{\Ca}{\t}{\sh}{Premise}
	  \shapePf{\Cc\where\Ca}{\t}{\sh}{By \ih}
	  \ForallPf{\semenv, \gt}{}{Definition of $\Cshape {\parens{\cexists \tv \Cc\where\Ca}} \t \sh$}
	  \vdashPf{\semenv}{\cexists \tv \cerase {\Cc\where\Ca\where{\cunif \t \gt}}}{$\implies$I}
	  \vdashPf{\semenv\where{\tv \is \gtp}}{\cerase {\Cc\where\Ca\where{\cunif \t \gt}}}{Simple inversion}
	  \eqPf{\shape \gt}{\sh}{$\implies$E on $\Cshape {\Cc\where\Ca} \t \sh$}
\Hand 	  \shapePf{\parens{\cexists \tv \Cc\where\Ca}}{\t}{\sh}{Above}
	\end{llproof}

      \proofcase{$\cfor \tv \Cc$}

	\begin{llproof}
	  Similar to $\cexists \tv \Cc$ case.
	\end{llproof}

      \proofcase{$\cexistsi \inst \x \Cc$}

	\begin{llproof}
	  Similar to $\cexists \tv \Cc$ case.
	\end{llproof}

      \proofcase{$\clet \x \tv \Cc \c$}

	\begin{llproof}
	  \shapePf{\Ca}{\t}{\sh}{Premise}
	  \shapePf{\Cc\where\Ca}{\t}{\sh}{By \ih}
	  \ForallPf{\semenv, \gt}{}{Definition of $\Cshape {\parens {\Let \x \ldots}} \t \sh$}
	  \vdashPf{\semenv}{\clet \x \tv {\cerase {\Cc\where\Ca\where{\cunif \t \gt}}} {\cerase \c}}{$\implies$I}
	  \vdashPf{\semenv}{\cexists \tv \cerase {\Cc\where\Ca\where{\cunif \t \gt}}}{Simple inversion}
	  \vdashPf{\semenv\where{\tv \is \gtp}}{\cerase {\Cc\where\Ca\where{\cunif \t \gt}}}{Simple inversion}
	  \eqPf{\shape \gt}{\sh}{$\implies$E on $\Cshape {\Cc\where\Ca} \t \sh$}
\Hand 	  \shapePf{\parens{\clet \x \tv {\Cc\where\Ca} \c}}{\t}{\sh}{Above}
	\end{llproof}

      \proofcase{$\clet \x \tv \c \Cc$}

	\begin{llproof}
	  Similar to $\clet \x \tv \Cc \c$ case.
	\end{llproof}

      \proofcase{$\cletr \x \tv \tvs \Cc \c$}

	\begin{llproof}
	  Similar to $\clet \x \tv \Cc \c$ case.
	\end{llproof}

      \proofcase{$\cletr \x \tv \tvs \c \Cc$}

	\begin{llproof}
	  Similar to $\clet \x \tv \c \Cc$ case.
	\end{llproof}
    \end{proofcases}
  \end{proof}
\end{lemma}

\begin{lemma}[Inversion of unicity]
  \label{lem:unicity-inversion}~
  \begin{enumerate}[(\roman*)]
    \item If $\Cshape {\parens{\cexists \tv \C}} \t \sh$, then $\Cshape \C \t \sh$.
    \item If $\Cshape {\parens{\cfor \tv \C}} \t \sh$, then $\Cshape \C \t \sh$.
  \end{enumerate}
  \begin{proof}
    The definition of $\Cshape \C \t \sh$ uses simple semantics on the
    erasure $\cerase \C$, so these results are easily shown by simple inversion.
  \end{proof}
\end{lemma}

\begin{lemma}[Decanonicalization]
  \label{lem:decanonicalization}
  If $\semenv \Th \c$, then $\semenv \th \c$.
  \begin{proof}
    Induction on the given derivation $\semenv \Th \c$
  \end{proof}
\end{lemma}

\begin{theorem}[Canonicalization]
  \label{thm:canonicalization}
  If $\semenv \th \c$, then $\semenv \Th \c$.
  \begin{proof}
  We proceed by induction on $\semenv \th \c$ with the measure $\cmeasure \c$.
  \begin{proofcases}
    \proofcasederivation
      {True}
      { }
      {\semenv \th \ctrue}

      \begin{llproof}
\Hand   \VdashPf{\semenv}{\ctrue}{immediate by \Rule{Can-Base}}
      \end{llproof}

    \proofcasederivation
      {Unif}
      {\semenv(\ta) = \semenv(\tb)}
      {\semenv \th \cunif \ta \tb}

      \begin{llproof}
	Similar to the \Rule{True} case.
      \end{llproof}
    \proofcasederivation
      {Conj}
      {\semenv \th \ca \\ \semenv \th \cb}
      {\semenv \th \ca \cand \cb}

      \begin{llproof}
	\vdashPf{\semenv}{\ca} {Premise}
	\vdashPf{\semenv}{\cb} {Premise}
	\VdashPf{\semenv}{\ca} {By \ih}
	\VdashPf{\semenv}{\cb} {By \ih}
	\decolumnizePf
	\casesPf{\semenv \Th \ca, \semenv \Th \cb}
      \end{llproof}

      \begin{proofcases}
	\proofcasederivationdouble
	  {Can-Base}
	  {\semenv \th \ca \\ \ca \simple}
	  {\semenv \Th \ca}
	  {Can-Base}
	  {\semenv \th \cb \\ \cb \simple}
	  {\semenv \Th \cb}

        \begin{llproof}
\Hand     \VdashPf{\semenv}{\ca \cand \cb}{immediate by \Rule{Can-Base}}
        \end{llproof}


	\proofcasederivationdouble
	  {Can-Susp-Ctx}
	  {\Cshape \C \t \sh \\ \semenv \Th \C\where{\cmatched \t \sh \cbrs}}
	  {\semenv \Th \underbrace{\C\where{\cmatch \t \cbrs}}_\ca}
	  {}
	  {}
	  {\semenv \Th \cb}

	  \begin{llproof}

	    \VdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs}} {Premise}
	    \vdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs}} {\cref{lem:decanonicalization}}
	    \vdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs} \cand \cb}{By \Rule{Conj}}
 	    \VdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs} \cand \cb}{By \ih}
	    \Pf{}{}{\Cshape \C \tv \sh}{Premise}
	    \Pf{}{}{\Cshape {\parens {\C \cand \cb}} \tv \sh}{\cref{lem:compose-unicity}}
\Hand 	    \VdashPf{\semenv}{\C\where{\cmatch \t \cbrs}}{By \Rule{Can-Susp-Ctx}}
	  \end{llproof}

	\proofcasederivationdouble
	  {}
	  {}
	  {\semenv \Th \ca}
	  {Can-Susp-Ctx}
	  {\Cshape \C \t \sh \\ \semenv \Th \C\where{\cmatched \t \sh \cbrs}}
	  {\semenv \Th \underbrace{\C\where{\cmatch \t \cbrs}}_\cb}

	  \begin{llproof}
	    \Pf{}{}{}{Symmetric to the above case.}
	  \end{llproof}
      \end{proofcases}

      \proofcasederivation
	{Exists}
	{\semenv\where{\tv \is \gt} \th \c}
	{\semenv \th \cexists \tv \c}

	\begin{llproof}
	  \vdashPf{\semenv\where{\tv \is \gt}}{\c}{Premise}
	  \VdashPf{\semenv\where{\tv \is \gt}}{\c}{By \ih}
	  \casesPf{\semenv\where{\tv \is \gt} \Th \c}
	\end{llproof}

	\begin{proofcases}

	    \proofcasederivation
	      {Can-Base}
	      {\semenv\where{\tv \is \gt} \th \c \\ \c \simple}
	      {\semenv\where{\tv \is \gt} \Th \c}

	      \begin{llproof}
\Hand 		\VdashPf{\semenv}{\cexists \tv \c}{Immediate by \Rule{Can-Base}}
	      \end{llproof}


	      \proofcasederivation
		{Can-Susp-Ctx}
		{\Cshape \C \t \sh \\ \semenv\where{\tv \is \gt} \Th \C\where{\cmatched \t \sh \cbrs}}
		{\semenv \Th \underbrace{\C\where{\cmatch \t \cbrs}}_\c}

		\begin{llproof}
		  \VdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatched \t \sh \cbrs}}{Premise}
		  \vdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatched \t \sh \cbrs}}{\cref{lem:decanonicalization}}
	    \decolumnizePf
		  \vdashPf{\semenv}{\cexists \tv \C\where{\cmatched \t \sh \cbrs}}{By \Rule{Exists}}
		  \VdashPf{\semenv}{\cexists \tv \C\where{\cmatched \t \sh \cbrs}}{By \ih}
		  \Pf{}{}{\Cshape \C \t \sh}{Premise}
		  \Pf{}{}{\Cshape {\parens {\cexists \tv \C}} \t \sh}{\cref{lem:compose-unicity}}
\Hand             \VdashPf{\semenv}{\cexists \tv \C\where{\cmatch \t \cbrs}}{By \Rule{Can-Susp-Ctx}}
		\end{llproof}
	\end{proofcases}

	\proofcasederivation
	  {Forall}
	  {\forall \gt,~ \semenv\where{\tv \is \gt} \th \c}
	  {\semenv \th \cfor \tv \c}

	  \begin{llproof}
	    Similar to the \Rule{Exists} case.
	  \end{llproof}

	\proofcasederivation
	  {Let}
	  {\semenv \th \cexists \tv \ca \\ \semenv\where{\x \is \semenv(\cabs \tv \ca)} \th \cb}
	  {\semenv \th \clet \x \tv \ca \cb}

	  \begin{llproof}
	    \vdashPf{\semenv}{\cexists \tv \ca}{Premise}
	    \VdashPf{\semenv}{\cexists \tv \ca}{By \ih}
	    \vdashPf{\semenv\where{\x \is \semenv(\cabs \tv \ca)}}{\cb}{Premise}
	    \VdashPf{\semenv\where{\x \is \semenv(\cabs \tv \ca)}}{\cb}{By \ih}
	    \decolumnizePf
	    \casesPf{\semenv \Th \cexists \tv \ca, \semenv\where{\x \is \semenv(\cabs \tv \ca)} \Th \cb}
	  \end{llproof}

	  \begin{proofcases}
	    \proofcasederivationdouble
	      {Can-Base}
	      {\semenv \th \cexists \tv \ca \\ \cexists \tv \ca \simple}
	      {\semenv \Th \cexists \tv \ca}
	      {Can-Base}
	      {\semenv\where{\x \is \semenv(\cabs \tv \ca)} \th \cb \\ \cb \simple}
	      {\semenv\where{\x \is \semenv(\cabs \tv \ca)} \Th \cb}

	      \begin{llproof}
\Hand		\VdashPf{\semenv}{\clet \x \tv \ca \cb}{Immediate by \Rule{Can-Base}}
	      \end{llproof}

	    \proofcasederivationdouble
	      {Can-Susp-Ctx}
	      {\Cshape {\parens {\cexists \tv \ca}} \t \sh \\ \semenv \Th \cexists \tv \C\where{\cmatched \t \sh \cbrs}}
	      {\semenv \Th \cexists \tv \underbrace{\C\where{\cmatch \t \cbrs}}_\ca}
	      {}
	      {}
	      {\semenv\where{\x \is \semenv(\cabs \tv \ca)} \Th \cb}

	      \begin{llproof}
		\shapePf{\parens {\cexists \tv \C}}{\t}{\sh}{Premise}
		\shapePf{\C}{\t}{\sh}{\cref{lem:unicity-inversion}}
		\VdashPf{\semenv}{\cexists \tv \C\where{\cmatched \t \sh \cbrs}}{Premise}
		\vdashPf{\semenv}{\cexists \tv \C\where{\cmatched \t \sh \cbrs}}{\cref{lem:decanonicalization}}
	    \decolumnizePf
		\eqPf{\semenv(\cabs \tv \ca)}
		  {\semenv(\cabs \tv \C\where{\cmatched \t \sh \cbrs})}
		  {\cref{corollary:matched-abstractions}}
		\vdashPf{\semenv}{\clet \x \tv {\C\where{\cmatched \t \sh \cbrs}} \cb}{By \Rule{Let}}
		\VdashPf{\semenv}{\clet \x \tv {\C\where{\cmatched \t \sh \cbrs}} \cb}{By \ih}
		\shapePf{\parens{\clet \x \tv \C \cb}}{\t}{\sh}{\cref{lem:compose-unicity}}
\Hand 		\VdashPf{\semenv}{\clet \x \tv {\C\where{\cmatch \t \cbrs}} \cb}{By \Rule{Can-Susp-Ctx}}
	      \end{llproof}

	    \proofcasederivationdouble
		{}
		{}
		{\semenv \Th \cexists \tv \ca}
		{Can-Susp-Ctx}
		{\Cshape \C \t \sh \\ \semenv\where{\x \is \semenv(\cabs \tv \ca)} \Th \C\where{\cmatched \t \sh \cbrs}}
		{\semenv\where{\x \is \semenv(\cabs \tv \ca)} \Th \underbrace{\C\where{\cmatch \t \cbrs}}_\cb}

		\begin{llproof}
		  \shapePf{\C}{\t}{\sh}{Premise}
		  \shapePf{\parens{\clet \x \tv \ca \C}}{\t}{\sh}{\cref{lem:compose-unicity}}
		  \VdashPf{\semenv\where{\x \is \semenv(\cabs \tv \ca)}}{\C\where{\cmatched \t \sh \cbrs}}{Premise}
		  \vdashPf{\semenv\where{\x \is \semenv(\cabs \tv \ca)}}{\C\where{\cmatched \t \sh \cbrs}}{\cref{lem:decanonicalization}}
		  \vdashPf{\semenv}{\clet \x \tv \ca {\C\where{\cmatched \t \sh \cbrs}}}{By \Rule{Let}}
		  \VdashPf{\semenv}{\clet \x \tv \ca {\C\where{\cmatched \t \sh \cbrs}}}{By \ih}
\Hand 		  \VdashPf{\semenv}{\clet \x \tv \ca {\C\where{\cmatch \t \sh}}}{By \Rule{Can-Susp-Ctx}}
		\end{llproof}
	  \end{proofcases}

      \proofcasederivation
	{App}
	{\semenv(\t) \in \semenv(\x)}
	{\semenv \th \capp \x \t}

      \begin{llproof}
	Similar to the \Rule{True} case.
      \end{llproof}

      \proofcasederivation
	{LetR}
	{\semenv \th \cexists {\tv, \tvs} \ca \\
	 \semenv\where{\x \is \semenv(\cabsr \tv \tvs \ca)} \th \cb}
	{\semenv \th \cletr \x \tv \tvs \ca \cb}

      \begin{llproof}
	Similar to the \Rule{Let} case.
      \end{llproof}

      \proofcasederivation
	{AppR}
	{\greg \tv \semenvp \in \semenv(\x) \\
	 \semenv(\t) = \semenvp(\tv)}
	{\semenv \th \capp \x \t}

      \begin{llproof}
	Similar to the \Rule{App} case.
      \end{llproof}

    \proofcasederivation
      {Exists-Inst}
      {\greg \tv \semenvp \in \semenv(\x) \\ \semenv\where{\inst \is \semenvp} \th \c}
      {\semenv \th \cexistsi \inst \x \c}

      \begin{llproof}
	Similar to the \Rule{Exists} case.
      \end{llproof}


    \proofcasederivation
      {Multi-Unif}
      {\forall \t \in \ueq,~ \semenv(\t) = \gt}
      {\semenv \th \ueq}

      \begin{llproof}
	Similar to the \Rule{Unif} case.
      \end{llproof}

    \proofcasederivation
      {Partial-Inst}
      {\semenv(\inst)(\tv) = \semenv(\t)}
      {\semenv \th \cpinst \inst \tv \t}


      \begin{llproof}
	Similar to the \Rule{App} case.
      \end{llproof}


  \end{proofcases}
  \end{proof}
\end{theorem}

\begin{lemma}[Inversion of suspension]
  \label{lem:susp-inversion}
  If $\semenv \th \C\where{\cmatch \t \cbrs}$ and $\Cshape \C \t \sh$,
  then\\$\semenv \th \C\where{\cmatched \t \sh \cbrs}$.

  \begin{proof}
    We use canonicalization (\cref{thm:canonicalization}) to induct on $\semenv \Th
    \C\where{\cmatch \t \cbrs}$ instead of $\semenv \th \C\where{\cmatch \t
    \cbrs}$.

    This simplifies the proof, but introduces a circular dependency between
    \cref{thm:canonicalization} and \cref{lem:susp-inversion}.
    %
    However, this does not compromise the well-foundedness of induction, as the
    application of \cref{lem:susp-inversion} (via
    \cref{corollary:matched-abstractions}) within the proof of
    \cref{thm:canonicalization} is restricted to strictly smaller constraints.

    \begin{proofcases}
      \proofcasederivation
	{Can-Base}
	{\semenv \th \C\where{\cmatch \t \cbrs} \\ \C\where{\cmatch \t \cbrs} \simple}
	{\semenv \Th \C\where{\cmatch \t \cbrs}}

        The second premise is a contradiction.

      \proofcasederivation
	{Can-Susp-Ctx}
	{\Cshape \Cp \tp \shp \\ \semenv \Th \Cp\where{\cmatched \tp \shp \cbrs'}}
	{\semenv \Th \underbrace{\Cp\where{\cmatch \tp \cbrs'}}_{\C\where{\cmatch {~\t~} {~\cbrs}}}}

	\begin{llproof}
	  \casesPf{\C = \Cp}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\C = \Cp$}

	    \begin{llproof}
	      \eqPf{\C}{\Cp}{Premise}
	      \eqPf{\tp}{\t}{}
	      \eqPf{\shp}{\sh}{}
	      \eqPf{\cbrs'}{\cbrs}{}
\Hand         \VdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs}}{Premise}
	    \end{llproof}

	  \proofcase{$\C \neq \Cp$}

	    \newcommand{\Ctwo}{\C_2}
	    \begin{llproof}
	      \eqPf{\Ctwo\where{\cmatch \t \cbrs, \cmatch \tp \cbrs'}}{\C\where{\cmatch \t \cbrs}}{For some 2-hole context $\Ctwo$}
	      \continueeqPf{\Cp\where{\cmatch \tp \cbrs'}}{}
	      \decolumnizePf
	      \VdashPf{\semenv}{\Ctwo\where{\cmatch \t \cbrs, \cmatched \tp \shp \cbrs'}}{Premise}
	      \decolumnizePf
	      \ForallPf{\semenvp, \gtp}{}{\hspace{32.5ex}Defn. of $\Cshape {\Ctwo\where{\square, \cmatched \tp \shp \cbrs'}} \t \sh$}
	      \decolumnizePf
	      \vdashPf{\semenvp}{\cerase {\Ctwo\where{\cunif \t \gtp, \cmatched \tp \shp \cbrs'}}}{$\implies$I}
	      \vdashPf{\semenvp}{\cerase {\Ctwo\where{\cunif \t \gtp, \ctrue}}}{\cref{lem:cong-simple}}
	    \decolumnizePf
	      \eqPf{\cerase {\Ctwo\where{\cunif \t \gtp, \ctrue}}}{\cerase {\Ctwo\where{\cunif \t \gtp, \cerase {\cmatch \tp \cbrs'}}}}{By definition}
	      \continueeqPf{\cerase {\C\where{\cunif \t \gtp}}}{By definition}
	      \vdashPf{\semenvp}{\cerase {\C\where{\cunif \t \gtp}}}{Above}
	      \eqPf{\shape \gtp}{\sh}{$\implies$E on $\Cshape \C \t \sh$}
	      \shapePf{\Ctwo\where{\square, \cmatched \tp \shp \cbrs'}}{\t}{\sh}{Above}
	      \VdashPf{\semenv}{\Ctwo\where{\cmatched \t \sh \cbrs, \cmatched \tp \shp \cbrs'}}{By \ih}
	      \decolumnizePf
	      \ForallPf{\semenvp, \gtp}{}{\hspace{32.5ex}Defn. of $\Cshape {\Ctwo\where{\cmatched \t \sh \cbrs, \square}} \tp \shp$}
	      \decolumnizePf
	      \vdashPf{\semenvp}{\cerase {\Ctwo\where{\cmatched \t \sh \cbrs, \cunif \tp \gtp}}}{$\implies$I}
	      \vdashPf{\semenvp}{\cerase {\Ctwo\where{\ctrue, \cunif \tp \gtp}}}{\cref{lem:cong-simple}}
	      \eqPf{\cerase {\Ctwo\where{\ctrue, \cunif \tp \gtp}}}{\cerase {\Ctwo\where{\cerase {\cmatch \t \cbrs}, \cunif \tp \gtp}}}{By definition}
	      \continueeqPf{\cerase {\Cp\where{\cunif \tp \gtp}}}{By definition}
	      \vdashPf{\semenvp}{\cerase {\C\where{\cunif \t \gtp}}}{Above}
	      \shapePf{\Cp}{\tp}{\shp}{Premise}
	      \eqPf{\shape \gtp}{\shp}{$\implies$E on $\Cshape \Cp \tp \shp$}
	      \shapePf{\Ctwo\where{\cmatched \t \sh \cbrs, \square}}{\tp}{\shp}{Above}
\Hand 	      \VdashPf{\semenv}{\Ctwo\where{\cmatched \t \sh \cbrs, \cmatch \tp \cbrs'}}{By \Rule{Con-Susp-Ctx}}
	    \end{llproof}
	\end{proofcases}
    \end{proofcases}
  \end{proof}
\end{lemma}

\begin{corollary}
  \label{corollary:matched-abstractions}
  If $\Cshape \C \t \sh$, then $\semenv(\cabs \tv \C\where{\cmatch \t \cbrs}) = \semenv(\cabs \tv \C\where{\cmatched \t \sh \cbrs})$.
  Similarly, $\semenv(\cabsr \tv \tvs \C\where{\cmatch \t \cbrs}) = \semenv(\cabsr \tv \tvs \C\where{\cmatched \t \sh \cbrs})$.
  \begin{proof}
    It is sufficient to show that $\semenv\where{\tv \is \gt} \th \C\where{\cmatch \t \cbrs}$ if and only if
    $\semenv \th \C\where{\cmatched \t \sh \cbrs}$.

    \begin{proofcases}
      \proofcase{$\implies$}

	\begin{llproof}
	  \shapePf{\C}{\t}{\sh}{Premise}
	  \vdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatch \t \cbrs}}{Premise}
\Hand 	  \vdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatched \t \sh \cbrs}}{\cref{lem:susp-inversion}}
	\end{llproof}
      \proofcase{$\impliedby$}

	\begin{llproof}
	  \shapePf{\C}{\t}{\sh}{Premise}
	  \vdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatched \t \sh \cbrs}}{Premise}
\Hand 	  \vdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatch \t \cbrs}}{By \Rule{Susp-Ctx}}
	\end{llproof}
    \end{proofcases}

    For $\semenv(\cabsr \tv \tvs \C\where{\cmatch \t \cbrs}) = \semenv(\cabsr \tv \tvs \C\where{\cmatched \t \sh \cbrs})$, the proof is identical.
  \end{proof}
\end{corollary}

\clearpage
\section{Properties of the constraint solver}
\label{app:proofs-solving}

The primary requirement of our constraint solver is correctness:
a constraint $\c$ is satisfiable if and only if the solver terminates with a solution.

This section decomposes this requirement into three properties: preservation,
progress, and termination---and provides proofs for each. Correctness then
follows as a corollary of these results.

\subsection{Preservation}

This section details the proof of \emph{preservation} for the solver: if $\ca
\csolve \cb$, then $\ca \cequiv \cb$.
%
Since rewriting may occur under arbitrary contexts, it suffices to check for
each rule, that the equivalence $\ca \cequiv \cb$ holds under all contexts
$\C$.

However, the introduction of suspended match constraints breaks congruence of
equivalence. That is, it is no longer the case that $\ca \cequiv \cb$ implies
$\C\where\ca \cequiv \C\where\cb$.
%
For instance, we have $\cmatch \tv \cbrs \cequiv \cfalse$, yet
$\C\where{\cmatch \tv \cbrs} \cnequiv \C\where\cfalse$ for $\C \is \square
\cand \cunif \tv \tint$.

As a result, we must prove \emph{contextual equivalence} for each rewriting
rule explicitly. This is both non-trivial and tedious. To simplify the task, we
first present a series of auxiliary lemmas that recover contextual equivalence
for many common cases.
%
Whenever possible, we prefer to work with equivalences on \emph{simple}
constraints, as these retain the desired congruence properties that do not hold
generally in our system.

\begin{definition}[Contextual eqiuvalence]
  Two constraints $\ca$ and $\cb$ are contextually equivalence, written $\ca \cequivctx \cb$,
  iff:
  \begin{mathpar}
    \ca \cequivctx \cb \uad\eqdef\uad \all \C \uad \C\where\ca \cequiv \C\where\cb
  \end{mathpar}
\end{definition}

\begin{corollary}[Simple equivalence is congruent]
  \label{corollary:cong-simple-equiv}
  Given simple constraints $\ca, \cb$ and simple context $\C$. If
  $\ca \cequiv \cb$, then $\C\where\ca \equiv \C\where\cb$.
  \begin{proof}
    Follows from \cref{lem:cong-simple}.
  \end{proof}
\end{corollary}

\begin{lemma}[Simple equivalence is contextual]
  \label{lem:ctxt-equiv-simple}
  For simple constraints $\ca, \cb$. If $\ca \cequiv \cb$, then $\ca \cequivctx \cb$.
  \begin{proof}
    We proceed by induction on the number of suspended match constraints $n$ in $\C$.

    \begin{proofcases}
      \proofcase{$n$ is 0}
	Follows from \cref{corollary:cong-simple-equiv}.

      \proofcase{$n$ is $k + 1$}

	\begin{proofcases}
	  \proofcase{$\implies$}

	  \newcommand{\Ctwo}{\Cb}
	  \begin{llproof}
	    \vdashPf{\semenv}{\C\where{\ca}}{Premise}
	    \VdashPf{\semenv}{\C\where{\ca}}{\cref{thm:canonicalization}}
	    \shapePf\Cp\t\sh{Inversion of \Rule{Can-Susp-Ctx}}
	    \VdashPf{\semenv}{\Cp\where{\cmatched \t \sh \cbrs}}{\ditto}
	    \eqPf{\C\where{\ca}}{\Cp\where{\cmatched \t \sh \cbrs}}{\ditto}
	    \continueeqPf{\Ctwo\where{\cmatched \t \sh \cbrs, \ca}}{For some two-hole context $\Ctwo$}
	    \vdashPf{\semenv}{\Ctwo\where{\cmatched \t \sh \cbrs, \cb}}{By \ih}
	    \ForallPf{\semenvp, \gt}{}{Defn of $\Cshape \Cp \t \sh$}
	    \vdashPf{\semenvp}{\cerase{\Ctwo\where{\t \is \gt, \cb}}}{Premise}
	    \vdashPf{\semenvp}{\cerase{\Ctwo\where{\t \is \gt, \ca}}}{\cref{corollary:cong-simple-equiv}}
	    \vdashPf{\semenvp}{\cerase{\Cp\where{\t \is \gt}}}{Above}
	    \eqPf{\shape \gt}{\sh}{$\implies$E on $\Cshape \Cp \t \sh$}
	    \decolumnizePf
	    \shapePf{\Ctwo\where{\square, \cb}}{\t}{\sh}{Above}
\Hand	    \vdashPf{\semenv}{\Ctwo\where{\cmatch \t \cbrs, \cb}}{By \Rule{Susp-Ctx}}
	  \end{llproof}

	  \proofcase{$\impliedby$}

	  \begin{llproof}
	    Symmetric argument.
	  \end{llproof}
	\end{proofcases}
    \end{proofcases}
  \end{proof}
\end{lemma}

\begin{lemma}[Unification is simple]
  \label{lem:unif-problem-simple}
  For all unification problems $\up$, $\up \simple$.
  \begin{proof}
    By induction on the structure of $\up$.
  \end{proof}
\end{lemma}


\begin{definition}[Context equivalence]
  Two contexts $\Ca$ and $\Cb$ are equivalent with guard $P$, written $\Ca \cctxequiv^P \Cb$ iff:
  \begin{mathpar}
    \Ca \cctxequiv^P \Cb \uad\eqdef\uad \all \cs \uad P(\cs) \implies \Ca\where\cs \cequivctx \Cb\where\cs
  \end{mathpar}
\end{definition}

\begin{definition}[Match-closed]
  A predicate $P$ on constraints is \emph{match-closed} if, for all constraints $\cs, \cs'$, matches $\cmatch \t \cbrs$ and shapes $\sh$,
  \begin{mathpar}
    P(\cs, \cmatch \t \cbrs, \cs') \implies P(\cs, \cmatched \t \sh \cbrs, \cs')
  \end{mathpar}
\end{definition}

\begin{lemma}[Determines is match-closed]
  \label{lem:determines-is-match-closed}
  $\cdetermines \c \tvbs$ is match-closed.
  \begin{proof}
    Follows from the definition of $\cdetermines \c \tvbs$ and \cref{lem:cong-simple}.
  \end{proof}
\end{lemma}


\begin{lemma}[Simple context equivalence]
  \label{lem:simple-ctxt-equiv}
  For any two simple contexts $\Ca, \Cb$ and a match-closed guard $P$. If
  the two contexts $\Ca$ and $\Cb$ are equivalent under any simple constraints satisfying $P$,
  then $\Ca \cctxequiv^P \Cb$.

  \begin{proof}
    Let us assume that ($\dagger$) holds:
    \begin{mathpar}
      \all{\C, \cs \simple} P(\cs) \implies \C\where{\Ca\where\cs} \cequiv \C\where{\Cb\where\cs}
    \end{mathpar}

    We proceed by induction on the number of suspended match constraints $n$ with
    the statement $Q(n) \is  \all {\cs, \C} \cnmatches {\C} + \cnmatches \cs = n \implies P(\cs) \implies
    \C\where{\Ca\where\cs} \equiv \C\where{\Cb\where\cs}$.


    \begin{proofcases}
      \proofcase{$n$ is 0}

	\begin{llproof}
	  \simplePf{\C, \cs}{Premise ($n$ is 0)}
	  \Hand	  \equivPf{P(\cs) \implies \C\where\Ca\where\cs}{\C\where\Cb\where\cs}{$\dagger$}
	\end{llproof}

      \proofcase{$n$ is $k + 1$}

	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{llproof}
	    \Pf{P(\cs)}{}{}{Premise}
	    \vdashPf{\semenv}{\C\where\Ca\where\cs}{Premise}
	    \VdashPf{\semenv}{\C\where\Ca\where\cs}{\cref{thm:canonicalization}}
	    \VdashPf{\semenv}{\Cp\where{\cmatched \t \sh \cbrs}}{Inversion of \Rule{Can-Susp-Ctx}}
	    \shapePf{\Cp}{\t}{\sh}{\ditto}
	    \eqPf{\C\where\Ca\where\cs}{\Cp\where{\cmatch \t \cbrs}}{\ditto}
	    \commentPf{Cases on $\C, \cs$.}{}
	  \end{llproof}

	  \begin{proofcases}
	    \proofcase{$\C$ contains $\Cp$'s hole}

	      \newcommand{\Ctwo}{\Cc}
	      \begin{llproof}
		\eqPf{\C\where\Ca\where\cs}{\Ctwo\where{\cmatch \t \cbrs, \Ca\where\cs}}{For some 2-hole context $\Ctwo$}
		\VdashPf{\semenv}{\Ctwo\where{\cmatched \t \sh \cbrs, \Ca\where\cs}}{}
		\eqPf{k}{\cnmatches {\Ctwo\where{\cmatched \t \sh \cbrs, \Ca\where\cs}}}{}
		\vdashPf{\semenv}{\Ctwo\where{\cmatched \t \sh \cbrs, \Cb\where\cs}}{By \ih}
		\decolumnizePf
		\ForallPf{\semenvp, \gt}{}{}
		\vdashPf{\semenvp}{\cerase{\Ctwo\where{\cunif \t \gt, \Cb\where\cs}}}{Premise}
		\vdashPf{\semenvp}{\cerase{\Ctwo\where{\cunif \t \gt, \Ca\where\cs}}}{$\dagger$}
		\eqPf{\shape \gt}{\sh}{$\implies$E on $\Cshape \Cp \t \sh$}
		\shapePf{\Ctwo\where{\square, \Cb\where\cs}}{\t}{\sh}{Above}
\Hand		\vdashPf{\semenv}{\Ctwo\where{\cmatch \t \cbrs, \Cb\where\cs}}{By \Rule{Susp-Ctx}}
	      \end{llproof}

	    \proofcase{$\ci$ contains $\Cp$'s hole}

	      \begin{llproof}
		Similar argument to the above case, but relies on the match-closure of $P$.
	      \end{llproof}
	  \end{proofcases}


	  \proofcase{$\impliedby$}

	  \begin{llproof}
	    Symmetric argument.
	  \end{llproof}
	\end{proofcases}
    \end{proofcases}
  \end{proof}
\end{lemma}


\begin{lemma}[Simple let equivalence]
  \label{lem:simple-let-equiv}
  Given simple constraints $\ca, \cb$ and a simple context $\C$.
  Suppose that
    \begin{mathpar}
      \forall \semenv, \semenvp, \cs \simple. \uad
	\semenvp(\x) = \semenv(\cabsr \tv \tvs {\C\where\cs}) \implies
	  \semenvp \th \ca \iff \semenvp \th \cb
    \end{mathpar}
  Then, for any context $\Cp$ that does not re-bind $\x$, we have:
    \begin{mathpar}
      \cletr \x \tv \tvs {\C\where{\bar\square}} {\Cp\where\ca}
	\cctxequiv^P \cletr \x \tv \tvs {\C\where{\bar\square}} {\Cp\where\cb}
    \end{mathpar}
  for any match-closed guard $P$ on the holes.

  \begin{proof}
    Let us assume ($\dagger$):
    \begin{mathpar}
      \forall \semenv, \semenvp, \cs. \uad
	\semenvp(\x) = \semenv(\cabsr \tv \tvs {\C\where\cs}) \implies
	  \semenvp \th \ca \iff \semenvp \th \cb
    \end{mathpar}

    We proceed by induction on the number of suspended match constraints in
    $\Cpp, \Cp, \cs$ with the statement $P(n) \is \all {\Cpp, \Cp, \cs} \cnmatches {\Cpp, \Cp, \cs} = n \implies \Cpp\where{\cletr \x \tv \tvs {\C\where\cs} {\Cp\where{\ca}}}
    \cequiv \Cpp\where{\cletr \x \tv \tvs {\C\where\cs} {\Cp\where\cb}}$.

    \begin{proofcases}
      \proofcase{$n$ is 0}

	Thus $\Cpp, \Cp, \cs$ are simple. It suffices to show the equivalence on the $\Let$-constraint directly and use congruence
	of equivalence for simple constraints (\cref{lem:ctxt-equiv-simple}) to establish the result.

	We proceed by induction on the structure of $\Cp$ with the statement ($\ddagger$):
	\begin{mathpar}
	\forall \semenv, \semenvp. \uad
	  \semenvp(\x) = \semenv(\cabsr \tv \tvs {\C\where\cs}) \implies
	    \semenvp \th \Cp\where{\ca} \iff \semenvp \th \Cp\where{\cb}
	\end{mathpar}
	This holds due to the compositionality of simple equivalence using $\dagger$ as a base case.

	\begin{proofcases}
	  \proofcase{$\implies$}

	\begin{llproof}
	  \vdashPf{\semenv}{\cletr \x \tv \tvs {\C\where{\cs}} {\Cp\where{\ca}}}{Premise}
	  \vdashPf{\semenv}{\cexists {\tv, \tvs} \C\where{\cs}}{Simple inversion}
	  \vdashPf{\semenv\where{\x \is \semenv(\cabsr \tv \tvs \C\where{\cs})}}{\Cp\where{\ca}}{\ditto}
	  \vdashPf{\semenv\where{\x \is \semenv(\cabsr \tv \tvs \C\where{\cs})}}{\Cp\where{\cb}}{$\ddagger$}
	  \vdashPf{\semenv}{\cletr \x \tv \tvs {\C\where{\cs}} {\Cp\where{\cb}}}{By \Rule{LetR}}
	\end{llproof}
	  \proofcase{$\impliedby$}

	  \begin{llproof}
	    Symmetric argument.
	  \end{llproof}
	\end{proofcases}

      \proofcase{$n$ is $k + 1$}

      \begin{llproof}
	Analogous to the inductive step in \cref{lem:simple-ctxt-equiv}.
      \end{llproof}
    \end{proofcases}
  \end{proof}
\end{lemma}

\newcommand{\disjointPf}[3]{\Pf{#1}{\disjoint}{#2}{#3}}
\begin{lemma}
  \label{lem:unicity-match-var}
  If $\cunif \tv {\cunif \t \ueq} \in \C$ and $\t \notin \TyVars$, then
  $\Cshape \C \tv {~\shape \t}$.
  \begin{proof}~

    \begin{llproof}
      \inPf{\cunif \tv {\cunif \t \ueq}}{\C}{Premise}
      \notinPf{\t}{\TyVars}{Premise}
      \eqPf{\t}{\shapp[\shape \t] \tys}{For some $\tys$}
      \eqPf{\C}{\Ca\where{\cunif \tv {\cunif \t \ueq} \cand \Cb}}{By definition}
      \disjointPf{\fvs {\tv, \t, \ueq}}{\bvs \Cb}{\ditto}
      \ForallPf{\semenv, \gt}{}{Defn. of $\Cshape \C \tv {~\shape \t}$}
      \vdashPf{\semenv}{\cerase{\Ca\where{\cunif \tv {\cunif {\shapp[\shape \t] \tys} \ueq} \cand \Cb\where{\cunif \tv \gt}}}}{Premise}
      \vdashPf{\semenva}{\cunif \tv {\cunif {\shapp[\shape \t] \tys} \ueq}}{Inversion of $\Ca$}
      \vdashPf{\semenvb}{\cunif \tv \gt}{Inversion of $\Cb$}
      \eqPf{\gt}{\semenvb(\tv)}{Simple inversion}
      \continueeqPf{\semenva(\tv)}{$\tv \disjoint \bvs \Cb$}
      \continueeqPf{\shapp[\shape \t] {\semenva(\tys)}}{Simple inversion}
\Hand \eqPf{\shape \gt}{\shape \t}{Applying shape to both sides}
    \end{llproof}
  \end{proof}
\end{lemma}

\begin{lemma}
  \label{lem:unicity-back-prop}
  If $\cunif {\tvc} {\cunif \t \ueq} \in \C\where\Cb$ and $\t \notin \TyVars$,
  then
  \begin{mathpar}
    \Cshape {\C\where
       {\cletr \x \tv {\tvs} {\Ca\where{\square}}
			     {\Cb\where{\cpapp \x \tvp \tvc \inst}}}}
      \tvp
      {~\shape \t}
  \end{mathpar}
  \begin{proof}
    Similar proof to \cref{lem:unicity-match-var}.
  \end{proof}
\end{lemma}


\begin{lemma}[Unification preservation]
  \label{lem:unification-preservation}
  If $\upa \unif \upb$, then $\upa \equiv \upb$
  \begin{proof}
    By induction on the given derivation $\upa \unif \upb$.
    See \citet*{Pottier-Remy/emlti} for more details.
  \end{proof}
\end{lemma}

\preservation
\newcommand{\unifPf}[3]{\Pf{#1}{\unif}{#2}{#3}}
\newcommand{\equivctxPf}[3]{\Pf{#1}{\cequivctx}{#2}{#3}}
\newcommand{\ctxequivPf}[3]{\Pf{#1}{\cctxequiv}{#2}{#3}}
\begin{proof}
  We proceed by induction on the given derivation.
  It suffices to show that for each individual rule $R$ ($\ca \csolve_R \cb$),
  that $\ca \cequivctx \cb$.

  \begin{proofcases}
    \proofcaserewrite
      {S-Unif}
      {\upa \\ \upa \unif \upb}
      {\upb}

	\begin{llproof}
	  \unifPf{\upa}{\upb}{Premise}
	  \equivPf{\upa}{\upb}{\cref{lem:unification-preservation}}
	  \simplePf{\upa, \upb}{\cref{lem:unif-problem-simple}}
\Hand 	  \equivctxPf{\upa}{\upb}{\cref{lem:ctxt-equiv-simple}}
	\end{llproof}

    \proofcaserewrite
      {S-Exists-Conj}
      {\parens {\cexists \tv \ca} \cand \cb \\ \tv \disjoint \cb}
      {\cexists \tv \ca \cand \cb}

	\begin{llproof}
	  \disjointPf{\tv}{\cb}{Premise}
	  \decolumnizePf
	  \sufficientPf{equivalence for simple constraints}{}{\cref{lem:simple-ctxt-equiv}}
	  \supposePf{\ca, \cb \simple} {Premise}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\parens {\cexists \tv \ca} \cand \cb}{Premise}
	    \vdashPf{\semenv\where{\tv \is \gt}}{\ca}{Simple inversion}
	    \vdashPf{\semenv}{\cb}{Simple inversion}
	    \vdashPf{\semenv\where{\tv \is \gt}}{\cb}{$\tv \disjoint \cb$}
	    \vdashPf{\semenv\where{\tv \is \gt}}{\ca \cand \cb}{By \Rule{Conj}}
\Hand       \vdashPf{\semenv}{\cexists \tv \ca \cand \cb}{By \Rule{Exists}}
	  \end{llproof}
	  \proofcase{$\impliedby$}

	    \begin{llproof}
	    Symmetric argument.
	    \end{llproof}
	\end{proofcases}


      \proofcase{\Rule{S-Let}, \Rule{S-True}, \Rule{S-False},
      \Rule{S-Let-ExistsLeft},
      \Rule{S-Let-Exists-InstLeft}, \Rule{S-Let-ExistsRight},
      \Rule{S-Let-Exists-InstRight}, \Rule{S-Let-ConjLeft},
      \Rule{S-Let-ConjRight}, \Rule{S-Inst-Name}, \Rule{S-Exists-Exists-Inst},
      \Rule{S-Exists-Inst-Conj}, \Rule{S-Exists-Inst-Let}, \Rule{S-Exists-Inst-Solve},
      \Rule{S-All-Conj}}

      \begin{llproof}
	Similar argument to the \Rule{S-Exists-Conj} case.
      \end{llproof}

    \proofcaserewrite
      {S-Match-Type}
      {\cmatch \t \cbrs \\ \t \notin \TyVars}
      {\cmatched \t {\shape \t} \cbrs}

	\begin{llproof}
	    \notinPf{\t}{\TyVars}{Premise}
	    \shapePf{\square}{\t}{~\shape \t}{By definition}
	    \sufficientPf{equivalences between constraints}{}{\cref{lem:compose-unicity}}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\cmatch \t \cbrs}{Premise}
\Hand 	    \vdashPf{\semenv}{\cmatched \t {\shape \t} \cbrs}{\cref{lem:susp-inversion}}
	  \end{llproof}

	  \proofcase{$\impliedby$}

	  \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\cmatched \t {\shape \t} \cbrs}{Premise}
\Hand 	    \vdashPf{\semenv}{\cmatch \t \cbrs}{By \Rule{Susp-Ctx}}
	  \end{llproof}
	\end{proofcases}

    \proofcaserewrite
      {S-Match-Var}
      {\C\where{\cmatch \tv \cbrs} \\ \cunif \tv {\cunif \t \ueq} \in \C}
      {\C\where{\cmatched \tv {\shape \t} \cbrs}}

	\begin{llproof}
	  \inPf{\cunif \tv {\cunif \t \ueq}}{\C}{Premise}
	  \shapePf{\C}{\tv}{~ \shape \t}{\cref{lem:unicity-match-var}}
	  \sufficientPf{equivalences between constraints}{}{\cref{lem:compose-unicity}}
	\end{llproof}

	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\C\where{\cmatch \tv \cbrs}}{Premise}
\Hand 	    \vdashPf{\semenv}{\C\where{\cmatched \tv {\shape \t} \cbrs}}{\cref{lem:susp-inversion}}
	  \end{llproof}

	  \proofcase{$\impliedby$}

	  \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\C\where{\cmatched \tv {\shape \t} \cbrs}}{Premise}
\Hand 	    \vdashPf{\semenv}{\C\where{\cmatch \tv \cbrs}}{By \Rule{Susp-Ctx}}
	  \end{llproof}
	\end{proofcases}


    \proofcaserewrite
      {S-Let-AppR}
      {\cletr \x \tv \tvs \ca {\C\where{\capp \x \t}} \\ \tvc \disjoint \t \\ \x \disjoint \bvs \C}
      {\cletr \x \tv \tvs \ca {\C\where{\cexistsi {\tvc, \inst} \x \cunif \tvc \t \cand \cpinst \inst \tv \tvc }}}


	\begin{llproof}
	  \disjointPf{\tvc}{\t}{Premise}
	  \disjointPf{\x}{\bvs \C}{Premise}
	  \decolumnizePf
	  \sufficientPf{equivalence between}{\capp \x \t \text{ and } \cexistsi {\tvc, \inst} \x \cunif \tvc \t \cand \cpinst \inst \tv \tvc}{\cref{lem:simple-let-equiv}}
	  \supposePf{\semenvp(\x) = \semenv(\cabsr \tv \tvs \ca)}{Premise}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\implies$}

	    \begin{llproof}
	      \vdashPf{\semenvp}{\capp \x \t}{Premise}
	      \inPf{\greg \tv {\semenva}}{\semenv(\x)}{Simple inversion}
	      \eqPf{\semenva(\tv)}{\semenvp(\t)}{\ditto}
	      \vdashPf{\semenvp\where{\tvc \is \semenvp(\t), \inst \is \semenva}}{\cpinst \inst \tv \tvc}{By \Rule{Partial-Inst}}
	      \vdashPf{\semenvp\where{\tvc \is \semenvp(\t), \inst \is \semenva}}{\cunif \tvc \t}{By \Rule{Unif}}
\Hand	      \vdashPf{\semenvp}{\cexistsi {\tvc, \inst} \x {\cunif \tvc \t \cand \cpinst \inst \tv \tvc}}{By \Rule{Exists}, \Rule{Exists-Inst} and \Rule{Conj}}
	    \end{llproof}

	  \proofcase{$\impliedby$}

	    \begin{llproof}
	      Symmetric argument.
	    \end{llproof}
	\end{proofcases}

    \proofcaserewrite
      {S-Inst-Copy}
      {\cletr \x \tv \tvs {\c}
	\C\where{\cpapp \x \tvp \tvc \inst}\\
	\c = \cp \cand \cunif \tvp {\cunif {\shapp \tvbs} \ueq}\\
	\tvp \in \reg \tv \tvs \\
	\neg \cyclic {\c} \\
	\tvbs' \disjoint \tvp, \tvc, \tvbs \\
       \x \disjoint \bvs \C}
      {\cletr \x \tv \tvs {\c}
	\C\where{\cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}}


	\begin{llproof}
	  \disjointPf{\x}{\bvs \C}{Premise}
	  \disjointPf{\tvbs'}{\tvp, \tvc, \tvbs}{Premise}
	  \decolumnizePf
	  \sufficientPf{equivalence between}{\cpapp \x \tvp \tvc \inst \text{ and } \cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}{\cref{lem:simple-let-equiv}}
	  \supposePf{\semenvp(\x) = \semenv(\cabsr \tv {\tvs} \c)}{Premise}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\implies$}

	    \begin{llproof}
	      \vdashPf{\semenvp} {\cpapp \x \tvp \tvc \inst}{Premise}
	      \inPf{\greg \tv \semenva}{\semenv(\x)}{$\cexistsi \inst \x \in \C$}
	      \eqPf{\semenvp(\inst)}{\semenva}{\ditto}
	      \eqPf{\semenvp(\tvc)}{\semenv(\inst)(\tvp)}{Simple inversion}
	      \continueeqPf{\semenva(\tvp)}{Above}
	      \vdashPf{\semenva}{\cp \cand \cunif \tvp {\cunif {\shapp \tvbs} \ueq}}{Above}
	      \vdashPf{\semenva}{\cunif \tvp {\cunif {\shapp \tvbs} \ueq}}{Simple inversion}
	      \eqPf{\semenva(\tvp)}{\shapp {\semenva(\tvbs)}}{\ditto}
	      \eqPf{\semenvp(\tvc)}{\shapp {\semenva(\tvbs)}}{Above}
	      \vdashPf{\semenvp\where{\tvbs' \is \semenva(\tvbs)}}{\cunif \tvc {\shapp {\tvbs'}}}{By \Rule{Unif}}
	      \vdashPf{\semenvp\where{\tvbs' \is \semenva(\tvbs)}}{\cpapp \x \tvbs {\tvbs'} \inst}{By \Rule{Partial-Inst}}
\Hand 	      \vdashPf{\semenvp}{\cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}{By \Rule{Exists} and \Rule{Conj}}
	    \end{llproof}

	  \proofcase{$\impliedby$}

	    \begin{llproof}
	      Symmetric argument.
	    \end{llproof}
	\end{proofcases}

    \proofcaserewrite
      {S-Inst-Unif}
      {\cpinst \inst \tv \tvca \cand \cpinst \inst \tv \tvcb}
      {\cpinst \inst \tv \tvca \cand \cunif \tvca \tvcb}

      \begin{llproof}

	\sufficientPf{equivalence between}{{\cpinst \inst \tv \tvca \cand
	\cpinst \inst \tv \tvcb} \text{ and } {\cpinst \inst \tv \tvca \cand
	\cunif \tvca \tvcb} }{\cref{lem:simple-ctxt-equiv}}

      \end{llproof}

      \begin{proofcases}
	\proofcase{$\implies$}

	  \begin{llproof}
	    \vdashPf{\semenv}{\cpinst \inst \tv \tvca \cand \cpinst \inst \tv \tvcb}{Premise}
	    \vdashPf{\semenv}{\cpinst \inst \tv \tvca}{Simple inversion}
	    \vdashPf{\semenv}{\cpinst \inst \tv \tvcb}{\ditto}
	    \eqPf{\semenv(\tvca)}{\semenv(\inst)(\tv)}{\ditto}
	    \eqPf{\semenv(\tvcb)}{\semenv(\inst)(\tv)}{\ditto}
	    \eqPf{\semenv(\tvca)}{\semenv(\tvcb)}{Above}
	    \vdashPf{\semenv}{\cunif \tvca \tvcb}{By \Rule{Unif}}
\Hand	    \vdashPf{\semenv}{\cpinst \inst \tv \tvca \cand \cunif \tvca \tvcb}{By \Rule{Conj}}
	  \end{llproof}

	\proofcase{$\impliedby$}

	  \begin{llproof}
	    Symmetric argument.
	  \end{llproof}
      \end{proofcases}

    \proofcaserewrite
      {S-Inst-Poly}
      {\cletr \x \tv {\tvs} {\ueqs \cand \c} {\C\where{\cpapp \x \tvp \tvc \inst}} \\
       \cfor \tvp \cexists {\tv, \tvs} {\ueqs} \cequiv \ctrue \\
       \tvp \in \reg \tv \tvs \\
       \tvp \disjoint \c \\
       \inst.\tvp \disjoint \insts \C \\
       \x \disjoint \bvs \C}
      {\cletr \x \tv {\tvs} {\ueqs \cand \c} {\C\where\ctrue}}


	\begin{llproof}
	  \equivPf{\cfor \tvp \cexists {\tv, \tvs} \ueqs}{\ctrue}{Premise}
	  \disjointPf{\tvp}{\c}{Premise}
	  \disjointPf{\inst.\tvp}{\insts \C}{Premise}
	  \disjointPf{\x}{\bvs \C}{Premise}
	  \decolumnizePf
	  \sufficientPf{equivalence between}
	    {\cpapp \x \tvp \tvc \inst \text{ and } \ctrue}
	    {\cref{lem:simple-let-equiv}}
	  \supposePf{\semenvp(\x) = \semenv(\cabsr \tv {\tvs, \tvp} \ueqs \cand \c)}{Premise}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\implies$}

	    \begin{llproof}
	      \vdashPf{\semenvp}{\cpapp \x \tvp \tvc \inst}{Premise}
\Hand	      \vdashPf{\semenvp}{\ctrue}{By \Rule{True}}
	    \end{llproof}

	  \proofcase{$\impliedby$}

	    \begin{llproof}
	      \vdashPf{\semenvp}{\ctrue}{Premise}
	      \inPf{\greg \tv {\semenva}}{\semenvp(\x)}{$\C = \Ca\where{\cexistsi \inst \x \Cb}$}
	      \eqPf{\semenvp(\inst)}{\semenva}{\ditto}
	      \casesPf{\semenva(\tvp)}
	    \end{llproof}
	    \begin{proofcases}
	      \proofcase{$\semenva(\tvp) = \semenvp(\tvc)$}

		\begin{llproof}
		  \eqPf{\semenva(\tvp)}{\semenvp(\tvc)}{Premise}
\Hand		  \vdashPf{\semenvp}{\cpapp \x \tvp \tvc \inst}{By \Rule{Partial-Inst}}
		\end{llproof}


	      \proofcase{$\semenva(\tvp) \neq \semenvp(\tvc)$}

		\begin{llproof}
		  \LetPf{\semenvb}{\semenva\where{\tvp \is \semenvp(\tvc)}}{}
		  \vdashPf{\semenva}{\ueqs \cand \c}{By definition}
		  \vdashPf{\semenva}{\ueqs}{Simple inversion}
		  \vdashPf{\semenvb}{\ueqs}{$\tvp$ is polymorphic}
		  \vdashPf{\semenvb}{\c}{$\tvp \disjoint \c$}
		  \vdashPf{\semenvb}{\ueqs \cand \c}{By \Rule{Conj}}
		  \inPf{\greg \tv \semenvb}{\semenv(\x)}{By definition}
		  \supposePf{\semenvc \th \Cb\where\ctrue}{Considering entailment on $\cexistsi \inst \x$}
		  \eqPf{\semenvc(\inst)}{\semenva}{\ditto}
		  \vdashPf{\semenvc\where{\inst \is \semenvb}}{\Cb\where\ctrue}{$\inst.\tvp \disjoint \insts \Cb$}
		  \vdashPf{\deriv :: \semenvc}{\Cb\where\ctrue}{By \Rule{Exists-Inst}}
		  \commentPf{$\deriv$ is a derivation that satisfies $\semenva(\tvp) = \semenvp(\tvc)$.}{}
\Hand		  \commentPf{So this case degenerates to the former case.}{}
		\end{llproof}
	    \end{proofcases}
	\end{proofcases}

    \proofcaserewrite
      {S-Inst-Mono}
      {\cletr \x \tv \tvs \c {\C\where{\cpapp \x \tvb \tvc \inst}} \\
       \tvb \notin \reg \tv \tvs \\
       \x, \tvb \disjoint \bvs \C}
      {\cletr \x \tv \tvs \c {\C\where{\cunif \tvb \tvc}}}

	\begin{llproof}
	  \disjointPf{\tvb}{\tv, \tvs}{Premise}
	  \disjointPf{\x, \tvb}{\bvs \C}{Premise}
	  \decolumnizePf
	  \sufficientPf{equivalence between}
	    {\cpapp \x \tvb \tvc \inst \text{ and } \cunif \tvb \tvc}
	    {\cref{lem:simple-let-equiv}}
	  \supposePf{\semenvp(\x) = \semenv(\cabsr \tv {\tvs} \c)}{Premise}
	\end{llproof}

	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{llproof}
	    \vdashPf{\semenvp}{\cpapp \x \tvb \tvc \inst}{Premise}
	    \inPf{\greg \tv \semenva}{\semenv(\c)}{$\cexistsi \inst \x \in \C$}
	    \eqPf{\semenvp(\inst)}{\semenva}{\ditto}
	    \eqPf{\semenvp(\tvc)}{\semenva(\tvb)}{Simple inversion}
	    \eqPf{\semenva(\tvb)}{\semenv(\tvb)}{$\tvb \disjoint \tv, \tvs$}
	    \eqPf{\semenvp(\tvb)}{\semenv(\tvb)}{$\tvb \disjoint \bvs \C$}
	    \eqPf{\semenvp(\tvc)}{\semenvp(\tvb)}{Above}
	    \vdashPf{\semenvp}{\cunif \tvc \tvb}{By \Rule{Unif}}
	  \end{llproof}

	  \proofcase{$\impliedby$}

	  \begin{llproof}
	    Symmetric argument.
	  \end{llproof}
	\end{proofcases}


    \proofcaserewrite
      {S-Let-Solve}
      {\cletr \x \tv \tvs \ueqs \c \\ \x \disjoint \c \\
       \cexists {\tv, \tvs} \ueqs \cequiv \ctrue}
      {\c}
	\begin{llproof}
	  \disjointPf{\x}{\c}{Premise}
	  \equivPf{\cexists {\tv, \tvs} \ueqs}{\ctrue}{}
	  \decolumnizePf
	  \sufficientPf{equivalence for simple constraints}{}{\cref{lem:simple-ctxt-equiv}}
	  \supposePf{\c \simple} {Premise}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\cletr \x \tv \tvs \ueqs \c}{Premise}
	    \vdashPf{\semenv}{\cexists {\tv, \tvs} \ueqs}{Simple inversion}
	    \vdashPf{\semenv\where{\x \is \semenv(\cabsr \tv \tvs \ueqs)}}{\c}{\ditto}
\Hand	    \vdashPf{\semenv}{\c}{$\x \disjoint \c$}
	  \end{llproof}
	  \proofcase{$\impliedby$}

	    \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\c}{Premise}
	    \vdashPf{\semenv\where{\x \is \semenv(\cabsr \tv \tvs \ueqs)}}{\c}{$\x \disjoint \c$}
	    \vdashPf{\semenv}{\cexists {\tv, \tvs} \ueqs}{}
\Hand	    \vdashPf{\semenv}{\cletr \x \tv \tvs \ueqs \c}{By \Rule{LetR}}
	    \end{llproof}
	\end{proofcases}

  \proofcaserewrite{S-Exists-Lower}
    {\cletr \x \tv {\tvas, \tvbs} \ca \cb \\
     \cdetermines {\cexists {\tv, \tvas} \ca} \tvbs \\
     }
    {\cexists \tvbs \cletr \x \tv \tvas \ca \cb}

    \begin{llproof}
      \Pf{}{}{\cdetermines {\cexists {\tv, \tvas} \ca} \tvbs}{Premise}
      \sufficientPf{equivalence for simple constraints}{}{\cref{lem:simple-ctxt-equiv} and \cref{lem:determines-is-match-closed}}
      \supposePf{\ca, \cb \simple}{Premise}
    \end{llproof}
    \begin{proofcases}
      \proofcase{$\implies$}

      \begin{llproof}
	\vdashPf{\semenv}{\cletr \x \tv {\tvas, \tvbs} \ca \cb}{Premise}
	\vdashPf{\semenv}{\cexists {\tv, \tvas, \tvbs} \ca}{Simple inversion}
	\vdashPf{\semenv\where{\x \is \semenv(\cabsr \tv {\tvs, \tvbs} \ca)}}{\cb}{\ditto}
	\vdashPf{\semenv\where{\tv \is \gt, \tvas \is \gts, \tvbs \is \bar\gtp}}{\ca}{\ditto}
	\vdashPf{\semenv\where{\tvbs \is \bar\gtp}}{\cexists {\tv, \tvas} \ca}{By \Rule{Exists}}
	\sufficientPf{}{\semenv\where{\x \is \semenv(\cabsr \tv {\tvs, \tvbs} \ca)} = \semenv\where{\tvbs \is \bar\gt'}(\cabsr \tv \tvs \ca)}{}
      \end{llproof}
      \begin{proofcases}

      \proofcase{$\implies$}

	\begin{llproof}
	  \vdashPf{\semenv\where{\tv \is \gta, \tvs \is \bar\gta, \tvbs \is \bar\gtb}}{\ca}{Premise}
	  \vdashPf{\semenv\where{\tvbs \is \bar\gtb}}{\cexists {\tv, \tvs} \ca}{By \Rule{Exists}}
	  \eqPf{\bar\gtb}{\bar\gtp}{By definition of determines}
\Hand	  \vdashPf{\semenv\where{\tvbs \is \bar\gtp, \tv \is \gta, \tvs \is \bar\gta}}{\ca}{Above}

	\end{llproof}

      \proofcase{$\impliedby$}

      \begin{llproof}
	Symmetric argument.
      \end{llproof}


      \end{proofcases}



      \proofcase{$\impliedby$}

      \begin{llproof}
	Symmetric argument.
      \end{llproof}

    \end{proofcases}


  \proofcaserewrite
    {S-BackProp}
    {\C\where
       {\cletr \x \tv {\tvs} {\Ca\where{\cmatch \tvp \cbrs}}
                           {\Cb\where{\cpapp \x \tvp \tvc \inst}}} \\
    \tvp \in \reg \tv \tvs \\
     \cunif {\tvc} {\cunif \t \ueq} \in \C\where\Cb \\
     \x \disjoint \bvs \Cb}
    {\C\where{\cletr \x \tv {\tvs} {\Ca\where{\cmatched \tvp {\shape \t} \cbrs}}
		      {\Cb\where{\cpapp \x \tvp \tvc \inst}}}}


    \begin{llproof}
      Similar argument to \Rule{S-Match-Var}, using \cref{lem:unicity-back-prop}.
    \end{llproof}

  \proofcase{\Rule{S-Compress}, \Rule{S-Gc}, \Rule{S-Exists-All}, \Rule{S-All-Escape}, \Rule{S-All-Rigid}, \Rule{S-All-Solve}}

  \begin{llproof}
    Similar argument. Use \cref{lem:simple-ctxt-equiv}.
    The simple equivalences are standard, see \citet*{Pottier-Remy/emlti}.
  \end{llproof}
  \end{proofcases}
\end{proof}

\subsection{Progress}

\begin{lemma}[Unification progress]
  If unification problem $\up$ cannot take a step $\up \unif \upp$, then either:
  \begin{enumerate}[(\roman*)]
    \item $\up$ is solved.
    \item $\up$ is $\cfalse$.
    \end{enumerate}
  \begin{proof}
    This is a standard result. See \citet*{Pottier-Remy/emlti}.
  \end{proof}
\end{lemma}


\progress
\begin{proof}
  We proceed by induction on the structure of $\c$. We
  focus on suspended match constraints, conjunctions, and $\Let$ rules.
  \begin{proofcases}
    \proofcase{$\cmatch \t \cbrs$}
      We have two cases:
      \begin{proofcases}
	\proofcase{$\t$ is a non-variable type} Apply \Rule{S-Match-Type}.
	\proofcase{$\t$ is a type variable $\tv$}

	  We have $\nCshape \square \tv$. It suffices
	  that every match constraint in a context-reachable position
	  $\hat\C\where{\cmatch \tvp \cbrs}$ satisfies $\nCshape {\hat\C} \tvp$.
	  By the definition of constraint contexts, there is only one such
	  $\hat\C$, namely $\square$, for which we already have $\nCshape \square \tv$.
	  Hence $\cmatch \t \cbrs$ is stuck.
      \end{proofcases}

    \proofcase{$\ca \cand \cb$}
    We begin by inducting on $\ca$ and $\cb$. Then we consider cases:
    \begin{proofcases}
      \proofcase{$\ca$ (or $\cb$) take a step} Apply congruence rewriting rule.
      \proofcase{$\ca$ (or $\cb$) is $\ctrue$} Apply \Rule{S-True}.
      \proofcase{$\ca$ (or $\cb$) is $\cfalse$} Apply \Rule{S-False}.
      \proofcase{$\ca$ (or $\cb$) begins with $\exists$} Apply \Rule{S-Exists-Conj}.
      \proofcase{$\ca, \cb$ are solved}

	We either apply the above $\exists$ case, or both $\ca$ and $\cb$ are solved
	multi-equations $\ueqs_1, \ueqs_2$. We perform cases on this:
	\begin{proofcases}
	  \proofcase{$\ueqs_1$ and $\ueqs_2$ are mergable} Apply \Rule{U-Merge}.
	  \proofcase{$\cyclic {\ueqs_1, \ueqs_2}$} Apply \Rule{U-Cycle}.
	  \proofcase{Otherwise} The conjunction $\ueqs_1 \cand \ueqs_2$ is solved.
	\end{proofcases}

      \proofcase{$\ca$ and $\cb$ are stuck (and not $\cfalse$)}

	\Wlog, consider cases $\ca$.
	\begin{proofcases}
	  \proofcase{$\hat\Ca\where{\capp \x \t}$}
	    We have $\x \disjoint \bvs {\hat\Ca}$.

	    $\hat\Ca\where{\capp \x \t} \cand \cb$ is stuck as we do not bind $\x$ in $\hat\Ca \cand \cb$.
	  \proofcase{$\hat\Ca\where{\cpapp \x \tv \tvc \inst}$}
	    We have $\x \disjoint \bvs {\hat \Ca}$ and $\inst.\tv \disjoint \insts {\hat \Ca}$.

	    If $\inst.\tv \in \insts \cb$ and $\inst \disjoint \bvs {\hat\ca}$, then apply \Rule{S-Inst-Unify}.
	    It must be the case that we can apply \Rule{S-Inst-Unify}, otherwise, we could lift these instantiation
	    constraints using \Rule{S-Exists-Lower} and \Rule{S-Let-ConjLeft}, contradicting that $\hat\Ca$ is stuck.

	    Otherwise, $\x \disjoint \bvs {\hat \Ca \cand \cb}$, thus $\hat\Ca\where{\cpapp \x \tv \tvc \inst}$ is stuck.

	  \proofcase{$\hat\Ca\where{\cmatch \tvp \cbrs}$}
	    We have $\nCshape \Ca \tvp$.

	    Consider a match constraint $\cmatch \tvp \cbrs$ in $\ca$.

	    If $\cunif \tvp {\cunif \t \ueq} \in \cb$ and $\t \notin \TyVars$. By the above logic, it must be at the root (otherwise $\cb$
	    is not stuck). So we have $\cunif \tvp {\cunif \t \ueq} \in \hat \Ca \cand \cb$. Thus we can apply \Rule{S-Match-Type}.

	    If $\cunif \tvc {\cunif \t \ueq} \in \cb$, $\t \notin \TyVars$, and $\hat\Ca$ contains $\cletr \x \tv \tvs {\hat\Cc\where{\cmatch \tvp \cbrs}} {\hat\C_4\where{\cpapp \x \tvp \tvc \inst}}$.
	    Apply \Rule{S-BackProp}.

	    Otherwise, we are stuck and $\nCshape {(\Ca \cand \cb)} \tvp$.
	\end{proofcases}

    \end{proofcases}

    \proofcase{$\cletr \x \tv \tvs \ca \cb$}
    We begin by inducting on $\ca$ and $\cb$. Then we consider cases:
    \begin{proofcases}
      \proofcase{$\ca$ (or $\cb$) take a step} Apply congruence rewriting rule.
      \proofcase{$\ca$ (or $\cb$) is $\cfalse$} Apply \Rule{S-False}.
      \proofcase{$\ca$ begins with $\exists$} Apply \Rule{S-Let-ExistsLeft}
      \proofcase{$\cb$ begins with $\exists$} Apply \Rule{S-Let-ExistsRight}
      \proofcase{$\cb$ begins with $\cand$ with $\x \disjoint$ from conjunct} Apply \Rule{S-Let-ConjRight}.
      \proofcase{$\ca$ begins with $\cand$ with $\tv, \tvs \disjoint$ from conjunct } Try apply \Rule{S-Let-ConjLeft}
      \proofcase{$\cb$ begins with $\cexistsi \inst \xp {}$, $\x \neq \xp$} Apply \Rule{S-Exists-Inst-Let}
      \proofcase{$\tvp \in \tvs$ is determined by $\ca$} Apply \Rule{S-Exists-Lower}
      \proofcase{$\cb$ is solved}

	Thus $\cb$ must be $\ctrue$ (due to above cases).
	\begin{proofcases}
	  \proofcase{$\ca$ is solved}
	    Thus $\ca$ must be $\ueqs$.

	    There are two cases:
	    \begin{itemize}
	      \proofcase{$\cexists {\tv, \tvs} \ueqs \cequiv \ctrue$} Apply \Rule{S-Let-Solve}.
	      \proofcase{$\cexists {\tv, \tvs} \ueqs \cnequiv \ctrue$} It must be the case there is some $\tvb$ that dominates a $\tvp$ in $\tv, \tvs$ in $\ueqs$.
		Hence $\cdetermines {\cexists {\tv, \tvs \setminus \tvp} \ueqs} \tvp$.
		So we can apply \Rule{S-Exists-Lower}.
	    \end{itemize}

	  \proofcase{$\ca$ is stuck}

	    The constraint $\cletr \x \tv \tvs \ca \cb$ remains stuck, since
	    no additional term variable bindings occur for the scope of $\ca$,
	    ruling out the instantiation cases. Additionally, we cannot apply
	    backpropagation since $\cb$ is $\ctrue$.
	\end{proofcases}

      \proofcase{$\cb$ is stuck}
	\begin{proofcases}
	  \proofcase{$\hat\C\where{\capp \x \t}$} We have $\x \disjoint \bvs {\hat\C}$.

	  Apply \Rule{S-Let-AppR}.

	  \proofcase{$\hat\C\where{\cpapp \x \tvp \tvc \inst}$} We have $\x \disjoint \bvs {\hat\C}$ or $\inst.\tvp \disjoint \insts {\hat\C}$.
	    \begin{itemize}
		\proofcase{$\tvp \in \reg \tv \tvs$}

		We can either apply \Rule{S-Inst-Copy} or \Rule{S-Compress}
		if a multi-equation involving $\tvp$ occurs in $\ca$.

		Otherwise, we consider cases where $\ca$ is solved or stuck.

		If $\ca$ is solved, then it must be of the form $\ueqs$.
		There are two cases:
		\begin{itemize}
		  \proofcase{$\cexists {\tv, \tvs} \ueqs \cequiv \ctrue$}
		  As $\tvp$ does not appear in the head position of any multi-equation in $\ueqs$,
		  it must be polymorphic. Thus $\cfor \tvp {\cexists {\tv, \tvs \setminus \tvp} \ueqs} \cequiv \ctrue$.
		  So we can apply \Rule{S-Inst-Poly}.

		  \proofcase{$\cexists {\tv, \tvs} \ueqs \cnequiv \ctrue$}
		  Apply \Rule{S-Lower-Exists} (using the same logic as above).

		\end{itemize}

		If $\ca$ is stuck, then neither case regarding instantiations
		in $\ca$ is fixed, so in these cases the constraint remains
		stuck. If $\ca$ is stuck with $\hat\Cp\where{\cmatch \tvb
		\cbrs'}$. Then either backpropagation (\Rule{S-BackProp})
		applies with an equation in $\hat\C$, or the entire constraint
		is stuck.

		\proofcase{$\tvp \notin \reg \tv \tvs$} Apply \Rule{S-Inst-Mono}.




	    \end{itemize}

	  \proofcase{For any $\hat\C\where{\cmatch \tvp \cbrs}$} We have $\nCshape {\hat\C} \tvp$.

	  Either $\cletr \x \tv \tvs \ca \cb$ can progress with an instantiation constraint (in the above case) to discharge
	  the match constraint or $\cletr \x \tv \tvs \ca \cb$ is stuck.
	\end{proofcases}

    \end{proofcases}


  \end{proofcases}
\end{proof}

\subsection{Termination}

This section presents a proof of termination for our solver.
%
Most rewrite rules, in both unification and constraint solving, are
\emph{destructive}---that is, they eliminate or modify the structure of a
constraint in a way that prevents the rule from begin applied again.
%
Consequently, to establish termination, it suffices to consider only those
rules that are not inherently destructive.

\begin{lemma}[Unification termination]
  \label{lem:unification-termination}
  The unifier terminates on all inputs.
  \begin{proof}
    \newcommand{\sw}[1]{\mathprefix{sw}{(#1)}}
    \newcommand{\iw}[1]{\mathprefix{iw}{(#1)}}
    \newcommand{\tw}[1]{\mathprefix{tw}{(#1)}}
    \newcommand{\uw}[1]{\mathprefix{uw}{(#1)}}

    Let every shape $\sh$ have an integer \emph{weight}
    defined by $\sw \sh \eqdef 4 + 2 \times |\sh|$, where $|\sh|$ is the
    arity of the shape $\sh$.
    %
    The weight of a type $\tw \t$ is defined by:
    \begin{mathpar}
      \begin{tabular}{RCL}
	\tw \tv &\eqdef& 1\\
	\tw {\shapp \tys} &\eqdef& \iw {\shapp \tys} - 2\\[1ex]
	\iw \tv &\eqdef& 0\\
	\iw {\shapp \tys} &\eqdef& \sw \sh + \iw \tys\\
        \iw \tys & \eqdef & \sum\iton \iw \ti\\

      \end{tabular}
    \end{mathpar}
    The helper $\iw \t$ computes the ``internal'' weight of $\t$; in
    the common case of shallow types it is just the weight of its head
    shape.

    We define the weight of a multi-equation as the sum of the weights of its
    members. The weight of a unification problem $\uw \up$ is defined
    as the sum of the weights of its multi-equations.

    In $\up \unif \upp$, the rules \Rule{U-Decomp} and \Rule{U-Name} are not
    obviously destructive, as they may introduce new constraints that
    are structurally larger than the constraint being rewritten.

    However, we show that this is not problematic: in both cases, the unification
    weight $\uw \up$ strictly decreases. The remaining rules are obviously
    destructive and either maintain or decrease the unification weight.

    \begin{proofcases}
      \proofcaserewrite
	{U-Decomp}
	{\cunif {\pshapp \tvs} {\cunif {\pshapp \tvbs} \ueq}}
	{\cunif {\pshapp \tvs} \ueq \cand \cunif \tvs \tvbs}

	We have:
	\begin{mathpar}
	  \begin{tabular}{RRCL}
           (+)&
	    \uw {\cunif {\pshapp \tvs} {\cunif {\pshapp \tvbs} \ueq}} &=&
	      \tw {\pshapp \tvs} + \tw {\pshapp \tvbs}  + \tw \ueq \\
           (-)&
	    \uw {\cunif {\pshapp \tvs} \ueq \cand \cunif \tvs \tvbs}
	      &=&
	      \tw {\pshapp \tvs} + \tw \ueq + \tw \tvs + \tw \tvbs \Strut \\
              \hline
	       &&=&\Strut \tw {\pshapp \tvbs} - \tw \tvs - \tw \tvbs \\
               &&=&  (\sw \sh  + 0 - 2) - 2 |\sh| \\
               &&=&  (2 + 2|\sh|) - 2 |\sh| \Wide = \textbf {2}\\
	  \end{tabular}
	\end{mathpar}
	Hence $\uw {{\cunif {\pshapp \tvs} {\cunif {\pshapp \tvbs} \ueq}}} > \uw {\cunif {\pshapp \tvs} \ueq \cand \cunif \tvs \tvbs}$.


      \proofcaserewrite
	{U-Name}
      {\cunif {\pshapp \parens{\tys, \ti, \typs}} \ueq \\ \tv \disjoint \tys, \typs, \ueq \\ \ti \notin \TyVars }
      {\cexists \tv {\cunif {\pshapp \parens{\tys, \tv, \typs}} \ueq \cand \cunif \tv \ti}}

	Given $\ti \notin \TyVars$, by \cref{thm:principal-shapes},
	$\ti = \shapp[\shp] \bar\typp$ for some shape $\shp$ and types $\bar\typp$.
	So we have:
	\begin{mathpar}
	  \begin{tabular}{.R;;R;C;L.}
          (+) &
	    \uw {\cunif {\pshapp {\parens{\tys, \ti, \typs}}} \ueq}
            &=& \sw \sh + \iw \tys + \iw \ti + \iw \typs - 2 + \uw \ueq \\
          (-) &
	    \uw {\cexists \tv {\cunif \tv \ti \cand \cunif {\pshapp \parens{\tys, \tv, \typs}} \ueq}}
            &=& \sw \sh + \iw \tys + 0 + \iw \typs - 2 + \uw \ueq + 1 + \tw \ti \\
            \hline
           &&=& \iw \tyi - \iw \tv - \tw \ti - 1 \\
	    &&=& \iw \tyi - 0 - (\iw \tyi - 2) - 1 \\
	    &&=& \textbf{1}
	  \end{tabular}
	\end{mathpar}

	Hence $\uw {\cunif {\pshapp \parens{\tys, \ti, \typs}} \ueq } > \uw {\cexists \tv {\cunif {\pshapp \parens{\tys, \tv, \typs}} \ueq \cand \cunif \tv \ti}}$.
    \end{proofcases}
  \end{proof}
\end{lemma}

\termination
\begin{proof}
  The difficulty for termination comes from the ``discharge'' rules
  \Rule{S-Match-Type}, \Rule{S-Match-Var} which can make arbitrary
  sub-constraints appear in the non-suspended part of the constraint;
  and from the instantiation rules that copy/duplicate existing
  structure in another part of the constraint, increasing its total
  size.

  As we argued before, the other rewrite rules are \emph{destructive},
  they strictly simplify the constraint towards a normal form and can
  only be applied finitely many times when taken together. The
  fragment without discharge rules and incremental instantiation is
  also extremely similar to the constraint language of
  \citet*{Pottier-Remy/emlti}, so their termination proof applies
  directly.

  \paragraph{Discharge rules} The discharge rules strictly decrease
  the number of occurrences of suspended match constraint (if we also
  count nested suspended constraints), and no rewriting rule
  introduces new suspended match constraints. So these discharge rules
  can only be applied finitely many times. To prove termination of
  constraint solving, it thus suffices to prove that rewriting
  sequences that do not contain one of the discharge rules (those that
  occur in-between two discharge rules) are always finite.

  \paragraph{Starting instantiations} By a similar argument, the number
  of non-partial instantiations $\capp \x \t$ decreases strictly on
  \Rule{S-Let-AppR} when a partial instantiation starts, and is
  preserved by other non-discharge rules. The rule \Rule{S-Let-AppR}
  can thus only occur finitely many times in non-discharging sequences,
  and it suffices to prove that all rewriting sequences that are
  non-discharging and do not contain \Rule{S-Let-AppR} are finite.

  \paragraph{Other instantiation rules} Among other instantiation
  rules, the rule of concern is \Rule{S-Inst-Copy}, which is not
  destructive: it introduces new instantiation constraints
  and structurally increases the size of the constraint.

  Intuitively, \Rule{S-Inst-Copy} should not endanger termination
  because the amount of copying it can perform for a given
  instantiation is bounded by the size of the types in the constraint
  $\c$ it is copying from. ($\c$ could have cyclic equations with
  infinite unfoldings, but \Rule{S-Inst-Copy} forbids copying in that
  case.) The difficulty is that rewrites to $\c$ can be interleaved
  with instantiation rules, so that the equations that are being
  copied can grow strictly during instantiation.

  To control this, we perform a structural induction: to prove that
  $(\cletr \x \tv \tvs \ca \cb)$ does not contain infinite
  non-discharging non-instance-starting rewrite rules, we can assume
  that the result holds for the strictly smaller constraint $\ca$, and
  then prove termination of the partial instantiations of $\x$ in
  $\cb$. (The notion of structural size used here is preserved by
  non-discharging rewrite rules, as they do not affect the
  $\Let$-structure of the constraint.)

  Assuming that $\ca$ has no infinite rewriting sequence, it suffices
  to prove that only finitely many rewrites in the rest of the
  constraint (namely $\cb$) can occur between each rewrite of $\ca$.

  \newcommand{\sw}[1]{\mathprefix{sw}{(#1)}}
  \newcommand{\iw}[1]{\mathprefix{iw}{(#1)}}
  \newcommand{\stw}[1]{\mathprefix{tw}{(#1)}}
  \newcommand{\tw}[2]{\mathprefix{tw}{(#1 \in #2)}}
  \newcommand{\eqs}[1]{\mathprefix{eqs}({#1})}
  \newcommand{\cw}[1]{\mathprefix{cw}{(#1)}}

  We define a weight that captures the contribution of types
  within $\ca$ to the partial instances in~$\cb$:
  \begin{mathpar}
    \begin{tabular}{RCL}
      \stw {\shapp \tys} &\eqdef& 2 \times \sw \sh + \sum \iton \stw \ti \\[1ex]
      \stw \tv &\eqdef&
      \left\{
        \begin{array}{ll}
        \sup \Braces {\stw \t : \cunif \tv \t \in \ca } & \text{if $\ca$ is acyclic} \\
        0 & \text{otherwise}
        \end{array}
      \right.
    \end{tabular}
  \end{mathpar}
  The weight of a partial instantiation $\cw {\cpapp \x \tv \t \inst}$ is
  defined as  the sum of $\stw \t$ and ${\stw \tv}$.
  The weight of other constraints is given using the measure
  $\mathprefix{uw}$ defined in the the
  proof of \cref{lem:unification-termination}.

  \begin{proofcases}
    \proofcaserewrite
      {S-Inst-Copy}
      {\cletr \x \tv \tvs {\c}
	\C\where{\cpapp \x \tvp \tvc \inst}\\
	\c = \cp \cand \cunif \tvp {\cunif {\shapp \tvbs} \ueq}\\
	\tvp \in \reg \tv \tvs \\
	\neg \cyclic {\c} \\
       \tvbs' \disjoint \tvp, \tvc, \tvbs \\
       \x \disjoint \bvs \C}
      {\cletr \x \tv \tvs {\c}
	\C\where{\cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}}

      We aim to show that the weight of the rewritten constraint
      $\cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst$
      is strictly less than the original $\cpapp \x \tvp \tvc \inst$.

      \begin{mathpar}
	\begin{tabular}{RCL}
	  \cw {\cpapp \x \tvp \tvc \inst} &=& 1 + \stw \tv \\
	  &\geq& 1 + 2 \times \sw \sh + \sum\iton \stw \tvbi  \\[1ex]
	  \cw {\cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}
	  &=&
	  1 + \sw \sh + \sum\iton \stw \tvbi + |\tvbs'|
	\end{tabular}
      \end{mathpar}
      To ensure a strict decrease, it suffices to show that $\sw \sh > |\tvbs'|$.
      Given that $|\tvbs'| = |\sh|$, and by the definition of $\sw \sh$, this inequality holds.
      Therefore, the weight strictly decreases under \Rule{S-Inst-Copy}.

  \end{proofcases}

  Thus the constraint solver terminates.
\end{proof}

\subsection{Correctness}

\begin{lemma}
  \label{lem:unsat-match}
  Given non-simple $\c$ constraint. If every match constraint $\C\where{\cmatch \t \cbrs} = \c$
  satisfies $\nCshape \C \t$, then $\c$ is unsatisfiable.
  \begin{proof}
    By contradiction, inverting on the canonical derivation of $\c$.
  \end{proof}
\end{lemma}

\begin{corollary}
  \label{corollary:correctness}
  For the closed-term-variable constraint $\c$, $\c$ is satisfiable if and only if
  $\c \csolve^* \hat\c$ and $\hat\c$ is a solved form equivalence to $\c$.
  \begin{proof}
    We show each direction individually:
    \begin{proofcases}
      \proofcase{$\implies$}

	By transfinite induction on the well-ordering of constraints whose
	existence is shown in \cref{thm:termination}.

	We have $\c$ is satisfiable.
	By \cref{thm:progress}, we have three cases:
	\begin{proofcases}
	  \proofcase{$\c$ is solved}
	  We have $\c \csolve^* \c$ and $\c \cequiv \c$ by reflexitivity.
	  So we are done.

	  \proofcase{$\c$ is stuck}
	    Given $\c$ is a closed-term-variable constraint,
	    it must be the case that either $\c$ is $\cfalse$
	    \emph{or} $\hat\C\where{\cmatch \t \cbrs}$ and $\nCshape \C \t \sh$ for any shape $\sh$.

	    If $\c$ is $\cfalse$, this contradicts our assumption that $\c$ is satisfiable.
	    Similarly, by \cref{lem:unsat-match}, if $\c$ is $\hat\C\where{\cmatch \t \cbrs}$,
	    then this also contradicts the satisfiability of $\c$.

	  \proofcase{$\c \csolve \cp$}

	  By \cref{thm:preservation}, we have $\c \cequiv \cp$, thus $\cp$ is satisfiable.
	  So by induction, we have $\cp \csolve^* \hat \c$ and $\hat\c$
	  is a solved form equivalent to $\cp$.
	  By transitivity of equivalence, we therefore have $\hat\c \cequiv \c$, as
	  required.

	\end{proofcases}

      \proofcase{$\impliedby$}

      By induction on the rewriting $\c \csolve^* \hat\c$.
      \begin{proofcases}
	\proofcaserewrite
	  {Zero-Step}
	  { }
	  {\hat\c \csolve^* \hat\c}

	We have $\c = \hat\c$ by inversion. All solved forms are satisfiable, thus
	$\c$ is satisfiable.

	\proofcaserewrite
	  {One-Step}
	  {\c \csolve \cp \\ \cp \csolve^* \hat\c}
	  {\c \csolve^* \hat\c}

	  By induction, we have $\cp$ is satisfiable. By \cref{thm:preservation},
	  $\c \cequiv \cp$, hence $\c$ is satisfiable.

      \end{proofcases}
    \end{proofcases}
  \end{proof}
\end{corollary}

\clearpage
\section{Properties of \OML}
\label{app:proofs-typing}

% What we do
This section states and proves the two central metatheoretic properties of \OML. The first
is the \emph{soundness and completeness} of the constraint generator $\cinfer \e \tv$ with
respect to the \OML typing rules. The second is the existence of \emph{principal types},
which follows as a consequence of soundness and completeness: every closed well-typed term $\e$
admits a most general type.

% Closed terms
Throughout this section, we restrict our attention to \emph{closed terms}. This is because the
typing context $\G$ can contain bindings to terms whose type is ``guessed''. When we
generate constraints for a term $\e$ under a context $\G$, we encode the type schemes in
$\G$ as part of the constraint itself using $\Let$-constraints. However, these schemes are treated as
known within the constraint! As a result, we assume terms are closed from the outside to avoid
$\G$ leaking any guessed type information.

\subsection{Simple syntax-directed system}

As a first step towards proving soundness and completeness of constraint
generation, we first present a variant of the \OML type system for \emph{simple terms}. For this
system, the syntax tree completely determines the derivation tree.

We use the standard technique of removing the \Rule{Inst} and \Rule{Gen} rules,
and always apply instantiations in \Rule{Var} (\Rule{Var-SD}) and always
generalize at let-bindings (\Rule{Let-SD}). We can show that this system is
sound and complete with respect to the declarative rules.

\begin{theorem}[Soundness of the syntax directed rules]
  \label{thm:soundness-sd}
  Given the simple term $\e$.
  If $\G \thsimplesd \e : \t$ then we also have $\G \thsimple \e : \t$
  \begin{proof}
    Induction on the given derivation.
  \end{proof}
\end{theorem}

\begin{theorem}[Completeness of the syntax directed rules]
  \label{thm:completeness-sd}
  Given the simple term $\e$.
  If $\G \thsimple \e : \ts$, then $\G \thsimple \e : \t$ for any instance $\t$ of $\ts$.
  \begin{proof}
    Induction on the given derivation.
  \end{proof}
\end{theorem}

The simple syntax-directed system has an inversion lemma:
\begin{lemma}[Simple inversion]
  \label{lem:simple-inversion-sd}
  ~
  \begin{enumerate}[(\roman*)]
    \item If $\G \thsimplesd \x : \t$, then $\x : \tfor \tvs \tp \in \G$ and $\t = \tp\where{\tvs \is \tys}$.
    \item If $\G \thsimplesd \efun \x \e : \t$, then $\G, \x : \ta \thsimplesd \e : \tb$ and $\t = \ta \to \tb$.
    \item If $\G \thsimplesd \eapp \ea \eb : \t$, then $\G \thsimplesd \ea : \tp \to \t$ and $\G \thsimplesd \eb : \tp$.
    \item If $\G \thsimplesd \eunit : \t$, then $\t = \tunit$.
    \item If $\G \thsimplesd \elet \x \ea \eb : \t$, then $\G \thsimplesd \ea : \tp$, $\tvs \disjoint \G$, and $\G, \x : \tfor \tvs \tp \thsimplesd \eb : \t$.
    \item If $\G \thsimplesd \eannot \e \tvs \tp : \t$, then $\G \thsimplesd \e : \tp\where{\tvs \is \tys}$ and $\t = \tp\where{\tvs \is \tys}$.
    \item If $\G \thsimplesd \erecord {\overline{\el = \e}} : \t$, then $\G \thsimplesd \eli = \ei : \t$ for $1 \leq i \leq n$ and $\bar\el \uni \t$.
    \item If $\G \thsimplesd \el = \e : \t$, then $\G \thsimplesd \e : \tp$ and $\el : \tp \to \t$.
    \item If $\G \thsimplesd \efield \e \el : \t$, then $\G \thsimplesd \e : \tp$, $\el : \tp \to \t$ and $\el \uni \t$.
    \item If $\G \thsimplesd \etuple {\ea, \ldots, \en} : \t$, then $\G \thsimplesd \ei : \ti$ for all $1 \leq i \leq n$ and $\t = \tProd \ti$.
    \item If $\G \thsimplesd \exproj \e j n : \t$, then $\G \thsimplesd \e : \tProd \ti$ and $\t = \tj$, with $n \geq j$.
    \item If $\G \thsimplesd \expoly \e \tvs {\tfor \tvbs \tp} : \t$, then $\G \thsimplesd \e : \t\where{\tvs \is \tys}$, $\tvbs \disjoint \G$ and
      $\t = \tpoly {\tfor \tvbs \tp}\where{\tvs \is \tys}$.
    \item If $\G \thsimplesd \exinst \e \tvs \ts : \t$, then $\G \thsimplesd \e : \tpoly \ts\where{\tvs \is \tys}$ and $\ts \leq \t$.
    \item If $\G \thsimplesd \emagic \e : \t$, then $\G \thsimplesd \e : \tp$.
  \end{enumerate}
\end{lemma}

\subsection{Canonicalization of typability}
Our system satisfies a similar canonicalization theorem to constraint satisfiability.

\begin{lemma}[Composability of unicity]
  ~
  \label{lem:comp-unicity-typing}
  \begin{enumerate}[(\roman*)]
    \item If $\Eshape \Ea \e \sh$, then $\Eshape {\Eb\where\Ea} \e \sh$.
    \item If $\eshape \Ea \e \sh$, then $\eshape {\Eb\where\Ea} \e \sh$.
    \item If $\Lshape \Lab \elab \T$, then $\Lshape {\Eb\where\Lab} \elab \T$.
  \end{enumerate}
  \begin{proof}
    By induction on $\Eb$.
  \end{proof}
\end{lemma}

\begin{lemma}[Decanonicalization]
  \label{lem:decanonicalization-typing}
  If $\Th \e : \t$, then $\eset \th \e : \t$.
  \begin{proof}
    By induction on the given derivation $\Th \e : \t$.
  \end{proof}
\end{lemma}

\newcommand{\enimplicit}[1]{{\#\mathprefix[\mathsf]{implicit} {#1}}}
\begin{theorem}[Canonicalization]
  \label{thm:canonicalization-typing}
  If $\th \e : \ts$, then $\Th \e : \t$ for any instance $\t$ of $\ts$.
  \begin{proof}
    By induction on the following measure of $\e$:
    \begin{mathpar}
      \| \e \| \uad\eqdef\uad \angles {\enimplicit \e, |\e|}
    \end{mathpar}
    where $\angles \ldots$ denotes a lexicographically ordered pair, and
  \begin{enumerate}

    \item $\enimplicit \e$ is the number of implicit constructs in $\e$ \ie overloaded tuple projections $\eproj \e j$,
      field projections $\efield \e \elab$, records $\erecord {\overline{\elab = \e}}$, polytype instantiations $\einst \e$
      and polytype boxing $\epoly \e$.

    \item the last component $|\e|$ is a structural measure of terms \ie a
      application $\eapp \ea \eb$ is larger than the two terms $\ea, \eb$.
  \end{enumerate}
  This measure is analogous to the measure $\cmeasure \c$ for constraints.
  \end{proof}
\end{theorem}

\subsection{Unifiers}

A substitution $\sub$ is an idempotent function from type variables to types.
The (finite) domain of $\sub$ is the set of type variables such that $\sub(\tv)
\neq \tv$ for any $\tv \in \dom \sub$, while the codomain consists of the free
type variables of its range.
%
We use the notation $\where{\tvs \is \tys}$ for the substitution $\sub$ with
domain $\tvs$ and $\sub(\tvs) = \tys$.

The constraint induced by a substitution $\sub$, written $\exists \sub$, is
$\cexists {\tvbs} \tvs = \tys$ where $\tvbs = \rng \sub$, $\tvs = \dom \sub$
and $\sub(\tvs) = \tys$.

\begin{definition}[Unifier]
  A substitution $\sub$ is a unifier of $\c$ if $\exists \sub$ entails $\c$.
  A unifier $\sub$ of $\c$ is \emph{most general} when $\exists \sub$ is equivalent
  to $\c$.
\end{definition}

\begin{lemma}[Simple inversion of unifiers]
  \label{lem:unifier-simple-inversion}
  ~
  \begin{itemize}
    \item If $\sub$ is a unifier of $\cunif \ta \tb$, then $\sub(\ta) = \sub(\tb)$.
    \item For simple $\ca, \cb$, if $\sub$ is a unifier of $\ca \cand \cb$, then $\sub$ is a unifier of $\ca$ and $\cb$.
    \item For simple $\c$, if $\sub$ is a unifier of $\cexists \tv \c$, then $\sub\where{\tv \is \t}$ is a unifier of $\c$ for some $\t$.
    \item For simple $\c$, if $\sub$ is a unifier of $\cfor \tv \c$, then $\sub$ is a unifier of $\c$.
  \end{itemize}
  \begin{proof}
    Follows by simple inversion.
  \end{proof}
\end{lemma}

\begin{lemma}
  \label{lem:unifier-abs-equiv}
  If $\sub$ unifies $\cexists \tv \c$, then there exists a unifier $\subp$ that extends $\sub$ with $\tv$,
  where $\subp$ is most general unifier of $\exists \sub \cand \c$.


  Then $\cabs \tv \c$ is equivalent to $\cabs \tv \sigma \leq \tv$ under $\sub$, where $\ts = \tfor \tvbs \subp(\tv)$ and
  $\tvbs = \fvs {\subp(\tv)} \setminus \rng \sub$. We write this equivalent constraint abstraction as $\csem {\cabs \tv \c}_\sub$.
  \begin{proof}
    See \citet*{Pottier-Remy/emlti}.
  \end{proof}
\end{lemma}

\begin{lemma}[Let inversion of unifiers]
  For simple $\ca, \cb$.
  If $\sub$ unifies $\clet \x \tv \ca \cb$, then
  $\sub$ unifies $\cexists \tv \ca$ and
  $\sub$ unifies $\cletin \x {\csem {\cabs \tv \ca}_\sub} \cb$
  \begin{proof}
    Follows from \cref{lem:unifier-abs-equiv} and simple inversion.
  \end{proof}
\end{lemma}

\begin{lemma}
  \label{lem:mgus}
  For two substitutions $\sub$, $\subp$. If $\exists \sub \centails \exists \subp$, there exists
  $\subpp$ such that $\sub = \subpp \compose \subp$.
  \begin{proof}
    Standard result, follows from definition of $\exists \sub$.
  \end{proof}
\end{lemma}

\subsection{Soundness and completeness of constraint generation}

\begin{lemma}
  \label{lem:ctxt-gen-correctness}
  For any term context $\E$, term $\e$, $\ctxinfer \E \tv \tvb \where{\cinfer \e \tv} = \cinfer {\E\where{\e}} \tvb$.
  \begin{proof}
    By induction on the structure of $\E$.
  \end{proof}
\end{lemma}

\begin{lemma}
  \label{lem:erasure-constraint-gen}
  For any term $\e$, $\cerase {\cinfer \e \tv} = \cinfer {\eerase \e} \tv$.
  \begin{proof}
    By induction on $\e$.
  \end{proof}
\end{lemma}

\begin{lemma}[Simple soundness and completeness]
  \label{lem:simple-soundness-completeness}
  For simple terms $\e$.
  $\sub(\G) \thsimplesd \e : \sub(\t)$ if and only if $\sub$ is a unifier of $\csem {\G \th \e : \t}$.
  \begin{proof}
    By induction on $\e \simple$.
  \end{proof}
\end{lemma}

\begin{theorem}[Soundness and completeness]
  \label{thm:soundness-and-completeness}
  $\Th \e : \sub(\tv)$ if and only if $\sub$ is a unifier of $\csem {\e : \tv}$
  \begin{proof}
    By induction on the number $n$ of implicit terms in $\e$.
    \begin{proofcases}
      \proofcase{$n$ is $0$}

	\begin{llproof}
	  \simplePf{\e}{Premise}
	  \iffPf{\eset\thsimplesd \e : \sub(\tv)}{\sub \text{ unifies } \csem {\e : \tv}}{\cref{lem:simple-soundness-completeness}}
	  \iffPf{\eset \thsimplesd \e : \sub(\tv)}{\Th \e : \sub(\tv)}{When $\e \simple$}
\Hand	  \iffPf{\Th \e : \sub(\tv)}{\sub \text{ unifies } \csem {\e : \tv}}{Above}
	\end{llproof}

      \proofcase{$n$ is $k + 1$}

	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{proofcases}

	    \proofcasederivation
	      {Can-Proj-I}
	      {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\ \sub(\G) \Th \E\where{\exproj \e j n} : \sub(\tv)}
	      {\Th \E\where{\eproj \e j} : \sub(\tv)}

	      \begin{llproof}
		\ThTypPf{\sub(\G)}{\E\where{\exproj \e j n}}{\sub(\tv)}{Premise}
		\UnifierPf{\sub}{\csem {\G \th \E\where{\exproj \e j n} : \tv}}{By \ih}
		\eqPf{\csem {\G \th \E\where{\exproj \e j n } : \tv}}{\cletG {\cinfer {\E\where{\exproj \e j n}} \tv}}{By definition}
		\continueeqPf{\cletG {\ctxinfer \E \tvb \tv}\where{\cinfer {\exproj \e j n} \tvb}}{\cref{lem:ctxt-gen-correctness}}
		\equivPf{\cinfer {\exproj \e j n} \tvb}{\cexists {\tvaa \tvcs} {\cinfer \e \tvaa \cand \cunif \tvaa {\Pi\iton \tvcs} \cand \cunif \tvb \tvc_j}}{By definition}
		\continueequivPf{\cexists {\tvaa} \cinfer \e \tvaa \cand \cmatched \tvaa {\any \tvcs \Pi\iton \tvcs}{\cbranch {\cpatprod \tvc j} {\cunif \tvb \tvc}}}{\ditto}
		\UnifierPf{\sub}{\cletG \ctxinfer \E \tvb \tv \where{\cexists \tvaa \cinfer \e \tvaa \cand \ldots}}{Above}
		\eshapePf{\E}{\e}{\any \tvcs \Pi\iton \tvcs}{Premise}
		\LetPf{\C}{\cletG \ctxinfer\E \tvb \tv \where{\cexists \tvaa \cinfer \e \tvaa \cand \square}}{}
		\vdashPf{\semenv}{\cerase{\C\where{\cunif \tvaa \gt}}}{Premise}
		\eqPf{\cexists \tvaa \cinfer \e \tvaa \cand \cunif \tvaa \gt}{\cexists \tvaa \cinfer {\eannot \e {} \gt} \tvaa}{By definition}
		\decolumnizePf
		\continueeqPf{\cinfer {\emagic {\eannot \e {} \gt}} \tvb}{\ditto}
		\eqPf{\cerase {\C\where{\cunif \tvaa \gt}}}{\cerase {\cletG \ctxinfer \E \tvb \tv \where{\cinfer {\emagic {\eannot \e {} \gt}} \tvb}}}{\ditto}
		\continueeqPf{\cerase {\cletG \cinfer {\E\where{\emagic {\eannot \e {} \gt}}} \tv}}{\cref{lem:ctxt-gen-correctness}}
		\continueeqPf{\cletG \cerase {\cinfer {\E\where{\emagic {\eannot \e {} \gt}}} \tv}}{By definition}
		\continueeqPf{\cletG \cinfer {\eerase {\E\where{\emagic {\eannot \e {} \gt}}}} \tv}{\cref{lem:erasure-constraint-gen}}
		\UnifierPf{\semenv}{\cletG \cinfer {\eerase {\E\where{\emagic {\eannot \e {} \gt}}}} \tv}{Above}
		\ThTypPf{}{\eerase {\E\where{\emagic {\eannot \e {} \gt}}}}{\semenv(\tv)}{By \ih}
		\thTypPf{\eset}{\eerase {\E\where{\emagic {\eannot \e {} \gt}}}}{\semenv(\tv)}{\cref{lem:decanonicalization-typing}}
		\eqPf{\shape \gt}{\any \tvcs \Pi\iton \tvcs}{$\implies$E}
		\shapePf \C \tvaa {\any \tvcs \Pi\iton \tvcs}{Above}
		\UnifierPf{\sub}{\C\where{\cmatch \tvaa {\cbranch {\cpatprod \tvc j} {\cunif \tvb \tvc}}}}{By \Rule{Susp-Ctx}}
		\eqPf{\cinfer {\eproj \e j} \tvb}{\cexists \tvaa \cinfer \e \tvaa \cand \cmatchdots \tvaa}{By definition}
		\eqPf{\C\where{\cmatchdots \tvaa}}{\cletG \ctxinfer \E \tvb \tv\where{\cexists \tvaa \cinfer \e \tvaa \cand \ldots}}{\ditto}
		\continueeqPf{\cletG \ctxinfer \E \tvb \tv \where{\cinfer {\eproj \e j} \tvb}}{Above}
		\continueeqPf{\cletG \cinfer {\E\where{\eproj \e j}} \tv}{\cref{lem:ctxt-gen-correctness}}
		\continueeqPf{\csem {\E\where{\eproj \e j} : \tv}}{}
\Hand  		\UnifierPf{\sub}{\csem {\E\where{\eproj \e j} : \tv}}{}
	      \end{llproof}

	    \proofcase{\Rule{Can-Poly-I}, \Rule{Can-Use-I}, \Rule{Can-Lab-I}}

	    \begin{llproof}
	      Similar arguments.
	    \end{llproof}
	  \end{proofcases}

	  \proofcase{$\impliedby$}

	  \begin{proofcases}
	    \proofcasederivation
	      {Can-Susp-Ctx}
	      {\Cshape \C \tvaa {\any \tvcs \Pi\iton \tvcs} \\
	       \sub \text{ unifies } \C\where{\cmatched \tvaa {\any \tvcs \Pi\iton \tvcs} {\ldots}}}
	      {\sub \text{ unifies } \underbrace{\C\where{\cmatch \tvaa {\cbranch {\cpatprod \tvc j} {\cunif \tvb \tvc}}}}_{\cinfer \e \tv}}

	      \begin{llproof}
		\eqPf{\csem {\e : \t}}{\cletG \cinfer {\E\where{\eproj \e j}} \tv}{Premise}
		\eqPf{\C}{\cletG \ctxinfer \E \tvb \tv\where{\cexists \tv \cinfer \e \tv \cand \square}}{Premise}
		\UnifierPf{\sub}{\C\where{\cmatched \tvaa {\any \tvcs \Pi\iton \tvcs} {\ldots}}}{Premise}
		\UnifierPf{\sub}{\csem {\E\where{\exproj \e j n} : \tv}}{Above (See $\implies$ direction)}
		\ThTypPf{}{\E\where{\exproj \e j n}}{\sub(\tv)}{By \ih}
		\thTypPf{\Gp}{\E\where{\emagic {\eannot \e {} \gt}}}{\tp}{Premise}
		\eqPf{\Gp}{\eset}{$\E\where{\emagic {\eannot \e {} \gt}}$ is closed}
		\ThTypPf{}{\E\where{\emagic {\eannot \e {} \gt}}}{\tp}{\cref{lem:decanonicalization-typing}}
		\UnifierPf{\where{\tv \is \tp}}{\csem {\E\where{\emagic {\eannot \e {} \gt}} : \tv}}{By \ih}
		\vdashPf{\semenv\where{\tv \is \semenv(\tp)}}{\cinfer {\E\where{\emagic {\eannot \e {} \gt}}} \tv}{By definition}
		\shapePf{\C}{\tvaa}{\any \tvcs \Pi\iton \tvcs}{Premise}
		\eqPf{\shape \gt}{\any \tvcs \Pi\iton \tvcs}{$\implies$E}
		\eshapePf{\E}{\e}{\any \tvcs \Pi\iton \tvcs}{Above}
		\ThTypPf{}{\E\where{\eproj \e j}}{\sub(\tv)}{By \Rule{Can-Proj-I}}
	      \end{llproof}

	    \proofcase{$\epoly \e$, $\einst \e$, $\ell$}

	    \begin{llproof}
	      Similar arguments.
	    \end{llproof}
	  \end{proofcases}
	\end{proofcases}
    \end{proofcases}
  \end{proof}
\end{theorem}

\subsection{Principal types}

\principalTypes
\begin{proof}

Let $\e$ be an arbitrary closed well-typed term; that is, there exists a type
  $\t$ such that $\th \e : \t$.
  By \cref{thm:soundness-and-completeness}, the constraint $\cinfer \e \tv$ is satisfiable
  (specifically under the unifier $\cunif \tv \t$). By \cref{corollary:correctness}, there
  exists a solved constraint $\hat\c$ such that $\hat\c \cequiv \cinfer \e \tv$.
  From $\hat\c$, we extract a unifier $\sub$. Since $\hat\c \cequiv \exists \sub$,
  it follows that $\sub$ is \emph{most general}.

  We claim that $\sub(\tv)$ is the principal type of $\e$. This amounts to showing:
  \begin{enumerate}[(\roman*)]
    \item
      \label{proof:principal-types:1}
      $\th \e : \sub(\tv)$
    \item
      \label{proof:principal-types:2}
      For any other typing $\th \e : \tp$, then $\tp = \theta(\sub(\tv))$ for some $\theta$.
  \end{enumerate}
  Since $\sub$ is a unifier of $\cinfer \e \tv$, it follows immediately from
  \cref{thm:soundness-and-completeness} that $\th \e : \sub(\tv)$, proving \ref{proof:principal-types:1}.
  For \ref{proof:principal-types:2}, suppose $\th \e : \tp$ for some $\tp$. Then by
  \cref{thm:soundness-and-completeness} again, there exists a unifier $\subp$ of $\cinfer \e \tv$
  such that $\subp(\tv) = \tp$. Since $\sub$ is most general, we have $\exists \subp \centails \exists \sub$,
  and by \cref{lem:mgus}, this implies the existence of a substitution $\subpp$ such that
  $\subp = \subpp \compose \sub$.
  Hence, $\tp = \subp(\tv) = \subpp(\sub(\tv))$, witnessing that $\tp$ is an instance of $\sub(\tv)$, as
  required \ref{proof:principal-types:2}.
\end{proof}



\clearpage
\setcounter{tocdepth}{1}
\tableofcontents


%%% Below this line will is a draft
\Draft{}{\end{document}}\color{blue}

\clearpage

\section{DRAFT: a later TODO  list}

Problems to solve or leave unsolved:
\begin{itemize}

\item
  Overloading of the bracket notation for context filling and polytypes,
  as in $E\where{\epoly \e}$.

  A possibility would be to use braces for either one. Although they are
  used for record expressions, I would say the overlapping with either
  polytypes (they never appear simultaneously) or context (idem, since we
  put label accesses but not records in contexts.

  Alternatively, we could use $\ceils \e$ for polytypes---and then $\floors
  \e$ for the projections.


\end{itemize}

\section{The \OML calculus, feature by feature}

\Xgabriel{This section contains work-in-progress content that I intended to use to rewrite Section 4, ``The \OML calculus''. I still believe that there will not be enough space to keep Section 4 anyway, so I decided to stop this rewrite effort and dump the current content here.}

\subsection{The core fragment}
\label{sec:language:core}
\label{sec/language/typing-rules}

\begin{mathparfig}{fig/typing-core}{Typing and inference: Core \ML}
  \inferrule[Var]
    {x : \sigma \in \G}
    {\G \th x : \sigma}

  \inferrule[Fun]
    {\G, x : \ta \th e : \tb }
    {\G \th \efun x e : \ta \to \tb}

  \inferrule[App]
    {\G \th \ea : \ta \to \tb \\
     \G \th \eb : \ta}
    {\G \th \eapp \ea \eb : \tb}

  \inferrule[Annot]
    {\G \th e : \t\where {\tvs \is \tys}}
    {\G \th (e : \exi \tvs \t) : \t\where {\tvs \is \tys}}

  \inferrule[Gen]
    {\G \th e : \sigma \\ \tv \disjoint \G}
    {\G \th e : \tfor \tv \sigma}

  \inferrule[Inst]
    {\G \th e : \tfor \tv \ts}
    {\G \th e : \ts \where{\tv \is \t}}

  \inferrule[Let]
    {\G \th \ea : \sigma \\
     \G, x : \sigma \th \eb : \t}
    {\G \th \elet x \ea \eb : \t}
\\
\newcommand {\Crule}[2]{#1 & \eqdef & #2}
\begin{array}{l@{\uad} c@{\uad} l}
\Crule
  {\cinfer {\efun \x \e} \t}
  {\cexists {\tva, \tvb}
    \cunif \t {\tva \to \tvb}
    {}}
\\ & & \quad\uad {} \cand \clet \x \tvc {\cunif \tvc \tva} {\cinfer \e \tvb}
\\
\Crule
  {\cinfer {\eapp \ea \eb} \t}
  {\cexists {\tva} \cinfer \ea {\tva \to \t} \cand \cinfer \eb \tva}
\end{array}
\quad
\begin{array}{l@{\uad} c@{\uad} l}
\Crule
   {\cinfer x \t}
   {\cinst x \t}
\\
\Crule
  {\cinfer {\elet \x \ea \eb} \t}
  {\clet \x \tva {\cinfer \ea \tva} {\cinfer \eb \t}}
\\
\Crule
  {\cinfer {\eannot \e \tvs \tp} \t}
  {\cexists \tvs \cunif \t \tp \cand \cinfer \e \tp}
\end{array}
\end{mathparfig}

As usual, the main typing judgment $\G \th \e : \ts$ states that in
context $\G$, expression $\e$ has type scheme $\ts$. We give the
typing rules for the core \ML fragment in \cref{fig/typing-core}. It
also defines constraint generation for this fragment: given a term
$\e$ and its expected type $\t$, which may contain some free type
variables, we define a constraint $\cinfer e \t$ that is satisfiable
if and only if the term is well-typed for some instantiation of those
free type variables. Both typing rules and constraint generations are
standard on this fragment, and we will not comment them further due to
space restrictions.

\subsection{Unicity via magic rules}

TODO: a figure with the magic rule and the two unicity criterion (not for labels).

\subsection{Overloaded tuples}

\begin{mathparfig}{fig/typing-tuples}{Typing and inference: tuples}
  \inferrule[Tuple]
    {\parens{\G \th \ei : \ti}\iton}
    {\G \th (\ea, \ldots, \en) : \Pi\iton \ti}

  \inferrule[Proj-X]
    {\G \th \e : \Pi\iton \ti \\
     1 \leq j \leq n}
    {\G \th \exfield \e n j : \tj}

  \inferrule[Proj-I]
    {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\
     \G \th \E\where{\exfield \e n j} : \t}
    {\G \th \E\where{\efield \e j} : \t}
\\
  \newcommand{\Mrule}[5][]{{#2} \Matches {(#3)} \; #4 &\eqdef& {#5} & #1}
 \begin{array}{rcl@{\qquad}l@{\qquad\qquad} r}
   \cpat & ::= & \dots \mid \cpatprod \tv j & & \text{tuple patterns} \\
    \Mrule[\text{if } n \geq j]
      {\cpatprod \tv j}
      {\any \tvcs \Pi\iton \tvcs} \tvbs
      {[\tv \is \tvb_j]}
   & \text{matching relation}
 \end{array}
\\
\newcommand {\Crule}[2]{#1 & \eqdef & #2}
\begin{array}{l@{\uad} c@{\uad} l}
\Crule
  {\cinfer {\etuple {\ea, \ldots, \en}} \t}
  {\cexists \tvs \cunif \t {\Pi\iton \tvs}
    \cand \cAnd \iton \cinfer \ei {\tv_i}}
\\
\Crule
  {\cinfer {\exfield \e j n} \t}
  {\cexists {\tvbs}
    \cinfer \e {\Pi\iton \tvbs}
    \cand \cunif \t {\tvb_j}}
\\
\Crule
  {\cinfer {\efield \e j} \t}
  {\cexists \tv \cinfer \e \tv
    \cand \cmatch \tv {\cbranch {\cpatprod \tvb j} {\cunif \t \tvb}}}
\end{array}
\end{mathparfig}

\subsection{Polytypes}

\begin{mathparfig}{fig/typing-polytypes}{Typing and inference: polytypes}
  \inferrule [Poly-X]
    {\G \th \e : \ts\where {\tvs \is \tys}}
    {\G \th \epoly[\exi \tvs \ts] \e : \tpoly {\ts \where {\tvs \is \tys}}}

  \inferrule [Poly-I]
    {\Eshape \E \e {{\any \tvcs \tpoly \ts}} \\
     \G \th \E \where{\epoly[\exi \tvcs \ts] \e} : \t}
    {\G \th \E \where{\epoly \e} : \t}

  \inferrule [Use-X]
    {\G \th \e : \tpoly \ts \where {\tvs \is \tys}}
    {\G \th \exinst e \tvs \ts : \ts \where {\tvs \is \tys}}

  \inferrule [Use-I]
    {\eshape \E  \e {\any \tvcs \tpoly \ts} \\
     \G \th \E\where{\exinst \e \tvcs \ts} : \t}
    {\G \th \E\where{\einst \e} : \t}
\\
  \newcommand{\Mrule}[5][]{{#2} \Matches {(#3)} \; #4 &\eqdef& {#5} & #1}
 \begin{array}{rcl@{\qquad}l@{\qquad\qquad} r}
   \cpat & ::= & \dots \mid \cpatpoly \cscm
               & & \text{polytype patterns} \\
   \c & ::= & \dots \mid \cscm \leq \t \mid \ts \leq \t \mid \x \leq \cscm \mid \x \leq \ts
            & & \text{polytype constraints} \\
    \Mrule
      {\cpatpoly \cscm}
      {\any \tvcs \tpoly \ts} \tvbs
      {[\cscm \is \ts \where{\tvcs \is \tvbs}]}
   & \text{matching relation}
 \end{array}
\\
\newcommand {\Crule}[2]{#1 & \eqdef & #2}
\begin{array}{l@{\uad} c@{\uad} l}
\\
\Crule
  {\cinfer {\expoly \e \tvs \ts} \t}
  {\cexists {\tvs}
    \cinfer \e \ts
    \cand \cunif \t {\tpoly \ts}}
\\
\Crule
  {\cinfer {\exinst \e \tvs \ts} \t}
  {\cexists {\tvs}
    \cinfer \e {\tpoly \ts}
    \cand \ts \leq \t}
\\
\Crule
  {\cinfer {\einst \e} \t}
  {\cexists \tva
    \cinfer \e \tva
    \cand \cmatch \tva {\cbranch {\cpatpoly \cscm} \cscm \leq \t}}
\\
\Crule
  {\cinfer {\epoly \e} \t}
  {\clet \x \tv {\cinfer \e \tv}
    {\cmatch \t {\cbranch {\cpatpoly \cscm} {\x \leq \cscm}}}}
\end{array}
\end{mathparfig}

\subsection{Nominal records}

TODO: extend the magic rule and the disambiguation rule, and also provide the unicity-in-env criterion definition. I propose to add those to the figure below.

\begin{mathparfig}{fig/typing-records}{Typing and inference: nominal records}
  \inferrule[Rcd-Assn]
    {\G \th \e : \t \\
     \G \th \el : \t \to \tp}
    {\G \th \el = \e : \tp}

  \inferrule[Rcd]
    {\parens{\G \th \eli = \ei : \t}\iton \\
     \G \th \bar \el \uni \t}
    {\G \th \erecord {\ela = \ea; \ldots; \el_n = \en} : \t}

  \inferrule[Rcd-Proj]
    {\G \th \e : \tp \\
     \G \th \el : \t \to \tp \\
     \G \th \el \uni \t }
    {\G \th \efield \e \el : \t}

  \inferrule[Lab-X]
    {\Omega(\elab / \T) = \tfor \tvs \t \to \tvs \T }
    {\G \th \elab / \T : \tys\where{\tvs \is \tys} \to \tys \T}

  \inferrule[Lab-I]
    {\Lshape \Lab \elab \T \\
      \G \th \Lab[\elab / \T] : \t}
    {\G \th \Lab[\elab] : \t}

  \inferrule[Lab-!]
    {\bar \el \uni \T \in \labenv}
    {\G \th \bar \el \uni \tys \T}

  \inferrule[Lab-?]
    {\G \th \t}
    {\G \th \bar \el \uni \t}
\\
  \newcommand{\Mrule}[5][]{{#2} \Matches {(#3)} \; #4 &\eqdef& {#5} & #1}
 \begin{array}{rcl@{}l@{\qquad} r}
   \cpat & ::= & \dots \mid \cpatrcd \ct & & \text{record patterns} \\
   \c & ::= & \dots
              \mid \labenv(\elab/\ct) \leq \ta \to \tb
              \mid \labenv(\elab/\T) \leq \ta \to \tb
            & & \text{record constraints} \\
    \Mrule
      {\cpatrcd \ct}
      {\any \tvcs \tvcs \Tapp} \tvbs
      {[\ct \is ~ \T]}
   & \text{matching relation}
 \end{array}
\\
\newcommand {\Crule}[2]{#1 & \eqdef & #2}
\begin{array}{l@{\uad} c@{\uad} l}
\Crule
  {\cinferassn \el \e \t}
  {\cexists \tv \cinfer \e \tv
    \cand \cinferlab \el \tv \t}
\\
\Crule
  {\cinferlab \elab \ta \tb}
  {\cmatch \tb {\cbranch {\cpatrcd \ct} {\labenv(\elab/\ct) \leq \ta \to \tb}}}
\\
\Crule
  {\cinferlab {\elab/\T} \ta \tb}
  {\labenv(\elab/\T) \leq \ta \to \tb}
\\
\Crule
  {\cinferlab {\elmagic \elab} \ta \tb}
  {\ctrue}
\\
\Crule
  {\cinferlab {\elannot \el \tvs \t} \ta \tb}
  {\cexists \tvs \cinferlab \el \ta \tb \cand \cunif \tb \t}
\\
\Crule
  {\cinferlabuni {\bar \el} \t}
  {\begin{cases}
    \cexists \tvs \cunif \t {\tvs \Tapp} &\text{if } \bar \el \uni \T \in \labenv \\
    \ctrue &\text{otherwise}
   \end{cases}}
\end{array}
\end{mathparfig}


\end{document}

% LocalWords:  omnidirectional typecheck polymorphism Hindley Milner kinded
% LocalWords:  GADTs typechecked codomain typechecking subexpressions Bodin
% LocalWords:  monomorphic subexpression Dunfield Riboulet jfla subtyping
% LocalWords:  greek Chargueraud typable monotype polytype Garrigue Remy th
% LocalWords:  impredicative polytypes minimality RCL ary Proj toplevel mlf
% LocalWords:  typability backpropagation arity Compositionality equi Damas
% LocalWords:  equitypable compositionality inlined equitypability nullary
% LocalWords:  metatheoretical finiteness nonvariable mydesc Inlining Yi na
% LocalWords:  unicity inlining typedness pincipality scrutinee equalities
% LocalWords:  declaratively LeBotlan directionality polymorphically mleth
% LocalWords:  directionally typecheckers typechecker disambiguates unshare
% LocalWords:  typechecks acyclic emlti Disambiguating disambiguated GADT
% LocalWords:  prototyped instantiation Monotypes postfixed unsatisfiable
% LocalWords:  satisfiable matchee datatypes arbritraty generalizable Unif
% LocalWords:  monomorphization desugars Forall satisfiability formers iff
% LocalWords:  equirecursive principalShapes subterms Susp Ctx foundedness
% LocalWords:  unsatisfiability getx olymorphic nstances ive typings LetR
% LocalWords:  metavariable subterm Metatheory principalTypes monotypes Rcd
% LocalWords:  ExistsLeft ExistsRight ConjLeft ConjRight equational AppR Wf
% LocalWords:  existentials instantiations desugared susp ively renamings
% LocalWords:  quantifications subcomponents BackProp Tarjan's invariants
% LocalWords:  rossberg wasm WebAssembly dunfield krishnaswami jones Huet's
% LocalWords:  huet unif conf Vytiniotis Peyton Schrijvers Sulzmann Leijen
% LocalWords:  disambiguating namespace implicits Bour Yallop Didier Annot
% LocalWords:  acyclicity canonicalization aaa formedness unannotated inX
% LocalWords:  casted inMagic inAnnot unsubstituted oml RCLL Scm LCL Decomp
% LocalWords:  mutli cheatsheet inI ProjX PolyX UseX unifier Gc Defn sw iw
% LocalWords:  InstLeft InstRight mergable tw uw RRCL eqs priori multiset
% LocalWords:  reflexitivity metatheoretic lexicographically Unifiers TODO
% LocalWords:  rcl env
