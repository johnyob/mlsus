%; whizzy section

%% Leave the above line for didier
%% No macros before \documentclass

\documentclass[acmsmall,screen,nonacm,review]{acmart}

\input{suspended.cfg}
\newcommand{\acmart}{\True}
\usepackage{suspended}

%% \Xfirstname defined in {mycomments}
%% Use either
%%   \Xfistname[text to comment]{your comment on the text}
%% or
%%   \Xfirstname{free comment}
%% Uncomment this line to hide all comments.
% \UNXXX{}

\usepackage{marginnote}

\title{Omnidirectional type inference for \ML: principality any way}

\begin{document}

\begin{abstract}
We propose a new concept of \emph{omnidirectional} type inference, which is
the ability to resolve \ML-style typing constraints in disorder, by
contrast with all known implementations that typecheck the
bindings before the bodies of let-expressions.
%
This relies on two technical devices. \emph{Suspended match constraints} suspend the resolution of some constraints until the context has more information on a type variable. \emph{Partial type schemes} allow taking instances of a type scheme that is not completely solved as it contains suspended constraints, with a mechanism to update their instances when their type scheme is refined, incrementally.

The benefits of omnidirectional type inference are striking for several
advanced \ML extensions, typically those that rely on optional type
annotations for which the principal type property is often fragile. We
illustrate them with \OCaml's static overloading of record labels and
constructors, semi-explicit first-class polymorphism, and tuple projections
\ala \SML.
\end{abstract}
\maketitle

\section{Introduction}
\label{sec/introduction}

\parcomment {Introduction (ML, principality)}

The Damas-Hindley-Milner (\HM) \cite{Damas-Milner/W@popl82} type system has
long occupied a sweet spot in the design space of strongly typed programming
languages, as it enjoys the \emph{principal type property}: every well-typed
expression $\e$ has a most general type $\ts$ from which all other valid
types for $\e$ are instances of $\ts$. For example, the identity function
$\efun \x \x$ has the principal type $\tfor \tv \tv \to \tv$, generalizing
types like $\tint \to \tint$ and $\tbool \to \tbool$.

\parcomment {Benefits of principality}

This property ensures predictable and efficient inference. Local typing
decisions are always optimal, yielding most general types without guessing or
backtracking. As a result, inference of subexpressions can proceed in any
order, and well-typedness is preserved under common program transformations
such as let-contraction, let-expansion, and argument reordering.

\parcomment {Extensions often break pincipality}

Over the years, many extensions of \ML have been proposed. Some of
them, such as extensible records with row-polymorphism, higher-kinded
types, or dimensional types, fit perfectly into the \ML
framework. Others such as GADTs, higher-rank polymorphism, or static
overloading, are \emph{fragile}, as they sometimes require explicit
type annotations. The return type of overloaded data constructors can
be annotated; polymorphic expressions can be annotated with a type
scheme; for GADTs, the type of the \texttt{match} scrutinee and return
type can be annotated to a rigid type which will be refined by type
equalities in each branch. Those type annotations may sometimes but
not always be omitted.

Consider impredicative higher-rank polymorphism for instance:
\begin{program}[input]
let self f = f f
\end{program}
With higher-rank types, one could \emph{guess} the type of \code{f} to be
either $\tfor \tv \tv \to \tv$ or $\tfor \tv \tv \to \tv \to \tv$ in order
to typecheck \code{self}---neither of which is more general than the other,
violating principality.

\parcomment {Current approaches are kinda bad}

To fix this, inference algorithms require a minimal amount of
\emph{known} type information to restore principality; in this example
the binding of \code{f} should be annotated with a polymorphic type
scheme. Yet specifying such requirements declaratively is
difficult. As a result, the specifications are often twisted with some
direct or indirect algorithmic flavor in order to preserve
principality and completeness.
%
Moreover, these (more or less) ad-hoc restrictions commonly reject examples
whose type could easily be guessed. For instance, \MLF~\cite{LeBotlan-Remy/recasting-mlf} accepts
or rejects the following expression, depending on the position of the
annotation (green and red background indicate type-checking success):
\begin{program}[input]
let self' (f : $\forall$'a. 'a -> 'a) = if true then f f else f $
$   °\Ocamlcomment{\ocamlFlag {\MLF}0}°
let self' f = if true then f f else (f : $\forall$'a. 'a -> 'a) $
$   °\Ocamlcomment{\ocamlFlag {\MLF}1}°
\end{program}

\parcomment {Annotations fixes all the issues (but they're problematic)}



To each fragile construct
corresponds a robust construct where the type annotation is mandatory. The
robust constructs fit perfectly into the \ML framework, but are
significantly more cumbersome to use, as they always require explicit type
annotations. Fragile constructs can be defined by elaboration into their
robust counterpart.
%
% The elaboration determines which annotations can be
% omitted and rebuilt from context, a point of view already taken by~\citet
% {Pottier-Regis-Gianas/stratified@popl06} in their work on stratified type
% inference.
%
The difficulty lies in finding a specification
that is sufficiently expressive, principled, intuitive for the user,
and for which we have a complete and effective elaboration algorithm.

The solutions proposed so far all enforce some ordering in which type
inference is performed, which can then be used to propagate both inferred
types and user-provided type annotations as \emph{known} types that can be
used for disambiguation and enable the omission of some annotations.

\paragraph{Bidirectional type inference}

Bidirectional type inference is a standard alternative to unification for
propagating type information. It can be presented by adding to the type
inference algorithm an optional expected type in addition to the expression
to be typechecked (and the context in which it should be typechecked). Type
inference is said in \emph{checking mode} when the expected type is present,
and in (the usual) \emph{inference mode} when it is absent.

For example the type-system designer can decide to type-check function
applications $\eapp \ea \eb$ by first \emph{inferring} that $\ea$ has some
function type $\t \tarrow \tp$, and then \emph{checking} $\eb$ against
$\t$. This is not the only possible choice: bidirectional type
inference is actually a framework that must be instantiated by
a particular choice of modes for each of the language construct. There
usually is no optimal combination of modes for the whole set of
language constructs. Once modes have been fixed, there are usually
principal solutions to the type inference problem, but with respect to
a specification that made non-principal choices.

Bidirectional type inference has been largely used for languages with
higher-rank polymorphism, dependent types, or subtyping.  Still, both \OCaml
and \Haskell only use a limited form of bidirectional type checking with an
underlying first-order-unification based type inference engine, which limits
the downsides of bidirectional type checking.

\paragraph{\Geninst-directional type inference}

\ML languages enforce an ordering in the typechecking of let-bindings
$\elet \x \ea \eb$, where (the polymorphic part of) the definition
$\ea$ must be typed before the body $\eb$. \OCaml relies on this
ordering to propagate type information in a principal way: if an
expression has a polymorphic type, then this type can be used for
type-directed disambiguation, whereas monomorphic type information
cannot as it may depend on inference order in a fragile way. We call this
\textbf{\geninst}-directional (to be read \textbf{pi}-directional)
type inference, to mean that \textbf{p}olymorphic expressions must be
typed before their \textbf{i}nstances.

This mechanism was introduced for semi-explicit first-class
polymorphism by~\citet {Garrigue-Remy/poly-ml}, and later used
by~\citet {LeBotlan-Remy/recasting-mlf} for empowering \MLF. It has
also been reused for overloading of record fields and variant
constructors in \OCaml, which we choose for illustration here as it is
simpler to explain than others (which will be
 presented in~\cref{sec/constraints/polytypes}).

The user may define two nominal record types with overlapping fields:
\begin{program}[input]
type 'a one = {x : 'a}
type two = {x : int; y : int}
\end{program}
In \OCaml, both definitions are visible and the compiler must
statically disambiguate field usage. It knows that \lstinline!{x = 1}! can
only be a \code{one}, and that \code{r.y} can only be a \code{two},
but field accesses \code{r.x} must be disambiguated. Consider for
example:\footnote{We use \textsf{Caml} and \textsf{Omni} as shorter names
for \OCaml and \OML.}
\begin{program}[input]
let e_1 r = r.x                         °\ocamlflags 11°
let e_2 = let r = {x = 1} in r.x        °\ocamlflags 00°
let e_3 = (fun r -> r.x) {x = 1}        °\ocamlflags 10°
\end{program}
To be able to disambiguate the projection \code{r.x}, the type of the
\code{r} should be \emph{known} to be either (an instance of)
\ocaml{'a one} or \ocaml{two}. The definition \ocaml[indices]{e_1} is
clearly ambiguous since there is no clue on the type of \ocaml{r} and
its typechecking fails.\footnote {In fact, \OCaml uses a default
resolution strategy instead of failing when the type is ambiguous,
  which is to emit a warning and use the last definition in scope. To
  check these examples, you should use the options
  \texttt{-principal -w +41}, which enforce principality checks and enables
  the warning on default resolution.}
\relax
By contrast, the only possible type for \ocaml{r} is \ocaml {'a one} in both
\ocaml{e_2} and \ocaml {e_3}.  Still, there is a difference. Indeed, the
type of~\ocaml{e_2} is considered to be unambiguous, while the type of
\ocaml{e_3} is ambiguous.
%
To understand why \ocaml{e_3} fails, consider the equivalent versions of
\ocaml{e_3} where \texttt{@@} and \ocaml{|>} are the application and the
reverse application functions.
\begin{program}[input]
let e_3_2 = (fun r -> r.x) @@ {x = 1}   °\ocamlflags 10°
let e_3_3 = {x = 1} |> (fun r -> r.x)   °\ocamlflags 10°
\end{program}
\OCaml does not make any difference between \ocaml[indices]{e_3},
\ocaml[indices]{e_3_2}, or \ocaml[indices]{e_3_3} and consider all
subexpressions in an application, including the function and all
arguments as being inferred simultaneously, until they are
let-bound. More precisely, polymorphic types\footnote{\Xgabriel{I
    propose to remove this footnote which I find too technical and
    I don't think is necessary or helpful to follow the
    introduction.} Technically, all type nodes are annotated with
  a special variable $\av$ called an annotation variable, so that we
  may distinguish between the polymorphic binding
  $\xa : \all \av \t^\av$ that binds $r$ to the known (raw) type $\t$
  and the monomorphic binding $\xb : \t^\av$ that binds $\xa$ to the
  unknown (raw) type $\t$.} are considered to be known while
monomorphic types are consider to be unknown---or, rather,
not-yet-known. This criterion also warns on the following example
where \code{r} has a monomorphic type.
\begin{program}[input,escapechar={}]
let f p r = if p then r.x else (r : two).x
\end{program}
Warning here is preferable to working or not depending on
the order of inference of \code{if} branches.

\paragraph{Limitations of directional type inference}

Directional type inference has been in used in different languages and
somehow proven to work in practice. The main downside of \emph{bidirectional} type inference is
that it requires arbitrary choices in the specification of the flow of
information, typically in applications: should the function be typed first
and its codomain be used to improve the typing of its argument or, on the
opposite, should the argument be typed first and be used as the type of the
codomain of the function?  There are examples when the former is a better
choice and others when the latter is preferable---but typing rules have to
choose one of the two alternative forever.  One may also allow information
to flow between multiple arguments passed to the same function, and several orders are possible. We eventually
have a complete algorithm with respect to a specification that made somewhat
arbitrary choices.

On the other hand, \emph{\Geninst-directional} type inference does not even
allow to propagate user-provided type annotations from a function to its
argument! For example, the following would be rejected as ambiguous with
\geninst-directional type inference alone:
\begin{program}[input]
let g (f : 'a one -> int) : int = f {x = 1} in g (fun r -> r.x) $
$ °\ocamlflags 00°
\end{program}

\OCaml uses \geninst-directional type inference as the
primary mechanism, but it also uses a weak form of bidirectional propagation: in this example the type of the argument of \code{g} is known \Geninst-directionally, but \OCaml then propagates this expected type within the function definition in bi-directional fashion, so that this example may be considered non-ambiguous.

Besides, the implementation of \geninst-directional type inference has an
algorithmic cost: for technical reasons, variable annotations must un-share
types (from acyclic graphs as naturally produced by unification to trees),
which may increase the size of types and the cost of type inference. For
that reason, the implementation of \OCaml cheats and is incomplete by
default. The user must explicitly pass the \texttt{\small -principal} flag to
require the more expensive computation of principal types when desired.

\paragraph{The relative completeness of directional type inference}

Both bidirectional and \geninst-directional type inference rely on an
ordering for type propagation that is partially specified, explicitly or
implicitly, to take advantage of user-provided type annotations and
already-inferred types to alleviated the need for extra annotations.
%
While they come with \emph{complete} algorithms, this is with respect to
their specifications, which include some choices that are subjective and may
sometimes look arbitrary.

\locallabelreset

Indeed, they all reject examples as ambiguous when sometimes there
would be a unique well-typed solution.
%
Let us illustrate these situations with a few more examples:
\begin{program}[input]
let e_6 r = (r.x, r.y)                          °\ocamlflags 10°
let e_7 r = let x = r.x in x + r.y              °\ocamlflags 10°
let e_8 = let getx r = r.x in getx {x = 1}      °\ocamlflags 10°
let e_9 r = (r.x : bool)                        °\ocamlflags 11°
let e_1_0 r = r.x.x                              °\ocamlflags 11°
\end{program}
All are arguably unambiguous; \OCaml accepts none of them\footnote{It
accepts \ocaml{e_6} with a warning, and fails if we reverse the order of the
type declarations.}, \OML accepts the first three.

In \ocaml{e_6}, \ocaml{r} can only be of type \ocaml{two}. Indeed,
considering the second projection first, we should learn that
\ocaml{r} is of type \ocaml{two} and since it is $\lambda$-bound, this
should then make the first projection unambiguous. Disambiguating this example is a matter
of solving the constraint in the right order.

A similar failure occurs in \ocaml{e_7}, where the type of the
$\lambda$-bound variable \code{r} is initially ambiguous and
unknown. It is only upon typing the projection \code{r.y} that
\code{r} is forced to have the type \ocaml{two}; this requires
inferring the $\Let$-body to disambiguate the $\Let$-definition.
%
In \code{e_8}, disambiguation information flows from an instance to
back the definition, opposite to the \Geninst-order; we call this
\emph{back-propagation}.

The example \ocaml{e_9} can be disambiguated from the return type of the
projection, rather than from its source. The typing rules for records that
we present on this work restrict disambiguation to the source type only and
rejects this example. But\Xdidier[we believe that]{Why not the affirmative?}
other typing rules using omni-directional type inference could support this
example as well.

Finally, \ocaml{e$_{10}$} is an example where none of the field
projections has enough type information to be disambiguated on its own, but the
constraints they impose can be combined to deduce that the type of
\ocaml{r} must be \ocaml{one}, as the \code{x} field of \code{two}
does not have a record type. This lies outside the framework of
omnidirectional type inference, in which suspended constraints must be
discharged one by one in some order, independently of other
still-suspended constraints.
%
We believe that this restriction is necessary for effective type inference,
since the complexity of general overloading without this restriction is
NP-hard, even in the absence of let-polymorphism, as shown by an encoding of
3-SAT problem by~\citet*
{Chargueraud-Bodin-Dunfield-Riboulet/jfla2025}.

\paragraph{Omnidirectional type inference}

In absence of \emph{implicit} polymorphism, type inference is solely based
on unification constraints which can be solved in any order;
omnidirectional inference is then natural and easy to implement.  The
difficulty originates from \ML \emph{implicit} let-polymorphism for which all known
implementations choose to always infer the type of a let-binding
first, to then turn it into a type scheme that is assigned to the
let-bound variable to extend the typing environment in which the body
is finally typed. The Hindley-Milner algorithm $\mathcal{J}$, one of
its variant $\mathcal{W}$ or $\mathcal{M}$~\cite
{Lee_Yi/algoM@toplas1998}, or more flexible constraint-based type
inference implementations~\citep* {Remy/mleth,Remy/thesis,
Odersky-Sulzmann-Wehr@tpos, Pottier-Remy/emlti} all follow this strategy, to
the best of our knowledge. However, this state of affairs is not a
necessity.

To efficiently achieve omnidirectional type inference for fragile \ML
extensions:
\begin{enumerate}

\item
  we introduce \emph{suspended match constraints} as a way to suspend
  ambiguity resolution until sufficient information has been found from
  context so that they can be discharged and hopefully resolved.

\item
  we work with \emph{partial types schemes}, \ie with the ability to
  instantiate type
  schemes that are not yet fully determined and consequently revisit their
  instances when they are being refined, incrementally. This allows
  inferring parts of a \texttt{let}-body to disambiguate its definition,
  without duplicating constraint-solving work.

\end{enumerate}

These technical devices are introduced once and for all---in a general
framework of constraint-based type inference. Each fragile \ML construct can
then be implemented by suspended constraints that expand to its robust
counterpart once the annotation has been inferred. This generality comes at
a cost, which is that everything is hard:
\begin{enumerate}

\item
  Giving an adequate semantics for suspended constraints is hard, as we
  must capture declaratively the intuition that some type information must be
  \emph{known} rather than \emph{guessed}, but also that some programs
  that are semantically non-ambiguous (there is a unique fully-annotated
  version that is well-typed) must still be rejected as ambiguous to prevent
  us from looking into suspended constraints.

\item
  Implementing partial types schemes (without duplicating constraint-solving
  work) is also hard.

\end{enumerate}
In return, the declarative semantics of suspended constraints
immediately suggests a systematic way to present user-facing typing rules
for each fragile construct, for which the implementation is correct and
complete.

\subsubsection* {Plan}

The rest of the paper is organized as follows.
\begin{enumerate*}[label={}]

\item
  In \cref{sec:constraints}, we give an overview of suspended constraints
  and their application to three extensions for \ML of various kind.

\item
  In \cref{sec:semantics}, we describe suspended constraints and their semantics.

\item
  In \cref{sec:language}, we define \OML, an extension of \ML featuring static
  overloading of record labels, overloaded tuple projections, and
  semi-explicit first-class polymorphism, sketch its typing rules,
  and states the theorems of soundness and completeness.
  By lack of space, detailed typing rules and constraint generation are
  postponed to \cref {app:oml-calculus}.

\item
  In \cref{sec:solving}, we provide a formal definition of our constraint
  solver as a series of non-deterministic rewriting rules.

\item
  In \cref{sec:discussion}, we discuss some extensions of suspended
  constraints that we have prototyped but whose theory is less clear.

\item
  In \cref{sec:related-work} and \cref{sec:future-work}, we discuss related
  and future work.

\end{enumerate*}
All proofs are postponed to appendices.

\subsubsection* {Our contributions}

Our contributions are
\begin{enumerate*}
\item
  A novel \emph{omnidirectional} type inference framework for
  extensions of \ML with advanced features, based on two new devices,
  suspended constraints and partial type schemes;

\item A declarative semantics of suspended constraints that captures the
  idea that they wait on information that must be propagated from the
  context, not \emph{guessed}.

  This includes, in particular, a new declarative caracterisation of
  \emph{known} type information.

\item
  A complete yet efficient constraint-solving type inference algorithm.

\item
  Three instantiation of our framework that give new declarative type
  systems and their implementation using suspended constraints for tuple
  projection in the style of \SML, static overloading of record fields and
  datatype constructors, and for semi-explicit first-class polymorphism.

\end{enumerate*}

\section{Suspended constraints: an overview}
\label{sec:constraints}

\begin{bnffig}[t]%
  {fig:constraint-syntax}%
  {Syntax of types and constraints}
\entryset[Type variables]{\tva, \tvb, \tvc}{\TyVars}{}
\\
%% \entryset[Types]{\t}{\Types}\\
\entry[Types]{\t}{
    \tv \and
    \tunit \and
    \ta \to \tb \color{gray} \and
    \Pi\iton \ti \and
    \T \tys \and
    \tpoly \ts
}\\
\entry[Type schemes]{\ts}{
    \t \and
    \all \tv \ts
}\\[1ex]
\entry[Constraints]{\c}{
        \ctrue
  \and  \cfalse
  \and  \ca \cand \cb
  \and  \cexists \tv \c
  \and 	\cfor \tv \c
  \and  \cunif \ta \tb
  \nextline
  \and  \clet \x \tv \ca \cb
  \and  \capp \x \t
  \nextline
  \and  \cmatch \t \cbrs
}\\[1ex]
\entry[Branches]{\cbr}{\cbranch \cpat \c} \\
\entry[Patterns]{\cpat}{}{} \\[1ex]
\entry[Constraint contexts]{\C}{
  \square
  \and \C \cand \c
  \and \c \cand \C
  \and \cexists \tv \C
  \and \cfor \tv \C
  \nextline
  \and \clet \x \tv \C \c
  \and \clet \x \tv \c \C
} \\
\entry[Shapes] {\Sh} {} {}
\\
\entry[Canonical principal shapes] {\sh} {} {}
\end{bnffig}

\parcomment{Syntax!}

The syntax of types and constraints is given
in~\Cref{fig:constraint-syntax}. Monotypes (or just types) are including, as
usual, type variables $\tv$, the unit type $\tunit$, arrow types, but
also\footnote {These are grayed, as they which will be introduced in the
following subsections.}  structural tuples $\Pi\iton \ti$, nominal
types\footnote {Type constructors are prefixed, except in \OCaml code, where
they are postfixed.}  $\T \tys$, and polytypes $\tpoly \ts$.  Type schemes
$\ts$ are of the form $\all \tvs \t$, they are equal up to the reordering of
binders. We write $\TyVars$ the set of type variables.

Building atop the constraint-based type inference framework of
\citet{Pottier-Remy/emlti}, we adopt a constraint language that includes both
term and type variables, described in~\Cref{fig:constraint-syntax}.

%
The constraint language contains tautological ($\ctrue$) and
unsatisfiable ($\cfalse$) constraints, conjunctions
($\ca \cand \cb$). The constraint form $(\cexists \tv \c)$ binds an
existentially quantified type variable $\tv$ in $\c$, while the
constraint $(\cfor \tv \c)$ binds $\tv$ universally. The constraint form
$(\cunif \ta \tb)$ asserts that the types $\ta$ and $\tb$ are
equal.
%
When $\ts$ is a polymorphic type scheme $\tfor \tvs \tp$, we use the
notation $(\cleq \ts \t)$ as syntactic sugar for the instantiation
constraint $\cexists \tvs \cunif \tp \t$.

\parcomment{Constraint abstractions}

Two constructs deal with the introduction and elimination of
constraint abstractions. A constraint abstraction $\cabs \tv \c$ can
simply be seen as a function which when applied to some type $\t$
returns $\c \where {\tv \is \t}$. Constraint abstractions are
introduced by a let-construct $(\clet \x \tv \ca \cb)$ which binds
the constraint abstraction to the term variable $\x$ in
$\cb$---additionally ensuring the abstraction is satisfiable. They
are eliminated using the application constraint $(\capp \x \t)$ which
applies the type $\t$ to the abstraction constraint bound to $x$.

\parcomment {Suspended match constraints}

Finally, we introduce \textit{suspended match constraints}.
%% \footnote
%% {Previously dubbed `frozen constraints'.
%% %in \citep{TODO} % this would be a de-anonymizing citation, silence it for now
%% }
$(\cmatch \t \cbrs)$. These constraints are \emph{suspended} until
until the \textit{shape} of $\t$, such as its top-level constructor,
is known. Then they are \emph{discharged}: a unique branch is selected
and its associated constraint has to be solved. A match constraint
that is never discharged is considered unsatisfiable.

More precisely:
\begin{enumerate}

\item
  The matchee $\t$ is a type. The constraint remains suspended
  while $\t$ is a type variable, that is,
  until the shape of $\t$ is determined.

\item
  $\cbrs$ is a list of branches of the form $\cbranch \cpat \c$,
  where $\cpat$ is a shape pattern. For example, the pattern
  $\tva \to \tvb$ matches function types, binding its domain and
  codomain to $\tva$ and $\tvb$, respectively. The constraint $\c$
  is then solved in the extended context.
  %
  To ensure determinism, the set of patterns $\bar \cpat$ must be
  \emph{disjoint}---that is, no shape may be matched by more
  than one pattern in the list.

\end{enumerate}

We keep the grammar of shapes and patterns abstract in this section, to
explain the general framework of suspended constraints. Shapes are
formalized in \cref{sec:semantics}. \Xdidier [We then introduce specific
shapes and patterns for specific language features in
\cref{sec:constraint-gen}.]{That's no more the case. So where do we
introduce shapes?}

\parcomment {Constraint contexts}

Throughout this paper, we will find it convenient to work with
\emph{constraint contexts}. A constraint context is simply a constraint with
a \emph{hole}, analogous to evaluation contexts $\E$ used extensively in
operational semantics. We write $\C\where{\c}$ to denote filling the hole of
the context $\C$ with the constraint $\c$. Hole filling may capture
variables.  Hence, we need explicit side-conditions when we mean to avoid
capture of a particular variable.

\paragraph{Suspended constraints in action}

The remainder of this section illustrates the role of suspended constraints
in supporting \emph{fragile} language features as defined above.
These include:
\begin{enumerate}
  \item Semi-explicit first-class polymorphism;
  \item Constructor and record label overloading for nominal algebraic
  datatypes;
  \item Overloaded tuple projection in the style of \SML.
\end{enumerate}
We demonstrate how the typability of each of these features can be elaborated
into constraints, formalized using a constraint generation function of the
form $\cinfer \e \tv$, which, given a term $e$ and expected type $\tv$,
produces a constraint $\c$ which is satisfiable if and only if $\e$ is
well-typed.
%
A formal account of the semantics of suspended constraints
is given in \cref{sec:semantics}.
The declarative typing rules for these features
are sketched in \cref{sec:language} with
details deferred to~\cref{sec/language/typing-rules}.

\subsection{Semi-explicit first-class polymorphism}
\label {sec/constraints/polytypes}

\parcomment {Intro (and annotations)}
Semi-explicit first-class polymorphism \citep{Garrigue-Remy/poly-ml} uses
\textit{annotated types} to track the origins of polymorphic types.
%
The type constructor $\tapoly \ts \av$ boxes a polymorphic type scheme
$\ts$, turning it into a \textit{polytype} annotated with the annotation
variable $\av$.  Once boxed, the polytype $\tapoly \ts \av$ is considered
a monotype, thereby enabling impredicative polymorphism. Annotation variables
may themselves be generalized, yielding type schemes such as
$\tfor \av {\tapoly \ts \av}$.

\parcomment {Boxing}

The introduction form for polytypes is a boxing operator $\expoly
\e \tvs \ts$ with an explicit polytype annotation $\exi \tvs \ts$
where the $\tvs$ are all the type variables that are free in
$\ts$.
%
The resulting expression has type $\tapoly {\ts \where {\tvs \is \tys}} \av$
where $\av$ is an arbitrary (typically fresh) annotation variable and $\tys$
are arbritraty types that replace the free variables $\tvs$.
The annotation variable $\av$ can thus be generalized.  That is $\expoly \e
\tvs \ts$ can also be assigned the type scheme $\all \av {\tapoly {\ts
\where {\tvs \is \tys}} \av}$.

\parcomment {Unboxing (principality restriction)}

Conversely, to instantiate a polytype expression, one must use an explicit
unboxing operator $\einst \e$, which requires no accompanying type
annotation.  However, the operator requires $e$ to have a polytype scheme of
the form $\all \av \tapoly \ts \av$ and then assigns $\einst \e$ a type
$\t$ that is an instance of $\ts$. If, by constrast, $\e$ has the type
$\tapoly \ts \av$ for some non-generalizable annotation variable $\av$, then
$\e$ is considered of a not-yet-known polytype, and therefore $\einst \e$ is
ill-typed.  It is precisely the polymorphism of $\av$ that ensures that the
polytype is indeed known and not being inferred.

\parcomment {Example ill-typed term}

For example, the expression $\efun \x {\einst \x}$ is not
typable. Indeed, the $\lambda$-bound variable $\x$ is assigned
a monotype. The only admissible type for $\x$ is $x : \tapoly \ts \av$
for some $\ts$ and $\av$.  Since $\av$ is bound in the surrounding
context at the point of typing $\einst \x$, it cannot be generalized
prior to unboxing, rendering the term ill-typed.

\parcomment {Annotations}

However, type annotations can be used to freshen annotation variables.
We usually omit annotation variables in annotations, since we can
implicitly introduce fresh ones in their place. For example,
$\efun {\x : \tapoly \ts {}} {\einst \x}$ which is syntactic sugar
for $\efun \x {\elet \x {(\x : \tapoly \ts {})} {\einst \x}}$, is
well-typed because the explicit annotation introduces a fresh
variable annotation $\ava$, which can then be generalized, yielding
$\tfor \ava {\tapoly \ts \ava}$.

This is the type-level feature that supports polymorphic methods and
polymorphic record fields in \OCaml. If a record type
\ocaml[mathescape=true]{$\tv$ t} has been declared with a single polymorphic
field
\ocaml[mathescape=true]{f} of type $\sigma$, then the record expression
\ocaml[mathescape=true]!{f = $e$}! desugars into
\ocaml[mathescape=true]!{f = $[e : \exists \tv. \ts]$}!,
and the record projection \ocaml{r.f} desugars into $\einst {\mathtt{r.f}}$.

\parcomment {Short commings of annotation variables}

The very purpose of annotation variables is to distinguish \emph{known},
polymorphic polytypes from \emph{not-yet-known}, monomorphic ones. However,
this may sometimes be unintuitive as some type information that has just been
inferred must still be considered as yet-unknown until its generalization.
This is also sensitive to the placement of type annotations, an artifact of the
fixed directionality of generalization in \geninst-directional inference. For
instance, the following two terms differ only in the position of the
annotation, yet only the one on the left-hand side is well-typed.
\begin{mathpar}
 \efun f {\eapp {\einst {(f : \tpoly {\tfor \tv {\tv \to \tv}})}} f}

\efun f {\eapp {\einst f} {(f : \tpoly {\tfor \tv {\tv \to \tv}})}}
\end{mathpar}
The difference lies in how generalization and annotation variables interact.
In the first term, the annotation occurs in an unboxing operator introducing
fresh annotation variables and may therefore be generalized to the type
scheme $\tfor \av {\tapoly {\tfor \tv {\tv \to \tv}} \av}$, enabling
unboxing to proceed. Whereas the second term applies the annotation to the
argument $f$, which fixes $f$'s type to the monotype $\tapoly {\tfor \tv
{\tv \to \tv}} \ava$ for some fresh annotation variable $\ava$. Because this
type is assigned to $f$ at its binding site, $\ava$ is bound in the context
when typing $\einst f$ and cannot be generalized, so the second term is
ill-typed despite the annotation.

\parcomment {Suspended match constraints fixes this}

Suspended match constraints eliminate this sensitivity to directionality
when type-checking $\einst e$. If $\e$ is already known to have the type
$[\ts]$, then we can simply
instantiate it.  However, if the type of $\e$ is not yet known, \ie  it is a
(possibly constrained) type variable $\tv$: then, we must defer until more
information is available. We capture this behaviour with a suspended match
constraint:
\begin{mathpar}
\cinfer {\einst \e} \tva \Wide\eqdef
    \cexists \tvb \cinfer \e \tvb
\cand
    \cmatch  \tvb {\parens {\cbranch {\tpoly s} s \leq \tva}}
\end{mathpar}
The match constraint is suspended until $\tvb$ is resolved to a polytype
$\tpoly \ts$ matching the pattern $\tpoly s$, which binds the type scheme
$\ts$ to the scheme variable $s$. The selected branch then performs the
instantiation $\cleq s \tva$, that is $\cleq \ts \tva$.
%
% If $\tvb$ is already known to be a polytype, the constraint discharges
% immediately and behaves like a standard instantiation constraint $\cleq \ts
% \tva$.
%
By waiting for the type of $e$ to be \emph{known}, we ensure principal types
without annotation variables.

\subsection{Static overloading of constuctors and record labels}

% What do we mean by static overloading?

\emph{Static overloading} denotes a form of overloading in which resolution is
performed entirely at compile time, enabling the compiler to select a unique
implementation without relying on runtime information---in contrast to
\emph{dynamic overloading}, which defers resolution to runtime via
mechanisms such as dictionary-passing or dynamic dispatch.

\parcomment {Other languages}

Many languages offer statically resolved overloading to avoid the overhead
of dynamic dispatch. C++ and Java resolve overloaded functions through
compile-time specialization based on argument types. Conversely, languages
like Rust and Haskell primarily employ dynamic overloading via traits and
type classes, respectively, which can incur runtime overhead unless
optimized away by monomorphization and aggressive inlining.

\parcomment {OCaml and OCaml's approach (PI-directionality)}

As noted in the introduction, \OCaml supports a limited yet useful form of
static overloading for record labels and datatype constructors. When
encountering overloaded labels or constructors, \OCaml resolves ambiguity
using local type information, guided by \geninst-directional
inference. Nominal types $\Tapp \tys$ carry annotation variables $\av$,
written $\Tapp^\av \tys$. As discussed in \cref{sec/constraints/polytypes},
this mechanism allows one to deduce that types polymorphic over their
annotation variable $\tfor \av {\Tapp^\av \tys}$ are \emph{known}.

\parcomment {A note on bidirectional expected type propagation}

Because static overloading involves more intricate flows of information than
polytype inference, \OCaml supplements \geninst-directionality with a limited,
ad-hoc form of bidirectional type inference. This mechanism is folklore; no
formal account has been given.

\parcomment {Closed-world reasoning}


Beyond propagation, \OCaml also exploits \emph{closed-world reasoning} to
resolve ambiguities in record types. For instance:
\begin{programsplit}
\begin{program}[input]
let e_1_1 = {x = 42; y = 13} °\ocamlflags 00°
\end{program}
\programjoin
\begin{program}[output]
val e$_{11}$ : two
\end{program}
\end{programsplit}
Here, \code{x} and \code{y} appear together only in the type \code{two},
allowing the type checker to unambiguously infer the type of \ocaml{e$_{11}$} as
\code{two}.

\parcomment {Default rules}

If local type information and closed-world reasoning are insufficient,
\OCaml falls back to a syntactic default: it selects the most recently
defined compatible type. For example:
\begin{programsplit}
\begin{program}[input]
let getx r = r.x         °\ocamlflags 01°
\end{program}
\programjoin
\begin{program}[output]
val getx : two -> int
\end{program}
\end{programsplit}
The expression is compatiable with both \code{one} and \code{two},
since each defines a field \code{x}. But \code{two} is chosen simply
because it appears later in the source.
We do not treat this behaviour as principal; accordingly, we provide
no formalization of such ``default'' rules, though their implementation is
discussed further in \cref{sec:discussion}.

This fallback mechanism highlights the directionality of \OCaml inference.
Once the compiler selects a type, it commits to it---even if that choice
causes errors downstream. Consider the example where we flip the order of the
definitions of \code{one} and \code{two}:
\begin{program}[input]
type two = {x : int; y : int}
type 'a one = {x : 'a}
let e_1_2 r = let x (* infers ['a one] *) = r.x in x + r.y °\ocamlflags 10°
\end{program}
\programjoin
\begin{program}[error, style=message]
Error: The expression has type "int one" There is no field "y" within "type one"
\end{program}

\parcomment {Record field disambiguation in suspended constraints}

We assume a global typing environment $\labenv$ mapping labels to type
schemes, written $\elab : \tfor \tvs \t \to \Tapp \tys \in \labenv$. A given
label $\elab$ may be defined several times in $\labenv$, but at most once at
a given record type~$\T$. We write $\labenv(\elab / \T)$ for the type scheme
of $\elab$ in $\T$ when it exists.

We propose an alternative account of static overloading using suspended
match constraints.  For example, in the case of an ambiguous record
projection $\efield \e \elab$, we generate the typing constraint:
\begin{mathpar}
\cinfer {\efield \e \elab} \tva \wide\eqdef
  \cexists \tvb \cinfer \e \tvb
  \cand
  \cmatch \tvb
      {\cbranch {(\Tapp \wild)}
	{\parens {\labenv(\elab / \T) \leq \tva \to \tvb}}
      }
\end{mathpar}
This constraint suspends resolution of the return type $\alpha$ until the
record type $\tvb$ of $\e$ is known. Its branch matches against the nominal
type pattern $\cpatrcd t$, binding the type constructor name to~$t$. Using
this, the appropriate type scheme for $\elab$ is retrieved from
$\labenv(\elab/t)$, instantiated, and the resulting constraints are imposed
on the domain and codomain of the field-access type.

\parcomment{Suspended constraints are better}

\OCaml programs that do not use the default rule are accepted by this
approach. Certain expressions, such as \code{e}$_{12}$ are well-typed under
our account but rejected by \OCaml's current type checker.

\subsection{Tuple projections \`a la \SML}

\SML supports positional projections from tuples using expressions of the form
\ocaml{#$j$ e} to extract the $j$-th component of the tuple \code{e}.
%
Internally, tuples in \SML are treated as structural records with numeric
labels, so \ocaml{(#$j$ e)} desugars into a structural record field access
\ocaml{e.$j$}: if $\e$ has the type $\tsrecord {j = \tj; \varrho}$, where
$\varrho$ is a row describing the remaining tuple fields, then $\eproj \e j$
has type $\tj$.

\SML enforces an additional restriction: the tail $\varrho$ must be fully
determined (\ie it cannot be a polymorphic row variable).  This ensures that
the arity of the tuple is \emph{known} statically from the surrounding
context, thereby avoiding the need for row polymorphism. The restriction is
not reflected in the typing rules themselves, but is instead enforced within
\SML's type inference algorithm.

\parcomment {Tuple projection is statically overloaded}

From a typing perspective, tuple projection in \SML behaves like a form
of static overloading: the expression $\eproj \e j$ is valid only when $\e$ is
known to be an $n$-ary tuple for some fixed $n \geq j$.

\parcomment {We can precisely specify this with suspended constraints}

We can capture the typing of tuple projections precisely using suspended
constraints. For the projection $\eproj \e j$, we generate the following
constraint:
\begin{mathpar}
  \cinfer {\eproj \e j } \tv \wide\eqdef
  \cexists \tvb
    \cinfer \e \tvb
    \cand \cmatch \tvb {\cbranch {\cpatprod \tvc j} {\cunif \tva \tvc}}
\end{mathpar}
\parcomment{Tuple patterns}
The suspended constraint $\cmatch \tvb {\cbranch {\cpatprod \tvc j} {\cunif
\tva \tvc}}$ blocks until the shape of $\e$ ($\tvb$) is known to be a tuple
of sufficient arity. The pattern $\cpatprod
\tvc j$ matches only tuple types $\tProd \ti$, where $n \geq j$, binding the
$j$-th component to $\tvc$, which is then unified with the expected result type
$\tva$.

\Xdidier
{Can we do better than \SML with \OML? ---I think not. Then, we should
say it explicitly!}
\Xgabriel{I don't know where to find a specification of how SML does
  overloading resolution -- Alistair said this was not terribly clear
  in the SML specification either. My \emph{guess} would be that there
  are examples that we support thanks to back-propagation, that are
  rejected in SML. I haven't bothered yet to install a SML
  implementation on my machine to find out, and my search for
  web-based SML toplevels were terribly inconclusive.}

\section{Semantics of constraints}
\label{sec:semantics}

To implement a type-checker using constraint-based type inference it
suffices to generate constraints from terms and to solve them. To study the
meta-theory of constraint generation and solving, we follow the standard
approach of defining \emph{semantics} for our constraints, as declarative as
possible. The existence of declarative semantics validates the design of the
constraint language.


In our work on suspended constraints, defining a satisfying semantics was
the hardest problem: it needs to capture what it means for type information
to be \emph{known}. Our semantics is declarative but not syntax-directed,
harder to manipulate than standard constraint semantics. On the upside, the
semantics directly suggest declarative typing rules for the surface
language.


\parcomment {Judgement shape}

The semantics of constraints follows the standard form of a satisfiability
judgment $\semenv \th \c$. The semantic environment $\semenv$ contains a
``guess'' for each free variable of $\c$ (type and term variable), and
$\semenv \th \c$ states that these guesses indeed satisfy $\c$. Let us write
$\Ground$ for the set of \emph{ground} types, types without free
variables.\footnote{Ground types are thus finite trees, assuming the
existence
%
of some base types such as $\tint$. In \cref{sec/rec-types}, we
discuss the alternative choice of regular trees for the set of ground
types that models equirecursive types.} $\semenv$ maps each type
variable $\tv$ to a ground types $\gt \in \Ground$, and each term
variable $x$ to sets of ground types $\gabs \subseteq \Ground$
(the set of ground instances of a type scheme for $\x$).
%
We write $\semenv\where{\tv \is \gt}$ and $\semenv\where{\x \is \gabs}$ for
the extension of $\semenv$ with a new binding. For a type $\t$, we write
$\semenv(\t)$ for the ground type obtained by substitution.

\parcomment {Definition exampled}

The judgment is defined in \cref{fig:constraint-semantics} for all
constraint-formers except suspended constraints; its definition on this
fragment is standard and somewhat tautological. $\ctrue$ is satisfied in any
environment, $\cfalse$ in none. An environment $\semenv$ satisfies $\ca
\cand \cb$ if it satisfies both $\ca$ and $\cb$. Satisfying $\cexists \tv
\c$ requires guessing a witness $\gt$ for $\tv$. The universal constraint
$\cfor \tv \c$ requires $\c$ to be satisfiable for any binding $\where{\tv \is \gt}$. The unification $\t_1 = \t_2$ is satisfied when
$\semenv(\t_1)$ and $\semenv(t_2)$ are equal.

The rule for $\clet \tv \ca \cb$ states that $\ca$ must satisfied under
\emph{some} instantiation of its bound variable, and that $\cb$ must be
satisfiable when $\x$ is bound $\cabs \tv \ca$, or rather its semantic
interpretation as a set of ground types.

An application constraints $\capp \x \t$ is interpreted by checking that $\t$
belongs to the set of types mapped to $\x$ in $\semenv$, that is, $\semenv(\t)
\in \semenv(\x)$. Note that when $\semenv(\x)$ is of the form
$\semenvp(\cabs \tv \c)$, where $\semenvp$ is the environment at the binding
site of $\x$, then $\semenv(\t) \in \semenv(x)$ holds iff
$\semenvp\where{\tv \is \semenv(\t)} \th \c$, which corresponds to the
intuition that the application $\capp {(\cabs \tv \c)} \t$ should be
equivalent to $\c \where {\tv \is \t}$.

\begin{mathparfig}[t]%
  {fig:constraint-semantics}%
  {Semantics of constraints (without suspended constraints)}
  \begin{bnfgrammar}
    \entry[Semantic environments]{\semenv}
    {\emptyset \and \semenv\where{\tv \is \gt} \and \semenv\where{\x \is \gabs}}
  \end{bnfgrammar}

  \infer[True]
    {}
    {\semenv \th \ctrue}

  \infer[Conj]
    {\semenv \th \ca \\
     \semenv \th \cb}
    {\semenv \th \ca \cand \cb}

  \infer[Exists]
    {\semenv\where{\tv \is \gt} \th \c}
    {\semenv \th \cexists \tv \c}

  \infer[Forall]
    {\forall \gt, ~ \semenv\where{\tv \is \gt} \th \c}
    {\semenv \th \tfor \tv \c}

  \infer[Unif]
    {\semenv(\ta) = \semenv(\tb)}
    {\semenv \th \cunif \ta \tb}

  \infer[Let]
    {\semenv \th \exists \tv. \ca \\
     \semenv\where{\x \is \semenv(\cabs \tv \ca)} \th \cb}
    {\semenv \th \clet \x \tv \ca \cb}

  \infer[App]
    {\semenv(\t) \in \semenv(\x)}
    {\semenv \th \capp x \t}

  \let \Eqdef\eqdef \def \eqdef {&\Eqdef&}
  \begin{array}{.r;;c;;l.}
  \semenv(\cabs \tv \c) \eqdef \set {\gt \in \Ground : \semenv\where{\tv \is \gt} \th \c}
  \\
  \ca \centails \cb \eqdef \forall \semenv,\ \semenv \th \ca \implies \semenv \th \cb
  \\
  \ca \cequiv \cb   \eqdef
  (\ca \centails \cb) \wide\wedge   (\ca \centails \cb)
  %% \forall \semenv,\ \semenv \th \ca \iff \semenv \th \cb
  \end{array}
\end{mathparfig}


Closed constraints are either satisfiable in any semantic environment (\ie
they are tautologies) or unsatisfiable. For example, the satisfiability of
the constraint $\cexists \tv {\cunif \tv \tint}$ is established by the
following derivation:
\begin{mathline}
  \infer*[Right=Exists]
    {\infer*[Right=Unif]
      {\infer*{}{\tint = \tint}}
      {\semenv\where{\tv \is \tint} \th \cunif \tv \tint}}
  {\semenv \th \cexists \tv \cunif \tv \tint}
\end{mathline}

% Equivalence and entailment

We write $\ca \centails \cb$ to express that $\ca$ \emph{entails} $\cb$,
meaning every solution $\semenv$ to $\ca$ is also a solution to $\cb$.
We write $\ca \cequiv \cb$ to indicate that $\ca$ and $\cb$ are equivalent,
that is, they have exactly the same set of solutions.

\subsection{Shapes
\label{sec/shapes}}

We introduce \emph{canonical shapes} for use in the syntax of suspended
constraints. It is a generalization of type constructors that is capable of
copying with polytypes---a polytype $(\forall \tvb. \tvb \to (\tva_1 \to
\tva_2))$ can be seen as a constructor-like structure $\any \tvc (\forall
\tvb. \tvb \to \tvc)$ applied with the argument $(\tva_1 \to
\tva_2)$. Canonical shapes $\sh$ are defined as a subset of shapes $\Sh$
satisying some minimality properties.

\parcomment {Definition of shape}

A shape $\Sh$ is a type with holes, written $\any \tvcs \t$, where $\tvcs$
denotes the set of type variables representing the holes.  By construction,
we require $\tvcs$ to be \emph{exactly} the free variables of $\t$.  Hence,
shapes are closed and do not contain useless binders.  We consider shapes up
to $\alpha$-conversion.  When $\t$ is a ground type, we omit the binder and
write simply $\t$.
%
tWe write $\bot$ for the shape $\any \tvc \tvc$, which we call the
\emph{trivial} shape. We write $\Shapesz$ the
set of non trivial shapes.
%% and use letter $\Sh$ to range
%% over non trivial shapes.

Shapes are equipped with the standard instantiation ordering, defined by:
\begin{mathpar}
  \infer[Inst-Shape]
    {\bar \tvcs_2 \disjoint \any {\tvcs_1} \t}
    {\any {\tvcs_1} \t \preceq
     \any {\tvcs_2} \t \where {\tvcs_1 \is \tys_1}}
\end{mathpar}
When writing $\Sh \preceq \Shp$, we say that $\Sh$ is more general than
$\Shp$. When $\Sh$ and $\Shp$ are more general than one another, they are
actually equal. The trivial shape $\bot$ is the most general shape.

If $\Sh$ is $\any \tvcs \t$, the shape application $\shapp[\Sh] \tys$ is
defined as $\t \where {\tvcs \is \tys}$. We say that $\Sh$ is a shape of
$\t$ when there exists $\tys$ such that $\t = \shapp[\Sh] \tys$; in this
case we write that the pair $(\Sh, \tys)$ is a decomposition of $\t$.

\begin{definition}
A non-trival shape $\Sh \in \Shapesz$ is the principal shape of the type
$\t$ iff:
\begin{enumerate}
  \item
    $\exists \typs,\ \t = \shapp[\Sh] \typs$
  \item
    $\forall \Shp \in \Shapesz, \forall \typs,\ \t = \shapp[\Shp] \typs
    \implies \Sh \preceq \Shp$
\end{enumerate}
\end{definition}

\begin{restatable}[Principal shapes]{theorem}{principalShapes}
  \label{th/shapes/principal}
Any non-variable type $\t$ has a non-trivial principal shape $\Sh$.
\end{restatable}

We can give an equivalent direct description of the set of principal shapes
$\sh$: they are the $\any \tvcs \t$:
\begin{itemize}

\item
  $\tvcs$ are the linear free variables of $\t$ \ie each type variable
  $\tvc$ in $\tvcs$ occurs exactly once in $\t$

\item
  $\t$ is shallow, which means the following for our particular type formers:
\begin{itemize}

\item
  When $\t$ is not a polytype, all subterms of $\t$ are variables.

  Shapes of this form are $\tvca \to \tvcb$, $\Pi\iton \tvci$, or $\T
  \tvcs$.

\item
  When $\t$ is a polytype $\tpoly {\all \tvs \tsp}$, then the only subterms of
  $\tsp$ that do not contain one of the $\tvs$
  are variables in $\tvcs$.

  \newcommand {\tsh}[1]
    {\def \tsi {\all \tvb {\parens{\tvb \to #1}} \tprod \tvb}
     \tpoly {\all \tva {\parens {\tpoly \tsi} \to \tva} \to \tva}}

  For example, the polytype $\tsh {\tint \tlist}$ has principal
  decomposition $\any \tvc {\tsh \tvc}$.
\end{itemize}
\end{itemize}

\parcomment {Define canonical shape}

A principal shape $\any \tvcs \t$ is \emph{canonical} if the sequence of its
free variables $\tvcs$ appear in the order in which the variables occur in
$\t$. We write $\sh$ for canonical principal shapes.
%
Each non-variable type $\t$ has a unique canonical principal shape, which we
write $\shape \t$. We write $\decomp \t$ for the decomposition of $\t$
induced by its canonical principal shape. For example, $\shape {\Tapp \tys}$
is $(\any \tvcs \Tapp \tvcs)$ and $\decomp {\tint \to \tbool}$ is the pair
$((\any {\tvca, \tvcb} {\tvca \to \tvcb}), (\tint, \tbool))$.

\subsection{Suspended constraints}

We have left the syntax of shape patterns deliberately abstract. We also
assume a matching relation
\begin{mathline}
  \cmatches \cpat \sh \tvcs \theta
\end{mathline}
This partial function matches a pattern $\cpat$ against a principal
shape $\sh$ opened with shape names $\tvcs$ (which must have the same
arity as $\sh$), yielding a substitution $\theta$. The substitution
binds the pattern variables to shape components, that may contain
occurrences of the shape variables $\tvcs$.
%
For our examples we define the trivial pattern $\cpatwild$ which matches
any shape and binds nothing:
\begin{mathline}
  \cmatches[\eqdef] \cpatwild \sh \tvcs \eset
\end{mathline}


\begin{definition}[Discharged constraint]
  Given a suspended constraint $(\cmatch \t \cbrs)$ and a canonical shape $\sh$, we introduce the syntactic sugar $(\cmatched \t \sh \cbrs)$ for the \emph{discharged constraint} that selects the branch in $\cbrs$ that matches $\sh$:
\begin{mathpar}
  \cmatched \t \sh {\cbranch \cpats \cs} \uad\eqdef\uad
    \cexists \tvs \cunif \t \shapp \tvs \cand \theta(\ci) \qquad \text{if }
    \cmatches \cpati \sh \tvs \theta
\end{mathpar}
The first conjunct ($\tau = \shapp \tvs$) ensures that $\sh$ is indeed
the canonical shape of $\t$, and the second conjunct is $\ci$ under
the appropriate substitution. The syntax of suspended match
constraints requires that branch patterns are non-overlapping, so the
matching branch $\cbranch \cpati \ci$ is uniquely determined; but it
may not exist as branches need not be exhaustive. The discharged
constraint is only defined when a matching $\cpati$ exists.
\end{definition}

\paragraph {A natural attempt}

To provide semantics for our suspended constraints, a first idea
is to propose the following rule---henceforth referred to as the
\emph{natural semantics} of suspended constraints:
\begin{mathpar}
\infer[Susp-Nat]
  {\sh = \shape {\semenv(\t)} \and \semenv \th \cmatched \t \sh \cbrs}
  {\semenv \th \cmatch \t \cbrs}
\end{mathpar}
This rule states that a suspended constraint is satisfied by $\semenv$ whenever the corresponding discharged constraint holds for the canonical shape $\sh$ of $\t$ in the semantic environment $\semenv$. If $\sh$ matches no branch in $\cbrs$, then the discharged constraint is not defined, so this rule cannot be applied and the suspended constraint is unsatisfiable.

% Consider the constraint $\cexists \tv \cunif \tv \tint \cand \cmatch \tv
% {\cbranch \cpatwild \ctrue}$. This is satisfiable, as intended, under the current
% semantics, as shown by the derivation:
% \begin{mathline}
% \def \cmatchex {\cmatch \tv {\cbranch \cpatwild \ctrue}}
% \def \semenvex {\semenv\where{\tv \is \tint}}
%     \infer*[Right=Conj]
%     {
%      \infer*[Left=Unif]
%       {\tint = \tint}
%       % -------------------------------
%       {\semenvex \th \cunif \tv \tint}
%      \\
%      \infer*[Right=Susp-Nat]
%       {
% 	\cmatches \cpatwild \tint \eset \eset
% 	\\
% 	\infer*[Right=True]
% 	  { }
% 	  % ---------------------
% 	  {\semenvex \th \ctrue}
%       }
%       % ------------------------
%       {\semenvex \th \cmatchex}
%     \hspace{-2em}
% }{% ---------------------
%     \infer*[Right=Exists]
%       {\semenvex \th \cunif \tv \tint \cand \cmatchex}
%     % ------------------------------------------------------------
%       {\semenv \th \cexists \tv \cunif \tv \tint \cand \cmatchex}
% }
% \end{mathline}

\parcomment {The problem}

This semantics rule is nicely declarative, but unfortunately it accepts to omany constraints. Consider for example: $\cexists \tv \cmatch \tv {\cbranch \cpatwild {\cunif \tv \tint}}$. It is satisfiable with this natural semantics:
\begin{mathpar}
\def \cmatchex {\cmatch \tv {\cbranch \cpatwild {\cunif \tv \tint}}}
\def \semenvex {\semenv\where{\tv \is \tint}}
    \infer*[Right=Susp-Nat]
    {
      \cmatches \cpatwild \tint \eset \eset
      \\
      \infer*[Right=Unif]
        {\tint = \tint}
	% -------------------------------
    {\semenvex \th \cunif \tv \tint}
}{% ---------------------------------
    \infer*[Right=Exists]
    {\semenvex \th \cmatchex}
  % -----------------------------------
  {\semenv \th \cexists \tv \cmatchex}
}
\end{mathpar}
The semantics can \emph{guess} the type of $\tv$ and use it to unlock the match constraint, rather than requiring it to be \emph{known} from the surrounding context. One could call the guess of $\cunif \tva \tint$ an ``out of thin air'' behavior. This does not match the intended meaning of suspended match constraints, and raises several problems:
\begin{enumerate*}

  \item A reasonable solver---one that avoids guessing or backtracking---cannot
    be complete with respect to this semantics.

  \item This breaks the existence of principal solutions.
    Consider the function $\efun \x (\efield \x 2)$, which projects the second
    component of a tuple. The natural semantics lets us to guess for $\x$ any tuple type of arity at least $2$; so there is no principal type for $\x$.
\end{enumerate*}

\paragraph {Contextual semantics}

To rule out guessing, we instead adopt a \emph{contextual} semantics in which the shape of a type must be known from the surrounding context in order to satisfy a match constraint. Its rule for suspended constraint is the only non-syntax-directed rule in our semantics:
\begin{mathpar}
  \infer[Susp-Ctx]
    {\Cshape \C \t \sh \\
      \semenv \th \C \where {\cmatched \t \sh \cbrs}
    }
    {\semenv \th \C \where {\cmatch \t \cbrs}}
\end{mathpar}
In this rule the shape $\sh$ is not guessed from $\semenv$, it must be determined from the constraint context $\C$. The \emph{unicity} condition $\Cshape \C \t \sh$, defined below, ensures that $\sh$ is known.

\begin{definition}[Erasure]
  We define the erasure $\cerase \c$ as the constraint
  where all suspended match constraints in $\c$  have been replaced by
  $\ctrue$; we define it in full in \cref{fig:constraint-erasure}
  (appendix).
\end{definition}

\begin{definition}[Simple constraints]
  We say that $\c$ is \emph{simple} if it does not contain any suspended match constraint. We write $\semenv \thsimple \c$ for a derivation of $\semenv \th \c$ that only uses the rules listed in \cref{fig:constraint-semantics}, without using \Rule{Susp-Ctx}. This judgment coincides with $\semenv \th \C$ on simple constraints.
\end{definition}

\begin{definition}[Unicity]
  We define the unicity condition $\Cshape \C t \sh$, which expresses that $\t$ has a unique canonical shape within the context $\C$, which is $\sh$.
  \begin{mathpar}
    \Cshape \C \t \sh \Wide\eqdef \forall \semenv, \gt. \uad
      \semenv \thsimple \cerase {\C\where{\cunif \t \gt}} \implies \shape \gt = \sh
  \end{mathpar}
\end{definition}

The use of erasure $\cerase {\C\where{\cunif \t \gt}}$ in the definition of $\Cshape \C t \sh$ ensures that the unicity of $\sh$ is determined only by the constraints that have already been discharged in $\C$, and cannot be justified from suspended constraints that will be discharged in the future. Implicitly, this induces a linear partial order between the suspended match constraints of a constraint, reflecting \emph{temporal} dependency: a match constraint may only be discharged once all of its dependencies have been discharged.

The erasure is a simple constraint so we use the
$(\thsimple)$ judgment, to avoid well-foundedness issues that would come from
a negative use of $(\th)$ in a premise of \Rule{Susp-Ctx}.
%
Note that, if $\t$ is not a variable, then $\Cshape \square \t \sh$
holds trivially for $\sh = \shape \t$. Also, if $\C$ is unsatisfiable,
then $\Cshape \C \tv \sh$ holds for any $\sh$. The interesting cases
arise when $\t$ is a type variable and $\C$ is satisfiable.

We summarize the definition of the unicity condition and the \Rule{Susp-Ctx} rule in \cref{fig:contextual-semantics}; together with \cref{fig:constraint-semantics} this forms the complete semantics of our consstraint language.

\begin{mathparfig}[t]
  {fig:contextual-semantics}
  {Semantics of suspended constraints}
\begin{array}{l}
\Cshape \C \t \sh \eqdef \forall \semenv, \gt. \\
\qquad
      \semenv \thsimple \cerase {\C\where{\cunif \t \gt}} \implies \shape \gt = \sh
\end{array}

  \infer[Susp-Ctx]
    {\Cshape \C \t \sh \\
      \semenv \th \C\where{\cmatched \t \sh \cbrs}
    }
    {\semenv \th \C\where{\cmatch \t \cbrs}}
\end{mathparfig}

\parcomment {Examples}

\begin{example}
Consider the two examples from above:
\begin{mathpar}
\cexists \tv \cunif \tv \tint
  \cand
  \cmatch \tv {\cbranch \cpatwild \ctrue}

  \cexists \tv \cmatch \tv {\cbranch \cpatwild {\cunif \tv \tint}}
\end{mathpar}
In the first example, we apply the contextual rule with the context $\C \is
(\exists \tv. \tv = \tint \cand \square)$. Any solution $\phi$ of this part
of the constraint necessarily satisfies $\tv = \tint$, so we have $\Cshape \C \tv \tint$ and the suspended constraint can be resolved.

In constrast, the second example has no contextual information around
the suspended constraint ($\C \is \square$), so any solution
$\semenv$ satisfies it, and $\semenv(\tv)$ can have an arbitrary shape, for example $\tint$ or $\tbool$. The uniqueness condition $\Cshape \C \tv \sh$ never holds and the constraint is unsatisfiable as intended.
\end{example}
\begin{example}
Consider the more intricate example:
\begin{mathpar}
  \cexists {\tva \tvb}
  \Parens{\begin{array}{l}
    \quad \cmatch \tva {\cbranch \cpatwild {\cunif \tvb \tbool}} \\
    {} \cand \cmatch \tvb {\cbranch \cpatwild \ctrue} \\
    {} \cand \tva = \tint
  \end{array}}
\end{mathpar}

Suppose we attempt to apply \Rule{Susp-Ctx} to the suspension on $\tvb$ first.
We want to show $\Cshape \C \tvb \tbool$ for the
context $\C \is \cmatch \tv {(\cbranch \cpatwild {\cunif \tvb \tbool})} \cand
\square \cand \cunif \tva \tint$. But the erasure $\cerase \C$ is $\ctrue \cand \square \cand \cunif \tva \tint$. In this constraint $\tvb$ is unconstrained, so for example $\cerase {\C {\cunif \tvb \tint}}$ and $\cerase {\C {\cunif \tvb \tbool}}$ are both satisfiable: unicity does not hold and \Rule{Susp-Ctx} cannot be applied.

Now consider instead applying \Rule{Susp-Ctx} to the suspension on $\tva$
first. To do, so, we must show that $\tva$ has a uniquely determined shape in
the context $\C \is \square \cand \cmatch \tvb {\cbranch \cpatwild \ctrue}
\cand \cunif \tva \tint$. The erasure $\cerase \C$ is
$(\square \cand \ctrue \cand \cunif \tva \tint)$. In this context $\tva$
is uniquely determined, so we have $\Cshape \C \tva \tint$.
%
We may now resolve the suspension on $\tva$: the discharged constraint $(\cmatched \tva \tint {\cbranch \cpatwild {\cunif \tvb \tbool}})$ is $(\tva = \tint \cand \cunif \tvb \tbool)$, so we are left to satisfy the constraint $\C \where {\tva = \tint \cand \cunif \tvb \tbool}$, that is,
$(\cunif \tva \tint \cand \cunif \tvb \tbool \cand \cmatch \tvb
{\cbranch \cpatwild \ctrue} \cand \cunif \tva \tint)$. At this point, we can
safely apply \Rule{Susp-Ctx} to the remaining match constraint on $\tvb$.
The unicity condition holds now that the erasure of the context includes the
discharged match constraint $\cunif \tvb \tbool$, so we can discharge
eliminating the second suspended match.

This demonstrates that suspended match constraints must be resolved in a
dependency-respecting order: attempting to resolve a match
constraint too early may result in unsatisfiability.
\end{example}

\begin{example}
Let us consider a constraint with a cyclic dependency between match
constraints:
\begin{mathpar}
  \cexists {\tva \tvb}
  \left(\begin{array}{l}
    \quad \cmatch \tva {\cbranch \cpatwild {\cunif \tvb \tbool}} \\
    {} \cand \cmatch \tvb {\cbranch \cpatwild {\cunif \tva \tint}}
  \end{array}\right)
\end{mathpar}
This constraint can be proved satisfiable under the ``natural semantics'' introduced
earlier: by guessing the assignment $\tva \is \tint, \tvb \is
\tbool$, the two matches suceed and the constraint holds. However,
our solver fails to solve it, as does our contextual semantics.

By symmetry we can try to apply \Rule{Susp-Ctx} on $\tva$ first: we
must show $\Cshape \C \tva \tint$ for the context
$\C \eqdef (\square \cand \cmatch \tvb {\cbranch \cpatwild {\cunif \tva \tint}})$. But
this unicity condition does not hold as the erasure
$\cerase \C = \square \cand \ctrue$ does not constrain $\tva$, so we cannot
apply the \Rule{Susp-Ctx} rule.
\end{example}

\begin{example}
Considering the example \code{e_7} from \cref{sec/introduction}:
\begin{program}[input]
let e_7 r = let x = r.x in x + r.y
\end{program}
The constraint generated when typing \code{e_7} contains the following, where $\tv$ stands for the type of \code{r}:
\begin{mathpar}
  \cexists \tv
    \clet x \tvb
      {(\cmatch \tva \dots)}
      {\cinst x \tint \cand \cunif \tv {\mathsf{two}}}
\end{mathpar}
The suspended constraint can be discharged under our semantics, as intended. We apply the
\Rule{Susp-Ctx} rule with context $\C \is \clet \x \tvb \square \capp \x
\tint \cand \cunif \tv {\mathsf{two}}$. Although the context includes a
\code{let}-binding --- which in practice involves let-generalization --- we
can still deduce $\Cshape \C \tv {\mathsf{two}}$, since the erased context $\cerase \C$ contains the unification $\cunif \tv
{\mathsf{two}}$.

This example illustrates that our formulation of suspended constraints
interacts nicely with \code{let}-polymorphism. Although the two features are
specified in a modular fashion, they are carefully crafted to work together,
as we will further show in our next example.
\end{example}

\begin{example}\label{ex:backprop}
A subtle yet crucial feature of our semantics is its support for
\emph{backpropagation}:
\begin{program}[input]
let e_8 = let getx r = r.x in getx { x = 1 }
\end{program}
As in the previous example the type of \code{r} cannot be disambiguated in the \code{let}-definition alone. In the previous example, this type was unified to a known shape in the \code{let}-body. Here this is more subtle: an \emph{instance} of the type scheme is taken, which is only well-typed if \code{r} has a variable type or a type of the form \lstinline[mathescape=true]{$\tva$ one}. The projection \code{r.x} would be forbidden if \code{r} had a variable type, so \lstinline[mathescape=true]{$\tva$ one} is the unique solution. We call \emph{backpropagation} the information flow from instances to definitions.

The constraint generated when typing
\code{e_8} is:
\begin{mathpar}
\begin{tabular}{L.L}
  \cexists \tv {}
  &\clet {getx} \tvd
     {\cexists {\tvb, \tvc} \Parens {\strut
        \cunif \tvd {\tvb \to \tvc} \cand
	\cmatch \tvb \dots
        }}{}
    \cinst {getx} {(\tint \ \mathsf{one} \to \tv)}
\end{tabular}
\end{mathpar}
With the context $\C$ equal to $\clet {getx}
\tvd {\cexists {\tvb, \tvc} \cunif \tvd {\tvb \to \tvc} \cand \square}
{\capp {getx} {(\tint \ \mathsf{one} \to \tv)}}$, we can show the unicity predicate $\Cshape \C \tvb \sh$ for the shape $\sh \eqdef (\any \tvc {\tvc~\mathsf{one}})$. :
\begin{mathpar}
  \all {\semenv, \gt} \uad
    \semenv \th \cerase {\C\where{\cunif \tvb \gt}} \implies \shape \gt = \sh
\end{mathpar}
For any $\semenv, \gt$, the erasure $\cerase {\C \where {\cunif \tvb \gt}}$ is
$\clet {getx}
\tvd {\cexists {\tvb, \tvc} \cunif \tvd {\tvb \to \tvc} \cand \cunif \tvb \gt}
{\capp {getx} {(\tint \ \mathsf{one} \to \tv)}}$. $getx$ is bound to the constraint abstraction $\cabs \tvd \exists \tvc.\uad \cunif \delta {(\gt \to \gamma)}$, so the instantiation $getx (\tint \ \mathsf{one} \to \tv)$ can only be satisfied when $\gt = \tint\ \mathsf{one}$. This proves unicity, so \code{e_7} is accepted by our semantics.
\end{example}

\section{The \OML calculus}
\label{sec:language}

\parcomment {Running example: tuple projection disambiguation}

\parcomment {We need a spec, but this itself is hard}

To show that the type-inference constraints we generate are correct,
we must first define a surface language and its type
system. Surprisngly, identifying an appropriate declarative type
system to use as a specification is itself an interesting problem!

\parcomment {Why do naive approaches not guarantee principal types.}

Na\"ive specifications, though accessible, often lack principal types. Take
overloaded tuple projections \ala \SML. We can ask the user to provide the length of the tuple explicitly, via an annotated syntax $\exfield \e n j$, which has a simple typing rule:
\begin{mathpar}
   \inferrule*
      {\G \th \e : \Pi\iton \ti \\ 1 \leq j \leq n }
      {\G \th \exfield \e n j : \tj}
\end{mathpar}

On the other hand, the natural typing rule for the fragile construct $\efield e j$ breaks principality:
\begin{mathpar}
  \infer
    {\G \th \e : \Pi\iton \ti \and 1 \leq j \leq n}
    {\G \th \efield \e j : \tj}
\end{mathpar}
The term $\efield e \j$ admits many typings, as any tuple of at least size $j$ satisfies the premise.
%
This is the exact same issue we had with the naive semantics of suspended constraints, and in fact we solve it in the same way, with a unicity condition and a contextual rule that transforms the fragile, implicit construct into the robust, explicit construct:
\begin{mathpar}
  \inferrule*
    {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\ \G \th E[\exfield \e n j] : \t}
    {\G \th \E[\efield \e j] : \t}
\end{mathpar}

We have to specify the condition $\eshape \E \e {\any \tvcs \Pi\iton \tvcs}$, which is the counterpart of our unicity condition $\Cshape \C \t \sh$ in the type system. We formally introduce it in the rest of this section; in fact the different fragile features need slightly different formulations of the unicity condition.

\subsection{Syntax}

\begin{bnffig}{fig/syntax}{Syntax of \OML}
\entry[Terms]{\e}{
  x \and
  () \and
  \efun x e \and
  \eapp \ea \eb \and
  \elet x \ea \eb \and
  \eannot \e \tvs \t \andcr
  \erecord {\overline{\el = \e} } \and
  \efield e \el \andcr
   (\ea, \ldots, \en) \and
   \efield e j \and
   \exfield e n j \andcr
   \epoly e \and
   \expoly e \tvs \ts \and
   \einst e \and
   \exinst e \tvs \ts
}\\
\entry[Labels]{l}{
  \elab \and \elab / \T
}\\[1ex]
\entry[Types]{\t}{
   \tv \and
   1 \and
   \tya \to \tyb \and
   \T \tys \and
   \Pi \iton \ti \and
   \tpoly \ts
}\\
\entry[Type schemes]{\ts}{
     \t \and
     \tfor \tv \ts
}\\
\entry[Contexts]{\G}{
   \eset \and
   \G, x : \ts
}\\
\end{bnffig}

In \cref {fig/syntax}, we give the grammar for our calculus. Terms include
all of the \ML calculus: variables $x$, the unit literal $\eunit$,
lambda-abstractions $\efun x e$, applications $\eapp \ea \eb$,
annotations $\eannot \e \tvs \t$ and let-bindings $\elet x \ea \eb$.
Our extensions include:
\begin{enumerate}
\item
  Constructor and record label disambiguation, modelled using record
  literals $\erecord { \ela = \ea; \ldots; \el_n = \en }$ and field
  projections $\efield \e l$.

\item
  Tuples $(\ea, \ldots, \en)$ with implicit projections
  $\efield \e j$ and explicit projections $\exfield \e j n$.

\item
  For semi-explicit first-class polymorphism, we have implicit and explicit boxing $\epoly \e$ and $\expoly \e \tvs \ts$, and implicit and explicit unboxing $\einst \e$ and $\exinst \e \tvs \ts$.

\end{enumerate}
We use the metavariables $\e^i$ or $\el^i$ to range over the fragile/implicit constructions, and $\e^x$ or $\el^x$ to range over their explicit counterpart.


\subsection{Unicity conditions in typing rules}

Our typing rules for implicit constructs are inspipred by the semantics: a contextual rule with a unicity condition, and an elaboration into an explicit rule. Our unicity conditions in typing rules request that the annotating shape is fully determined from the context, either from the type of the expression.
%
In order to define the unicity conditions, we introduce a \emph{typed
  hole} construct $\emagic \e$ that allows any well-typed expression
$\e$ to be treated as if it had any type:
\begin{mathpar}
  \inferrule[Magic]
    {\G \th \e : \t}
    {\G \th \emagic \e : \tp}
\end{mathpar}
Typed holes are not allowed in source terms and are just a device for
the definition of unicity conditions. We also introduce an erasure
function $\eerase \e$, the term counterpart of constraint erasure
$\cerase \c$, which erases all not-yet-elaborated implicit constructs
$\e^i$ in $\e$. They are replaced by their subterms placed into magic
casts, so that they must remain typeable but do not influence the output
type. For example $\eerase {\efield \e j}$ is $\emagic {\cerase \e}$;
the full definition is given in \cref{fig:defn-term-erasure}
(appendix).

We can now state that a shape is uniquely determined by the type of a context or an expression:
\begin{mathpar}
\def \Eqdef {&\eqdef&}
{\begin{tabular}{RCL}
\eshape E \e \sh \Eqdef
  \forall \G, \t, \gt, \uad
  \G \th \eerase {\E \where {\emagic {\eannot \e {} \gt }}} : \t
      \wide\implies \shape \gt = \sh
\\[1ex]
\Eshape E \e \sh \Eqdef
  \forall \G, \t, \gt, \uad
      \G \th \eerase {\E\where{\eannot {\emagic \e} {} \gt}} : \t
      \wide\implies \shape \gt = \sh
\end{tabular}}
\end{mathpar}
These states that the shape $\sh$ of expression $\e$ in context $\E$ is
determined by the expression $\e$, for $\eshape E \e \sh$, or by the context
$E$, for $\Eshape E \e \sh$.

\subsection{Typing rules and constraint generation}

We have detailed typing rules and a definition of constraint
generation for the full \OML calculus, but unfortunately they do not
fit in the margins of the 25 pages of this document. We moved them
all, along with detailed examples, in appendix
\cref{app:oml-calculus}.

Our typing judgment $\G \th \e : \t$ are mostly standard, except for
the typing rules for implicit/fragile constructs which use unicyt
conditions as explained above. We use the unicity condition
$\eshape E \e \sh$ for constructs that we disambiguate using the type
of their subterms, such as overloaded tuple and record projections or
polytype unboxing, and $\Eshape E \e \sh$ for constructs that we
disambiguate using the type of the context, such as polytype boxing,
or overloaded variant constructors if we described them.

Our constraint generation is defined as follows. Given a term $\e$ and
its expected type $\t$, which may contain some free type variables, we
define a constraint $\cinfer e \t$ that is satisfiable if and only if
the term is well-typed for some instantiation of those free type
variables. The constraint generation for implicit constructs used
suspended match constraints, with a language of patterns that is
specific to each feature. The generated constraints are very simple,
as suspended match constraints are doing all the work..

\subsection{Metatheory}
\label{sec:constraint-prop}

Constraint generation is sound and complete with respect to the typing judgment.
That is to say, the term $\e$ is typable with $\t$ if and only if
$\cinfer \e \tv$ is satisfiable when $\tv$ is $\t$.
%
\begin{theorem}[Constraint generation is sound and complete]
Given a closed term $\e$ and type $\t$. Then for any $\tv \disjoint \t$,
$\th \e : \t$ iff\/
$\cunif \tv \t \centails \csem {\e : \tv}$.
\end{theorem}

\begin{theorem}[Principal types]
  For any well-typed closed term $\e$, there exists a type $\t$, which we call principal, such that:
  \begin{enumerate}[(\roman*)]
    \item $\th \e : \t$.
    \item For any other typing $\th \e : \tp$, then $\tp = \theta(\t)$ for some substitution $\theta$.
  \end{enumerate}
\end{theorem}

It is also interesting to discuss the stability of typing by common program transformations.

\paragraph{Application equi-typability does hold}

\newcommand {\eswap}{\mathprefix  {swap}}
The expressions $\eappp f \ea \eb$ and $\eappp {\eswap f} \eb \ea$ are
equitypable where $\eswap$ is
$\efun f {\efun \xa {\efun \xb {\eappp f \xb \ea}}}$. We also have
that $\eapp f \e$ and $\eappp {\mathsf{app}} f \e$ and
$\eappp {\mathsf{rev\_app}} \e f$ are equitypable, where
$\mathsf{app}$ and $\mathsf{rev\_app}$ are the application function
$\efun f \efun \x \eapp f \x$ and the reverse application function
$\efun \x \efun f \eapp f \x$, respectively. It is well-known that
bidirectional types inference breaks application
equitypability. Both \Geninst-directional and omnidirectional
type inference preserve it.

\paragraph{Factorization does not hold} If $\G \th \e \where {\x \is {\e_0}} : \t$ and $\G \th \ez : \ts$, we do not necessarily have $\G \th \elet \x \ez \e : \t$. This is not a defect of our system, but a general property of all systems that support static overloading: the expanded term $\e \where {x \is \e_0}$ can pick a different overloading choice for each occurrence of $\e_0$, and if they are incompatible the factored form may not type-check.

\paragraph{Inlining does not hold} If $\G \th \elet \x \ez \e : \t$, we do not necessarily have $\G \th \e \where {\x \is {\e_0}} : \t$. This is specific to our support for \emph{back-propagation}: the $\Let$-form will use information from all occurences of $\x$ in $\e$ to resolve fragile constructs in $e_0$, but in the inlined form each copy of $\e$ must resolve its implicit constructs independently, it has access to less information to establish unicity.

\section{Solving constraints}
\label{sec:solving}

\parcomment{Intro}
We now present a machine for solving constraints in our language. The solver
operates as a rewriting system on constraints $\c \csolve \cp$. Once no further
transitions are applicable, \ie $\c \cnsolve$, the constraint $\c$ is either in
solved form---from which we can read off a most general solution---or the
solver becomes stuck, indicating that $\c$ is unsatisfiable.

\begin{definition}[Solved form $\hat\up$]
  \label{def:solved-form}
  A solved form is a constraint $\hat\up$ of the form $\cexists \tvs \cAnd
\iton \ueqi$, where:
\begin{enumerate*}
  \item each $\ueqi$ contains at most one non-variable type,
  \item head variables do not occur in multiple equations,
  \item the constraint is acyclic.
\end{enumerate*}
\end{definition}

\subsection{Unification}
%
Our constraints ultimately reduce to equations between types, which we solve
using first-order unification. Like our solver, we specify unification as a
non-deterministic rewriting relation between \emph{unification problems} $\upa
\unif \upb$, that eventually reduces to a solved form $\hat\up$ or to $\cfalse$.

\begin{mathparfig}[htpb!]
  {fig:unification-syntax-and-semantics}
  {Syntax and semantics of unification problems.
   %Constraints are also extended with the administrative multi-equation construct.
  }
\begin{minipage}[t]{0.45\textwidth}
\begin{bnfgrammar}
  \entry[Unification problems]{\up}{
    \ctrue \and \cfalse \and \upa \cand \upb \and \cexists \tv \up \and \ueq
  } \\
  \entry[Multi-equations]{\ueq}{
    \eset \mid \cunif \t \ueq
  } \\
  \entry[Constraints]{\c}{
    \dots \and \ueq
  }
\end{bnfgrammar}
\end{minipage}
\hspace{0.3\textwidth}
\begin{minipage}[t]{0.45\textwidth}
  \infer[Multi-Unif]
    {\all {\t \in \ueq}\, \semenv(\t) = \gt}
    {\semenv \th \ueq}
\end{minipage}
\end{mathparfig}

\parcomment{Unification problems and multi-equations}

Unification problems $\up$
(\cref{fig:unification-syntax-and-semantics}) are a restricted subset
of constraints, extended with \emph{multi-equations}
\citep{Pottier-Remy/emlti}---a multi-set of types considered
equal. These generalize binary equalities: $\semenv$ satisfies
a multi-equation $\ueq$ if all of its memebers are mapped to a single
ground type $\gt$ (Rule \Rule{Multi-Unif}). Multi-equations are
considered equal modulo permutation of their members.

Our algorithm is largely standard. For reasons of space we describe it in \cref{app:unification} (appendix).

\subsection{Solving rules}

% What we do (introduce / explain the solver)

We now gradually introduce the rules of the constraint solver itself (\cref{fig:}
and \cref{TODO}).
These rules define a non-deterministic rewriting
system, operating modulo $\alpha$-equivalence and the associativity and
commutativity of conjunction. $\C$ represents an arbitrary
one-hole constraint context.

% Solved forms
A constraint $C$ is satisfiable if rewrites into a solved form
$\hat\up$ (\cref{def:solved-form}). Otherwise it gets
stuck.

\paragraph{Basic rules}

\parcomment{Unification}

\Rule{S-Unif} invokes the unification algorithm to the
current unification problem. The unification algorithm itself is treated as a
black box by the solver, so the system could be extended with any
equational theory of types implemented by the unifier.
\begin{mathparfig}[htpb!]
  {fig:constraint-let-regions}
  {Syntax and semantics of region-based $\Let$ constraints.}
\begin{bnfgrammar}
 \entry[Constraints]{\c}{
    \dots \and \cletr \x \tv \tvs \ca \cb
  }
\end{bnfgrammar}
\\
  \infer[LetR]
    {\semenv \th \cexists {\tv, \tvs} \ca \\
     \semenv, \x \is \semenv(\cabsr \tv \tvs \ca) \th \cb}
    {\semenv \th \cletr \x \tv \tvs \ca \cb}

  \infer[AppR]
    {\greg \tv \semenvp \in \semenv(\x) \\
     \semenv(\t) = \semenvp(\tv) }
    {\semenv \th \capp \x \t}
\\
  \semenv(\cabsr \tv \tvs \c) \uad\eqdef\uad \set{\greg \tv {\semenv\where{\tv \is \gt, \tvs \is \gts}} \in \GroundRegion :
    \semenv\where{\tv \is \gt, \tvs \is \gts} \th \c}
\end{mathparfig}

\parcomment{Regional let constraints}

In general, existential quantifiers $\cexists \tv \c$ are lifted to the nearest
enclosing $\Let$, if one exists, or otherwise to the top of the constraint. The
resulting existential prefix $\exists \tvs$ is called a \emph{region}. To make
regions explicit, we introduce the syntax $\cletr \x \tv \tvs \ca \cb$, where
$\tv$ is the \emph{root} of the region and $\tvs$ are auxiliary existential
variables. The order of $\tvs$ is immaterial; regions are considered equal up
to permutation of these variables.

Satisfiability of regional $\Let$-constraints is defined in
\cref{fig:constraint-let-regions}. The semantics of an
abstraction with a region, written $\semenv(\cabsr \tv \tvs \c)$, is a set of
\emph{ground regions} that satisfy $\c$. A ground region is a satisfying
interpretation for the region $\semenvp$ with a designated \emph{root} variable
$\tv$, written $\greg \tv \semenvp$. Regional $\Let$-constraints strictly
generalize ordinary constraint abstractions, as captured by the equivalence:
\begin{mathline}
  (\clet \x \tv \ca \cb) \cequiv (\cletr \x \tv \eset \ca \cb)
\end{mathline}

\parcomment{Explaination of rules}

\Rule{S-Let} rewrites let constraints into regional
form.
%
\Rule{S-Exists-Conj} lifts existentials across conjunctions;
\Rule{S-Let-ExistsLeft} and \Rule{S-Let-ExistsRight} lift existentials across
let-binders; \Rule{S-Let-ConjLeft}, \Rule{S-Let-ConjRight} hoist
constraints out of let-binders when they are independent of the local
variables.
%
Collectively, these lifting rules normalize the structure of each
region into a block of existentially bound variables, whose body
consists of a conjunction of solved multi-equations followed by
a residual constraint---typically an application, let-binding, or
suspended constraint.

\begin{mathparfig}[htpb!]
  {fig:solver-basic}
  {Basic rewriting rules $\ca \csolve \cb$}
  \rewrite[S-Unif]
    {\upa \quad \upa \unif \upb}
    {\upb}

  \rewrite[S-False]
    {\C\where\cfalse \quad \C \neq \square}
    {\cfalse}

  \rewrite[S-Let]
    {\clet \x \tv \ca \cb}
    {\cletr \x \tv \eset \ca \cb}

  \rewrite[S-Exists-Conj]
    {(\cexists \alpha \ca) \cand \cb \quad
     \tv \disjoint \cb}
    {\cexists \tv {\ca \cand \cb}}
  \\
  \rewrite[S-Let-ExistsLeft]
    {\cletr \x \tv \tvs {\cexists \tvb \ca} \cb \\
     \tvb \disjoint \tv, \tvs, \cb}
    {\cletr \x \tv {\tvs, \tvb} \ca \cb}

  \rewrite[S-Let-ExistsRight]
    {\cletr \x \tv \tvs \ca {\cexists \tvb \cb} \\
     \tvb \disjoint \tv, \tvs, \cb}
    {\cexists \tvb {\clet \x \tvs \ca \cb}}
  \\
  \rewrite[S-Let-ConjLeft]
    {\cletr \x \tv \tvs {\ca \cand \cb} \cc \\
     \ca \disjoint \tv, \tvs}
    {\ca \cand \cletr \x \tv \tvs \cb \cc}

  \rewrite[S-Let-ConjRight]
    {\cletr \x \tv \tvs \ca (\cb \cand \cc) \\
     \x \disjoint \cc}
    {\cc \cand \Clet \x \tv \ca \cb}
\end{mathparfig}


\parcomment{OmniML constraints do not need dedicated rules}

\OML-specific constraints, such as the label and polytype instantiations from
\cref{sec:constraint-gen}, require no special treatment in our solver. Once
their pattern variables are substituted---after solving a match
constraint---they are desugared into constraints already handled by the solver.

\paragraph{Suspended match constraints}

\begin{mathparfig}
  {fig:solver-susp}
  {Rewriting rules for suspended match constraints.}
  \rewrite[S-Match-Type]
    {\cmatch \t \cbrs \\
     \t \notin \TyVars }
    {\cmatched \t {\shape \t} \cbrs}

  \rewrite[S-Match-Var]
    {\C\where{\cmatch \tv \cbrs} \\
     \cunif \tv {\cunif \t \ueq} \in \C}
    {\C\where{\cmatched \tv {\shape \t} \cbrs}}
\end{mathparfig}

\parcomment{S-Match-Type}

\Rule{S-Match-Type} solves suspended match constraints whose scrutinee is a
non-variable type $\t$ by rewriting them using the sugar $\cmatched \t {\shape \t}
\cbrs$, introduced in \cref{sec:constraints}. If no branch matches $\shape \t$,
the rule is stuck and the constraint is unsatisfiable.

\parcomment {S-Match-Var}

\Rule{S-Match-Var} applies when the scrutinee is a variable $\tv$ and
the context $\C$ proves that $\tv$ is equal to some non-variable type
$\t$, so we have the unicity property
$\Cshape \C \t {~\shape \t}$.

\paragraph{Let constraints}

% Let-constraint solving is generalization

\parcomment{Background on efficient solving of applications (aka generalization)}

Application constraints can be solved by copying constraints:
\begin{mathpar}
  \rewrite[S-Let-App-Beta]
    {\cletr \x \tv \tvs \ca {\C\where{\capp \x \t}} \\ \tv, \tvs \disjoint \t \\ x \disjoint \bvs \C}
    {\clet \x \tv \ca {\C\where{\cexists {\tv, \tvs} \cunif \tv \t \cand \ca}}}
\end{mathpar}
This resembles $\beta$-reduction, except that the original abstraction is
retained. While correct for simple constraints, it may duplicate solving work
across applications of the same abstraction.
%
A more efficient approach first solves the abstraction once---\eg reducing it
to $\cabsr \tv \tvs \ueqs$, where $\tvs$ are generalizable variables---and then
reuses the result at each application site by only copying the solved
constraint $\ueq$. This mirrors \ML generalization and instantiation, a
connection formalized by \citep{Pottier-Remy/emlti}, where $\cabsr \tv \tvs
\ueqs$ corresponds to the type scheme $\tfor \tvs {\sub(\tv)}$ and $\sub$ is
the \mgu of $\ueqs$. This optimization underlies efficient implementations of
\HM inference, such as \OCaml's.

\parcomment{Generalization with suspended constraints is hard}

However, this approach does not extend to suspended constraints. To illustrate
this, let us examine \ocaml{e_7} (from \cref{sec/introduction}):
\begin{program}[input]
  let e_7 r = let x = r.x in x + r.y °\ocamlcomment {\OML~- typechecks}°
\end{program}
The generated constraint\footnote{Simplified for readability.} is of the
form:
\begin{mathpar}
  \cexists \tv
    \clet x \tvb
      {\cmatch \tvb {\cbranch {(\cpatrcd \ct)} {\C\where {\ct,\tva,\tvb}}}}
      {\cinst x \tint \cand \cunif \tv {\mathsf{two}}}
\end{mathpar}
where $\C\where{\ct,\tv,\tvb}$ is ${\Omega(\elab / t) \leq \tva \to \tvb}$.
Here, $\tv$ stands for \code{r}'s type. The constraint remains suspended until
\code{r.y} forces \code{r}'s type to be \code{two}. Cruicially, the variable
$\tvb$ (introduced inside the abstraction for the type of \code{y}) is captured
by the suspended match constraint that is not yet resolved at the point of
solving the $\Let$ constraint that binds \code{x}.

\parcomment {Partial type schemes}
Nonetheless, to continue solving the let-body, we must assign a scheme to
\code{x}. We na\"ively pick $\tfor \tvb \tvb$. This appears unsound, since
$\tvb$ will later unify with $\tint$ once the match constraint is discharged.
But it would be incomplete to lower $\tvb$ as a monomorphic variable.
%
This motivates, \emph{partial type schemes}, our second novel mechanism for
omnidirectional inference. Partial type schemes are type schemes that delay
commitment to certain quantifications (\eg $\tvb$). Such \emph{partially
generalized} variables are treated as generalized, but can still be refined
in future as suspended constraints are discharged.

\begin{mathparfig}
  {fig:constraint-partial-app}
  {The syntax and semantics of partial instantiations.}
  \begin{bnfgrammar}
    \entry[Constraints]{\c}{
      \dots
      \and \cexistsi \inst \x \c
      \and \cpinst \inst \tv \t
    } \\
    \entry[Semantic environments]{\semenv}{
      \dots
      \and \semenv\where{\inst := \semenvp}
    }
  \end{bnfgrammar}
\\
\infer[Exists-Inst]
  {\greg \tv\semenvp \in \semenv(\x) \\
   \semenv\where{\inst \is \semenvp} \th \c}
  {\semenv \th \cexistsi \inst \x \c}

\infer[Partial-Inst]
  {\semenv(\inst)(\tv) = \semenv(\t) }
  {\semenv \th \cpinst \inst \tv \t}
\end{mathparfig}


\parcomment {Intro partial applications}

To support this, we extend the constraint language with \emph{partial
instantiation constraints}. Instead of duplicating an abstraction at each
application site, we introduce:
\begin{enumerate*}
  \item $\cexistsi \inst \x \c$, which binds a fresh instantiation $\inst$ of $\x$'s
    region within $\c$, and
  \item $\cpinst \inst \tv \t$, which asserts that the copy of $\tv$ in $\inst$
    equals $\t$.
\end{enumerate*}
%
The instantiation variable $\inst$ is required to ensure all partial
instantiations $\cpinst \inst \tv \t$ are solved uniformly. Within the solver,
we view partial instantiations as markers indicating which parts of the
abstraction still need to be copied.

Partial instantiations enables efficient incremental instantiation of
constraint abstractions: solved parts are reused immediately, while
suspended constraints can be solved later, further refining the
abstraction and propagation additional equations to the application
sites.

\parcomment{Semantics of partial applications}

The semantics of the existential constraint $\cexistsi \inst \x \c$
(\Rule{Exists-Inst}) introduces the fresh instantation $\inst$ by ``guessing''
a region $\semenvp$ that satisfies the regional constraint abstraction bound to
$\x$.
%
Partial instantiations (\Rule{Partial-Inst}) equate the copy of $\tv$ in
$\inst$ with $\t$.
%
The domain of partial instantiation constraints must lie within the closure of
the abstraction or among the regional variables of $\x$. Consequently, the
variables $\tv, \tvs$ bound by the $\Let$-constraint $\cletr \x \tv \tvs \ca
\cb$ are bound not only in the body of the abstraction $\ca$, but also in the
constraint $\cb$, where they may appear in partial instantiations of $\x$ via
renamings---and only there. Hence, they cannot appear in $\cb$ when the
corresponding variable $\x$ does not itself appear in $\cb$.

\parcomment{Solving partial instantiations}

Partial instantiation constraints are reduced using the following rules:
\begin{enumerate}

\item
  \Rule{S-Inst-Copy} copies the shape of a type to the instantiation site,
    introducing fresh variables for each subcomponents and marking them with
    corresponding instantiation constraints.
    %
    We write $\cpapp \x \tv \t \inst$ as a shorthand for $\cpinst \inst \tv \t$
    when $\inst$ is bound with $\exists \inst^\x$ in the context. To ensure
    termination, the abstraction must contain acyclic types.
    \Xgabriel{This is confusing when trying to read the rules directly. Could you instead stick to the $\inst^\x$ notation throughout, so that we only see $\cpinst {\inst^\x} \tv t$?}

  \item \Rule{S-Inst-Unify} unifies two instantiations if they refer to the
    same source variable.
\end{enumerate}
There are three cases in which an instantiation constraint is eliminated:
\begin{enumerate}
  \item A nullary shape is copied and no further instantiations are needed (\Rule{S-Inst-Copy}).

  \item The copied variable $\tvb$ is polymorphic, and thus the instantiation constraint
    imposes no restriction (\Rule{S-Inst-Poly}), provided no other instantiations of
    $\tvb$ remain (if not, then apply \Rule{S-Inst-Unify}).

  \item The copy is monomorphic and in scope, so we unify it directly (\Rule{S-Inst-Mono}).
\end{enumerate}


\begin{mathparfig}[htpb!]
  {fig:solver-schemes}
  {Select rewriting rules for let-bindings and applications.}
  \rewrite[S-Let-AppR]
    {\cletr \x \tv \tvs \c {\C\where{\capp \x \t}} \\
     \tvc \disjoint \t \\
     \x \disjoint \bvs \C}
    {\cletr \x \tv \tvs \c {\C\where{\cexistsi {\tvc, \inst} \x {\cunif \tvc \t \cand \cpinst \inst \tv \tvc}}}}

  \rewrite[S-Inst-Copy]
    {\cletr \x \tv \tvs {\c}
      \C\where{\cpapp \x \tvp \tvc \inst}\\
      \c = \cp \cand \cunif \tvp {\cunif {\shapp \tvbs} \ueq}\\
      \tvp \in \reg \tv \tvs \\
      \neg \cyclic {\c} \\
     \x \disjoint \bvs \C}
    {\cletr \x \tv \tvs {\c}
      \C\where{\cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}}

  \rewrite[S-Inst-Unify]
    {\cpinst \inst \tv \tvca \cand \cpinst \inst \tv \tvcb}
    {\cpinst \inst \tv \tvca \cand \cunif \tvca \tvcb}

  \rewrite[S-Inst-Poly]
    {\cletr \x \tv {\tvs, \tvp} {\ueqs \cand \c} {\C\where{\cpapp \x \tvp \tvc \inst}} \\
     \cfor \tvp \cexists {\tv, \tvs} {\ueqs} \cequiv \ctrue \\
     \tvp \disjoint \c, \insts \C \inst \\
     \x \disjoint \bvs \C}
    {\cletr \x \tv {\tvs,\tvp} {\ueqs \cand \c} {\C\where\ctrue}}

  \rewrite[S-Inst-Mono]
    {\cletr \x \tv \tvs \c {\C\where{\cpapp \x \tvb \tvc \inst}} \\
     \tvb \disjoint \tv, \tvs \\
     \x, \tvb \disjoint \bvs \C}
    {\cletr \x \tv \tvs \c {\C\where{\cunif \tvb \tvc}}}

  \rewrite[S-Let-Solve]
    {\cletr \x \tv \tvs \ueqs \c \\
     \cexists {\tv, \tvs} \ueqs \cequiv \ctrue \\
     \x \disjoint \c}
    {\c}

  \rewrite[S-Compress]
    {\cletr \x \tv {\tvs, \tvb} {\ca \cand \cunif \tvb {\cunif \tvc \ueq}} {\cb} \\ \tvb \neq \tvc}
    {\cletr \x \tv {\tvs} {\ca\where{\tvb \is \tvc} \cand \cunif \tvc {\ueq\where{\tvb \is \tvc}}} {\cb\where{\x.\tvb \is \tvc}}}

  \rewrite[S-Exists-Lower]
    {\cletr \x \tv {\tvas, \tvbs} \ca \cb \\
     \cdetermines {\cexists {\tv, \tvas} \ca} \tvbs \\
     }
    {\cexists \tvbs \cletr \x \tv \tvas \ca \cb}

  \rewrite[S-BackProp]
    {\C\where
       {\cletr \x \tv {\tvs} {\Ca\where{\cmatch \tvp \cbrs}}
                           {\Cb\where{\cpapp \x \tvp \tvc \inst}}} \\
    \tvp \in \reg \tv \tvs \\
     \cunif {\tvp} {\cunif \t \ueq} \in \C\where\Cb \\
     \x \disjoint \bvs \Cb}
    {\C\where{\cletr \x \tv {\tvs} {\Ca\where{\cmatched \tvp {\shape \t} \cbrs}}
		      {\Cb\where{\cpapp \x \tvp \tvc \inst}}}}
\end{mathparfig}


\parcomment{Cleaning up partial applications and let constraints}

\Rule{S-Let-Solve} remove a $\Let$ constraint when the bound term variable is
unused and the abstraction is satisfiable. \Rule{S-Compress} determines that a
regional variable $\tvb$ is an an alias for $\tvc$. We replace every free
occurrence of $\tvb$ with $\tvc$--- \emph{including} the domains of any partial
instantiation constraints, written as the substitution $\where{\x.\tvb \is
\tvc}$. We view this as an analogous copy rule for variables.

\parcomment{Lowering}

\Rule{S-Exists-Lower} implements the non-trivial case of lowering
existentials across $\Let$-binders. It identifies a subset of variables in
the region of a $\Let$ constraint that are unified with variables from
outside the region. Such variables are considered monomorphic and thus
cannot be generalized; they can instead be safely lowered to the outer
scope.

\parcomment {Determines}

This is the case when the types of $\tvbs$ are \emph{determined} in a unique
way. In short, $\c$ determines $\tvbs$ if and only if the solutions for
$\tvbs$ are uniquely fixed by the solutions to other variables in $\c$.

\begin{definition}
  $\cdetermines \c \tvbs$ if and only if every ground assignments
  $\semenv$ and $\semenvp$ that satisfy (the erasure of) $\c$ and coincide outside of $\tvb$
  concide on $\tvbs$ as well.
  \begin{mathpar}
    \cdetermines \c \tvb \uad\eqdef\uad \all {\semenv, \semenvp} \uad
      \semenv \th \cerase c
      \wedge \semenvp \th \cerase \c
      \wedge \semenv =_{\setminus \tvbs} \semenvp
      \implies
      \semenv = \semenvp
  \end{mathpar}
\end{definition}

\parcomment {How the determines relation corresponds to ML}

Conceptually, this corresponds to the negation of the generalization condition
in \ML: a type variable cannot be generalized if it appears in the typing
context. In the constraint setting, it cannot be generalized if it depends on
variables from outside the region.

\parcomment{How to decide the relation}

To decide when $\cdetermines {\cexists \tvs \c} \tvbs$ holds for $\tvbs
\disjoint \tvs$, we search for a multi-equation $\ueq$ in $\c$ of the form:
\begin{enumerate*}
  \item $\cunif \tvc \ueq'$ where $\tvc \disjoint \tvs, \tvbs$ and
    $\tvbs \subseteq \fvs {\ueq'}$, or
  \item $\cunif \tvbs {\cunif \t \ueq'}$ where $\fvs \t \disjoint
    \tvs, \tvbs$.
\end{enumerate*}
For instance, $\cexists \tvba \cunif \tv {\tvba \to \tvbb}$ determines
$\tvbb$, as $\tvbb$ is free.

\parcomment{Why we lower?}

Lowering such variables improves solver efficiency. It avoids unnecessary
duplication of work that would otherwise occur via \Rule{S-Inst-Copy}. By
reducing the number of variables that need to be copied, lowering directly
reduces instantiation overhead.

\paragraph{Backpropagation}

Finally, \Rule{S-BackProp} expresses \emph{backpropagation}, previously
illustrated in \cref{ex:backprop}. In particular, the shape of a regional
variable can sometimes be determined from its instantiations. If an abstraction
contains a suspended match constraint on a regional variable $\tvp$, and the
constraint context includes a partial instantiation $\cpapp \x \tvp \tvc \inst$
together with a multi-equation constraining the copy of $\tvp$ ($\tvc$)
to a non-variable type $\t$, then $\shape \t$ must be the unique shape of
$\tvp$. Any other shape would render the instantiation unsatisfiable.

\Xalistair{We should drop this if we cannot fit the two rules of interest in the main paper. }
\paragraph{Universal quantification}

Universally quantified constraints are solved using \emph{unification under a
mixed prefix}. Our rules (in \cref{TODO}) are entirely standard \citep{Pottier-Remy/emlti}
and are rather analogous to that of $\Let$ constraints. There are two failure
conditions: \Rule{S-All-Escape} detects that $\cfor \tvs \cexists \tvbs \c$ is
false if a rigid variable $\tv$ is indirectly dominated by a free variable $\delta$.
If so, the value of $\tv$ is determined by that of $\delta$---but, a universally
quantified variable ranges over all values, resulting in a contradiction;
\Rule{S-All-Rigid} occurs when $\tv$ is equated with a non-variable type.
This similarly partially determines the shape of $\tv$, contradicting $\tv$'s
universality.

% Properties

\begin{restatable}[Progress]{theorem}{progress}
  For any constraint $\c$, then either
  \begin{enumerate}[(\roman*)]
    \item $\c$ is solved.
    \item $\c$ is stuck: either $\cfalse$; $\hat\C\where{\capp \x \t}$ where $\x \disjoint \hat\C$; $\hat\C\where{\cpapp \x \tv \tvc \inst}$
      where $\x \disjoint \hat\C$ and $\insts {\hat\C} \inst = \eset$; $\hat\C\where{\cmatch \tv \cbrs}$ where $\nCshape {\hat\C} \tv \sh$
      for any shape. Here $\hat\C$ is a \emph{solved} context \ie no other rewrites can be applied.
    \item $\c \csolve \cp$ for some $\cp$.
  \end{enumerate}
\end{restatable}

\begin{restatable}[Termination]{theorem}{termination}
  The constraint solver terminates on all inputs.
\end{restatable}

\begin{restatable}[Preservation]{theorem}{preservation}
  If $\ca \csolve \cb$, then $\ca \cequiv \cb$.
\end{restatable}

\section{Implementation}
\label{sec:implementation}

We have a working prototype of a core \ML language with suspended
match constraints and partial generalization, in which we have
reproduced the various type-system features and examples presented in
this work. This prototype is public and open-source (link omitted for anonymity).

The implementation is inspired by previous work such as
Inferno~\citet*{inferno}. It uses state-of-the-art implementation
techniques for efficiency, such as a Union-Find data structure and the
use of \emph{ranks} (or \emph{levels}) for efficient
generalization. Let us discuss a few salient points.

\paragraph{Unification and scheduling} Each unsolved unification
variable maintains a \emph{wait list} of suspended constraints that
are blocked until the variable is unified with a concrete type. At
this point the wait list is flushed: the suspended constraints are
scheduled on the global constraint scheduler, which is responsible for
eventually solving them.

\paragraph{From a stack to a tree}
% To implement generalization (the \Rule{S-Lower-Exists} rule)
% efficiently, we follow the classic rank-based approach to
% generalization. Each $\Let$ constraint and type variable is allocated
% an integer \emph{rank}, which informs us the depth of the region
% within the constraint. Type variables of rank $0$ are bound at the
% top-level region, and type variables of rank $r \geq 1$ are bound in
% the region of $\Let$ constraint at depth $r$.

% As inference progresses, unification may widen the scope of variables,
% thereby lowering their rank. The set of variables eligible for
% generalization at a given region consists precisely of those
% whose rank remains equal to that of the region.

Many standard \ML implementations, for example Inferno, represent the
solver state as a linear \emph{stack} of inference regions, from the
outermost variable scope to the current region being inferred. Unification maintains an integer \emph{rank} (or \emph{level}) for each variable, that index a region in the stack.
%
This choice does not work for partial generalization. If
generalization at some region is suspended by a match constraint, the
region must remain alive while we restart inference in outer
regions. Later parts of the constraint may introduce a new
$\Let$-region at the same rank that is unrelated -- neither an
ancestor nor a descendant -- breaking the linear assumption of ranks.

Our implementation must instead use a \emph{tree} of nested
$\Let$-regions. Under this scheme, ranks no longer uniquely determine
a variable's region. Instead, we interpret a rank relative to a path in the region tree from the root. When two variables are
unified, they must always lie on some shared path---by scoping
invariants---so computing their minimum rank (along this path)
sufficies to determine the lowered region: we keep the efficient integer comparisons.

\paragraph{Partial generalization}

Partial generalization arises when a region cannot be fully
generalized due to suspended constraints that may still update
its variables. To manage this, we classify type variables
into four categories:

\begin{itemize}
  \item[\textbf{I}] Variables are yet to be generalized. \\
    \emph{Introduced by applications or source types in constraints}

  \item[\textbf{G}] Variables that are generalized. \\
    \emph{Not accessible from any instance type. Treated polymorphically.}

  \item[\textbf{PG}] Variables that are generalizable, but may be
    updated in the future. \\
    \emph{Variables mentioned by suspended match constraint or partial applications.}

  \item[\textbf{PI}] Variables that were previously partially generalized
    but have since been updated.  \\
    \emph{Awaiting re-generalization. Introduced by unification of partial generics.}
\end{itemize}

At generalization time, we conservatively approximate whether a variable may be
updated in the future using \emph{guards}. A guard is a mark on a variable that
indicates the variable is captured by some suspended constraint that has not
yet been solved. Guarded variables are generalized as partial generics (PG);
unguarded ones are fully generalized (G).

When an instance is taken from a partial generic, we retain a forward-reference
from the partial generic (PG) to the instance. This enables the generic to
notify the instance that it has been updated, propagating the updated type
structure to all instances. This is a reversed analogue of how partial
application constraints track renamings. In addition, the instance remains
guarded by the partial generic until the latter is either lowered or fully
generalized.

Once a suspended match constraint is solved, it removes the guard it
introduced. This may enable previously partial generics to become fully
generalizable. Conversely, if a partially generalized variable is lowered (\eg by \Rule{S-Lower-Exists}), it must be unified with all its instances.

\paragraph{Lazy generalization} Repeatedly generalzing a region after every update is expensive.  Instead we generalize on demand. We mark regions as ``stale'' when they may require re-generalization. When an instance is taken, we re-generalize the stale descendants of the region in the region tree.

\section{Discussion and Future Work}
\label{sec:discussion}
\label{sec:future-work}

\subsection{Other uses of suspended constraints}

We applied omnidirectional type inference to three features that have
already been used in some dialect of \ML, with specific typing rules we propose for each feature. Suspended match constraints can be used to encode other typing rules for those fragile features, and to support other features.

\citet*{Leijen-Ye/prefix@pldi2025} propose a general mechanism for overloading identifiers, with an implicit form $\eover \x$ and an explicit form $\exover \M \x$ prefixed by a disambiguation name $\M$. We can extend our approach to typing rules for this construct:
\begin{mathpar}
\infer [Over-X]{
    \exover \Mi \x : \t \in \G
}{% --------------------------
    \G \th \exover \Mi \x : \t
}

\infer [Over-I]{
    \G \th \Eshape \E \x \Sh  \\
    \G \th \E \where {\exover \M \x} : \t \\
    \exists !z.\ \Sh \leq \G(\exover \M \x)
}{% --------------------------------------
    \G \th \E \where {\eover \x} : \t
}
\end{mathpar}
The third premise of \Rule {Over-I} asks that there is a unique
explicit name $\exover \M \x$ that instantiates $\Sh$ in the
context. The framework we presented for \OML does not immediately
allow to implement these rules, as it only uses patterns that
discriminate on minimal (shallow) shapes, but it can be extended to support patterns on arbitrary shapes (as long as none is a prefix of another).

\subsection{Default rules}

Some type systems use type information to disambiguate fragile
construct, but also have a fallback mechanism to make a default,
non-principal choice when no type information is available. \OCaml
uses such a fallback when a field name cannot be disambiguated, it
selects the last declaration of a record type with this field in the
lexical scope.

To support this specification we considered
adding \emph{default rules} for suspended match constraints, that
would be selected instead of failing when a suspended constraint is
never discharged. This extension is however difficult to design, as it
would likely break principality.

If two suspended constraints could unlock each other, then defaulting
the first or the second one may result in different branches being
selected for one of them. A more robust strategy is to fire all
default rules of all suspended constraints that remain after the
solver terminates. A more permissive one is to fire defaults in the
minimal connected component for the dependency ordering between
suspended constraints.

\paragraph{Behavior of default rules} Giving priority to most recent
definitions is a possible default behavior for field and constructor
disambiguation. For structural tuples there is no reasonable default
rule.
%
For polytypes, one option is to fallback to a monomorphic polytype. The
other one is to pick the principal type scheme of the expression with an
unresolved polytype. Of course, there are examples that favor one choice
and other examples that favor the other.

\section{Related work}
\label{sec:related-work}


\paragraph{Principality tracking in \OCaml}
\citet*{Garrigue-Remy/poly-ml} introduced an approach to principality
tracking for polytypes, that has since be extended to other features
of the \OCaml language: whenever the type-checker wants to know if
a type is known in a robust way, it checks whether the type is
generalizable. We compare this approach to ours in
\cref{sec/constraints/polytypes}.

\paragraph{Qualified types} Qualified
types~\citep*{jones-qualified-types}, most well-known via their usage
in Haskell type-classes, are related to our suspended match
constraints as they represent constraints on types or type
variables. At generalization time, the constraints on generalizable
variables are kept as part of the generalized type scheme, and they
get copied during instantiation. This is much simpler to implement
than our partial generalization and partial instantiations, but it
provides a different behavior where each instance can choose
independently how to resolve the constraint. Qualified types are an
excellent choice when this is the desired behavior, typically for
dynamic overloading. We had to introduce the more complex partial
generalization to express features that require a unique resolution of
the constraint, typically for static overloading.

\paragraph{Suspended constraints in dependent-type systems}
Suspending the constraints that cannot be solved yet is not a novel
idea, it is a standard approach to implement unification
dependently-typed systems. This goes back to Huet's algorithm for
higher-order unification~\citep*{huet-unif}, where flexible-flexible
pairs are delayed until at least one side becomes rigid. The
contributions of our work are the combination with implicit
generalization, which is typically absent from those systems, and the
design of declarative semantics to establish principality.

\paragraph{Bidirectional type inference} At the level of simply-typed
terms or \ML, we believe that omni-directional inference works better
than bidirectional type inference: it can type more programs than
a given fixed bidirectional system, and has a more declarative
specification -- we would say that it is ``more principal''. In fact
a direct inspiration for the present work was a user complaint in
\citet*{rossberg-wasm} on the type-based disambiguation of \OCaml: its
bidirectional logic propagates type information from patterns to
definitions in \code{let}-bindings, when the WebAssembly reference
implementation would sometimes prefer the other direction.
%
% De-anonymizing URL: https://github.com/ocaml/ocaml/issues/7389
%
On the other hand, bidirectional typing is known to scale to powerful
systems such as fully-implicit predicative
polymorphism~\citep*{dunfield-krishnaswami-bidirectional-poly} and we
have not considered scaling our approach to those systems.

\paragraph{Leijen et al. (TODO change paragraph naming)}
Should we cite \cite{Leijen-Ye/prefix@pldi2025}?
\Xdidier{I'm volunteering to write this, but we are not sure we have to}.

\paragraph{\OutsideIn}

\OutsideIn \citep{conf/icfp/SchrijversJSV09} is a type system for GADTs that
introduces \emph{delayed implications} of the form $\where{\tvs}(\all \tvbs \ca
\Rightarrow \cb)$. Constraint solving for delayed implications proceeds in two
steps; solving simple constraints first and then solving delayed implications.
The deferall ensures that inference for GADT match branches occurs when more is
known about the scrutinee and expected return type from the context.
%
To ensure principality, \OutsideIn enforces an algorithmic
restriction: the variables $\tvs$ must already be instantiated to
concrete type constructors before they may be unified by the
implication's conclusion $\cb$. This ensures information only flows
from the outside into the implication's conclusion. They do not give
a declarative semantics for delayed implication that their solver
preserves. Moreover, later work on \OutsideIn argues
\citep{Vytiniotis-Peyton-Jones-Schrijvers-Sulzmann/outsidein@jfp2011}
that delayed implication constraints make local let-generalization all
but unmanagable, both in theory and implementation. Their proposed fix
is to abondon local let-generalization altogether. We believe that we
have solved the troubling interactions between let-generalization and
suspended constraints in this work, and would be interested in
studying applications to GADT typing, which was also one of our
original motivations.

% \begin{acks}
% \end{acks}

\Xgabriel{No conclusion? I'm fine with this, and it takes less space than having a conclusion.}

%% \bibliographystyle{ACM-Reference-Format}
\bibliography{suspended}

\newpage
\appendix

\section{The \OML calculus: typing rules and constraint generation}
\label{app:oml-calculus}

\subsection{Typing rules}
\label{sec/language/typing-rules}

As usual, the main typing judgment $\G \th \e : \ts$ states that in context
$\G$, expression $\e$ has type scheme $\ts$.  Typing rules are given on \cref
{fig/typing}.  They use auxiliary typing judgemnents $\G \th \elab = \e : \t$
and $\G \th \el : \t \to \tp$ for the typing of record assignments and
label instantiations respectively.

\begin{mathparfig}{fig/typing}{Typing rules of \OML}
  \inferrule[Var]
    {x : \sigma \in \G}
    {\G \th x : \sigma}

  \inferrule[Fun]
    {\G, x : \ta \th e : \tb }
    {\G \th \efun x e : \ta \to \tb}

  \inferrule[App]
    {\G \th \ea : \ta \to \tb \\
     \G \th \eb : \ta}
    {\G \th \eapp \ea \eb : \tb}

  \inferrule[Unit]
    {}
    {\G \th () : 1}

  \inferrule[Annot]
    {\G \th e : \t\where {\tvs \is \tys}}
    {\G \th (e : \exi \tvs \t) : \t\where {\tvs \is \tys}}

  \inferrule[Gen]
    {\G \th e : \sigma \\ \tv \disjoint \G}
    {\G \th e : \tfor \tv \sigma}

  \inferrule[Inst]
    {\G \th e : \tfor \tv \ts}
    {\G \th e : \ts \where{\tv \is \t}}

  \inferrule[Let]
    {\G \th \ea : \sigma \\
     \G, x : \sigma \th \eb : \t}
    {\G \th \elet x \ea \eb : \t}

  \inferrule[Tuple]
    {\parens{\G \th \ei : \ti}\iton}
    {\G \th (\ea, \ldots, \en) : \Pi\iton \ti}

  \inferrule[Proj-X]
    {\G \th \e : \Pi\iton \ti \\
     1 \leq j \leq n}
    {\G \th \exfield \e n j : \tj}

  \inferrule[Proj-I]
    {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\
     \G \th \E\where{\exfield \e n j} : \t}
    {\G \th \E\where{\efield \e j} : \t}

  \inferrule [Poly-X]
    {\G \th \e : \ts\where {\tvs \is \tys}}
    {\G \th \epoly[\exi \tvs \ts] \e : \tpoly {\ts \where {\tvs \is \tys}}}

  \inferrule [Poly-I]
    {\Eshape \E \e {{\any \tvcs \tpoly \ts}} \\
     \G \th \E \where{\epoly[\exi \tvcs \ts] \e} : \t}
    {\G \th \E \where{\epoly \e} : \t}

  \inferrule [Use-X]
    {\G \th \e : \tpoly \ts \where {\tvs \is \tys}}
    {\G \th \exinst e \tvs \ts : \ts \where {\tvs \is \tys}}

  \inferrule [Use-I]
    {\eshape \E  \e {\any \tvcs \tpoly \ts} \\
     \G \th \E\where{\exinst \e \tvcs \ts} : \t}
    {\G \th \E\where{\einst \e} : \t}

  \inferrule[Rcd-Assn]
    {\G \th \e : \t \\
     \G \th \el : \t \to \tp}
    {\G \th \el = \e : \tp}

  \inferrule[Rcd]
    {\parens{\G \th \eli = \ei : \t}\iton \\
     \G \th \bar \el \uni \t}
    {\G \th \erecord {\ela = \ea; \ldots; \el_n = \en} : \t}

  \inferrule[Rcd-Proj]
    {\G \th \e : \tp \\
     \G \th \el : \t \to \tp \\
     \G \th \el \uni \t }
    {\G \th \efield \e \el : \t}

  \inferrule[Lab-X]
    {\Omega(\elab / \T) = \tfor \tvs \t \to \T \tvs }
    {\G \th \elab / \T : \tys\where{\tvs \is \tys} \to \T \tys}

  \inferrule[Lab-I]
    {\Lshape \Lab \elab \T \\
      \G \th \Lab[\elab / \T] : \t}
    {\G \th \Lab[\elab] : \t}

  \inferrule[Lab-!]
    {\bar \el \uni {\T} \in \labenv}
    {\G \th \bar \el \uni \T \tys}

  \inferrule[Lab-?]
    {\G \th \t}
    {\G \th \bar \el \uni \t}
\end{mathparfig}

\TODO{We should consider handling the three features (tuples, records, polytypes) separately, one in each subsection.
If we later run out of space budget it will be easier to move only some of those subsections to an appendix.
Concrete proposal:
\begin{itemize}
\item one subsection at the beginning that only hints at the standard ML stuff:
  show the syntax, hint at typing rules, show a short bit of constraint generation
\item then each advanced feature (from the simplest to the more complex: tuples, polytypes, records)
  show the typing rules, and examples, and its dedicated patterns, and its constraint generation
\end{itemize}}

\begin{version}{}
\begin{bnffig}{fig/types/bnf}{aaa}
\entry[Types]{\t}{
    \tv \and
    \tunit \and
    \t \to \t \and
    \Pi \parens \t\iton \and
    \T \tys \and
    \tpoly \ts
}
\end{bnffig}

\begin{mathparfig}
  {fig/types/wf}
  {Well-formedness of types}
  \inferrule[Var-Wf]
    {\tv \in \G}
    {\G \th \tv}

  \inferrule[Unit-Wf]
    {}
    {\G \th \tunit}

  \inferrule[Arr-Wf]
    {\G \th \t \\ \G \th \tp}
    {\G \th \t \to \tp}

  \inferrule[Prod-Wf]
    {(\G \th \ti)\iton}
    {\G \th \Pi\iton \ti}

  \inferrule[Rcd-Wf]
    {(\G \th \ti)\iton \\
     {\T} \in \dom \Omega}
    {\G \th \T \tys}

  \inferrule[Poly-Wf]
    {\G \th \ts}
    {\G \th \tpoly \ts}

  \inferrule[Forall-Wf]
    {\G, \tv \th \ts}
    {\G \th \tfor \tv \ts}
\end{mathparfig}
\end{version}


\parcomment {Simple typing rules explained}

Rule \Rule{Var} retrieves the type scheme $\x : \ts$ from the context $\G$.
Function types are introduced via lambda abstractions: in Rule \Rule{Fun}, the
system guesses a well-formed type $\ta$ for the type of $x$, typechecks the
body $e$ is under the extended context $\G, \x : \tya$ producing the return
type $\tyb$, and assigns the abstraction the function type $\tya \to \tyb$.
Conversely, function types are eliminated by applications; in Rule \Rule{App},
the type of the argument must match the function's parameter type $\tya$ and
application returns the type $\tyb$. Rule \Rule{Unit} asserts that $\eunit$ has
the unit type $\tunit$.

\parcomment {Gen/Inst explained}

Rules \Rule{Gen} and \Rule{Inst} correspond to implicit
\textit{generalization} and \textit{instantiation} respectively.
Generalization universally quantifies a type variable $\tv$, introducing it
as a fresh polymorphic variable in the typing context. In \Rule{Inst}, we
specialize a type scheme $\tfor \tv \ts$ to $\ts \where{\tv \is \t}$,
substituting $\tv$ for an arbitrary monotype $\t$.

\parcomment {Let rule}

Let-polymorphism is handled by the \Rule{Let} rule, where a
\textit{polymorphic} term can be bound. This allows a single definition to be
instantiated differently at each use site---an essential feature of \ML. In
this rule, the term $\ea$ has a polymorphic type scheme $\ts$, adds $\x :
\ts$ into the context $\G$ to typecheck $\eb$.

\parcomment {Annotations}

Annotations $(e : \exi \tvs \t)$ ensures that the type of $e$ is (an instance
of) the type $\t$. The type variables $\tvs$ are \emph{flexibly} (or
existentially) bound in $\t$, meaning that $\tvs$ may be unified with some
types $\tys$ to produce a well-typed term. For instance, the term $(\efun x x
+ 1 : \exi \tv \tv \to \tv)$ is well-typed with $\tv := \tint$ in
\Rule{Annot}.

\parcomment {Contextual rules (Poly-*, Use-*, Proj-*)}

\paragraph{Polytypes and overloaded tuples}
The typing rules for fully annotated terms ($\e^x$) are unsurprising.
However, typing rules for terms with omitted type annotations are
non-compositional as they depend on a surrounding one-hole context
$\E$. Hence, they assert that the typability of the expression $\G \th \E
\where {\e^i}: \t$ where $\e^i$ is an expression with an implicit type
annotation.
%
We first request a typing for the expression with an explicit annotation $\G
\th \E \where {\e^x}: \t$ where $\e^x$ is a fully annotated variant of $\e^i$.
We then request that (the shape of) the annotation is fully determined from
context, either from the type of the expression, which we write $\eshape \E
\e \sh$, or from the type of the hole, which we write $\Eshape \E \e \sh$.

In order to describe the judgments $\eshape \E \e \sh$ and $\Eshape \E \e \sh$,
we introduce a \emph{typed hole} construct $\emagic \e$ that allows any
well-typed expression $\e$ to be treated as if it had any type. That is the
typing rule for holes is:
\begin{mathpar}
  \inferrule[Magic]
    {\G \th \e : \t}
    {\G \th \emagic \e : \tp}
\end{mathpar}
\TODO{This rule should go in a figure dedicated to the various magic rules.}
Typed holes are not allowed on source terms and are just a device for
the definition of non-ambiguous shapes.  Finally, we define what it means for a
shape to be determined from the type of a context or an expression:
\begin{mathpar}
\def \Eqdef {&\eqdef&}
{\begin{tabular}{RCL}
\eshape E \e \sh \Eqdef
  \forall \G, \t, \gt, \uad
  \G \th \eerase {\E \where {\emagic {\eannot \e {} \gt }}} : \t
      \wide\implies \shape \gt = \sh
\\[1ex]
\Eshape E \e \sh \Eqdef
  \forall \G, \t, \gt, \uad
      \G \th \eerase {\E\where{\eannot {\emagic \e} {} \gt}} : \t
      \wide\implies \shape \gt = \sh
\end{tabular}}
\end{mathpar}
These states that the shape $\sh$ of expression $\e$ in context $\E$ is
determined by the expression $\e$, in the former case, or by the context
$\E$ in the latter case. Just like constraints, we must erase implicit constructs
in the term that have not yet been elaborated, written $\eerase \e$ (defined in
??).

%% Shapes are equal modulo alpha equivalence and the removal of useless
%% polymorphic type variables. They do not have useless existential variables.

% Expression-based implicit rules

The implicit rule \Rule{Proj-I} types the projection $\eproj \e j$ provided the
context $\E$ \emph{infers} that the shape of $\e$ must be a tuple with arity $n$.
Similarly, \Rule{Use-I} permits instantiating a polytype in $\einst e$ if
the context $\E$ infers that the type of $\e$ must be a polytype with shape
$\any \tvcs \tpoly \ts$. The rule \Rule{Poly-I} types the implicit boxing
construct $\epoly \e$ by \emph{checking} the expected type of $\epoly \e$ in the
context $\E$ is a polytype with the shape $\any \tvcs \tpoly \ts$. This rule
differs from the previous two as the shape is determined by the expected type
within the context as opposed to the inferred type of $\e$.


% Labels

\paragraph{Overloaded record labels}
% Contextual rules
We adopt a similar non-compositional approach for elaborating overloaded
labels, whether in record projection ($\efield e \elab$) or record
construction ($\erecord {\overline{\elab = \e}}$), although the definitions
are slighly more involved.  Here, a one-hole label context $\Lab$ provides the
surrounding context in which a label $\elab$ may appear:
\begin{mathpar}
\begin{bnfgrammar}
\entry [Label contexts]{\Lab}{
    \E \where {\e.\square} \and
    \E \where
         {\erecord
            {\ela = \ea; \ldots; \square = \ei ; \ldots; \el_n = \en}
         }
}
\end{bnfgrammar}
\end{mathpar}

As with our contextual rules for expressions, we define two rules for labels.
\Rule{Lab-X} handles explicitly annotated labels $\elab / \T$ by instantiating
the type scheme $\tfor \tvs \t \to \T \tvs$ associated with $\elab$ in label
environment $\labenv$. \Rule{Lab-I} handles unannotated labels by elaborating
$\elab$ to $\elab / \T$ if the context $\Lab$ uniquely infers the record type
$\T$ for $\elab$ and the resulting elaboration is well-typed.

The unicity of the inferred record type is captured by the judgement $\Lshape
\Lab \elab \T$. The definition fits into the framework we established for
expressions above by introducing analogous annotation and hole constructs for
labels.
\begin{mathpar}
  \infer[Lab-Magic]
    {}
    {\G \th \elmagic \elab : \tp \to \t}

  \infer[Lab-Annot]
    {\G \th \el : \tp \to \t\where{\tvs \is \tys}}
    {\G \th \elannot \el \tvs \t : \tp \to \t\where{\tvs \is \tys}}

\\
\Eshape \Lab \elab \T \Wide\eqdef
   \forall \G, \t, \gt , \uad
     \G \th \eerase {\Lab[\elannot {\elmagic \elab} {} \gt]} : \t
	\implies \shape \gt= \any \tvcs {\tvcs \T}
\end{mathpar}

% Rules
\Rule{Rcd} types a record $\erecord {\overline{\el = \e}}$ as a record type
$\t$ provided that each field assignment $\el = \e$ can be assigned the record
type $\t$.
\Rule{Rcd-Assn} checks that $\e$ has the appropriate field type in $\el = \e$
and returns the instantiated record type $\tp$ for the label $\el$.
\Rule{Rcd-Proj} types the projection $\efield \e \el$ by checking that the
type of $\e$ matches the record type associated with label $\el$, returning
the field type $\t$.

% Closed world reasoning
Both \Rule{Rcd} and \Rule{Rcd-Proj} impose additional constraints on their
record types to support \emph{closed-world} reasoning. These constraints
exploit the uniqueness of type definitions in the global label environment
$\labenv$ to resolve overloaded labels:
\begin{enumerate*}
\item
  in a record projection $\efield \e \elab$, if the label $\elab$ is not
  overloaded, then the global record typing context $\labenv$ assigns a
  unqiue record type $\T$ to $\elab$;

\item
  in a record expression $\erecord {\ela = \ea; \ldots; \el_n =
  \en}$, if the set of labels ${ \ela, \ldots, \el_n }$ uniquely
  identifies a record type $\T$ in the typing context $\labenv$, then
  we can assign this type to the record expression.
\end{enumerate*}

We formalize this with the judgement $\G \th \bar \el \uni \t$, which
either:
\begin{enumerate*}
  \item enforces $\t$ to be of the form $\T \tys$ if the labels $\bar \el$
    uniquely identify a nominal record type $\T$ in $\labenv$ (\Rule{Lab-!}),
    or
  \item imposes no constraint on $\t$ in the ambiguous case
    (\Rule{Lab-?}).
\end{enumerate*}

Label declarations in $\labenv$ have the form $\elab : \tfor \tvs \tp \to \T
\tvs$, assigning labels to field types and record types\footnote{For a given
record type $\T$, we assume each label associated with it is unique.}. We
write $\elab / {\T} \in \labenv$ if such a declaration of $\elab$ exists for the
record type $\T$. This membership relation extends to explicitly annotated and
casted labels:
\begin{mathpar}
  \infer[Lab-$\in$X]
    {\elab / {\T} \in \labenv}
    {(\elab / \T) / {\T} \in \labenv}

  \infer[Lab-$\in$Magic]
    {\elab / {\T} \in \labenv}
    {\elmagic \elab / {\T} \in \labenv}

  \infer[Lab-$\in$Annot]
    {\el / {\T} \in \labenv}
    {\elannot \el \tvs \t / {\t} \in \labenv}
\end{mathpar}
We then define the uniqueness predicate $\bar \el \uni {\T} \in \labenv$ as:
\begin{mathpar}
  \infer[Lab-U]
    {\bar \el / {\T} \in \labenv \\
     \all {\T'} \uad\bar \el / \T' \in \labenv \implies {\T} = \T'}
    {\bar \el \uni \T \in \labenv}
\end{mathpar}
This states that the set of labels $\bar \el$ determines a unique nominal type
$\T$ in $\labenv$ if no other type $\T'$ can be associated with the same label
set.
\TODO{Should the rules above be in a figure as well?}

\subsection {Examples of typings}

The following lemma shows that we can always take a larger context
$\E$ or $\Lab$ for implicit rules \Rule {Proj-I}, \Rule {Use-I}, \Rule {Poly-I}
and \Rule{Lab-I}.
That is, there is always a derivation using only toplevel contexts.
\begin{lemma}
\label{lem/context/largest}
\newcommand {\Eab}{\parens{\Ea\where \Eb}}
If $\eshape \Eb \e \sh$, then $\eshape \Eab \e \sh$. Similarly, for label
contexts, if $\Lshape \Lab \elab \T$, then \\$\Lshape {(\E[\Lab])} \elab \T$.
\end{lemma}

% Examples
We now illustrate the typing of implicit constructs with a few examples.
\begin{example}
To illustrate a simple case of non-typability, we show that the expression $e$
equal to $\efun \x {\eproj \x k}$ is ambiguous, \ie that it does not
typecheck.
%
%% Let $e_n$ be the explicitly annotated version $\efun r
%% {\eproj[n] \x i}$. for $n \le k$.
If there is a derivation of $\efun \x
{\eproj \x k}$ then there must be one of the form:
\begin{mathpar}
\infer*[Right=Proj-I]{
                  \eshape \E \x {\any \tvcs \Pi\iton \tvcs} \\
                \eset \th \E \where {\eproj[n] \x k} : \t
}{%             -------------------------------------------
                  \eset \th \E \where {\eproj \x k} : \t
}
\end{mathpar}
where $E$ is the term $\efun \x \ehole$, which is the largest possible
context, thanks to~\cref {lem/context/largest}.
%
Let $\t$ be $\Pi\iton \ti \to \t_k$ for some $n \geq k$.  We have the
following derivation:
\begin{mathpar}
\infer* [Right=Fun]{
          \infer*[Right=Proj-X]
                {\x : \Pi\iton \ti \th \x : \Pi\iton \ti}
                {\x : \Pi\iton \ti \th \eproj[n] \x k : \t_k}
}{%      ----------------------------------------------------------
         \eset \th \E \where{\eproj[n] \x k} : \t
}
\end{mathpar}
Unfortunately, $\eshape \E  \x {\any \tvcs \Pi\iton \tvcs}$ does not hold.
  Indeed, we have $\eset \th \E \where {\emagic {\eannot \x {} {\gt}}} : \t$
for any $\gt$ assuming $\t$ is of the form $\gt \to \tp$.
Hence, $\any \tvcs \Pi\iton[n] \tvcs$ and $\any \tvcs \Pi\iton[n+1] \tvcs$
are two possible shapes for the type of $\x$.
\end{example}

\begin{example}
\locallabelreset
We now illustrate a non-ambiguous example, showing that the
expression $e$ equal to $\th \eapp {(\efun \x {\eproj
\x  1})} {(1, 2)} : \tint$.
%
%
Let $\E$ be the context $\eapp {(\efun \x \ehole)} {(1, 2)}$.  We
have the derivation:
\begin{mathpar}
\infer* [Right=Proj-I]{
		\eshape \E \x {\any {\tvca, \tvcb} \tvca \tprod \tvcb} \\
                \eset \th \E \where {\eproj[2] \x 1} : \tint
}{%             -------------------------------------------
                  \eset \th \E \where {\eproj \x 1} : \tint
}
\end{mathpar}
We have $\eset \th \E \where {\eproj[2] \x 1} : \tint$, indeed. Therefore, it
just remains to show $\eshape \E \x {\any {\tvca, \tvcb} \tvca \tprod \tvcb}$~\llabel C.
Assume $\eset \th \E \where{\emagic {\eannot \x {} \gt}} : \t$. Since $\x : \tint \tprod \tint$
is bound in the context at the hole in $\E$,
there is no other choice but take $\gt$ equal to $\tint \tprod \tint$,
hence $\shape \gt = \any {\tvca, \tvcb} \tvca \tprod \tvcb$, which proves~\lref C.
\end{example}

The following example of non-typability illustrates how the typing rules
still forces to reject typing of some expressions whose elaboration would be
unambiguous. This is intended, to prevent us from having to focus at several
terms simultaneously. Our typing rules enforce the resolution of
shape inference, locally, one at a time.

\begin{example}
\newcommand{\tyid}{\ty_{\kwd{id}}}
  \newcommand{\eid}{\efun z z}
\newcommand {\epid}[1][]{\epoly[#1]{\eid}}
Let $\tyid$ be $\tpoly{\all \tv \tv \to \tv}$.
%
We show that the expression $e$ equal to $\elet \x {\epoly {\efun z z}}
{(\eapp {\einst \x} 1, \eapp {\einst \x} \eunit)}$ is rejected as ambiguous.
Let $\tyid$ be $\tpoly {\all \tv \tv \to \tv}$.  Clearly, we have $\elet \x
{\epoly [\tyid] {\efun z z}} {(\eapp {\einst[\tyid] \x} 1, \eapp
{\einst[\tyid] \x} \eunit)}$.  This is actually the only possible fully
annotated derivation.
%
To show that $e$ is typable, we must be able to make all annotations
optional, sequentially.  Therefore, the final step, which will eliminate the
last annotation has a single point of focus of the form $\E\where{e^i}$,
where $\e^i$ can be any of the three positions with a missing annotation.  We
consider each case independently, and show that it is actually not typable.
\begin{proofcases}
\proofcase
{$\E$ is $\elet \x \ehole (\eapp {\einst \x} 1, \eapp {\einst \x}\eunit)$}
%
If this holds, we should have a derivation that ends with
\begin{mathpar}
\infer*[Right=Poly-I]{
		  \Eshape \E \eid {\tpoly \tyid} \\
                  \eset \th \E \where {\epid [\tyid]}: \t
}{%               ---------------------------------------
                       \eset \th \E \where \epid : \t
}
\end{mathpar}
However, $\Eshape \E \eid {{\tpoly \tyid}}$ does not hold.
Indeed, the following judgment
$\eset \th \E \where {\eannot {\emagic \eid} {} {\tpoly \ts}} : \t$ holds, where
$\ts$ is either $\tfor \tv \tv \to \tv$ or $\tfor \tv \tv \to
\tv\to\tv$. Hence, the shape of the type of $\eid$ is not uniquely
determined and this case cannot occur.

\proofcase
{$\E$ is
    $\elet \x {\epid} {\eapp {\einst \ehole} 1, \eapp {\einst \x} \eunit}$}
%
The derivation must end with:
\begin{mathpar}
\infer*[Right=Proj-X]{
		  \eshape \E \x {\tpoly \tyid} \\
                \eset \th \E \where {\einst[\tyid] \x} : \t
}{%             -------------------------------------------
                    \eset \th \E \where {\einst \x} : \t
}
\end{mathpar}
However, $\eshape \E \x \tyid$ does not hold (the proof is similar to the
previous case).

\proofcase {$\E$ is  $\elet \x \epid {(\eapp {\einst \x} 1, \eapp
  {\einst \ehole} \eunit)}$} This is symmetric to the previous case, which cannot
hold either.
  \end{proofcases}
\end{example}

\begin{example}
Let $\e$ be $\elet f {\efun \x {\eproj \x 1}} {\eapp f (1, 2)}$.
$\e$ is well-typed using \emph{backpropagation}.
$\e$ is of the form $\E \where {\x}$ where  $\E$ is the context $\elet f
{\efun \x \ehole} {\eapp f (1, 2)}$.
We have $\eset \th \E \where {\eproj[2] \x 1} : \tint$.
Let us show that $\eshape \E \x {\any {\tvca, \tvcb} \tvca \tprod \tvcb}$.
%
Assume $\eset \th \E \where {\emagic {\eannot \x {} \gt} } : \t$. As $\gt$ is a ground
type, the type $\gt$ of $\x$ is not a variable.  Then, $\gt$ cannot be that
of an arbitrary sized tuple, since there is no such type for a tuple of
arbitrary size. Hence, $\gt$ must be a tuple $\Pi\iton \tys$ for some size
$n$. Since the codomain of $f$ must be a tuple of size~$2$ (for $\eapp f (1,
2)$ to be well-typed), then $n$ must also be $2$. This shows that $\eshape \E
\x {\any {\tvca, \tvcb} \tvca \tprod \tvcb}$.
%% \begin{mathpar}
%%   \infer
%%     {
%%     \infer
%%       {
%% 	\infer
%% 	  {
%% 	    \infer
%% 	      {
%% 		\infer
%% 		  {}
%% 		  {\tva, \tvb, x : \tva \th x : \tva}}
%% 	      {\tva, \tvb, x : \tva \th \ecast x \tva \tvb : \tvb}}
%% 	  {\tva, \tvb \th \efun x {\ecast x \tva \tvb : \tva \to \tvb}}}
%%       {\emptyset \th \efun \x \ecast \x \tva \tvb : \tfor {\tva, \tvb} \tva \to \tvb} \\
%%     \infer
%%       {\ldots}
%%       {f : \tfor {\tva, \tvb} \tva \to \tvb \th \eapp f (1, 2) : \tunit}}
%%     {\emptyset \th \elet f {\efun \x {\ecast \x \tva \tvb}} {\eapp f (1, 2)} : \tunit}
%% \end{mathpar}
\end{example}


\subsection{Constraint generation}
\label{sec:constraint-gen}

% Intro
We now present the formal translation from terms $\e$ to constraints $\c$,
such that the resulting constraint is satisfiable if and only if the term is
well typed. The translation is defined as a function $\cinfer \e \t$, where $\e$
is the term to be translated and $\t$ is the expected type of $\e$.

% Explanation of expected type
The expected type $\t$ is permitted to contain type variables, which can be
existentially bound in order to perform type inference. The models of constraint
$\cinfer \e \t$ interpret the free variables of $\t$ such that
$\t$ becomes a valid type of $\e$. For example, to infer the entire type of $\e$
we may pick a fresh type variable $\tv$ for $\t$.
\paragraph{Pattern constraints}

Thus far, our formal presentation of constraint patterns has remained
abstract, deliberately leaving the syntax and semantics of patterns unspecified to
accommodate a range of language features. We now concretize this by specifying
the patterns used in \OML (See \cref{fig:patterns-oml}), and introducing the
corresponding constraints for the variables they bind.
%
Patterns include:
\begin{enumerate*}

  \item Tuple patterns $\cpatprod \tv j$, matching a tuple type $\Pi\iton
    \tys$ of arity $n \geq j$, and binding the $j$-th component to $\tv$.

  \item Nominal patterns $\cpatrcd \ct$, binding the name of a nominal type
    $\Tapp \tys$ to the nominal variable $\ct$.

  \item Polytype patterns $\cpatpoly \cscm$ matching a polytype $\tpoly \ts$ and
    binding the resulting scheme to the variable $\cscm$.

\end{enumerate*}

Each new constraint has an unsubstituted form ($\cscm \leq \t, \x \leq \cscm$
\etc), whose semantics is defined via substitution into a sugared form ($\ts
\leq \t, \x \leq \ts,$ \etc). Semantic environments $\semenv$ are extended to
interpret nominal variables $\ct$ as names $\T$ and scheme variables $\cscm$ as
ground type schemes $\gscm$, that is type schemes with no unbound variables
(\ie $\tfor {\fvs \t} \t$).

\begin{mathparfig}
  {fig:patterns-oml}
  {Patterns for \OML}
  \begin{bnfgrammar}
   \entry[Patterns]{\cpat}{
      \cpatprod \tv j
      \and \cpatrcd \ct
      \and \cpatpoly \cscm
    } \\
    \entry[Constraints]{\c}{
      \dots
      \and \labenv(\elab/\ct) \leq \ta \to \tb
      \and \labenv(\elab/\T) \leq \ta \to \tb
      \andcr \cscm \leq \t
      \and \ts \leq \t
      \andcr \x \leq \cscm
      \and \x \leq \ts
    }
 \end{bnfgrammar}
  \\
  \newcommand{\Mrule}[5][]{{#2} \Matches {(#3)} \; #4 &\eqdef& {#5} & #1}
  \begin{tabular}{RCLL}
    \Mrule[\text{if } n \geq j]
      {\cpatprod \tv j}
      {\any \tvcs \Pi\iton \tvcs} \tvbs
      {[\tv \is \tvb_j]}
    \\[1ex]
    \Mrule
      {\cpatrcd \ct}
      {\any \tvcs \Tapp} \tvbs
      {[\ct \is \T]}
    \\[1ex]
    \Mrule
      {\cpatpoly \cscm}
      {\any \tvcs \tpoly \ts} \tvbs
      {[\cscm \is \ts \where{\tvcs \is \tvbs}]}
  \end{tabular}
  \\
  \inferrule[Lab-Inst]
    {\semenv \th \labenv(\elab/\semenv(\ct)) \leq \ta \to \tb}
    {\semenv \th \labenv(\elab/\ct) \leq \ta \to \tb}

  \inferrule[Scm-Inst]
    {\semenv \th \semenv(\cscm) \leq \t}
    {\semenv \th \cscm \leq \t}

  \inferrule[Abs-Inst]
    {\semenv \th \x \leq \semenv(\cscm)}
    {\semenv \th \x \leq \cscm}
  \\
  \newcommand{\Srule}[3][]{{#2} &\eqdef& {#3} & {#1}}
  \begin{tabular}{RCLL}
    \Srule[\text{if } \labenv(\elab/\T) = \tfor \tvs \t \to \Tapp \tvs]
      {\labenv(\elab/\T) \leq \ta \to \tb}
      {\cexists \tvs \cunif \ta \t \cand \cunif \tb {\Tapp \tvs}}
    \\[1ex]
    \Srule
      {(\tfor \tvs \tp) \leq \t}
      {\cexists \tvs \cunif \tp \t}
    \\[1ex]
    \Srule
      {\x \leq (\tfor \tvs \t)}
      {\cfor \tvs \capp \x \t}
  \end{tabular}

\end{mathparfig}


% Explanation of constraint gen cases
% Simple constraint gen

\paragraph{Constraint generation}

\begin{mathparfig}
  {fig:constraint-gen}
  {The constraint generation translation for \OML}
\newcommand {\Crule}[2]{#1 &\eqdef& #2}
\def \arraystretch{1.2}%4
\begin{tabular}{LCL}
\Crule
   {\cinfer x \t}
   {\cinst x \t}
\\
\Crule
  {\cinfer {()} \t}
  {\cunif \t \tunit}
\\
\Crule
  {\cinfer {\efun \x \e} \t}
  {\cexists {\tva, \tvb} \cunif \t {\tva \to \tvb}
    \cand \clet \x \tvc {\cunif \tvc \tva} {\cinfer \e \tvb}}
\\
\Crule
  {\cinfer {\eapp \ea \eb} \t}
  {\cexists {\tva} \cinfer \ea {\tva \to \t} \cand \cinfer \eb \tva}\
\\
\Crule
  {\cinfer {\elet \x \ea \eb} \t}
  {\clet \x \tva {\cinfer \ea \tva} {\cinfer \eb \t}}
\\
\Crule
  {\cinfer {\eannot \e \tvs \tp} \t}
  {\cexists \tvs \cunif \t \tp \cand \cinfer \e \tp}
\\
\Crule
  {\cinfer {\etuple {\ea, \ldots, \en}} \t}
  {\cexists \tvs \cunif \t {\Pi\iton \tvs}
    \cand \cAnd \iton \cinfer \ei {\tv_i}}
\\
\Crule
  {\cinfer {\exfield \e j n} \t}
  {\cexists {\tvbs}
    \cinfer \e {\Pi\iton \tvbs}
    \cand \cunif \t {\tvb_j}}
\\
\Crule
  {\cinfer {\efield \e j} \t}
  {\cexists \tv \cinfer \e \tv
    \cand \cmatch \tv {\cbranch {\cpatprod \tvb j} {\cunif \t \tvb}}}
\\
\Crule
  {\cinfer {\expoly \e \tvs \ts} \t}
  {\cexists {\tvs}
    \cinfer \e \ts
    \cand \cunif \t {\tpoly \ts}}
\\
\Crule
  {\cinfer {\exinst \e \tvs \ts} \t}
  {\cexists {\tvs}
    \cinfer \e {\tpoly \ts}
    \cand \ts \leq \t}
\\
\Crule
  {\cinfer {\einst \e} \t}
  {\cexists \tva
    \cinfer \e \tva
    \cand \cmatch \tva {\cbranch {\cpatpoly \cscm} \cscm \leq \t}}
\\
\Crule
  {\cinfer {\epoly \e} \t}
  {\clet \x \tv {\cinfer \e \tv}
    {\cmatch \t {\cbranch {\cpatpoly \cscm} {\x \leq \cscm}}}}
\\
\Crule
  {\cinfer {\efield \e \el} \t}
  {\cexists \tv \cinfer \e \tv
    \cand \cinferlabuni \el \tv
    \cand \cinferlab \elab \t \tv}
\\
\Crule
  {\cinfer {\erecord {\overline{\el = \e}}} \t}
  {\cinferlabuni {\bar \el} \t
    \cand \cAnd \iton \cinferassn \eli \ei \t}
\\
\Crule
  {\cinfer {\emagic \e} \t}
  {\cexists \tv \cinfer \e \tv}
\\
\Crule
  {\cinfer \e {\tfor \tvs \t}}
  {\cfor \tvs \cinfer \e \t}
\\ \\
\Crule
  {\cinferassn \el \e \t}
  {\cexists \tv \cinfer \e \tv
    \cand \cinferlab \el \tv \t}
\\
\Crule
  {\cinferlab \elab \ta \tb}
  {\cmatch \tb {\cbranch {\cpatrcd \ct} {\labenv(\elab/\ct) \leq \ta \to \tb}}}
\\
\Crule
  {\cinferlab {\elab/\T} \ta \tb}
  {\labenv(\elab/\T) \leq \ta \to \tb}
\\
\Crule
  {\cinferlab {\elmagic \elab} \ta \tb}
  {\ctrue}
\\
\Crule
  {\cinferlab {\elannot \el \tvs \t} \ta \tb}
  {\cexists \tvs \cinferlab \el \ta \tb \cand \cunif \tb \t}
\\
\Crule
  {\cinferlabuni {\bar \el} \t}
  {\begin{cases}
    \cexists \tvs \cunif \t {\Tapp \tvs} &\text{if } \bar \el \uni \T \in \labenv \\
    \ctrue &\text{otherwise}
   \end{cases}}
\\ \\
\Crule
  {\csem {\Gnil \th \e : \t}}
  {\cinfer \e \t}
\\
\Crule
  {\csem {\tv, \G \th \e : \t}}
  {\call \tv {\csem {\G \th \e : \t}}}
\\
\Crule
  {\csem {x : \ts, \G \th \e : \t}}
  {\clet \x \tv {\ts \le \tv} {\csem {\G \th \e : \t}}}
\\
\end{tabular}
\end{mathparfig}
\TODO{Change the constraint generator to take a variable as a expected type}


The function $\cinfer - {\mathop{=}}$ is defined in \cref{fig:constraint-gen}.
All generated type variables are fresh with respect to the expected type $\t$,
ensuring capture-avoidance.
%
Unsurprisingly, variables generate an instantiation constraint. Unit $()$
requires the type $\t$ to be $\tunit$. A function generates a constraint that
binds two fresh flexible type variables for the argument and return types.  We
use a $\Let$ constraint to bind the argument in the constraint generated for
the body of the function. The $\Let$ constraint is monomorphic since $\tvc$ is
fully constrained by type variables defined outside the abstraction's scope
and therefore cannot be generalized. Applications introduce a fresh flexible
type variable for the argument type and ensures $\t$ is the return type of the
function. Let-bindings generates a polymorphic let constraint; $\cabs \tv
{\cinfer \e \tv}$ is a principal constraint abstraction for $\e$: its intended
interpretation is the set of all types that $\e$ admits.

% New constraint gen cases
% Annotations, tuples
Annotations bind their flexible variables and enforce the equility of
the annotated type $\tp$ and the expected type $\t$. Tuples introduce
fresh variables for each component and unify their product with $\t$.
Explicit projections ensure $\e$ has a tuple type $\Pi\iton \tvbs$
and extract the $j$-th component $\tvb_j$, unifying it with $\t$.
Implicit projections defer this via a suspended match constraint, until
the shape of $\e$'s expected type is known to be a tuple, extracting the
$j$-th component with the pattern $\cpatprod \tvb j$,

% Polytypes
For polytypes, boxing asserts that $\e$ has the polymorphic type $\ts$ (using
universal quantification) and that the expected type is the polytype $\tpoly
\ts$. Unboxing suspends until the inferred type of $\e$ is known to be a
polytype, captured by the pattern $\cpatpoly \cscm$, at which point we require
$\t$ to be an instance of $\cscm$. Explicit unboxing is analogous, but uses an
explicit scheme $\ts$ and therefore does not require a suspended match
constraint. Implicit boxing infers the principal type for $\e$ using a $\Let$
constraint and suspends until the expected type of the entire term is known to
be a polytype, bound to $\cscm$. We then assert that the principal type of $\e$
is at least as general as $\cscm$, via the constraint $\x \leq \cscm$.


% Records
Record projections generate a fresh variable for the nominal record type,
constraining $\e$ to this type, and use the auxiliary function $\cinferlab \el
\ta \tb$ to instantiate the label. The function $\cinferlabuni {\bar \el}
\t$ checks whether a label sequence $\bar \el$ uniquely determines a record
type, unifying $\t$ with $\Tapp \tvs$ if so, or leaving it unconstrained if
ambiguous. This function enables closed-world reasoning for both projections
and constructions, and corresponds to the judgement $\G \th \bar \el \uni \t$
judgement defined in \cref{sec/language/typing-rules}.

Record construction checks label uniqueness and generates a per-field
constraint $\eli = \ei$, introducing a fresh variable $\tv$ for each
field's type and ensuring that $\e$ has this type and the label $\el$
instantiates to $\tv \to \t$.

Label instantiation constraints $\cinferlab \elab \ta \tb$ suspend
until $\tb$ is known to be a record type; once resolved, the label type is
looked up in $\labenv$ and instantiated. Explicit instantiations bypass
suspension and directly instantiate the label's type.

% Other cases
The remaining (greyed) cases \TODO{Make the cases grey} correspond to internal
constructs used in \OML's typing rules and are included for completeness.

% Soundness/completeness of constraint gen

\section{Unification}
\label{app:unification}

The unification rules are listed in \cref{fig:omni-unification-algorithm}.
Rewriting proceeds under an arbitrary context $\Up$, modulo $\alpha$-equivalence
and associativity/commutativity of conjunctions.

Our algorithm is largely standard \cite{Pottier-Remy/emlti} but replaces type
constructors with \emph{canonical principal shapes}, enabling a uniform
treatment of monotypes and polytypes within unification compared to
prior formulations \citep{Garrigue-Remy/poly-ml}.

%


\begin{mathparfig}[htpb!]
  {fig:unification-algorithm}
  {Unification algorithm as a series of rewriting rules
   $\upa \unif \upb$. All shapes are principal.}
   \rewrite[U-Exists]
      {(\cexists \alpha \upa) \cand \upb \\ \tv \disjoint \upb}
      {\cexists \tv {\upa \cand \upb}}

    \rewrite[U-Cycle]
      {\up \\ \cyclic \up}
      {\cfalse}

    \rewrite[U-True]
      {\up \cand \ctrue}
      {\up}

    \rewrite[U-False]
      {\Up\where\cfalse \\ \Up \neq \square}
      {\cfalse}

    \rewrite[U-Merge]
      {\cunif \tv \ueqa \cand \cunif \tv \ueqb}
      {\cunif \tv {\cunif \ueqa \ueqb}}

    \rewrite[U-Stutter]
      {\cunif \tv {\cunif \tv \ueq}}
      {\cunif \tv \ueq}

    \rewrite[U-Name]
      {\cunif {\pshapp \parens{\tys, \ti, \typs}} \ueq \\ \tv \disjoint \tys, \typs, \ueq }
      {\cexists \tv {\cunif \tv \ti \cand \cunif {\pshapp \parens{\tys, \tv, \typs}} \ueq}}

    \rewrite[U-Decomp]
      {\cunif {\pshapp \tvs} {\cunif {\pshapp \tvbs} \ueq}}
      {\cunif {\pshapp \tvs} \ueq \cand \cunif \tvs \tvbs}

    \rewrite[U-Clash]
      {\cunif {\pshapp \tvs} {\cunif {\pshapp[\shp]\tvbs } \ueq }\\
       \sh \neq \shp}
      {\cfalse}

    \rewrite[U-Trivial]
      {\ueq \\ |\ueq| \leq 1}
      {\ctrue}
\end{mathparfig}


\parcomment{Explaination of the rules}

We briefly summarize the role of each rule. \Rule{U-Exists} lifts existential
quantifiers, enabling applications of \Rule{U-Merge} and \Rule{U-Cycle} since
all multi-equations eventually become part of a single conjunction.
\Rule{U-Merge} combines mutli-equations sharing a common variable and
\Rule{U-Stutter} removes duplicate variables. \Rule{U-Decomp} decomposes equal
types with matching shapes into equalities between their subcomponents, while
\Rule{U-Clash} detects shape mismatches that result in failure. \Rule{U-Name}
introduces fresh variable for subcomponents, ensuring unification operates on
\emph{shallow terms}, making sharing of type variables explicit and avoiding
copying types in rules such as \Rule{U-Decomp}. \Rule{U-True} and
\Rule{U-Trivial} eliminate trivial constraints, and \Rule{U-False} propagates
failure.
%
Finally, \Rule{U-Cycle} implements the \emph{occurs check}, ensuring that a
type variable does not occur in the type it is being unified with. This is a
necessary condition for unification, as it would otherwise lead to infinite
types\footnote{We discuss relaxing this constraint in \cref{sec/rec-types}.}.
This is formalized by the relation $\tv \prec_\up \tvb$ indicating that $\tv$
occurs in a type assigned to $\tvb$ in $\up$. A unification problem is cyclic,
written $\cyclic \up$, if $\tv \prec_\up^* \tv$ for some $\tv$.

\section{More discussion}

\subsection{Equi-recursive types}
\label {sec/rec-types}

For sake of simplicity, we have taken finite trees for ground types, that
is, for the semantics of constraints.  Iso-recursive types can easily be
added as in \ML, using a new datatype definition where  a record label
or datatype constructor is used to fold or unfold the recursive definition.

\OCaml also allows equi-recursive types, which can be modeled by taking
regular trees instead of tree for ground types.  Doing this change would
preserve the main metatheoretical properties, as in~\cite
{Pottier-Remy/emlti}, as we never rely on finiteness of ground types.  This
would allow type inference with equi-recursive types.

Technically, we need to extend the syntax of types with
a new introduction form $\trec \tv \t$ with the condition that $\t$ is
constructive, \ie a nonvariable type.  Internally, we never manipulate
recursive types but equations. The change, is a remove
\Rule {U-Cycle} and consistently allow canonical forms to contain cycles,
as they now admit regular tree solutions.

Similarly, shapes may be recursive, but only minimal shapes of polytypes may
be recursive. All types still have unique minimal shapes where equality of
shapes is taken up to equi-recursion, indeed.  While equality of shapes is
syntactical in the absence of recursive types, this is no longer the
case---but this does not raise any issue.

\Xdidier{There is an inline note here.}
\begin{version}{}
I did not see any difficult with equi-recursive types.
I am not even sure we need to mention~\cite
{Gauthier-Pottier/numbering@icfp04}.
Ths provides a cannonical representation, generalizing de Bruin indicies so
that second-order equality of terms amount to fisrt-order equality.
The canonical representation useing shapes is simiular.
\Xdidier {How much more should we say?}

\Xdidier {Should we give the change in unification rules?}
\end{version}

\section{Figures}

This section contains supplementary material to the main paper, including a
list of figures and definitions. Some of them are repeated from the main paper.

\begin{bnffig}[htpb!]%
  {fig:all--syntax}%
  {All syntax definitions.}
\entryset[Type variables]{\tva, \tvb, \tvc}{\TyVars}{}
\\
%% \entryset[Types]{\t}{\Types}\\
\entry[Types]{\t}{
    \tv \and
    \tunit \and
    \ta \to \tb \and
    \Pi\iton \ti \and
    \T \tys \and
    \tpoly \ts
}\\
\entry[Type schemes]{\ts}{
    \t \and
    \all \tv \ts
}\\[1ex]
\entry[Ground types]{\gt}{}{}\\
\entry[Ground type schemes]{\gscm}{}{}\\
  \entry[Ground region]{\gr}{\greg \tv \semenv}\\
\entry[Sets of ground types]{\gabs \subseteq \GroundRegion}{}{}\\
\entry[Sets of ground regions]{\gabsr \subseteq \Ground}{}\\
\entry[Constraints]{\c}{
        \ctrue
  \and  \cfalse
  \and  \ca \cand \cb
  \and  \cexists \tv \c
  \and 	\cfor \tv \c
  \and  \cunif \ta \tb
  \nextline
  \and  \clet \x \tv \ca \cb
  \and  \capp \x \t
  \nextline
  \and  \cmatch \t \cbrs
  \nextline
  \and \ueqs
  \and \cletr \x \tv \tvs \ca \cb
  \and \cexistsi \inst \x \c
  \and \cpinst \inst \tv \t
  \nextline
  \and \labenv(\elab/\ct) \leq \ta \to \tb
  \and \labenv(\elab/\T) \leq \ta \to \tb
  \nextline
  \and \cscm \leq \t \mid \ts \leq \t \mid \x \leq \cscm \mid \x \leq \ts
}\\[1ex]
\entry[Branches]{\cbr}{\cbranch \cpat \c} \\
\entry[Patterns]{\cpat}{
  \cpatwild \and \cpatprod \tv j \and \cpatrcd \ct \and \cpatpoly \cscm
} \\[1ex]
\entry[Semantic environment]{\semenv}{
  \eset \and \semenv\where{\tv := \gt}
  \and \semenv\where{\x := \gabs}
  \and \semenv\where{\x := \gabsr}
  \and \semenv\where{\inst := \semenvp}
  \nextline
  \and \semenv\where{\ct := \T}
  \and \semenv\where{\cscm := \gscm}
}\\
\entry[Unification problems]{\up}{
  \ctrue \and \cfalse \and \upa \cand \upb \and \cexists \tv \up \and \ueq
} \\
\entry[Multi-equations]{\ueq}{
  \eset \mid \cunif \t \ueq
} \\[1ex]
\entry[Constraint contexts]{\C}{
  \square
  \and \C \cand \c
  \and \c \cand \C
  \and \cexists \tv \C
  \and \cfor \tv \C
  \nextline
  \and \clet \x \tv \C \c
  \and \clet \x \tv \c \C
  \nextline
  \and \cletr \x \tv \tvs \C \c
  \and \cletr \x \tv \tvs \c \C
  \and \cexistsi \inst \x \C
} \\
\entry[Shapes] {\Sh} {
  \any \tvcs \t
}
\\
\entry[Canonical principal shapes] {\sh} {} {}\\
\entry[Terms]{\e}{
  x \and
  () \and
  \efun x e \and
  \eapp \ea \eb \and
  \elet x \ea \eb \and
  \eannot \e \tvs \t \andcr
  \erecord {\overline{\el = \e} } \and
  \efield e \el \andcr
   (\ea, \ldots, \en) \and
   \efield e j \and
   \exfield e n j \andcr
   \epoly e \and
   \expoly e \tvs \ts \and
   \einst e \and
   \exinst e \tvs \ts
   \nextline
   \and \emagic \e
}\\
\entry[Labels]{l}{
  \elab \and \elab / \T ~ \and \elmagic \elab \and \elannot \el \tvs \t
}\\[1ex]
\entry[Term contexts]{\E}{
  \square
  \and \eapp \E \e
  \and \eapp \e \E
  \and \elet \x \E \e
  \and \elet \x \e \E
  \and \eannot \E \tvs \t
  \andcr \erecord {\ela = \ea\; \ldots\; \eli = \E\; \ldots\; \el_n = \en}
  \and \efield \E \el
  \andcr (\ea, \ldots, \E, \ldots, \en)
  \and \eproj \E j
  \and \exproj \E j n
  \andcr \epoly \E
  \and \expoly \E \tvs \ts
  \and \einst \E
  \and \exinst \E \tvs \ts
  \andcr
  \emagic \E
}\\
\entry[Label contexts]{\Lab}{
    \E \where {\e.\square} \and
    \E \where
         {\erecord
            {\ela = \ea; \ldots; \square = \ei ; \ldots; \el_n = \en}
         }
  }\\[1ex]
\entry[Typing contexts]{\G}{
   \eset \and
   \G, x : \ts
}\\
\entry[Label environment]{\labenv}{
  \eset \and \labenv, \elab : \tfor \tvs \t \to \T \tvs
}
\end{bnffig}
\clearpage



\begin{judgboxmathpar}
  {\semenv \th \c}
  {Under the environment $\semenv$, the constraint $\c$ is satisfiable.}

  \infer[True]
    { }
    {\semenv \th \ctrue}

  \infer[Conj]
    {\semenv \th \ca \\
     \semenv \th \cb}
    {\semenv \th \ca \cand \cb}

  \infer[Exists]
    {\semenv\where{\tv \is \gt} \th \c}
    {\semenv \th \cexists \tv \c}

  \infer[Forall]
    {\forall \gt, ~ \semenv\where{\tv \is \gt} \th \c}
    {\semenv \th \tfor \tv \c}

  \infer[Unif]
    {\semenv(\ta) = \semenv(\tb)}
    {\semenv \th \cunif \ta \tb}

  \infer[Let]
    {\semenv \th \exists \tv. \ca \\
     \semenv\where{\x \is \semenv(\cabs \tv \ca)} \th \cb}
    {\semenv \th \clet \x \tv \ca \cb}

  \infer[App]
    {\semenv(\t) \in \semenv(\x)}
    {\semenv \th \capp \x \t}

  \infer[Susp-Ctx]
    {\Cshape \C \t \sh \\
      \semenv \th \C\where{\cmatched \t \sh \cbrs}
    }
    {\semenv \th \C\where{\cmatch \t \cbrs}}

  \infer[Multi-Unif]
    {\forall \t \in \ueq,~ \semenv(\t) = \gt}
    {\semenv \th \ueq}

  \infer[LetR]
    {\semenv \th \cexists {\tv, \tvs} \ca \\
     \semenv, \x \is \semenv(\cabsr \tv \tvs \ca) \th \cb}
    {\semenv \th \cletr \x \tv \tvs \ca \cb}

  \infer[AppR]
    {\greg \tv \semenvp \in \semenv(\x) \\
     \semenv(\t) = \semenvp(\tv) }
    {\semenv \th \capp \x \t}

  \infer[Exists-Inst]
    {\greg \tv\semenvp \in \semenv(\x) \\
     \semenv\where{\inst \is \semenvp} \th \c}
    {\semenv \th \cexistsi \inst \x \c}

  \infer[Partial-Inst]
    {\semenv(\inst)(\tv) = \semenv(\t) }
    {\semenv \th \cpinst \inst \tv \t}

  \inferrule[Lab-Inst]
    {\semenv \th \labenv(\elab/\semenv(\ct)) \leq \ta \to \tb}
    {\semenv \th \labenv(\elab/\ct) \leq \ta \to \tb}

  \inferrule[Scm-Inst]
    {\semenv \th \semenv(\cscm) \leq \t}
    {\semenv \th \cscm \leq \t}

  \inferrule[Abs-Inst]
    {\semenv \th \x \leq \semenv(\cscm)}
    {\semenv \th \x \leq \cscm}
\\
  \newcommand{\Srule}[3][]{{#2} &\eqdef& {#3} & {#1}}
  \begin{tabular}{RCLL}
    \Srule[\text{if } \cmatches \cpati \sh \tvs \theta]{\cmatched \t \sh {\cbranch \cpat \cs}}
      {\cexists \tvs \cunif \t \shapp \tvs \cand \theta(\ci)}
    \\[1ex]
    \Srule[\text{if } \labenv(\elab/\T) = \tfor \tvs \t \to \Tapp \tvs]
      {\labenv(\elab/\T) \leq \ta \to \tb}
      {\cexists \tvs \cunif \ta \t \cand \cunif \tb {\Tapp \tvs}}
    \\[1ex]
    \Srule
      {(\tfor \tvs \tp) \leq \t}
      {\cexists \tvs \cunif \tp \t}
    \\[1ex]
    \Srule
      {\x \leq (\tfor \tvs \t)}
      {\cfor \tvs \capp \x \t}
  \end{tabular}
\\
  \semenv(\cabsr \tv \tvs \c) \uad\eqdef\uad \set{\greg \tv {\semenv\where{\tv \is \gt, \tvs \is \gts}} \in \GroundRegion :
    \semenv\where{\tv \is \gt, \tvs \is \gts} \th \c}
\\
\semenv(\cabs \tv \c) \Wide\eqdef \
  \set {\gt \in \Ground : \semenv\where{\tv \is \gt} \th \c}
\\
\Cshape \C \t \sh \Wide\eqdef \
  \forall \semenv, \gt. \uad
      \semenv \th \cerase {\C\where{\cunif \t \gt}} \implies \shape \gt = \sh
\end{judgboxmathpar}
\emph{Note: in most definitions, we ignore the additional  $\OML$ constraints, as they are not particularly interesting.} \\

\begin{judgboxmathpar}
  {\Sh \preceq \Shp}
  {The shape $\Shp$ is an instance of $\Sh$. Alternatively, $\Shp$ is more general than $\Sh$.}
  \infer[Inst-Shape]
    {\bar \tvcs_2 \disjoint \any {\tvcs_1} \t}
    {\any {\tvcs_1} \t \preceq
     \any {\tvcs_2} \t \where {\tvcs_1 \is \tys_1}}
\end{judgboxmathpar}

\begin{definition}
A non-trival shape $\Sh \in \Shapesz$ is the principal shape of the type
$\t$ iff:
\begin{enumerate}
  \item
    $\exists \typs,\ \t = \shapp[\Sh] \typs$
  \item
    $\forall \Shp \in \Shapesz, \forall \typs,\ \t = \shapp[\Shp] \typs
    \implies \Sh \preceq \Shp$
\end{enumerate}

A principal shape $\any \tvcs \t$ is \emph{canonical} if the sequence of its
free variables $\tvcs$ appear in the order in which the variables occur in
$\t$. $\shape \t$ is the canonical principal shape of $\t$.
\end{definition}

\begin{judgboxmathpar}
  {\cmatches \cpat \sh \tvs \theta}
  {The pattern $\cpat$ matches the shape $\sh$ with components $\tvs$ binding\\pattern variables in $\theta$.}
  \\
  \newcommand{\Mrule}[5][]{{#2} \Matches {(#3)} \; #4 &\eqdef& {#5} & #1}
  \begin{tabular}{RCLL}
    \Mrule[\text{if } n \geq j]
      {\cpatprod \tvb j}
      {\any \tvcs \Pi\iton \tvcs} \tvs
      {[\tvb \is \tv_j]}
    \\[1ex]
    \Mrule
      {\cpatrcd \ct}
      {\any \tvcs \Tapp} \tvs
      {[\ct \is \T]}
    \\[1ex]
    \Mrule
      {\cpatpoly \cscm}
      {\any \tvcs \tpoly \ts} \tvs
      {[\cscm \is \ts \where{\tvcs \is \tvs}]}
  \end{tabular}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\c \simple}
  {The constraint $\c$ is simple.}

  \inferrule[Simple-True]
    {}
    {\ctrue \simple}

  \inferrule[Simple-False]
    {}
    {\cfalse \simple}

  \inferrule[Simple-Conj]
    {\ca \simple \\ \cb \simple}
    {\ca \cand \cb \simple}

  \inferrule[Simple-Exists]
    {\c \simple}
    {\cexists \tv \c \simple}

  \inferrule[Simple-Forall]
    {\c \simple}
    {\cfor \tv \c \simple}

  \inferrule[Simple-Unif]
    {}
    {\cunif \ta \tb \simple}

  \inferrule[Simple-Let]
    {\ca \simple \\ \cb \simple}
    {\clet \x \tv \ca \cb \simple}

  \inferrule[Simple-App]
    {}
    {\capp \x \t \simple}

  \inferrule[Simple-LetR]
    {\ca \simple \\ \cb \simple}
    {\cletr \x \tv \tvs \ca \cb \simple}

  \inferrule[Simple-Exists-Inst]
    {\c \simple}
    {\cexistsi \inst \x \c \simple}

  \inferrule[Simple-Partial-Inst]
    {}
    {\cpinst \inst \tv \t \simple}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\C \simple}
  {The constraint context $\C$ is simple.}

  \inferrule[Simple-Ctx-Hole]
    {}
    {\square \simple}

  \inferrule[Simple-Ctx-Conj-Left]
    {\C \simple \\ \c \simple}
    {\C \cand \c \simple}

  \inferrule[Simple-Ctx-Conj-Right]
    {\C \simple \\ \c simple}
    {\c \cand \C \simple}

  \inferrule[Simple-Ctx-Exists]
    {\C \simple}
    {\cexists \tv \C \simple}

  \inferrule[Simple-Ctx-Forall]
    {\C \simple}
    {\cfor \tv \C \simple}

  \inferrule[Simple-Ctx-Let-Abs]
    {\C \simple \\ \c \simple}
    {\clet \x \tv \C \c \simple}

  \inferrule[Simple-Ctx-Let-In]
    {\c \simple \\ \C \simple}
    {\clet \x \tv \c \C \simple}

  \inferrule[Simple-Ctx-Exists-Inst]
    {\C \simple}
    {\cexistsi \inst \x \C \simple}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\cerase \c}
  {The erasure of $\c$.}
\newcommand{\Erule}[2]{\cerase {#1} &\eqdef& {#2}}
\begin{tabular}{RCL}
  \Erule{\ctrue}{\ctrue} \\
  \Erule{\cfalse}{\cfalse} \\
  \Erule{\ca \cand \cb}{\cerase \ca \cand \cerase \cb} \\
  \Erule{\cexists \tv \c}{\cexists \tv \cerase \c} \\
  \Erule{\cfor \tv \c}{\cfor \tv \cerase \c} \\
  \Erule{\cunif \ta \tb}{\cunif \ta \tb} \\
  \Erule{\clet \x \tv \ca \cb}{\clet \x \tv {\cerase \ca} {\cerase \cb}} \\
  \Erule{\capp \x \t}{\capp \x \t} \\
    \Erule{\cmatch \t {\cbranch {\bar \cpat} {\bar \c}}}{\ctrue} \\
  \Erule{\cletr \x \tv \tvs \ca \cb}{\cletr \x \tv \tvs {\cerase \ca} {\cerase \cb}} \\
  \Erule{\cexistsi \inst \x \c}{\cexistsi \inst \x \cerase \c}\\
  \Erule{\cpinst \inst \tv \t}{\cpinst \inst \tv \t}
\end{tabular}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\semenv \Th \c}
  {Under the semantic environment $\semenv$,
   the constraint $\c$ is canonically satisfiable.}
  \inferrule[Can-Simple]
    {\semenv \thsimple \c}
    {\semenv \Th \c}

  \inferrule[Can-Susp-Ctx]
    {\Cshape \C \t \sh \\ \semenv \Th \C\where{\cmatched \t \sh \cbrs}}
    {\semenv \Th \C\where{\cmatch \t \cbrs}}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\semenv \Th \c}
  {Under the semantic environment $\semenv$,
   the constraint $\c$ is canonically satisfiable.}
  \inferrule[Can-Simple]
    {\semenv \thsimple \c}
    {\semenv \Th \c}

  \inferrule[Can-Susp-Ctx]
    {\Cshape \C \t \sh \\ \semenv \Th \C\where{\cmatched \t \sh \cbrs}}
    {\semenv \Th \C\where{\cmatch \t \cbrs}}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\G \th \el : \ta \to \tb}
  {Under the typing context $\G$, the label $\el$ has the field type $\ta$ and record type $\tb$.}
  \infer[Lab-Magic]
    {}
    {\G \th \elmagic \elab : \tp \to \t}

  \infer[Lab-Annot]
    {\G \th \el : \tp \to \t\where{\tvs \is \tys}}
    {\G \th \elannot \el \tvs \t : \tp \to \t\where{\tvs \is \tys}}

  \inferrule[Lab-X]
    {\Omega(\elab / \T) = \tfor \tvs \t \to \T \tvs }
    {\G \th \elab / \T : \tys\where{\tvs \is \tys} \to \T \tys}
\end{judgboxmathpar}

\judgbox
  {\el / {\T} \in \labenv}
  {The label $\el$ belongs to the nominal record type $\T$ in $\labenv$.}

\judgbox
  {\bar\el \uni {\T} \in \labenv}
  {The set of labels $\bar\el$ belong to a unique nominal record type $\T$ in $\labenv$.}

\begin{judgboxmathpar}
  {\bar \el \uni \t}
  {The set of labels $\bar\el$ infer the possibly unique type $\t$.}
  \infer[Lab-$\in$I]
    {\elab : \tfor \tvs \t \to \T \tvs \in \labenv}
    {\elab / {\T} \in \labenv}

  \infer[Lab-$\in$X]
    {\elab / {\T} \in \labenv}
    {(\elab / \T) / {\T} \in \labenv}

  \infer[Lab-$\in$Magic]
    {\elab / {\T} \in \labenv}
    {\elmagic \elab / {\T} \in \labenv}

  \infer[Lab-$\in$Annot]
    {\el / {\T} \in \labenv}
    {\elannot \el \tvs \t / {\T} \in \labenv}

  \infer[Lab-U]
    {\bar \el / {\T} \in \labenv \\
     \forall {\T'}, \uad\bar \el / \T' \in \labenv \implies {\T} = \T'}
    {\bar \el \uni {\T} \in \labenv}

  \inferrule[Lab-!]
    {\bar \el \uni {\T} \in \labenv}
    {\el \uni {\T \tys}}

  \inferrule[Lab-?]
    {}
    {\bar \el \uni \t}
\end{judgboxmathpar}


\judgbox
  {\G \th \el = \e : \t}
  {Under the typing context $\G$, the record assignment $\el = \e$ has the record type $\t$.}

\begin{judgboxmathpar}
  {\G \th \e : \ts}
  {Under the typing context $\G$, the term $\e$ is assigned the type $\ts$.}
  \inferrule[Var]
    {x : \sigma \in \G}
    {\G \th x : \sigma}

  \inferrule[Fun]
    {\G, x : \ta \th e : \tb }
    {\G \th \efun x e : \ta \to \tb}

  \inferrule[App]
    {\G \th \ea : \ta \to \tb \\
     \G \th \eb : \ta}
    {\G \th \eapp \ea \eb : \tb}

  \inferrule[Unit]
    {}
    {\G \th () : 1}

  \inferrule[Annot]
    {\G \th e : \t\where {\tvs \is \tys}}
    {\G \th (e : \exi \tvs \t) : \t\where {\tvs \is \tys}}

  \inferrule[Gen]
    {\G \th e : \sigma \\ \tv \disjoint \G}
    {\G \th e : \tfor \tv \sigma}

  \inferrule[Inst]
    {\G \th e : \tfor \tv \ts}
    {\G \th e : \tv \where{\tv \is \t}}

  \inferrule[Let]
    {\G \th \ea : \sigma \\
     \G, x : \sigma \th \eb : \t}
    {\G \th \elet x \ea \eb : \t}

  \inferrule[Tuple]
    {\parens{\G \th \ei : \ti}\iton}
    {\G \th (\ea, \ldots, \en) : \Pi\iton \ti}

  \inferrule[Proj-X]
    {\G \th \e : \Pi\iton \ti \\
     1 \leq j \leq n}
    {\G \th \exfield \e n j : \tj}

  \inferrule[Proj-I]
    {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\
     \G \th \E\where{\exfield \e n j} : \t}
    {\G \th \E\where{\efield \e j} : \t}

  \inferrule [Poly-X]
    {\G \th \e : \ts\where {\tvs \is \tys}}
    {\G \th \epoly[\exi \tvs \ts] \e : \tpoly {\ts \where {\tvs \is \tys}}}

  \inferrule [Poly-I]
    {\Eshape \E \e {{\any \tvcs \tpoly \ts}} \\
     \G \th \E \where{\epoly[\exi \tvcs \ts] \e} : \t}
    {\G \th \E \where{\epoly \e} : \t}

  \inferrule [Use-X]
    {\G \th \e : \tpoly \ts \where {\tvs \is \tys}}
    {\G \th \exinst e \tvs \ts : \ts \where {\tvs \is \tys}}

  \inferrule [Use-I]
    {\eshape \E  \e {\any \tvcs \tpoly \ts} \\
     \G \th \E\where{\exinst \e \tvcs \ts} : \t}
    {\G \th \E\where{\einst \e} : \t}

  \inferrule[Rcd-Assn]
    {\G \th \e : \t \\
     \G \th \el : \t \to \tp}
    {\G \th \el = \e : \tp}

  \inferrule[Rcd]
    {\parens{\G \th \eli = \ei : \t}\iton \\
     \bar \el \uni \t}
    {\G \th \erecord {\ela = \ea; \ldots; \el_n = \en} : \t}

  \inferrule[Rcd-Proj]
    {\G \th \e : \tp \\
     \G \th \el : \t \to \tp \\
     \el \uni \t }
    {\G \th \efield \e \el : \t}

  \inferrule[Lab-I]
    {\Lshape \Lab \elab \T \\
      \G \th \Lab[\elab / \T] : \t}
    {\G \th \Lab[\elab] : \t}

  \inferrule[Magic]
    {\G \th \e : \t}
    {\G \th \emagic \e : \tp}
\\
\def \Eqdef {&\eqdef&}
{\begin{tabular}{RCL}
\eshape E \e \sh \Eqdef
  \forall \G, \t, \gt, \uad
  \G \th \eerase {\E \where {\emagic {\eannot \e {} \gt }}} : \t
      \wide\implies \shape \gt = \sh
\\[1ex]
\Eshape E \e \sh \Eqdef
  \forall \G, \t, \gt, \uad
      \G \th \eerase {\E\where{\eannot {\emagic \e} {} \gt}} : \t
      \wide\implies \shape \gt = \sh
\\[1ex]
\Lshape \Lab \elab \T \Eqdef
   \forall \G, \t, \gt , \uad
     \G \th \eerase {\Lab[\elannot {\elmagic \elab} {} \gt]} : \t
	\implies \shape \gt= \any \tvcs {\tvcs \T}

\end{tabular}}
\end{judgboxmathpar}

\judgbox
  {\cinfer {\G \th \e} \t}
  {$\cinfer {\G \th \e} \t$ is satisfiable iff $\e$ has the expected \emph{known} type $\t$ under \emph{known} context $\G$.}

\judgbox
  {\cinferlabuni {\bar\el} \tv}
  {$\cinferlabuni {\bar\el} \tv$ is satisfiable iff $\bar\el$ has the possibly unique type $\tv$.}

\judgbox
  {\cinferlab \el \tva \tvb}
  {$\cinferlab \el \tva \tvb$ is satisfiable iff $\el$ has the record type $\tvb$ and field type $\tva$. }

\judgbox
  {\cinferassn \el \e \tv}
  {$\cinferassn \el \e \tv$ is satisfiable iff the record assignment $\el = \e$ has the record type $\tv$.}

\judgbox
  {\cinfer \e \ts}
  {$\cinfer \e \ts$ is satisfiable iff $\e$ has the expected \emph{known} type scheme $\ts$.}

\begin{judgboxmathpar}
  {\cinfer \e \tv}
  {$\cinfer \e \tv$ is satisfiable iff $\e$ has the expected type $\tv$.}

\newcommand {\Crule}[2]{#1 &\eqdef& #2}
\def \arraystretch{1.2}%4
\begin{tabular}{LCL}
\Crule
   {\cinfer x \tv}
   {\cinst x \tv}
\\
\Crule
  {\cinfer {()} \tv}
  {\cunif \tv \tunit}
\\
\Crule
  {\cinfer {\efun \x \e} \tv}
  {\cexists {\tvb, \tvc} \cunif \tv {\tvb \to \tvc}
    \cand \clet \x \tvbp {\cunif \tvbp \tvb} {\cinfer \e \tvc}}
\\
\Crule
  {\cinfer {\eapp \ea \eb} \tv}
  {\cexists {\tvb \tvc} \cunif \tvc {\tvb \to \tv} \cand \cinfer \ea {\tvc} \cand \cinfer \eb \tvb}\
\\
\Crule
  {\cinfer {\elet \x \ea \eb} \tv}
  {\clet \x \tvb {\cinfer \ea \tvb} {\cinfer \eb \tv}}
\\
\Crule
  {\cinfer {\eannot \e \tvs \t} \tv}
  {\cexists \tvs \cunif \tv \t \cand \cinfer \e \tv}
\\
\Crule
  {\cinfer {\etuple {\ea, \ldots, \en}} \tv}
  {\cexists \tvs \cunif \tv {\tProd \tvs}
    \cand \cAnd \iton \cinfer \ei {\tv_i}}
\\
\Crule
  {\cinfer {\exproj \e j n} \tv}
  {\cexists {\tvb, \tvbs}
    \cinfer \e \tvb
    \cand \cunif \tvb {\tProd \tvbs}
    \cand \cunif \tv {\tvb_j}}
\\
\Crule
  {\cinfer {\eproj \e j} \tv}
  {\cexists \tvb \cinfer \e \tvb
    \cand \cmatch \tvb {\cbranch {\cpatprod \tvc j} {\cunif \tv \tvc}}}
\\
\Crule
  {\cinfer {\expoly \e \tvs \ts} \tv}
  {\cexists {\tvs}
    \cinfer \e \ts
    \cand \cunif \tv {\tpoly \ts}}
\\
\Crule
  {\cinfer {\exinst \e \tvs \ts} \tv}
  {\cexists {\tvs, \tvb}
    \cinfer \e \tvb
    \cand \cunif \tvb {\tpoly \ts}
    \cand \ts \leq \tv}
\\
\Crule
  {\cinfer {\einst \e} \tv}
  {\cexists \tva
    \cinfer \e \tva
    \cand \cmatch \tva {\cbranch {\cpatpoly \cscm} \cscm \leq \tv}}
\\
\Crule
  {\cinfer {\epoly \e} \tv}
  {\clet \x \tvb {\cinfer \e \tvb}
    {\cmatch \tv {\cbranch {\cpatpoly \cscm} {\x \leq \cscm}}}}
\\
\Crule
  {\cinfer {\efield \e \el} \tv}
  {\cexists \tvb \cinfer \e \tvb
    \cand \cinferlabuni \el \tvb
    \cand \cinferlab \elab \tv \tvb}
\\
\Crule
  {\cinfer {\erecord {\overline{\el = \e}}} \tv}
  {\cinferlabuni {\bar \el} \tv
    \cand \cAnd \iton \cinferassn \eli \ei \tv}
\\
\Crule
  {\cinfer {\emagic \e} \tv}
  {\cexists \tvb \cinfer \e \tvb}
\\\\
\Crule
  {\cinfer \e \t}
  {\cexists \tv \cunif \tv \t \cand \cinfer \e \tv}
\\
\Crule
  {\cinfer \e {\tfor \tvs \t}}
  {\cfor \tvs \cinfer \e \t}
\\\\
\Crule
  {\cinferassn \el \e \tv}
  {\cexists \tvb \cinfer \e \tvb
    \cand \cinferlab \el \tvb \tv}
\\\\
\Crule
  {\cinferlab \elab \tva \tvb}
  {\cmatch \tb {\cbranch {\cpatrcd \ct} {\labenv(\elab/\ct) \leq \tva \to \tvb}}}
\\
\Crule
  {\cinferlab {\elab/\T} \tva \tvb}
  {\labenv(\elab/\T) \leq \tva \to \tvb}
\\
\Crule
  {\cinferlab {\elmagic \elab} \tva \tvb}
  {\ctrue}
\\
\Crule
  {\cinferlab {\elannot \el \tvs \t} \tva \tvb}
  {\cexists \tvs \cunif \tvb \t \cand \cinferlab \el \tva \tvb}
\\
\Crule
  {\cinferlabuni {\bar \el} \tv}
  {\begin{cases}
    \cexists \tvs \cunif \tv {\Tapp \tvs} &\text{if } \bar \el \uni {\T} \in \labenv \\
    \ctrue &\text{otherwise}
   \end{cases}}
\\ \\
\Crule
  {\csem {\eset \th \e : \t}}
  {\cinfer \e \t}
\\
\Crule
  {\csem {\x : \ts, \G \th \e : \t}}
  {\clet \x \tv {\ts \le \tv} {\csem {\G \th \e : \t}}}
\end{tabular}
\end{judgboxmathpar}


\begin{judgboxmathpar}
  {\e \simple}
  {The term $\e$ is simple.}
  \inferrule[Simple-Var]
    {}
    {\x \simple}

  \inferrule[Simple-Fun]
    {\e \simple}
    {\efun \x \e \simple}

  \inferrule[Simple-App]
    {\ea \simple \\ \eb \simple}
    {\eapp \ea \eb \simple}

  \inferrule[Simple-Unit]
    {}
    {\eunit \simple}

  \inferrule[Simple-Let]
    {\ea \simple \\ \eb \simple}
    {\elet \x \ea \eb \simple}

  \inferrule[Simple-Annot]
    {\e \simple}
    {\eannot \e \tvs \t \simple}

  \inferrule[Simple-Tuple]
    {\parens {\ei \simple}\iton}
    {\etuple {\ea, \ldots, \en} \simple}

  \inferrule[Simple-ProjX]
    {\e \simple}
    {\exproj \e j n \simple}

  \inferrule[Simple-PolyX]
    {\e \simple}
    {\expoly \e \tvs \ts \simple}

  \inferrule[Simple-UseX]
    {\e \simple}
    {\exinst \e \tvs \ts \simple}

  \inferrule[Simple-Rcd]
    {\parens {\eli = \ei \simple} \iton}
    {\erecord {\ela = \ea\; \ldots\; \el_n = \en}}

  \inferrule[Simple-Rcd-Assn]
    {\el \simple \\ \e \simple}
    {\el = \e \simple}

  \inferrule[Simple-Rcd-Proj]
    {\e \simple \\ \el \simple}
    {\efield \e \el \simple}

  \inferrule[Simple-Magic]
    {\e \simple}
    {\emagic \e \simple}

  \inferrule[Simple-Lab]
    {}
    {\elab / \T ~ \simple}

  \inferrule[Simple-Lab-Magic]
    {}
    {\elmagic \elab \simple}

  \inferrule[Simple-Lab-Annot]
    {\el \simple}
    {\elannot \el \tvs \t \simple}
\end{judgboxmathpar}

\judgbox
  {\eerase \el}
  {The erasure of $\el$.}

\begin{judgboxmathpar}
  {\eerase \e}
  {The erasure of $\e$.}
\newcommand{\Erule}[2]{\eerase {#1} &\eqdef& {#2}}
  \begin{tabular}{RCL}
  \Erule{\x}{\x} \\
  \Erule{\efun \x \e}{\efun \x \eerase \e} \\
  \Erule{\eapp \ea \eb}{\eapp {\eerase \ea} {\eerase \eb}} \\
  \Erule{\eunit}{\eunit} \\
  \Erule{\elet \x \ea \eb}{\elet \x {\eerase \ea} {\eerase \eb}} \\
  \Erule{\eannot \e \tvs \t}{\eannot {\eerase \e} \tvs \t} \\
  \Erule{\etuple {\ea, \ldots, \en}}{\etuple {\eerase \ea, \ldots, \eerase \en}} \\
  \Erule{\eproj \e j}{\emagic {\eerase \e}} \\
  \Erule{\exproj \e j n}{\exproj {\eerase \e} j n} \\
  \Erule{\expoly \e \tvs \ts}{\expoly {\eerase \e} \tvs \ts} \\
  \Erule{\epoly \e}{\emagic {\eerase \e}}\\
  \Erule{\einst \e}{\emagic {\eerase \e}}\\
  \Erule{\exinst \e \tvs \ts}{\exinst {\eerase \e} \tvs \ts}\\
  \Erule{\erecord {\ela = \ea\; \ldots\; \el_n = \en}}{\erecord {\eerase \ela = \eerase \ea\; \ldots\; \eerase {\el_n} = \eerase \en}}\\
  \Erule{\efield \e \el}{\efield {\eerase \e} {\eerase \el}}\\[1ex]
  \Erule{\elab/\T}{\elab/\T}\\
  \Erule{\elab}{\elmagic \elab}\\
  \Erule{\elannot \el \tvs \t}{\elannot {\eerase \el} \tvs \t}\\
  \Erule{\elmagic \elab}{\elmagic \elab}
\end{tabular}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\G \thsimplesd \e : \t}
  {Under the typing context $\G$, the simple term $\e$ has the type $\t$.}
\\
  \inferrule[Var-SD]
    {x : \tfor \tvs \t \in \G}
    {\G \thsimplesd x : \t\where{\tvs \is \tys}}

  \inferrule[Let-SD]
    {\G \thsimplesd \ea : \ta\\
     \tvs \disjoint \G \\
     \G, x : \tfor \tvs \ta \thsimplesd \eb : \tb}
    {\G \thsimplesd \elet x \ea \eb : \tb}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\Th \e : \t}
  {The term $\e$ canonically has the type $\t$.}
  \inferrule[Can-Base]
    {\eset \thsimplesd \e : \t}
    {\Th \e : \t}

  \inferrule[Can-Proj-I]
    {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\
     \Th \E\where{\exfield \e n j} : \t}
    {\Th \E\where{\efield \e j} : \t}

  \inferrule [Can-Poly-I]
    {\Eshape \E \e {{\any \tvcs \tpoly \ts}} \\
     \Th \E \where{\epoly[\exi \tvcs \ts] \e} : \t}
    {\Th \E \where{\epoly \e} : \t}

  \inferrule [Can-Use-I]
    {\eshape \E  \e {\any \tvcs \tpoly \ts} \\
     \Th \E\where{\exinst \e \tvcs \ts} : \t}
    {\th \E\where{\einst \e} : \t}

  \inferrule[Can-Lab-I]
    {\Lshape \Lab \elab \T \\
      \Th \Lab[\elab / \T] : \t}
    {\Th \Lab[\elab] : \t}
\end{judgboxmathpar}

\TODO{@Didier are you able to fix the odd spacing going on here? I'm at a loss of
      why mathpar is adding this space}

\begin{judgboxmathpar}
  {\up \unif \upp}
  {The unifier rewrites $\up$ to $\upp$.}
   \rewrite[U-Exists]
      {(\cexists \alpha \upa) \cand \upb \\ \tv \disjoint \upb}
      {\cexists \tv {\upa \cand \upb}}

    \rewrite[U-Cycle]
      {\up \\ \cyclic \up}
      {\cfalse}

    \rewrite[U-True]
      {\up \cand \ctrue}
      {\up}

    \rewrite[U-False]
      {\Up\where{\cfalse} \\ \Up \neq \square}
      {\cfalse}

    \rewrite[U-Merge]
      {\cunif \tv \ueqa \cand \cunif \tv \ueqb}
      {\cunif \tv {\cunif \ueqa \ueqb}}

    \rewrite[U-Stutter]
      {\cunif \tv {\cunif \tv \ueq}}
      {\cunif \tv \ueq}

    \rewrite[U-Name]
      {\cunif {\pshapp \parens{\tys, \ti, \typs}} \ueq \\ \tv \disjoint \tys, \typs, \ueq }
      {\cexists \tv {\cunif \tv \ti \cand \cunif {\pshapp \parens{\tys, \tv, \typs}} \ueq}}

    \rewrite[U-Decomp]
      {\cunif {\pshapp \tvs} {\cunif {\pshapp \tvbs} \ueq}}
      {\cunif {\pshapp \tvs} \ueq \cand \cunif \tvs \tvbs}

    \rewrite[U-Clash]
      {\cunif {\pshapp \tvs} {\cunif {\pshapp[\shp]\tvbs } \ueq }\\
       \sh \neq \shp}
      {\cfalse}

    \rewrite[U-Trivial]
      {\ueq \\ |\ueq| \leq 1}
      {\ctrue}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\c \csolve \cp}
  {The constraint solver rewrites $\c$ to $\cp$.}

  \rewrite[S-Unif]
    {\upa \\ \upa \unif \upb}
    {\upb}

  \rewrite[S-True]
    {C \cand \ctrue}
    {C}

  \rewrite[S-False]
    {\C\where\cfalse \\ \C \neq \square}
    {\cfalse}

  \rewrite[S-Let]
    {\clet \x \tv \ca \cb}
    {\cletr \x \tv \eset \ca \cb}

  \rewrite[S-Exists-Conj]
    {(\cexists \alpha \ca) \cand \cb \\
     \tv \disjoint \cb}
    {\cexists \tv {\ca \cand \cb}}

  \rewrite[S-Let-ExistsLeft]
    {\cletr \x \tv \tvs {\cexists \tvb \ca} \cb \\
     \tvb \disjoint \tv, \tvs}
    {\cletr \x \tv {\tvs, \tvb} \ca \cb}

  \rewrite[S-Let-ExistsRight]
    {\cletr \x \tv \tvs \ca {\cexists \tvb \cb} \\
     \tvb \disjoint \tv, \tvs, \cb}
    {\cexists \tvb {\clet \x \tvs \ca \cb}}

  \rewrite[S-Let-ConjLeft]
    {\cletr \x \tv \tvs {\ca \cand \cb} \cc \\
     \ca \disjoint \tv, \tvs}
    {\ca \cand \cletr \x \tv \tvs \cb \cc}

  \rewrite[S-Let-ConjRight]
    {\cletr \x \tv \tvs \ca (\cb \cand \cc) \\
     \x \disjoint \cc}
    {\cc \cand \Clet \x \tv \ca \cb}

  \rewrite[S-Match-Type]
    {\cmatch \t \cbrs \\ \t \notin \TyVars}
    {\cmatched \t {\shape \t} \cbrs}

  \rewrite[S-Match-Var]
    {\C\where{\cmatch \tv \cbrs} \\
     \cunif \tv {\cunif \t \ueq} \in \C}
    {\C\where{\cmatched \tv {\shape \t} \cbrs}}

   \rewrite[S-Inst-Name]
    {\cpinst \inst \tv \t}
    {\cexists \tvc \cunif \tvc \t \cand \cpinst \inst \tv \tvc}

  \rewrite[S-Let-AppR]
    {\cletr \x \tv \tvs \c {\C\where{\capp \x \t}} \\
     \tvc \disjoint \t \\
     \x \disjoint \bvs \C}
    {\cletr \x \tv \tvs \c {\C\where{\cexistsi {\tvc, \inst} \x {\cunif \tvc \t \cand \cpinst \inst \tv \tvc}}}}

  \rewrite[S-Inst-Copy]
    {\cletr \x \tv \tvs {\c}
      \C\where{\cpapp \x \tvp \tvc \inst}\\
      \c = \cp \cand \cunif \tvp {\cunif {\shapp \tvbs} \ueq}\\
      \tvp \in \reg \tv \tvs \\
      \neg \cyclic {\c} \\
     \tvbs' \disjoint \tvp, \tvc, \tvbs \\
     \x \disjoint \bvs \C}
    {\cletr \x \tv \tvs {\c}
      \C\where{\cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}}

  \rewrite[S-Inst-Unify]
    {\cpinst \inst \tv \tvca \cand \cpinst \inst \tv \tvcb}
    {\cpinst \inst \tv \tvca \cand \cunif \tvca \tvcb}

  \rewrite[S-Inst-Poly]
    {\cletr \x \tv {\tvs, \tvp} {\ueqs \cand \c} {\C\where{\cpapp \x \tvp \tvc \inst}} \\
     \cfor \tvp \cexists {\tv, \tvs} {\ueqs} \cequiv \ctrue \\
     \tvp \disjoint \c, \insts \C \inst \\
     \x \disjoint \bvs \C}
    {\cletr \x \tv {\tvs,\tvp} {\ueqs \cand \c} {\C\where\ctrue}}

  \rewrite[S-Inst-Mono]
    {\cletr \x \tv \tvs \c {\C\where{\cpapp \x \tvb \tvc \inst}} \\
     \tvb \disjoint \tv, \tvs \\
     \x, \tvb \disjoint \bvs \C}
    {\cletr \x \tv \tvs \c {\C\where{\cunif \tvb \tvc}}}

  \rewrite[S-Let-Solve]
    {\cletr \x \tv \tvs \ueqs \c \\
     \cexists {\tv, \tvs} \ueqs \cequiv \ctrue \\
     \x \disjoint \c}
    {\c}

  \rewrite[S-Compress]
    {\cletr \x \tv {\tvs, \tvb} {\ca \cand \cunif \tvb {\cunif \tvc \ueq}} {\cb} \\ \tvb \neq \tvc}
    {\cletr \x \tv {\tvs} {\ca\where{\tvb \is \tvc} \cand \cunif \tvc {\ueq\where{\tvb \is \tvc}}} {\cb\where{\x.\tvb \is \tvc}}}

  \rewrite[S-Gc]
    {\cletr \x \tv {\tvs, \tvb} {\ca \cand \cunif \tvb \ueq} \cb \\ \tvb \disjoint \ca, \ueq, \cb}
    {\cletr \x \tv {\tvs} {\ca \cand \ueq} \cb}

  \rewrite[S-Exists-Lower]
    {\cletr \x \tv {\tvas, \tvbs} \ca \cb \\
     \cdetermines {\cexists {\tv, \tvas} \ca} \tvbs \\
     }
    {\cexists \tvbs \cletr \x \tv \tvas \ca \cb}

  \rewrite[S-BackProp]
    {\C\where
       {\cletr \x \tv {\tvs} {\Ca\where{\cmatch \tvp \cbrs}}
                           {\Cb\where{\cpapp \x \tvp \tvc \inst}}} \\
    \tvp \in \reg \tv \tvs \\
     \cunif {\tvc} {\cunif \t \ueq} \in \C\where\Cb \\
     \x \disjoint \bvs \Cb}
    {\C\where{\cletr \x \tv {\tvs} {\Ca\where{\cmatched \tvp {\shape \t} \cbrs}}
		      {\Cb\where{\cpapp \x \tvp \tvc \inst}}}}

  \rewrite[S-Exists-Exists-Inst]
    {\cexistsi \inst \x \cexists \tv \c}
    {\cexists \tv \cexistsi \inst \x \c}

  \rewrite[S-Exists-Inst-Conj]
    {\cexistsi \inst \x \ca \cand \cb \\ \inst \disjoint \ca}
    {\ca \cand \cexistsi \inst \x \cb}

  \rewrite[S-Exists-Inst-Let]
    {\cletr \x \tv \tvs \ca {\cexistsi \inst \xp \cb} \\ \x \neq \xp}
    {\cexistsi \inst \xp \cletr \x \tv \tvs \ca \cb}

  \rewrite[S-Exists-Inst-Solve]
    {\cexistsi \inst \x \c \\ \inst \disjoint \c}
    {\c}

  \rewrite[S-All-Conj]
    {\cfor \tvs {\cexists \tvbs {\ca \cand \cb}} \\ \tvs, \tvbs \disjoint \ca}
    {\ca \cand \cfor \tvs {\cexists \tvbs \cb}}

  \rewrite[S-Exists-All]
    {\cfor \tvs {\cexists {\tvbs, \tvcs} \c} \\ \cdetermines {\cexists {\tvs, \tvbs} \c} \tvcs}
    {\cexists \tvcs \cfor \tvs {\cexists \tvbs \c}}

  \rewrite[S-All-Escape]
    {\cfor {\tvs, \tv} {\cexists \tvbs {\c \cand \ueqs}} \\ \tv \prec_{\ueqs}^* \tvc \\ \tvc \disjoint \tv, \tvbs \\  \tv \disjoint \tvbs}
    {\cfalse}

  \rewrite[S-All-Rigid]
    {\cfor {\tvs, \tv} {\cexists \tvbs \C \cand \cunif \tv {\cunif \t \ueq}} \\ \t \notin \TyVars \\ \tv \disjoint \tvbs}
    {\cfalse}

  \rewrite[S-All-Solve]
    {\cfor \tvs \cexists \tvbs \ueqs \\ \cexists \tvbs \ueqs \cequiv \ctrue}
    {\ctrue}
\end{judgboxmathpar}

\begin{definition}
  $\cdetermines \c \tvbs$ if and only if every ground assignments
  $\semenv$ and $\semenvp$ that satisfy (the erasure of) $\c$ and coincide outside of $\tvb$
  concide on $\tvbs$ as well.
  \begin{mathpar}
    \cdetermines \c \tvb \uad\eqdef\uad \all {\semenv, \semenvp} \uad
      \semenv \th \cerase c
      \wedge \semenvp \th \cerase \c
      \wedge \semenv =_{\setminus \tvbs} \semenvp
      \implies
      \semenv = \semenvp
  \end{mathpar}
\end{definition}

\begin{definition}
A context $\C$ proves a multi-equation $\ueq$, written $\ueq \in \C$,  if there exists a decomposition
  $\C = \Ca[\ueq \cand \Cb]$ such that $\fvs \ueq \disjoint \bvs \Cb$
\end{definition}



\begin{definition}[Measure]
  For the relation $\semenv \th \c$, the following measure enables a useful
  induction principle:
    \begin{mathpar}
    \cmeasure \c \uad\eqdef\uad \angles{\cnmatches \c, \csize \c}
  \end{mathpar}
  where $\angles \ldots$ denotes a pair with lexicographic ordering, and:
  \begin{enumerate}

    \item $\cnmatches \c$ is the number of $\cmatch \t \cbrs$ constraints in
      $\c$.

    \item the last component $\csize \c$ is a structural measure of constraints \ie a
      conjunction $\ca \cand \cb$ is larger than the two conjuncts $\ca,
      \cb$.

  \end{enumerate}
\end{definition}


\section{Properties of the constraint language}

This appendix establishes key properties of the constraint language. The first
is the principality of shapes \cref{th/shapes/principal}: any non-variable type
$\t$ admits a non-trivial principal shape $\sh$.

The second is the canonicalization of satisfiability derivations $\semenv \th
\c$, which enables a simple induction principal for reasoning about unicity.
This canonical form for derivations is a cruicial tool in our proof of
soundness and completeness in \cref{TODO}.

\subsection{Principality of shapes}

\principalShapes
\begin{proof}
  Let us assume $\t$ is a non-variable type.

  \begin{proofcases}
    \proofcase{$\t$ is a type constructor $\tconstr \tys$}

    $\tconstr$ is a top-level type constructor of arity $n$, which in our
    setting may be the nullary $\tunit$, the binary arrow, the $n$-ary product,
    or a $n$-ary nominal type. In all these cases, the shape of $\t$ is $\any
    \tvcs \tconstr \tvcs$ where $\tvcs$ is a sequence of $n$ distinct type
    variables. This is clearly principal.

    \proofcase{$\t$ is a polytype $\tpoly {\tfor \tvs \t}$}

    We may assume \Wlog that each variable of $\tvs$ occurs free in
    $\t$.
    \Xalistair{We never say we equate type schemes up to dead generic variables.}
    %
    Let $(\pi_i)\iton$ be the sequence of shortest paths in $\t$ that cannot be
    extended to reach a (polymorphic) variable in $\tvas$, in lexicographic
    order and $\tvcs$ be a sequence $(\tvci)\iton$ of distinct variables that do
    not appear in~$\t$.
    %
    Let $\tyz$ be $\t \where {\pi_i \is \tvci}\iton$, \ie the term $\t$ where each
    path $\pi_i$ has been substituted by the variable $\tvci$.  Let $\Sh$ be the
    shape $\any \tvcs {\tpoly {\all \tvs \tyz}}$.
    We claim that $\Sh$ is actually the principal shape of $\tpoly {\all \tvs
    \t}$.

    \medskip
    \locallabelreset

    By construction, $\t$ is equal to $\shapp[\Sh] \tys$~\llabel 1.
    where $\tys$ is the sequence composed of $\ti$ equal to $\t/\pi_i$
    for $i$ ranging from $1$ to $n$.
    %
    Indeed, by
    definition, $\shapp[\Sh] \tys$ is equal to $(\t\where {\pi_i \is \tvci}\iton)
    \where {\tvci \is \ti}$ which is obviously equal to $\t$.
    The remaining of the proof checks that $\Sh$ is minimal~\llabel 2, that is,
    we assume that $\Sh'$ is another shape such that $\tpoly {\all\tvs\t}$ is
    equal to $\shapp [\Shp] \typs$ for some $\typs$~\llabel H and show that $\Sh
    \preceq \Shp$~\llabel C.

    \medskip

    It follows from~\lref H that
      $\Shp$ must be a polytype shape, \ie of the form $\any \tvcps {\tpoly
      {\all \tvbs \typ}}$ and
      $\tpoly {\all \tvs \t}$ is equal to $\tpoly {\all\tvbs \tp} \where {\tvcps
      \is \typs}$~\llabel{P}.
    \relax
    We may assume \Wlog that $\tvbs$ and $\tvcps$ are disjoint, that
    $\tvcps$ does not contain useless variables, \ie
    that they all appear in $\tp$ and that they actually appear in lexicographic
    order.
    \relax
    Now that never term contains useless variables, \lref P implies that the
    sequences $\tvas$ and $\tvbs$ can be put in one-to-one correspondances.
    Besides, since they all ordered in the order of appearance in terms, they
    the correspondance respects the ordering. Hence, the subsitution $\where
    {\tvbs \is \tvas}$ is a renaming. Therefore, we can assume \Wlog that
    $\tvbs$ is $\tvas$,
    \relax
    That is, \lref P becomes that $\tpoly {\all \tvs \t}$ is equal to $\tpoly
    {\all \tvs \typ \where {\tvcps \is \typs}}$, which given that they $\tvs$
    apprear in the same order in both terms, implies that $\t$ is equal to $\typ
    \where {\tvcps \is
    \typs}$~\llabel T.

    \relax

    \medskip

    Since $\typs$ does not contain any variable in $\tvs$, every path $\pi_i$
    is a path in $\typ$. Thus, we may write $\typ$ as
    \relax $\typ \where {\pi_i \is \tyi''}\iton$ where $\tyi''$ is $\typ/\pi_i$.
    This is also equal to
    \relax $(\typ \where {\pi_i \is \tvci}\iton) \where {\tvci \is \tyi''}\iton$,
    that is $\tyz\where {\tvci \is \tyi''}\iton$.
    %
    In summary, we have $\typ$ is equal to
    \relax $\tyz \where {\tvci \is \tyi''}\iton$,
    which implies that
    \relax  $\tpoly {\all \tvs \typ}$ is equal to
    \relax  $\tpoly {\all \tvs {\tyz \where {\tvci \is \tyi''}\iton}}$, \ie
    \relax  $\tpoly {\all \tvs \tyz} \where {\tvci \is \tyi''}\iton$~\llabel E.
    %
    By Rule \Rule {Inst-Shape}, we have
    \begin{mathpar}[inline]
    \any \tvcs  \tpoly {\all \tvs \tyz} \preceq
    \any \tvcps\tpoly {\all \tvs \tyz} \where {\tvci \is \tyi''}\iton,
    \end{mathpar}
    which, given~\lref E, is exactly~\lref C.

  \end{proofcases}
\end{proof}

\subsection{Canonicalization of satisfiability}

This section aims at proving the canonicalization of satisfiability, that is,
for any $\semenv \th \c$, there is a canonical derivation $\semenv \Th \c$.
%
We begin by proving some auxillary lemmas regarding inversion and
entailment in our system.

\begin{lemma}
  \label{lem:match-is-not-simple}
  For any constraint context $\C\where{\square}$,
  the constraint $\C\where{\cmatch \t \cbrs}$ is not simple.
  \begin{proof}
    Structural induction on $\C$.
  \end{proof}
\end{lemma}


\begin{lemma}[Simple inversion]~
  \label{lem:simple-inversion}
  \begin{enumerate}[(\roman*)]
    \item If $\semenv \th \cunif \ta \tb$, then $\semenv(\ta) = \semenv(\tb)$.
    \item If $\semenv \th \ueq$, then $\semenv(\t) = \gt$ for all $\t \in \ueq$ and some ground type $\gt$.
    \item If $\semenv \th \capp \x \t$, then $\semenv(\t) \in \semenv(\x)$ or $\greg \tv \semenvp \in \semenv(\x)$ and $\semenvp(\tv) = \semenv(\t)$.
    \item If $\semenv \th \cpinst \inst \tv \t$, then $\semenv(\inst)(\tv) = \semenv(\t)$

    \item If $\semenv \th \ca \cand \cb$ and $\ca \cand \cb \simple$, then $\semenv \th \ca$ and $\semenv \th \cb$.
    \item If $\semenv \th \cexists \tv \c$ and $\cexists \tv \c \simple$, then $\semenv\where{\tv \is \gt} \th \c$ for some $\gt$.
    \item If $\semenv \th \cexistsi \inst \x \c$ and $\cexistsi \inst \x \c \simple$, then $\semenv\where{\inst \is \semenvp} \th \c$ for some $\semenvp$ such that $\greg \tv \semenvp \in \semenv(\x)$.
    \item If $\semenv \th \cfor \tv \c$ and $\cfor \tv \c \simple$, then $\semenv\where{\tv \is \gt} \th \c$ for all ground types $\gt$.
    \item If $\semenv \th \clet \x \tv \ca \cb$ and $\clet \x \tv \ca \cb \simple$, then $\semenv \th \cexists \tv \ca$ and \\$\semenv\where{\x \is \semenv(\cabs \tv \ca)} \th \cb$.
    \item If $\semenv \th \cletr \x \tv \tvs \ca \cb$ and $\cletr \x \tv \tvs \ca \cb \simple$, then
      $\semenv \th \cexists {\tv, \tvs} \ca$ and \\$\semenv\where{\x \is \semenv(\cabsr \tv \tvs \ca)} \th \cb$.
  \end{enumerate}
  \begin{proof}~
    \begin{enumerate}[(\roman*)]
      \item Case analysis on the given derivation $\semenv \th \cunif \ta \tb$.
	There is a unique case for the atomic constraint $\cunif \ta \tb$:
	\begin{proofcases}
	    \proofcasederivation
	      {Unif}
	      {\semenv(\ta) = \semenv(\tb)}
	      {\semenv \th \cunif \ta \tb}

	    \begin{llproof}
\Hand 		\eqPf{\semenv(\ta)}{\semenv(\tb)}  {Premise}
	    \end{llproof}
	\end{proofcases}

      \item Similar to \Rule{Unif} case.
      \item Similar to \Rule{Unif} case.
      \item Similar to \Rule{Unif} case.

      \item Case analysis on the given derivation $\semenv \th \ca \cand \cb$.
      \begin{proofcases}
	\proofcasederivation
	  {Conj}
	  {\semenv \th \ca \\ \semenv \th \cb}
	  {\semenv \th \ca \cand \cb}

	\begin{llproof}
\Hand 	  \vdashPf{\semenv}{\ca} {Premise}
\Hand     \vdashPf{\semenv}{\cb} {Premise}
	\end{llproof}

	\proofcasederivation
	  {Susp-Ctx}
	  {\Cshape \C \t \sh \\ \semenv \th \C\where{\cmatched \t \sh \cbrs}}
	  {\semenv \th \underbrace{\C\where{\cmatch \t \cbrs}}_{\ca \cand \cb}}

	\begin{llproof}
	  \simplePf{\C\where{\cmatch \t \cbrs}} {Given}
	  \nsimplePf{\C\where{\cmatch \t \cbrs}} {By \cref{lem:match-is-not-simple}}
\Hand 	  \contraPf{\semenv \th \ca, \semenv \th \cb}
	\end{llproof}

      \end{proofcases}

      \item Similar to \Rule{Conj} case.
      \item Similar to \Rule{Conj} case.
      \item Similar to \Rule{Conj} case.
      \item Similar to \Rule{Conj} case.
      \item Similar to \Rule{Conj} case.
    \end{enumerate}
  \end{proof}
\end{lemma}

\begin{lemma}[Composability of simplicity]
  \label{lem:compose-simple}
  If $\c \simple$ and $\C \simple$, then $\C\where\c \simple$.
  Additionally, if $\Ca \simple$ and $\Cb \simple$, then $\Ca\where\Cb \simple$.
  \begin{proof}
    Induction on the derivation of $\C \simple$ and $\Ca \simple$, respectively.
  \end{proof}
\end{lemma}

\begin{lemma}[Simple congruence]
  \label{lem:cong-simple}
  Given simple constraints $\ca, \cb$ and simple context $\C$.
  If \\$\ca \centails \cb$, then $\C\where{\ca} \centails \C\where{\cb}$.
  \begin{proof}
    Induction on the derivation of $\C \simple$.
  \end{proof}
\end{lemma}

\begin{lemma}[Erasure is simple]
  \label{lem:erase-simple}
  For all constraints $\c$, $\cerase \c \simple$.
  \begin{proof}
    Induction on the structure of $\c$.
  \end{proof}
\end{lemma}



\begin{lemma}[Composability of unicity]
  \label{lem:compose-unicity}
  If $\Cshape \Ca \t \sh$, then $\Cshape {\Cb\where\Ca} \t \sh$.
  \begin{proof}
    Induction on the structure of $\Cb$.
    \begin{proofcases}
      \proofcase{$\square$}

	\begin{llproof}
	  \shapePf{\Ca}{\t}{\sh}{Premise}
	  \eqPf{\Cb\where\Ca}{\square\where\Ca}{$\Cb$ is $\square$}
	  \continueeqPf{\Ca}{By definition}
\Hand	  \shapePf{\square\where\Ca}{\t}{\sh}{From premise}
	\end{llproof}

      \proofcase{$\Cc \cand \c$}

	\begin{llproof}
	  \shapePf{\Ca}{\t}{\sh}{Premise}
	  \shapePf{\Cc\where\Ca}{\t}{\sh}{By \ih}
	  \ForallPf{\semenv, \gt}{}{Definition of $\Cshape {\parens{\Cc\where\Ca \cand \c}} \t \sh$}
	  \vdashPf{\semenv}{\cerase {\Cc\where\Ca\where{\cunif \t \gt} \cand \c}}{$\implies$I}
	  \eqPf{\cerase {\Cc\where\Ca\where{\cunif \t \gt} \cand \c}}{\cerase {\Cc\where\Ca\where{\cunif \t \gt}} \cand \cerase \c}{By definition}
	  \simplePf{\cerase {\Cc\where\Ca\where{\cunif \t \gt} \cand \c}}{\cref{lem:erase-simple}}
	  \vdashPf{\semenv}{\cerase {\Cc\where\Ca\where{\cunif \t \gt}}}{\cref{lem:simple-inversion}}
	  \eqPf{\shape \gt}{\sh}{$\implies$E on $\Cshape {\Cc\where\Ca} \t \sh$}
\Hand 	  \shapePf{\parens{\Cc\where\Ca \cand \c}}{\t}{\sh}{Above}
	\end{llproof}

      \proofcase{$\c \cand \Cc$}

	\begin{llproof}
	  Similar to the $\Cc \cand \c$ case.
	\end{llproof}

      \proofcase{$\cexists \tv \Cc$}

	\begin{llproof}
	  \shapePf{\Ca}{\t}{\sh}{Premise}
	  \shapePf{\Cc\where\Ca}{\t}{\sh}{By \ih}
	  \ForallPf{\semenv, \gt}{}{Definition of $\Cshape {\parens{\cexists \tv \Cc\where\Ca}} \t \sh$}
	  \vdashPf{\semenv}{\cerase {\cexists \tv \Cc\where\Ca\where{\cunif \t \gt}}}{$\implies$I}
	  \eqPf{\cerase {\cexists \tv \Cc\where\Ca\where{\cunif \t \gt}}}{\cexists \tv \cerase {\Cc\where\Ca\where{\cunif \t \gt}}}{By definition}
	  \simplePf{\cerase {\cexists \tv \Cc\where\Ca\where{\cunif \t \gt}}}{\cref{lem:erase-simple}}
	  \vdashPf{\semenv\where{\tv \is \gtp}}{\cerase {\Cc\where\Ca\where{\cunif \t \gt}}}{\cref{lem:simple-inversion}}
	  \eqPf{\shape \gt}{\sh}{$\implies$E on $\Cshape {\Cc\where\Ca} \t \sh$}
\Hand 	  \shapePf{\parens{\cexists \tv \Cc\where\Ca}}{\t}{\sh}{Above}
	\end{llproof}

      \proofcase{$\cfor \tv \Cc$}

	\begin{llproof}
	  Similar to $\cexists \tv \Cc$ case.
	\end{llproof}

      \proofcase{$\cexistsi \inst \x \Cc$}

	\begin{llproof}
	  Similar to $\cexists \tv \Cc$ case.
	\end{llproof}

      \proofcase{$\clet \x \tv \Cc \c$}

	\begin{llproof}
	  \shapePf{\Ca}{\t}{\sh}{Premise}
	  \shapePf{\Cc\where\Ca}{\t}{\sh}{By \ih}
	  \ForallPf{\semenv, \gt}{}{Definition of $\Cshape {\parens {\Let \x \ldots}} \t \sh$}
	  \vdashPf{\semenv}{\cerase {\clet \x \tv {\Cc\where\Ca\where{\cunif \t \gt}} \c}}{$\implies$I}
	  &&$\cerase {\clet \x \tv {\Cc\where\Ca\where{\cunif \t \gt}} \c}$ & \\
	  &&$=\clet \x \tv {\cerase {\Cc\where\Ca\where{\cunif \t \gt}}} {\cerase \c}$ & {By definition} \\
	  \simplePf{\cerase {\clet \x \tv {\Cc\where\Ca\where{\cunif \t \gt}} \c}}{\cref{lem:erase-simple}}
	  \vdashPf{\semenv}{\cexists \tv \cerase {\Cc\where\Ca\where{\cunif \t \gt}}}{\cref{lem:simple-inversion}}
	  \simplePf{\cerase {\Cc\where\Ca\where{\cunif \t \gt}}}{\cref{lem:erase-simple}}
	  \vdashPf{\semenv\where{\tv \is \gtp}}{\cerase {\Cc\where\Ca\where{\cunif \t \gt}}}{\cref{lem:simple-inversion}}
	  \eqPf{\shape \gt}{\sh}{$\implies$E on $\Cshape {\Cc\where\Ca} \t \sh$}
\Hand 	  \shapePf{\parens{\clet \x \tv {\Cc\where\Ca} \c}}{\t}{\sh}{Above}
	\end{llproof}

      \proofcase{$\clet \x \tv \c \Cc$}

	\begin{llproof}
	  Similar to $\clet \x \tv \Cc \c$ case.
	\end{llproof}

      \proofcase{$\cletr \x \tv \tvs \Cc \c$}

	\begin{llproof}
	  Similar to $\clet \x \tv \Cc \c$ case.
	\end{llproof}

      \proofcase{$\cletr \x \tv \tvs \c \Cc$}

	\begin{llproof}
	  Similar to $\clet \x \tv \c \Cc$ case.
	\end{llproof}
    \end{proofcases}
  \end{proof}
\end{lemma}

\begin{lemma}[Inversion of unicity]
  \label{lem:unicity-inversion}~
  \begin{enumerate}[(\roman*)]
    \item If $\Cshape {\parens{\cexists \tv \C}} \t \sh$, then $\Cshape \C \t \sh$.
    \item If $\Cshape {\parens{\cfor \tv \C}} \t \sh$, then $\Cshape \C \t \sh$.
  \end{enumerate}
  \begin{proof}
    Follows from \cref{lem:simple-inversion}.
  \end{proof}
\end{lemma}

\begin{lemma}[Decanonicalization]
  \label{lem:decanonicalization}
  If $\semenv \Th \c$, then $\semenv \th \c$.
  \begin{proof}
    Induction on the given derivation $\semenv \Th \c$
  \end{proof}
\end{lemma}

\begin{theorem}[Canonicalization]
  \label{thm:canonicalization}
  If $\semenv \th \c$, then $\semenv \Th \c$.
  \begin{proof}
  We proceed by induction on $\semenv \th \c$ with the measure $\cmeasure \c$.
  \begin{proofcases}
    \proofcasederivation
      {True}
      {}
      {\semenv \th \ctrue}

      \begin{llproof}
	\simplePf{\ctrue}{By definition}
\Hand 	\VdashPf{\semenv}{\ctrue}{By \Rule{Can-Base}}
      \end{llproof}
    \proofcasederivation
      {Unif}
      {\semenv(\ta) = \semenv(\tb)}
      {\semenv \th \cunif \ta \tb}

      \begin{llproof}
	Similar to the \Rule{True} case.
      \end{llproof}
    \proofcasederivation
      {Conj}
      {\semenv \th \ca \\ \semenv \th \cb}
      {\semenv \th \ca \cand \cb}

      \begin{llproof}
	\vdashPf{\semenv}{\ca} {Premise}
	\vdashPf{\semenv}{\cb} {Premise}
	\VdashPf{\semenv}{\ca} {By \ih}
	\VdashPf{\semenv}{\cb} {By \ih}
	\decolumnizePf
	\casesPf{\semenv \Th \ca, \semenv \Th \cb}
      \end{llproof}

      \begin{proofcases}
	\proofcasederivationdouble
	  {Can-Base}
	  {\semenv \th \ca \\ \ca \simple}
	  {\semenv \Th \ca}
	  {Can-Base}
	  {\semenv \th \cb \\ \cb \simple}
	  {\semenv \Th \cb}

	  \begin{llproof}
	    \simplePf{\ca}{Premise}
	    \simplePf{\cb}{Premise}
	    \simplePf{\ca \cand \cb}{By \Rule{Simple-Conj}}
	    \decolumnizePf
\Hand 	    \VdashPf{\semenv}{\ca \cand \cb}{By \Rule{Can-Base}}

	  \end{llproof}

	\proofcasederivationdouble
	  {Can-Susp-Ctx}
	  {\Cshape \C \t \sh \\ \semenv \Th \C\where{\cmatched \t \sh \cbrs}}
	  {\semenv \Th \underbrace{\C\where{\cmatch \t \cbrs}}_\ca}
	  {}
	  {}
	  {\semenv \Th \cb}

	  \begin{llproof}

	    \VdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs}} {Premise}
	    \vdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs}} {\cref{lem:decanonicalization}}
	    \vdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs} \cand \cb}{By \Rule{Conj}}
 	    \VdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs} \cand \cb}{By \ih}
	    \Pf{}{}{\Cshape \C \tv \sh}{Premise}
	    \Pf{}{}{\Cshape {\parens {\C \cand \cb}} \tv \sh}{\cref{lem:compose-unicity}}
\Hand 	    \VdashPf{\semenv}{\C\where{\cmatch \t \cbrs}}{By \Rule{Can-Susp-Ctx}}
	  \end{llproof}

	\proofcasederivationdouble
	  {}
	  {}
	  {\semenv \Th \ca}
	  {Can-Susp-Ctx}
	  {\Cshape \C \t \sh \\ \semenv \Th \C\where{\cmatched \t \sh \cbrs}}
	  {\semenv \Th \underbrace{\C\where{\cmatch \t \cbrs}}_\cb}

	  \begin{llproof}
	    \Pf{}{}{}{Symmetric to the above case.}
	  \end{llproof}
      \end{proofcases}

      \proofcasederivation
	{Exists}
	{\semenv\where{\tv \is \gt} \th \c}
	{\semenv \th \cexists \tv \c}

	\begin{llproof}
	  \vdashPf{\semenv\where{\tv \is \gt}}{\c}{Premise}
	  \VdashPf{\semenv\where{\tv \is \gt}}{\c}{By \ih}
	  \casesPf{\semenv\where{\tv \is \gt} \Th \c}
	\end{llproof}

	\begin{proofcases}

	    \proofcasederivation
	      {Can-Base}
	      {\semenv\where{\tv \is \gt} \th \c \\ \c \simple}
	      {\semenv\where{\tv \is \gt} \Th \c}

	      \begin{llproof}
		\simplePf{\c}{Premise}
		\simplePf{\cexists \tv \c}{By \Rule{Simple-Exists}}
\Hand 		\VdashPf{\semenv}{\cexists \tv \c}{By \Rule{Can-Base}}
	      \end{llproof}


	      \proofcasederivation
		{Can-Susp-Ctx}
		{\Cshape \C \t \sh \\ \semenv\where{\tv \is \gt} \Th \C\where{\cmatched \t \sh \cbrs}}
		{\semenv \Th \underbrace{\C\where{\cmatch \t \cbrs}}_\c}

		\begin{llproof}
		  \VdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatched \t \sh \cbrs}}{Premise}
		  \vdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatched \t \sh \cbrs}}{\cref{lem:decanonicalization}}
	    \decolumnizePf
		  \vdashPf{\semenv}{\cexists \tv \C\where{\cmatched \t \sh \cbrs}}{By \Rule{Exists}}
		  \VdashPf{\semenv}{\cexists \tv \C\where{\cmatched \t \sh \cbrs}}{By \ih}
		  \Pf{}{}{\Cshape \C \t \sh}{Premise}
		  \Pf{}{}{\Cshape {\parens {\cexists \tv \C}} \t \sh}{\cref{lem:compose-unicity}}
\Hand             \VdashPf{\semenv}{\cexists \tv \C\where{\cmatch \t \cbrs}}{By \Rule{Can-Susp-Ctx}}
		\end{llproof}
	\end{proofcases}

	\proofcasederivation
	  {Forall}
	  {\forall \gt,~ \semenv\where{\tv \is \gt} \th \c}
	  {\semenv \th \cfor \tv \c}

	  \begin{llproof}
	    Similar to the \Rule{Exists} case.
	  \end{llproof}

	\proofcasederivation
	  {Let}
	  {\semenv \th \cexists \tv \ca \\ \semenv\where{\x \is \semenv(\cabs \tv \ca)} \th \cb}
	  {\semenv \th \clet \x \tv \ca \cb}

	  \begin{llproof}
	    \vdashPf{\semenv}{\cexists \tv \ca}{Premise}
	    \VdashPf{\semenv}{\cexists \tv \ca}{By \ih}
	    \vdashPf{\semenv\where{\x \is \semenv(\cabs \tv \ca)}}{\cb}{Premise}
	    \VdashPf{\semenv\where{\x \is \semenv(\cabs \tv \ca)}}{\cb}{By \ih}
	    \decolumnizePf
	    \casesPf{\semenv \Th \cexists \tv \ca, \semenv\where{\x \is \semenv(\cabs \tv \ca)} \Th \cb}
	  \end{llproof}

	  \begin{proofcases}
	    \proofcasederivationdouble
	      {Can-Base}
	      {\semenv \th \cexists \tv \ca \\ \cexists \tv \ca \simple}
	      {\semenv \Th \cexists \tv \ca}
	      {Can-Base}
	      {\semenv\where{\x \is \semenv(\cabs \tv \ca)} \th \cb \\ \cb \simple}
	      {\semenv\where{\x \is \semenv(\cabs \tv \ca)} \Th \cb}

	      \begin{llproof}
		\simplePf{\cexists \tv \ca}{Premise}
		\simplePf{\ca}{Inversion of \Rule{Simple-Exists}}
		\simplePf{\cb}{Premise}
		\simplePf{\clet \x \tv \ca \cb}{By \Rule{Simple-Let}}
\Hand		\VdashPf{\semenv}{\clet \x \tv \ca \cb}{By \Rule{Can-Base}}
	      \end{llproof}

	    \proofcasederivationdouble
	      {Can-Susp-Ctx}
	      {\Cshape {\parens {\cexists \tv \ca}} \t \sh \\ \semenv \Th \cexists \tv \C\where{\cmatched \t \sh \cbrs}}
	      {\semenv \Th \cexists \tv \underbrace{\C\where{\cmatch \t \cbrs}}_\ca}
	      {}
	      {}
	      {\semenv\where{\x \is \semenv(\cabs \tv \ca)} \Th \cb}

	      \begin{llproof}
		\shapePf{\parens {\cexists \tv \C}}{\t}{\sh}{Premise}
		\shapePf{\C}{\t}{\sh}{\cref{lem:unicity-inversion}}
		\VdashPf{\semenv}{\cexists \tv \C\where{\cmatched \t \sh \cbrs}}{Premise}
		\vdashPf{\semenv}{\cexists \tv \C\where{\cmatched \t \sh \cbrs}}{\cref{lem:decanonicalization}}
	    \decolumnizePf
		\eqPf{\semenv(\cabs \tv \ca)}
		  {\semenv(\cabs \tv \C\where{\cmatched \t \sh \cbrs})}
		  {\cref{corollary:matched-abstractions}}
		\vdashPf{\semenv}{\clet \x \tv {\C\where{\cmatched \t \sh \cbrs}} \cb}{By \Rule{Let}}
		\VdashPf{\semenv}{\clet \x \tv {\C\where{\cmatched \t \sh \cbrs}} \cb}{By \ih}
		\shapePf{\parens{\clet \x \tv \C \cb}}{\t}{\sh}{\cref{lem:compose-unicity}}
\Hand 		\VdashPf{\semenv}{\clet \x \tv {\C\where{\cmatch \t \cbrs}} \cb}{By \Rule{Can-Susp-Ctx}}
	      \end{llproof}

	    \proofcasederivationdouble
		{}
		{}
		{\semenv \Th \cexists \tv \ca}
		{Can-Susp-Ctx}
		{\Cshape \C \t \sh \\ \semenv\where{\x \is \semenv(\cabs \tv \ca)} \Th \C\where{\cmatched \t \sh \cbrs}}
		{\semenv\where{\x \is \semenv(\cabs \tv \ca)} \Th \underbrace{\C\where{\cmatch \t \cbrs}}_\cb}

		\begin{llproof}
		  \shapePf{\C}{\t}{\sh}{Premise}
		  \shapePf{\parens{\clet \x \tv \ca \C}}{\t}{\sh}{\cref{lem:compose-unicity}}
		  \VdashPf{\semenv\where{\x \is \semenv(\cabs \tv \ca)}}{\C\where{\cmatched \t \sh \cbrs}}{Premise}
		  \vdashPf{\semenv\where{\x \is \semenv(\cabs \tv \ca)}}{\C\where{\cmatched \t \sh \cbrs}}{\cref{lem:decanonicalization}}
		  \vdashPf{\semenv}{\clet \x \tv \ca {\C\where{\cmatched \t \sh \cbrs}}}{By \Rule{Let}}
		  \VdashPf{\semenv}{\clet \x \tv \ca {\C\where{\cmatched \t \sh \cbrs}}}{By \ih}
\Hand 		  \VdashPf{\semenv}{\clet \x \tv \ca {\C\where{\cmatch \t \sh}}}{By \Rule{Can-Susp-Ctx}}
		\end{llproof}
	  \end{proofcases}

      \proofcasederivation
	{App}
	{\semenv(\t) \in \semenv(\x)}
	{\semenv \th \capp \x \t}

      \begin{llproof}
	Similar to the \Rule{True} case.
      \end{llproof}

      \proofcasederivation
	{LetR}
	{\semenv \th \cexists {\tv, \tvs} \ca \\
	 \semenv\where{\x \is \semenv(\cabsr \tv \tvs \ca)} \th \cb}
	{\semenv \th \cletr \x \tv \tvs \ca \cb}

      \begin{llproof}
	Similar to the \Rule{Let} case.
      \end{llproof}

      \proofcasederivation
	{AppR}
	{\greg \tv \semenvp \in \semenv(\x) \\
	 \semenv(\t) = \semenvp(\tv)}
	{\semenv \th \capp \x \t}

      \begin{llproof}
	Similar to the \Rule{App} case.
      \end{llproof}

    \proofcasederivation
      {Exists-Inst}
      {\greg \tv \semenvp \in \semenv(\x) \\ \semenv\where{\inst \is \semenvp} \th \c}
      {\semenv \th \cexistsi \inst \x \c}

      \begin{llproof}
	Similar to the \Rule{Exists} case.
      \end{llproof}


    \proofcasederivation
      {Multi-Unif}
      {\forall \t \in \ueq,~ \semenv(\t) = \gt}
      {\semenv \th \ueq}

      \begin{llproof}
	Similar to the \Rule{Unif} case.
      \end{llproof}

    \proofcasederivation
      {Partial-Inst}
      {\semenv(\inst)(\tv) = \semenv(\t)}
      {\semenv \th \cpinst \inst \tv \t}


      \begin{llproof}
	Similar to the \Rule{App} case.
      \end{llproof}


  \end{proofcases}
  \end{proof}
\end{theorem}

\begin{lemma}[Inversion of suspension]
  \label{lem:susp-inversion}
  If $\semenv \th \C\where{\cmatch \t \cbrs}$ and $\Cshape \C \t \sh$,
  then\\$\semenv \th \C\where{\cmatched \t \sh \cbrs}$.

  \begin{proof}
    We use canonicalization (\cref{thm:canonicalization}) to induct on $\semenv \Th
    \C\where{\cmatch \t \cbrs}$ instead of $\semenv \th \C\where{\cmatch \t
    \cbrs}$.

    This simplifies the proof, but introduces a circular dependency between
    \cref{thm:canonicalization} and \cref{lem:susp-inversion}.
    %
    However, this does not compromise the well-foundedness of induction, as the
    application of \cref{lem:susp-inversion} (via
    \cref{corollary:matched-abstractions}) within the proof of
    \cref{thm:canonicalization} is restricted to strictly smaller constriaints.

    \begin{proofcases}
      \proofcasederivation
	{Can-Base}
	{\semenv \th \C\where{\cmatch \t \cbrs} \\ \C\where{\cmatch \t \cbrs} \simple}
	{\semenv \Th \C\where{\cmatch \t \cbrs}}

	\begin{llproof}
	  \simplePf{\C\where{\cmatch \t \cbrs}}{Premise}
	  \nsimplePf{\C\where{\cmatch \t \cbrs}}{\cref{lem:match-is-not-simple}}
\Hand 	  \contraPf{\semenv \th \C\where{\cmatched \t \sh \cbrs}}{}
	\end{llproof}

      \proofcasederivation
	{Can-Susp-Ctx}
	{\Cshape \Cp \tp \shp \\ \semenv \Th \Cp\where{\cmatched \tp \shp \cbrs'}}
	{\semenv \Th \underbrace{\Cp\where{\cmatch \tp \cbrs'}}_{\C\where{\cmatch {~\t~} {~\cbrs}}}}

	\begin{llproof}
	  \casesPf{\C = \Cp}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\C = \Cp$}

	    \begin{llproof}
	      \eqPf{\C}{\Cp}{Premise}
	      \eqPf{\tp}{\t}{}
	      \eqPf{\shp}{\sh}{}
	      \eqPf{\cbrs'}{\cbrs}{}
\Hand         \VdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs}}{Premise}
	    \end{llproof}

	  \proofcase{$\C \neq \Cp$}

	    \newcommand{\Ctwo}{\C_2}
	    \begin{llproof}
	      \eqPf{\Ctwo\where{\cmatch \t \cbrs, \cmatch \tp \cbrs'}}{\C\where{\cmatch \t \cbrs}}{For some 2-hole context $\Ctwo$}
	      \continueeqPf{\Cp\where{\cmatch \tp \cbrs'}}{}
	      \decolumnizePf
	      \VdashPf{\semenv}{\Ctwo\where{\cmatch \t \cbrs, \cmatched \tp \shp \cbrs'}}{Premise}
	      \decolumnizePf
	      \ForallPf{\semenvp, \gtp}{}{\hspace{32.5ex}Defn. of $\Cshape {\Ctwo\where{\square, \cmatched \tp \shp \cbrs'}} \t \sh$}
	      \decolumnizePf
	      \vdashPf{\semenvp}{\cerase {\Ctwo\where{\cunif \t \gtp, \cmatched \tp \shp \cbrs'}}}{$\implies$I}
	      \vdashPf{\semenvp}{\cerase {\Ctwo\where{\cunif \t \gtp, \ctrue}}}{\cref{lem:cong-simple}}
	    \decolumnizePf
	      \eqPf{\cerase {\Ctwo\where{\cunif \t \gtp, \ctrue}}}{\cerase {\Ctwo\where{\cunif \t \gtp, \cerase {\cmatch \tp \cbrs'}}}}{By definition}
	      \continueeqPf{\cerase {\C\where{\cunif \t \gtp}}}{By definition}
	      \vdashPf{\semenvp}{\cerase {\C\where{\cunif \t \gtp}}}{Above}
	      \eqPf{\shape \gtp}{\sh}{$\implies$E on $\Cshape \C \t \sh$}
	      \shapePf{\Ctwo\where{\square, \cmatched \tp \shp \cbrs'}}{\t}{\sh}{Above}
	      \VdashPf{\semenv}{\Ctwo\where{\cmatched \t \sh \cbrs, \cmatched \tp \shp \cbrs'}}{By \ih}
	      \decolumnizePf
	      \ForallPf{\semenvp, \gtp}{}{\hspace{32.5ex}Defn. of $\Cshape {\Ctwo\where{\cmatched \t \sh \cbrs, \square}} \tp \shp$}
	      \decolumnizePf
	      \vdashPf{\semenvp}{\cerase {\Ctwo\where{\cmatched \t \sh \cbrs, \cunif \tp \gtp}}}{$\implies$I}
	      \vdashPf{\semenvp}{\cerase {\Ctwo\where{\ctrue, \cunif \tp \gtp}}}{\cref{lem:cong-simple}}
	      \eqPf{\cerase {\Ctwo\where{\ctrue, \cunif \tp \gtp}}}{\cerase {\Ctwo\where{\cerase {\cmatch \t \cbrs}, \cunif \tp \gtp}}}{By definition}
	      \continueeqPf{\cerase {\Cp\where{\cunif \tp \gtp}}}{By definition}
	      \vdashPf{\semenvp}{\cerase {\C\where{\cunif \t \gtp}}}{Above}
	      \shapePf{\Cp}{\tp}{\shp}{Premise}
	      \eqPf{\shape \gtp}{\shp}{$\implies$E on $\Cshape \Cp \tp \shp$}
	      \shapePf{\Ctwo\where{\cmatched \t \sh \cbrs, \square}}{\tp}{\shp}{Above}
\Hand 	      \VdashPf{\semenv}{\Ctwo\where{\cmatched \t \sh \cbrs, \cmatch \tp \cbrs'}}{By \Rule{Con-Susp-Ctx}}
	    \end{llproof}
	\end{proofcases}
    \end{proofcases}
  \end{proof}
\end{lemma}

\begin{corollary}
  \label{corollary:matched-abstractions}
  If $\Cshape \C \t \sh$, then $\semenv(\cabs \tv \C\where{\cmatch \t \cbrs}) = \semenv(\cabs \tv \C\where{\cmatched \t \sh \cbrs})$.
  Similarly, $\semenv(\cabsr \tv \tvs \C\where{\cmatch \t \cbrs}) = \semenv(\cabsr \tv \tvs \C\where{\cmatched \t \sh \cbrs})$.
  \begin{proof}
    It is sufficient to show that $\semenv\where{\tv \is \gt} \th \C\where{\cmatch \t \cbrs}$ if and only if
    $\semenv \th \C\where{\cmatched \t \sh \cbrs}$.

    \begin{proofcases}
      \proofcase{$\implies$}

	\begin{llproof}
	  \shapePf{\C}{\t}{\sh}{Premise}
	  \vdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatch \t \cbrs}}{Premise}
\Hand 	  \vdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatched \t \sh \cbrs}}{\cref{lem:susp-inversion}}
	\end{llproof}
      \proofcase{$\impliedby$}

	\begin{llproof}
	  \shapePf{\C}{\t}{\sh}{Premise}
	  \vdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatched \t \sh \cbrs}}{Premise}
\Hand 	  \vdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatch \t \cbrs}}{By \Rule{Susp-Ctx}}
	\end{llproof}
    \end{proofcases}

    For $\semenv(\cabsr \tv \tvs \C\where{\cmatch \t \cbrs}) = \semenv(\cabsr \tv \tvs \C\where{\cmatched \t \sh \cbrs})$, the proof is identical.
  \end{proof}
\end{corollary}

\clearpage
\section{Properties of the constraint solver}

The primary requirement of our constraint solver is correctness:
a constraint $\c$ is satisfiable if and only if the solver terminates with a solution.

This section decomposes this requirement into three properties: preservation,
progress, and termination---and provides proofs for each. Correctness then
follows as a corollary of these results.

\subsection{Preservation}

This section details the proof of \emph{preservation} for the solver: if $\ca
\csolve \cb$, then $\ca \cequiv \cb$.
%
Since rewriting may occur under arbitrary contexts, it sufficies to check for
each rule, that the equivalence $\ca \cequiv \cb$ holds under all contexts
$\C$.

However, the introduction of suspended match constraints breaks congruence of
equivalence. That is, it is no longer the case that $\ca \cequiv \cb$ implies
$\C\where\ca \cequiv \C\where\cb$.
%
For instance, we have $\cmatch \tv \cbrs \cequiv \cfalse$, yet
$\C\where{\cmatch \tv \cbrs} \cnequiv \C\where\cfalse$ for $\C \is \square
\cand \cunif \tv \tint$.

As a result, we must prove \emph{contextual equivalence} for each rewriting
rule explicitly. This is both nontrivial and tedious. To simplify the task, we
first present a series of auxillary lemmas that recover contextual equivalence
for many common cases.
%
Whenever possible, we prefer to work with equivalences on \emph{simple}
constraints, as these retain the desired congruence properties that do not hold
generally in our system.

\begin{definition}[Contextual eqiuvalence]
  Two constraints $\ca$ and $\cb$ are contextually equivalence, written $\ca \cequivctx \cb$,
  iff:
  \begin{mathpar}
    \ca \cequivctx \cb \uad\eqdef\uad \all \C \uad \C\where\ca \cequiv \C\where\cb
  \end{mathpar}
\end{definition}

\begin{corollary}[Simple equivalence is congruent]
  \label{corollary:cong-simple-equiv}
  Given simple constraints $\ca, \cb$ and simple context $\C$. If
  $\ca \cequiv \cb$, then $\C\where\ca \equiv \C\where\cb$.
  \begin{proof}
    Follows from \cref{lem:cong-simple}.
  \end{proof}
\end{corollary}

\begin{lemma}[Simple equivalence is contextual]
  For simple constraints $\ca, \cb$. If $\ca \cequiv \cb$, then $\ca \cequivctx \cb$.
  \begin{proof}
    We proceed by induction on the number of suspended match constraints $n$ in $\C$.

    \begin{proofcases}
      \proofcase{$n$ is 0}
	Follows from \cref{corollary:cong-simple-equiv}.

      \proofcase{$n$ is $k + 1$}

	\begin{proofcases}
	  \proofcase{$\implies$}

	  \newcommand{\Ctwo}{\Cb}
	  \begin{llproof}
	    \vdashPf{\semenv}{\C\where{\ca}}{Premise}
	    \VdashPf{\semenv}{\C\where{\ca}}{\cref{thm:canonicalization}}
	    \shapePf\Cp\t\sh{Inversion of \Rule{Can-Susp-Ctx}}
	    \VdashPf{\semenv}{\Cp\where{\cmatched \t \sh \cbrs}}{\ditto}
	    \eqPf{\C\where{\ca}}{\Cp\where{\cmatched \t \sh \cbrs}}{\ditto}
	    \continueeqPf{\Ctwo\where{\cmatched \t \sh \cbrs, \ca}}{For some two-hole context $\Ctwo$}
	    \vdashPf{\semenv}{\Ctwo\where{\cmatched \t \sh \cbrs, \cb}}{By \ih}
	    \ForallPf{\semenvp, \gt}{}{Defn of $\Cshape \Cp \t \sh$}
	    \vdashPf{\semenvp}{\cerase{\Ctwo\where{\t \is \gt, \cb}}}{Premise}
	    \vdashPf{\semenvp}{\cerase{\Ctwo\where{\t \is \gt, \ca}}}{\cref{corollary:cong-simple-equiv}}
	    \vdashPf{\semenvp}{\cerase{\Cp\where{\t \is \gt}}}{Above}
	    \eqPf{\shape \gt}{\sh}{$\implies$E on $\Cshape \Cp \t \sh$}
	    \decolumnizePf
	    \shapePf{\Ctwo\where{\square, \cb}}{\t}{\sh}{Above}
\Hand	    \vdashPf{\semenv}{\Ctwo\where{\cmatch \t \cbrs, \cb}}{By \Rule{Susp-Ctx}}
	  \end{llproof}

	  \proofcase{$\impliedby$}

	  \begin{llproof}
	    Symmetric argument.
	  \end{llproof}
	\end{proofcases}
    \end{proofcases}
  \end{proof}
\end{lemma}

\begin{lemma}[Unification is simple]
  For all unification problems $\up$, $\up \simple$.
  \begin{proof}
    By induction on the structure of $\up$.
  \end{proof}
\end{lemma}


\begin{definition}[Context equivalence]
  Two contexts $\Ca$ and $\Cb$ are equivalent with guard $P$, written $\Ca \cctxequiv^P \Cb$ iff:
  \begin{mathpar}
    \Ca \cctxequiv^P \Cb \uad\eqdef\uad \all \cs \uad P(\cs) \implies \Ca\where\cs \cequivctx \Cb\where\cs
  \end{mathpar}
\end{definition}

\begin{definition}[Match-closed]
  A predicate $P$ on constraints is \emph{match-closed} if, for all constraints $\cs, \cs'$, matches $\cmatch \t \cbrs$ and shapes $\sh$,
  \begin{mathpar}
    P(\cs, \cmatch \t \cbrs, \cs') \implies P(\cs, \cmatched \t \sh \cbrs, \cs')
  \end{mathpar}
\end{definition}


\begin{lemma}[Simple context equivalence]
  For any two simple contexts $\Ca, \Cb$ and a match-closed guard $P$. If
  the two contexts $\Ca$ and $\Cb$ are equivalent under any simple constraints satisfying $P$,
  then $\Ca \cctxequiv^P \Cb$.

  \begin{proof}
    Let us assume that ($\dagger$) holds:
    \begin{mathpar}
      \all{\C, \cs \simple} P(\cs) \implies \C\where{\Ca\where\cs} \cequiv \C\where{\Cb\where\cs}
    \end{mathpar}

    We proceed by induction on the number of suspended match constraints $n$ with
    the statement $Q(n) \is  \all {\cs, \C} \cnmatches {\C} + \cnmatches \cs = n \implies P(\cs) \implies
    \C\where{\Ca\where\cs} \equiv \C\where{\Cb\where\cs}$.


    \begin{proofcases}
      \proofcase{$n$ is 0}

	\begin{llproof}
	  \simplePf{\C, \cs}{Premise ($n$ is 0)}
	  \Hand	  \equivPf{P(\cs) \implies \C\where\Ca\where\cs}{\C\where\Cb\where\cs}{$\dagger$}
	\end{llproof}

      \proofcase{$n$ is $k + 1$}

	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{llproof}
	    \Pf{P(\cs)}{}{}{Premise}
	    \vdashPf{\semenv}{\C\where\Ca\where\cs}{Premise}
	    \VdashPf{\semenv}{\C\where\Ca\where\cs}{\cref{thm:canonicalization}}
	    \VdashPf{\semenv}{\Cp\where{\cmatched \t \sh \cbrs}}{Inversion of \Rule{Can-Susp-Ctx}}
	    \shapePf{\Cp}{\t}{\sh}{\ditto}
	    \eqPf{\C\where\Ca\where\cs}{\Cp\where{\cmatch \t \cbrs}}{\ditto}
	    \commentPf{Cases on $\C, \cs$.}{}
	  \end{llproof}

	  \begin{proofcases}
	    \proofcase{$\C$ contains $\Cp$'s hole}

	      \newcommand{\Ctwo}{\Cc}
	      \begin{llproof}
		\eqPf{\C\where\Ca\where\cs}{\Ctwo\where{\cmatch \t \cbrs, \Ca\where\cs}}{For some 2-hole context $\Ctwo$}
		\VdashPf{\semenv}{\Ctwo\where{\cmatched \t \sh \cbrs, \Ca\where\cs}}{}
		\eqPf{k}{\cnmatches {\Ctwo\where{\cmatched \t \sh \cbrs, \Ca\where\cs}}}{}
		\vdashPf{\semenv}{\Ctwo\where{\cmatched \t \sh \cbrs, \Cb\where\cs}}{By \ih}
		\decolumnizePf
		\ForallPf{\semenvp, \gt}{}{}
		\vdashPf{\semenvp}{\cerase{\Ctwo\where{\cunif \t \gt, \Cb\where\cs}}}{Premise}
		\vdashPf{\semenvp}{\cerase{\Ctwo\where{\cunif \t \gt, \Ca\where\cs}}}{$\dagger$}
		\eqPf{\shape \gt}{\sh}{$\implies$E on $\Cshape \Cp \t \sh$}
		\shapePf{\Ctwo\where{\square, \Cb\where\cs}}{\t}{\sh}{Above}
\Hand		\vdashPf{\semenv}{\Ctwo\where{\cmatch \t \cbrs, \Cb\where\cs}}{By \Rule{Susp-Ctx}}
	      \end{llproof}

	    \proofcase{$\ci$ contains $\Cp$'s hole}

	      \begin{llproof}
		Similar argument to the above case, but relies on the match-closure of $P$.
	      \end{llproof}
	  \end{proofcases}


	  \proofcase{$\impliedby$}

	  \begin{llproof}
	    Symmetric argument.
	  \end{llproof}
	\end{proofcases}
    \end{proofcases}
  \end{proof}
\end{lemma}


\begin{lemma}[Simple let equivalence]
  Given simple constraints $\ca, \cb$ and a simple context $\C$.
  Suppose that
    \begin{mathpar}
      \forall \semenv, \semenvp, \cs \simple. \uad
	\semenvp(\x) = \semenv(\cabsr \tv \tvs {\C\where\cs}) \implies
	  \semenvp \th \ca \iff \semenvp \th \cb
    \end{mathpar}
  Then, for any context $\Cp$ that does not re-bind $\x$, we have:
    \begin{mathpar}
      \cletr \x \tv \tvs {\C\where{\bar\square}} {\Cp\where\ca}
	\cctxequiv^P \cletr \x \tv \tvs {\C\where{\bar\square}} {\Cp\where\cb}
    \end{mathpar}
  for any match-closed guard $P$ on the holes.

  \begin{proof}
    Let us assume ($\dagger$):
    \begin{mathpar}
      \forall \semenv, \semenvp, \cs. \uad
	\semenvp(\x) = \semenv(\cabsr \tv \tvs {\C\where\cs}) \implies
	  \semenvp \th \ca \iff \semenvp \th \cb
    \end{mathpar}

    We proceed by induction on the number of suspended match constraints in
    $\Cpp, \Cp, \cs$ with the statement $P(n) \is \all {\Cpp, \Cp, \cs} \cnmatches {\Cpp, \Cp, \cs} = n \implies \Cpp\where{\cletr \x \tv \tvs {\C\where\cs} {\Cp\where{\ca}}}
    \cequiv \Cpp\where{\cletr \x \tv \tvs {\C\where\cs} {\Cp\where\cb}}$.

    \begin{proofcases}
      \proofcase{$n$ is 0}

	Thus $\Cpp, \Cp, \cs$ are simple. Sufficies to show the equivalence on the $\Let$-constraint directly and use congruence
	of equivalence for simple constraints (Lemma XXX) to establish the result.

	We proceed by induction on the structure of $\Cp$ with the statement ($\ddagger$):
	\begin{mathpar}
	\forall \semenv, \semenvp. \uad
	  \semenvp(\x) = \semenv(\cabsr \tv \tvs {\C\where\cs}) \implies
	    \semenvp \th \Cp\where{\ca} \iff \semenvp \th \Cp\where{\cb}
	\end{mathpar}
	This holds due to the compositionality of simple equivalence using $\dagger$ as a base case.

	\begin{proofcases}
	  \proofcase{$\implies$}

	\begin{llproof}
	  \vdashPf{\semenv}{\cletr \x \tv \tvs {\C\where{\cs}} {\Cp\where{\ca}}}{Premise}
	  \vdashPf{\semenv}{\cexists {\tv, \tvs} \C\where{\cs}}{Lemma XXX}
	  \vdashPf{\semenv\where{\x \is \semenv(\cabsr \tv \tvs \C\where{\cs})}}{\Cp\where{\ca}}{\ditto}
	  \vdashPf{\semenv\where{\x \is \semenv(\cabsr \tv \tvs \C\where{\cs})}}{\Cp\where{\cb}}{$\ddagger$}
	  \vdashPf{\semenv}{\cletr \x \tv \tvs {\C\where{\cs}} {\Cp\where{\cb}}}{By \Rule{LetR}}
	\end{llproof}
	  \proofcase{$\impliedby$}

	  \begin{llproof}
	    Symmetric argument.
	  \end{llproof}
	\end{proofcases}

      \proofcase{$n$ is $k + 1$}

      \begin{llproof}
	Analogous to the inductive step in Lemma XXX.
      \end{llproof}
    \end{proofcases}
  \end{proof}
\end{lemma}

\newcommand{\disjointPf}[3]{\Pf{#1}{\disjoint}{#2}{#3}}
\begin{lemma}
  If $\cunif \tv {\cunif \t \ueq} \in \C$ and $\t \notin \TyVars$, then
  $\Cshape \C \tv {~\shape \t}$.
  \begin{proof}~

    \begin{llproof}
      \inPf{\cunif \tv {\cunif \t \ueq}}{\C}{Premise}
      \notinPf{\t}{\TyVars}{Premise}
      \eqPf{\t}{\shapp[\shape \t] \tys}{For some $\tys$}
      \eqPf{\C}{\Ca\where{\cunif \tv {\cunif \t \ueq} \cand \Cb}}{By definition}
      \disjointPf{\fvs {\tv, \t, \ueq}}{\bvs \Cb}{\ditto}
      \ForallPf{\semenv, \gt}{}{Defn. of $\Cshape \C \tv {~\shape \t}$}
      \vdashPf{\semenv}{\cerase{\Ca\where{\cunif \tv {\cunif {\shapp[\shape \t] \tys} \ueq} \cand \Cb\where{\cunif \tv \gt}}}}{Premise}
      \vdashPf{\semenva}{\cunif \tv {\cunif {\shapp[\shape \t] \tys} \ueq}}{Inversion of $\Ca$}
      \vdashPf{\semenvb}{\cunif \tv \gt}{Inversion of $\Cb$}
      \eqPf{\gt}{\semenvb(\tv)}{Lemma XXX}
      \continueeqPf{\semenva(\tv)}{$\tv \disjoint \bvs \Cb$}
      \continueeqPf{\shapp[\shape \t] {\semenva(\tys)}}{Lemma XXX}
\Hand \eqPf{\shape \gt}{\shape \t}{Applying shape to both sides}
    \end{llproof}
  \end{proof}
\end{lemma}

\begin{lemma}
  If $\cunif {\tvc} {\cunif \t \ueq} \in \C\where\Cb$ and $\t \notin \TyVars$,
  then
  \begin{mathpar}
    \Cshape {\C\where
       {\cletr \x \tv {\tvs} {\Ca\where{\square}}
			     {\Cb\where{\cpapp \x \tvp \tvc \inst}}}}
      \tvp
      {~\shape \t}
  \end{mathpar}
  \begin{proof}
    Similar proof to Lemma XXX.
  \end{proof}
\end{lemma}


\begin{lemma}[Unification preservation]
  If $\upa \unif \upb$, then $\upa \equiv \upb$
  \begin{proof}
    By induction on the given derivation $\upa \unif \upb$.
    See \cite{Pottier-Remy/emlti} for more details.
  \end{proof}
\end{lemma}

\preservation
\newcommand{\unifPf}[3]{\Pf{#1}{\unif}{#2}{#3}}
\newcommand{\equivctxPf}[3]{\Pf{#1}{\cequivctx}{#2}{#3}}
\newcommand{\ctxequivPf}[3]{\Pf{#1}{\cctxequiv}{#2}{#3}}
\begin{proof}
  We proceed by induction on the given derivation.
  It sufficies to show that for each individual rule $R$ ($\ca \csolve_R \cb$),
  that $\ca \cequivctx \cb$.

  \begin{proofcases}
    \proofcaserewrite
      {S-Unif}
      {\upa \\ \upa \unif \upb}
      {\upb}

	\begin{llproof}
	  \unifPf{\upa}{\upb}{Premise}
	  \equivPf{\upa}{\upb}{Theorem XXX}
	  \simplePf{\upa, \upb}{Lemma XXX}
\Hand 	  \equivctxPf{\upa}{\upb}{Lemma XXX}
	\end{llproof}

    \proofcaserewrite
      {S-Exists-Conj}
      {\parens {\cexists \tv \ca} \cand \cb \\ \tv \disjoint \cb}
      {\cexists \tv \ca \cand \cb}

	\begin{llproof}
	  \disjointPf{\tv}{\cb}{Premise}
	  \decolumnizePf
	  \sufficientPf{equivalence for simple constraints}{}{Lemma XXX}
	  \supposePf{\ca, \cb \simple} {Premise}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\parens {\cexists \tv \ca} \cand \cb}{Premise}
	    \vdashPf{\semenv\where{\tv \is \gt}}{\ca}{\cref{lem:simple-inversion}}
	    \vdashPf{\semenv}{\cb}{\cref{lem:simple-inversion}}
	    \vdashPf{\semenv\where{\tv \is \gt}}{\cb}{Lemma XXX}
	    \vdashPf{\semenv\where{\tv \is \gt}}{\ca \cand \cb}{By \Rule{Conj}}
\Hand       \vdashPf{\semenv}{\cexists \tv \ca \cand \cb}{By \Rule{Exists}}
	  \end{llproof}
	  \proofcase{$\impliedby$}

	    \begin{llproof}
	    Symmetric argument.
	    \end{llproof}
	\end{proofcases}


      \proofcase{\Rule{S-Let}, \Rule{S-Exists-Exists-Inst},
      \Rule{S-Exists-Inst-Conj}, \Rule{S-Let-ExistsLeft},
      \Rule{S-Let-Exists-InstLeft}, \Rule{S-Let-ExistsRight},
      \Rule{S-Let-Exists-InstRIght}, \Rule{S-Let-ConjLet},
      \Rule{S-Let-ConjRight}, \Rule{S-Inst-Name}, \Rule{S-Exists-Inst-Solve},
      \Rule{S-All-Exists-Inst}, \Rule{S-All-Conj}}

      \begin{llproof}
	Similar argument to the \Rule{S-Exists-Conj} case.
      \end{llproof}

    \proofcaserewrite
      {S-Match-Type}
      {\cmatch \t \cbrs \\ \t \notin \TyVars}
      {\cmatched \t {\shape \t} \cbrs}

	\begin{llproof}
	    \notinPf{\t}{\TyVars}{Premise}
	    \shapePf{\square}{\t}{~\shape \t}{By definition}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\cmatch \t \cbrs}{Premise}
\Hand 	    \vdashPf{\semenv}{\cmatched \t {\shape \t} \cbrs}{\cref{lem:susp-inversion}}
	  \end{llproof}

	  \proofcase{$\impliedby$}

	  \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\cmatched \t {\shape \t} \cbrs}{Premise}
\Hand 	    \vdashPf{\semenv}{\cmatch \t \cbrs}{By \Rule{Susp-Ctx}}
	  \end{llproof}
	\end{proofcases}

    \proofcaserewrite
      {S-Match-Var}
      {\C\where{\cmatch \tv \cbrs} \\ \cunif \tv {\cunif \t \ueq} \in \C}
      {\C\where{\cmatched \tv {\shape \t} \cbrs}}

	\begin{llproof}
	  \inPf{\cunif \tv {\cunif \t \ueq}}{\C}{Premise}
	  \shapePf{\C}{\tv}{~ \shape \t}{Lemma XXX}
	\end{llproof}

	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\C\where{\cmatch \tv \cbrs}}{Premise}
\Hand 	    \vdashPf{\semenv}{\C\where{\cmatched \tv {\shape \t} \cbrs}}{\cref{lem:susp-inversion}}
	  \end{llproof}

	  \proofcase{$\impliedby$}

	  \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\C\where{\cmatched \tv {\shape \t} \cbrs}}{Premise}
\Hand 	    \vdashPf{\semenv}{\C\where{\cmatch \tv \cbrs}}{By \Rule{Susp-Ctx}}
	  \end{llproof}
	\end{proofcases}


    \proofcaserewrite
      {S-Let-AppR}
      {\cletr \x \tv \tvs \ca {\C\where{\capp \x \t}} \\ \tvc \disjoint \t \\ \x \disjoint \bvs \C}
      {\cletr \x \tv \tvs \ca {\C\where{\cexistsi {\tvc, \inst} \x \cunif \tvc \t \cand \cpinst \inst \tv \tvc }}}


	\begin{llproof}
	  \disjointPf{\tvc}{\t}{Premise}
	  \disjointPf{\x}{\bvs \C}{Premise}
	  \decolumnizePf
	  \sufficientPf{equivalence between}{\capp \x \t \text{ and } \cexistsi {\tvc, \inst} \x \cunif \tvc \t \cand \cpinst \inst \tv \tvc}{Lemma XXX}
	  \supposePf{\semenvp(\x) = \semenv(\cabsr \tv \tvs \ca)}{Premise}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\implies$}

	    \begin{llproof}
	      \vdashPf{\semenvp}{\capp \x \t}{Premise}
	      \inPf{\greg \tv {\semenva}}{\semenv(\x)}{Lemma XXX}
	      \eqPf{\semenva(\tv)}{\semenvp(\t)}{\ditto}
	      \vdashPf{\semenvp\where{\tvc \is \semenvp(\t), \inst \is \semenva}}{\cpinst \inst \tv \tvc}{By \Rule{Partial-Inst}}
	      \vdashPf{\semenvp\where{\tvc \is \semenvp(\t), \inst \is \semenva}}{\cunif \tvc \t}{By \Rule{Unif}}
\Hand	      \vdashPf{\semenvp}{\cexistsi {\tvc, \inst} \x {\cunif \tvc \t \cand \cpinst \inst \tv \tvc}}{By \Rule{Exists}, \Rule{Exists-Inst} and \Rule{Conj}}
	    \end{llproof}

	  \proofcase{$\impliedby$}

	    \begin{llproof}
	      Symmetric argument.
	    \end{llproof}
	\end{proofcases}

    \proofcaserewrite
      {S-Inst-Copy}
      {\cletr \x \tv \tvs {\c}
	\C\where{\cpapp \x \tvp \tvc \inst}\\
	\c = \cp \cand \cunif \tvp {\cunif {\shapp \tvbs} \ueq}\\
	\tvp \in \reg \tv \tvs \\
	\neg \cyclic {\c} \\
	\tvbs' \disjoint \tvp, \tvc, \tvbs \\
       \x \disjoint \bvs \C}
      {\cletr \x \tv \tvs {\c}
	\C\where{\cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}}


	\begin{llproof}
	  \disjointPf{\x}{\bvs \C}{Premise}
	  \disjointPf{\tvbs'}{\tvp, \tvc, \tvbs}{Premise}
	  \decolumnizePf
	  \sufficientPf{equivalence between}{\cpapp \x \tvp \tvc \inst \text{ and } \cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}{Lemma XXX}
	  \supposePf{\semenvp(\x) = \semenv(\cabsr \tv {\tvs} \c)}{Premise}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\implies$}

	    \begin{llproof}
	      \vdashPf{\semenvp} {\cpapp \x \tvp \tvc \inst}{Premise}
	      \inPf{\greg \tv \semenva}{\semenv(\x)}{$\cexistsi \inst \x \in \C$}
	      \eqPf{\semenvp(\inst)}{\semenva}{\ditto}
	      \eqPf{\semenvp(\tvc)}{\semenv(\inst)(\tvp)}{Lemma XXX}
	      \continueeqPf{\semenva(\tvp)}{Above}
	      \vdashPf{\semenva}{\cp \cand \cunif \tvp {\cunif {\shapp \tvbs} \ueq}}{Above}
	      \vdashPf{\semenva}{\cunif \tvp {\cunif {\shapp \tvbs} \ueq}}{Lemma XXX}
	      \eqPf{\semenva(\tvp)}{\shapp {\semenva(\tvbs)}}{\ditto}
	      \eqPf{\semenvp(\tvc)}{\shapp {\semenva(\tvbs)}}{Above}
	      \vdashPf{\semenvp\where{\tvbs' \is \semenva(\tvbs)}}{\cunif \tvc {\shapp {\tvbs'}}}{By \Rule{Unif}}
	      \vdashPf{\semenvp\where{\tvbs' \is \semenva(\tvbs)}}{\cpapp \x \tvbs {\tvbs'} \inst}{By \Rule{Partial-Inst}}
\Hand 	      \vdashPf{\semenvp}{\cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}{By \Rule{Exists} and \Rule{Conj}}
	    \end{llproof}

	  \proofcase{$\impliedby$}

	    \begin{llproof}
	      Symmetric argument.
	    \end{llproof}
	\end{proofcases}

    \proofcaserewrite
      {S-Inst-Unif}
      {\cpinst \inst \tv \tvca \cand \cpinst \inst \tv \tvcb}
      {\cpinst \inst \tv \tvca \cand \cunif \tvca \tvcb}

      \begin{llproof}

	\sufficientPf{equivalence between}{{\cpinst \inst \tv \tvca \cand
	\cpinst \inst \tv \tvcb} \text{ and } {\cpinst \inst \tv \tvca \cand
	\cunif \tvca \tvcb} }{Lemma XXX}

      \end{llproof}

      \begin{proofcases}
	\proofcase{$\implies$}

	  \begin{llproof}
	    \vdashPf{\semenv}{\cpinst \inst \tv \tvca \cand \cpinst \inst \tv \tvcb}{Premise}
	    \vdashPf{\semenv}{\cpinst \inst \tv \tvca}{Lemma XXX}
	    \vdashPf{\semenv}{\cpinst \inst \tv \tvcb}{Lemma XXX}
	    \eqPf{\semenv(\tvca)}{\semenv(\inst)(\tv)}{Lemma XXX}
	    \eqPf{\semenv(\tvcb)}{\semenv(\inst)(\tv)}{\ditto}
	    \eqPf{\semenv(\tvca)}{\semenv(\tvcb)}{Above}
	    \vdashPf{\semenv}{\cunif \tvca \tvcb}{By \Rule{Unif}}
\Hand	    \vdashPf{\semenv}{\cpinst \inst \tv \tvca \cand \cunif \tvca \tvcb}{By \Rule{Conj}}
	  \end{llproof}

	\proofcase{$\impliedby$}

	  \begin{llproof}
	    Symmetric argument.
	  \end{llproof}
      \end{proofcases}

    \proofcaserewrite
      {S-Inst-Poly}
      {\cletr \x \tv {\tvs, \tvp} {\ueqs \cand \c} {\C\where{\cpapp \x \tvp \tvc \inst}} \\
       \cfor \tvp \cexists {\tv, \tvs} {\ueqs} \cequiv \ctrue \\
       \tvp \disjoint \c, \insts \C \inst \\
       \x \disjoint \bvs \C}
      {\cletr \x \tv {\tvs,\tvp} {\ueqs \cand \c} {\C\where\ctrue}}


	\begin{llproof}
	  \equivPf{\cfor \tvp \cexists {\tv, \tvs} \ueqs}{\ctrue}{Premise}
	  \disjointPf{\tvp}{\c, \insts \C \inst}{Premise}
	  \disjointPf{\x}{\bvs \C}{Premise}
	  \decolumnizePf
	  \sufficientPf{equivalence between}
	    {\cpapp \x \tvp \tvc \inst \text{ and } \ctrue}
	    {Lemma XXX}
	  \supposePf{\semenvp(\x) = \semenv(\cabsr \tv {\tvs, \tvp} \ueqs \cand \c)}{Premise}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\implies$}

	    \begin{llproof}
	      \vdashPf{\semenvp}{\cpapp \x \tvp \tvc \inst}{Premise}
\Hand	      \vdashPf{\semenvp}{\ctrue}{By \Rule{True}}
	    \end{llproof}

	  \proofcase{$\impliedby$}

	    \begin{llproof}
	      \vdashPf{\semenvp}{\ctrue}{Premise}
	      \inPf{\greg \tv {\semenva}}{\semenvp(\x)}{$\C = \Ca\where{\cexistsi \inst \x \Cb}$}
	      \eqPf{\semenvp(\inst)}{\semenva}{\ditto}
	      \eqPf{\semenvp(\tvc)}{\semenva(\tvp)}{Lemma XXX}
	      \casesPf{\semenva(\tvp)}
	    \end{llproof}
	    \begin{proofcases}
	      \proofcase{$\semenva(\tvp) = \semenvp(\tvc)$}

		\begin{llproof}
		  \eqPf{\semenva(\tvp)}{\semenvp(\tvc)}{Premise}
\Hand		  \vdashPf{\semenvp}{\cpapp \x \tvp \tvc \inst}{By \Rule{Partial-Inst}}
		\end{llproof}


	      \proofcase{$\semenva(\tvp) \neq \semenvp(\tvc)$}

		\begin{llproof}
		  \LetPf{\semenvb}{\semenva\where{\tvp \is \semenvp(\tvc)}}{}
		  \vdashPf{\semenva}{\ueqs \cand \c}{By definition}
		  \vdashPf{\semenva}{\ueqs}{Lemma XXX}
		  \vdashPf{\semenvb}{\ueqs}{$\tvp$ is polymorphic}
		  \vdashPf{\semenvb}{\c}{$\tvp \disjoint \c$}
		  \vdashPf{\semenvb}{\ueqs \cand \c}{By \Rule{Conj}}
		  \inPf{\greg \tv \semenvb}{\semenv(\x)}{By definition}
		  \supposePf{\semenvc \th \Cb\where\ctrue}{Considering entailment on $\cexistsi \inst \x$}
		  \eqPf{\semenvc(\inst)}{\semenva}{\ditto}
		  \vdashPf{\semenvc\where{\inst \is \semenvb}}{\Cb\where\ctrue}{$\inst.\tvp \disjoint \Cb$}
		  \vdashPf{\deriv :: \semenvc}{\Cb\where\ctrue}{By \Rule{Exists-Inst}}
		  \commentPf{$\deriv$ is a derivation that satisfies $\semenva(\tvp) = \semenvp(\tvc)$.}{}
\Hand		  \commentPf{So this case degenerates to the former case.}{}
		\end{llproof}
	    \end{proofcases}
	\end{proofcases}

    \proofcaserewrite
      {S-Inst-Mono}
      {\cletr \x \tv \tvs \c {\C\where{\cpapp \x \tvb \tvc \inst}} \\
       \tvb \disjoint \tv, \tvs \\
       \x, \tvb \disjoint \bvs \C}
      {\cletr \x \tv \tvs \c {\C\where{\cunif \tvb \tvc}}}

	\begin{llproof}
	  \disjointPf{\tvb}{\tv, \tvs}{Premise}
	  \disjointPf{\x, \tvb}{\bvs \C}{Premise}
	  \decolumnizePf
	  \sufficientPf{equivalence between}
	    {\cpapp \x \tvb \tvc \inst \text{ and } \cunif \tvb \tvc}
	    {Lemma XXX}
	  \supposePf{\semenvp(\x) = \semenv(\cabsr \tv {\tvs} \c)}{Premise}
	\end{llproof}

	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{llproof}
	    \vdashPf{\semenvp}{\cpapp \x \tvb \tvc \inst}{Premise}
	    \inPf{\greg \tv \semenva}{\semenv(\c)}{$\cexistsi \inst \x \in \C$}
	    \eqPf{\semenvp(\inst)}{\semenva}{\ditto}
	    \eqPf{\semenvp(\tvc)}{\semenva(\tvb)}{Lemma XXX}
	    \eqPf{\semenva(\tvb)}{\semenv(\tvb)}{$\tvb \disjoint \tv, \tvs$}
	    \eqPf{\semenvp(\tvb)}{\semenv(\tvb)}{$\tvb \disjoint \bvs \C$}
	    \eqPf{\semenvp(\tvc)}{\semenvp(\tvb)}{Above}
	    \vdashPf{\semenvp}{\cunif \tvc \tvb}{By \Rule{Unif}}
	  \end{llproof}

	  \proofcase{$\impliedby$}

	  \begin{llproof}
	    Symmetric argument.
	  \end{llproof}
	\end{proofcases}


    \proofcaserewrite
      {S-Let-Solve}
      {\cletr \x \tv \tvs \ueqs \c \\ \x \disjoint \c \\
       \cexists {\tv, \tvs} \ueqs \cequiv \ctrue}
      {\c}
	\begin{llproof}
	  \disjointPf{\x}{\c}{Premise}
	  \equivPf{\cexists {\tv, \tvs} \ueqs}{\ctrue}{}
	  \decolumnizePf
	  \sufficientPf{equivalence for simple constraints}{}{Lemma XXX}
	  \supposePf{\c \simple} {Premise}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\cletr \x \tv \tvs \ueqs \c}{Premise}
	    \vdashPf{\semenv}{\cexists {\tv, \tvs} \ueqs}{\cref{lem:simple-inversion}}
	    \vdashPf{\semenv\where{\x \is \semenv(\cabsr \tv \tvs \ueqs)}}{\c}{\ditto}
\Hand	    \vdashPf{\semenv}{\c}{$\x \disjoint \c$}
	  \end{llproof}
	  \proofcase{$\impliedby$}

	    \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\c}{Premise}
	    \vdashPf{\semenv\where{\x \is \semenv(\cabsr \tv \tvs \ueqs)}}{\c}{$\x \disjoint \c$}
	    \vdashPf{\semenv}{\cexists {\tv, \tvs} \ueqs}{}
\Hand	    \vdashPf{\semenv}{\cletr \x \tv \tvs \ueqs \c}{By \Rule{LetR}}
	    \end{llproof}
	\end{proofcases}

  \proofcaserewrite
    {S-BackProp}
    {\C\where
       {\cletr \x \tv \tvs {\Ca\where{\cmatch \tvp \cbrs}}
                           {\Cb\where{\cpapp \x \ren \ueqs \tvc}}} \\
     \tvp \in \dom \ren \\
     \cunif {\ren(\tv')} {\cunif \t \ueq} \in \C\where\Cb \\
     \x \disjoint \Cb}
    {\C\where{\cletr \x \tv \tvs {\Ca\where{\cmatched \tvp {\shape \t} \cbrs}}
		      {\Cb\where{\cpapp \x \ren \ueqs \tvc}}}}

    \TODO{Lemma for this that determines unicity}


  \proofcase{\Rule{S-Compress}, \Rule{S-Gc}, \Rule{S-Exists-All}, \Rule{S-All-Escape}, \Rule{S-All-Rigid}, \Rule{S-All-Solve}}

  \begin{llproof}
    Equivalences are standard, see \citep{Pottier-Remy/emlti}.
  \end{llproof}
  \end{proofcases}
\end{proof}

\subsection{Progress}

\begin{lemma}[Unification progress]
  For any unification problem $\up$, either:
  \begin{enumerate}[(\roman*)]
    \item $\up$ is solved.
    \item $\up$ is $\cfalse$.
    \item $\up \unif \upp$ for some $\upp$.
    \end{enumerate}
  \begin{proof}
    This is a standard result. See \citep{Pottier-Rem/emlti}.
  \end{proof}
\end{lemma}


\progress
\begin{proof}
  We proceed by induction on the structure of $\c$. We
  focus on conjunctions and $\Let$ rules.

  \begin{proofcases}
    \proofcase{$\ca \cand \cb$}
    We begin by inducting on $\ca$ and $\cb$. Then we consider cases:
    \begin{proofcases}
      \proofcase{$\ca$ (or $\cb$) take a step} Apply congruence rewriting rule.
      \proofcase{$\ca$ (or $\cb$) is $\ctrue$} Apply \Rule{S-True}.
      \proofcase{$\ca$ (or $\cb$) is $\cfalse$} Apply \Rule{S-False}.
      \proofcase{$\ca$ (or $\cb$) begins with $\exists$} Apply \Rule{S-Exists-Conj}.
      \proofcase{$\ca, \cb$ are solved}
	We either apply the above $\exists$ case, or both $\ca$ and $\cb$ are solved
	multi-equations $\ueqs_1, \ueqs_2$. We perform cases on this:
	\begin{proofcases}
	  \proofcase{$\ueqs_1$ and $\ueqs_2$ are mergable} Apply \Rule{U-Merge}.
	  \proofcase{$\cyclic {\ueqs_1, \ueqs_2}$} Apply \Rule{U-Cycle}.
	  \proofcase{Otherwise} The conjunction $\ueqs_1 \cand \ueqs_2$ is solved.
	\end{proofcases}

      \proofcase{$\ca$ and $\cb$ are stuck (and not $\cfalse$)}

	\Wlog, consider cases $\ca$.
	\begin{proofcases}
	  \proofcase{$\hat\Ca\where{\capp \x \t}$}
	    We have $\x \disjoint \bvs {\hat\Ca}$.
	    $\hat\Ca\where{\capp \x \t} \cand \cb$ is stuck as we do not bind $\x$ in $\hat\Ca \cand \cb$.
	  \proofcase{$\hat\Ca\where{\cpapp \x \tv \tvc \inst}$}
	    We have $\x \disjoint \bvs {\hat \Ca}$ and $\tv \disjoint ~ \insts {\hat \Ca} \inst$.

	    If $\tv \in \insts \cb \inst$ and $\inst \disjoint \bvs {\hat\ca}$, then apply \Rule{S-Inst-Unify}.
	    It must be the case that we can apply \Rule{S-Inst-Unify}, otherwise, we could lift these instantiation
	    constraints using \Rule{S-Exists-Lower} and \Rule{S-Let-ConjLeft}, contradicting that $\hat\Ca$ is stuck.

	    Otherwise, $\x \disjoint \bvs {\hat \Ca \cand \cb}$, thus $\hat\Ca\where{\cpapp \x \tv \tvc \inst}$ is stuck.

	  \proofcase{$\hat\Ca\where{\cmatch \tvp \cbrs}$}
	    We have $\nCshape \Ca \tvp \sh$ for any $\sh$.

	    If $\cunif \tvp {\cunif \t \ueq} \in \cb$ and $\t \notin \TyVars$. By the above logic, it must be at the root (otherwise $\cb$
	    is not stuck). So we have $\cunif \tvp {\cunif \t \ueq} \in \hat \Ca \cand \cb$. Thus we can apply \Rule{S-Match-Type}.

	    If $\cunif \tvc {\cunif \t \ueq} \in \cb$, $\t \notin \TyVars$, and $\hat\Ca$ contains $\cletr \x \tv \tvs {\hat\Cc\where{\cmatch \tvp \cbrs}} {\hat\C_4\where{\cpapp \x \tvp \tvc \inst}}$.
	    Apply \Rule{S-BackProp}.

	    Otherwise, we are stuck and $\nCshape {(\Ca \cand \cb)} \tvp \sh$ for any $\sh$.
	\end{proofcases}

    \end{proofcases}

    \proofcase{$\cletr \x \tv \tvs \ca \cb$}
    We begin by inducting on $\ca$ and $\cb$. Then we consider cases:
    \begin{proofcases}
      \proofcase{$\ca$ (or $\cb$) take a step} Apply congruence rewriting rule.
      \proofcase{$\ca$ (or $\cb$) is $\cfalse$} Apply \Rule{S-False}.
      \proofcase{$\ca$ begins with $\exists$} Apply \Rule{S-Let-ExistsLeft}
      \proofcase{$\cb$ begins with $\exists$} Apply \Rule{S-Let-ExistsRight}
      \proofcase{$\cb$ begins with $\cand$ with $\x \disjoint$ from conjunct} Apply \Rule{S-Let-ConjRight}.
      \proofcase{$\ca$ begins with $\cand$ with $\tv, \tvs \disjoint$ from conjunct } Try apply \Rule{S-Let-ConjLeft}
      \proofcase{$\cb$ begins with $\cexistsi \inst \xp {}$, $\x \neq \xp$} Apply \Rule{S-Exists-Inst-Let}
      \proofcase{$\cb$ is solved}

	Thus $\cb$ must be $\ctrue$ (due to above cases).
	\begin{proofcases}
	  \proofcase{$\ca$ is solved}
	    Thus $\ca$ must be $\ueqs$. There are two cases:
	    \begin{itemize}
	      \proofcase{$\cexists {\tv, \tvs} \ueqs \cequiv \ctrue$} Apply \Rule{S-Let-Solve}.
	      \proofcase{$\cexists {\tv, \tvs} \ueqs \cnequiv \ctrue$} It must be the case there is some $\tvb$ that dominates a $\tvp$ in $\tv, \tvs$ in $\ueqs$.
		Hence $\cdetermines {\cexists {\tv, \tvs \setminus \tvp} \ueqs} \tvp$.
		So we can apply \Rule{S-Exists-Lower}.
	    \end{itemize}

	  \proofcase{$\ca$ is stuck}
	    The constraint $\cletr \x \tv \tvs \ca \cb$ remains stuck, since
	    no additional term variable bindings occur for the scope of $\ca$,
	    ruling out the instantiation cases. Additionally, we cannot apply
	    backpropagation since $\cb$ is $\ctrue$.
	\end{proofcases}

      \proofcase{$\cb$ is stuck}
	\begin{proofcases}
	  \proofcase{$\hat\C\where{\capp \x \t}$} Apply \Rule{S-Let-AppR}.

	  \proofcase{$\hat\C\where{\cpapp \x \tvp \tvc \inst}$}
	    \begin{itemize}
	      \proofcase{$\tvp \in \reg \tv \tvs$}

		We can either apply \Rule{S-Inst-Copy} or \Rule{S-Compress}
		if a multi-equation involving $\tvp$ occurs in $\ca$.

		Otherwise, we consider cases where $\ca$ is solved or stuck.

		If $\ca$ is solved, then it must be of the form $\ueqs$.
		There are two cases:
		\begin{itemize}
		  \proofcase{$\cexists {\tv, \tvs} \ueqs \cequiv \ctrue$}
		  As $\tvp$ does not appear in the head position of any multi-equation in $\ueqs$,
		  it must be polymorphic. Thus $\cfor \tvp {\cexists {\tv, \tvs \setminus \tvp} \ueqs} \cequiv \ctrue$.
		  So we can apply \Rule{S-Inst-Poly}.

		  \proofcase{$\cexists {\tv, \tvs} \ueqs \cnequiv \ctrue$}
		  Apply \Rule{S-Lower-Exists} (using the same logic as above).

		\end{itemize}

		If $\ca$ is stuck, then neither case regarding instantiations
		in $\ca$ is fixed, so in these cases the constraint remains
		stuck. If $\ca$ is stuck with $\hat\Cp\where{\cmatch \tvb
		\cbrs'}$. Then either backpropagation (\Rule{S-BackProp})
		applies with an equation in $\hat\C$, or the entire constraint
		is stuck.

		\proofcase{$\tvp \notin \reg \tv \tvs$} Apply \Rule{S-Inst-Mono}.




	    \end{itemize}

	  \proofcase{$\hat\C\where{\cmatch \tvp \cbrs}$}

	  Either $\cb$ can progress with an instantiation constraint to discharge
	  the match constraint or $\cletr \x \tv \tvs \ca \cb$ is stuck.
	\end{proofcases}

    \end{proofcases}


  \end{proofcases}
\end{proof}

\subsection{Termination}

This section presents a proof of termination for our solver.
%
Most rewrite rules, in both unification and constraint solving, are
\emph{destructive}---that is, they eliminate or modify the structure of a
constraint in a way that prevents the rule from begin applied again.
%
Consequently, to establish termination, it sufficies to consider only those
rules that are not inherently destructive.

\begin{lemma}[Unification termination]
  The unifier terminates on all inputs.
  \begin{proof}
    \newcommand{\sw}[1]{\mathprefix{sw}{(#1)}}
    \newcommand{\iw}[1]{\mathprefix{iw}{(#1)}}
    \newcommand{\tw}[1]{\mathprefix{tw}{(#1)}}
    \newcommand{\uw}[1]{\mathprefix{uw}{(#1)}}

    Let every shape $\sh$ have an integer \emph{weight}
    defined by $\sw \sh \eqdef 2 + 2 \times |\sh|$, where $|\sh|$ is the
    arity of the shape $\sh$.
    %
    The weight of a type $\tw \t$ is defined by:
    \begin{mathpar}
      \begin{tabular}{RCL}
	\tw \tv &\eqdef& 1\\
	\tw {\shapp \tys} &\eqdef& \iw {\shapp \tys} - 1\\[1ex]
	\iw \tv &\eqdef& 0\\
	\iw {\shapp \tys} &\eqdef& \sw \sh + \iw \tys\\
        \iw \tys & \eqdef & \sum\iton \iw \ti\\

      \end{tabular}
    \end{mathpar}
    The helper $\iw \t$ computes the ``internal'' weight of $\t$; in
    the common case of shallow types it is just the weight of its head
    shape.

    We define the weight of a multi-equation as the sum of the weights of its
    members. The weight of a unification problem $\uw \up$ is defined
    as the sum of the weights of its multi-equations.

    In $\up \unif \upp$, the rules \Rule{U-Decomp} and \Rule{U-Name} are not
    obviously destructive, as they may introduce new constraints that
    are structurally larger than the constraint being rewritten.

    However, we show that this is not problematic: in both cases, the unification
    weight $\uw \up$ strictly decreases. The remaining rules are obviously
    destructive and either maintain or decrease the unification weight.

    \begin{proofcases}
      \proofcaserewrite
	{U-Decomp}
	{\cunif {\pshapp \tvs} {\cunif {\pshapp \tvbs} \ueq}}
	{\cunif {\pshapp \tvs} \ueq \cand \cunif \tvs \tvbs}

	We have
	\begin{mathpar}
	  \begin{tabular}{RCL}
	    \uw {\cunif {\pshapp \tvs} {\cunif {\pshapp \tvbs} \ueq}} &=&
	      2 \times (\sw \sh - 1) + \uw \ueq \\
	      &=& 4 \times |\sh| + 2  + \uw \ueq \\[1ex]
	    \uw {\cunif {\pshapp \tvs} \ueq \cand \cunif \tvs \tvbs}
	      &=&
	      \sw \sh - 1 + \uw \ueq + 2 \times |\sh| \\
	      &=&
	      3 \times |\sh| + 1 + \uw \ueq
	  \end{tabular}
	\end{mathpar}
	Hence $\uw {{\cunif {\pshapp \tvs} {\cunif {\pshapp \tvbs} \ueq}}} > \uw {\cunif {\pshapp \tvs} \ueq \cand \cunif \tvs \tvbs}$.


      \proofcaserewrite
	{U-Name}
      {\cunif {\pshapp \parens{\tys, \ti, \typs}} \ueq \\ \tv \disjoint \tys, \typs, \ueq }
      {\cexists \tv {\cunif {\pshapp \parens{\tys, \tv, \typs}} \ueq \cand \cunif \tv \ti}}

	We have
	\begin{mathpar}
	  \begin{tabular}{RCL}
	    \uw {\cunif {\pshapp {\parens{\tys, \ti, \typs}}} \ueq} &=& \sw \sh + \iw \tys + \iw \ti + \iw \typs - 1 + \uw \ueq \\
	    \uw {\cexists \tv {\cunif \tv \ti \cand \cunif {\pshapp \parens{\tys, \tv, \typs}} \ueq}}
	      &=& \sw \sh + \iw \tys + 0 + \iw \typs - 1 + \uw \ueq + 1 + \tw \ti
	  \end{tabular}
	\end{mathpar}
	So it sufficies to show that $1 + \tw \ti < \iw \ti$. Given $\ti \notin \TyVars$, this is indeed the case.
	So we are done.

        \Xgabriel{I don't follow, for example if $\tau_i$ is a nullary shape $\shapp \eset$ I would expect $1 + \tw {\shapp \eset} = \iw {\shapp \eset}$.}
    \end{proofcases}
  \end{proof}
\end{lemma}


\termination
\begin{proof}
  The ``discharge'' rules \Rule{S-Match-Type}, \Rule{S-Match-Var} and \Rule{S-BackProp} discharge suspended constraints, and they can make arbitrary sub-constraints appear in the non-suspended part of the constraint. On the other hand, they strictly decrease the number of occurrences of suspended match constraint (if we also count nested suspended constraints), and no rewriting rule introduces new suspended match constraints. So these discharge rules can only be applied finitely many time. To prove termination of constraint solving, it thus suffices to prove that that rewriting sequences that do not contain one of the discharge rules are always finite.

  By a similar argument, the number of non-partial instantiations $\capp \x \t$ decreases strictly on \Rule{S-Let-AppR} when a partial instantiation starts, and is preserved by other non-discharge rule. The rule \Rule{S-Let-AppR} can thus only occur finitely many time in non-discharging sequences, and it suffices to prove that all rewriting sequences that are non-discharging and do not start new partial instances are finite.

  The termination argument for this fragment follows similar lines to that of unification.

  The only rule of concern is \Rule{S-Inst-Copy}, which is not obviously destructive:
  it introduces new instantiation constraints and structurally increases the size of the
  constraint.

  \newcommand{\sw}[1]{\mathprefix{sw}{(#1)}}
  \newcommand{\iw}[1]{\mathprefix{iw}{(#1)}}
  \newcommand{\stw}[1]{\mathprefix{tw}{(#1)}}
  \newcommand{\tw}[2]{\mathprefix{tw}{(#1 \in #2)}}
  \newcommand{\eqs}[1]{\mathprefix{eqs}({#1})}
  \newcommand{\cw}[1]{\mathprefix{cw}{(#1)}}

  We define a weight function that captures the contribution of types within constraints.
  The type weight of a type $\t$ within a constraint $\c$, written $\tw \t \c$, is defined
  as:
  \begin{mathpar}
    \begin{tabular}{RCL}
      \tw {\shapp \tys} \c &\eqdef& 2 \times \sw \sh + \sum \iton \tw \ti \c \\[1ex]
    \tw \tv \c &\eqdef& \sup \Braces {\tw \t \c : \cerase \c \centails \cunif \tv \t}
    \end{tabular}
  \end{mathpar}
  Intuivitely this weight corresponds to the \emph{size} of the type.
  Our conjecture is that \Rule{S-Inst-Copy} results on instantiations of types
  with \emph{smaller} sizes.

  This weight is well-defined whenever $\cerase \c$ is satisfiable (and thus acyclic).
  If $\cerase \c$ is unsatisfiable, then some destructive rule (\ie unification rules) must be applicable.

  The weight of a partial instantiation $\cw {\cpapp \x \tv \t \inst}$ is defined as
  the sum of $\stw \t$ and $\tw \tv \c$, where $\x$ is bound to the abstraction $\cabsr \tv \tvs \c$.
  The weight of other constraints is given using the measure $\mathprefix{uw}$ defined in the the
  proof of Lemma XXX.

  \begin{proofcases}
    \proofcaserewrite
      {S-Inst-Copy}
      {\cletr \x \tv \tvs {\c}
	\C\where{\cpapp \x \tvp \tvc \inst}\\
	\c = \cp \cand \cunif \tvp {\cunif {\shapp \tvbs} \ueq}\\
	\tvp \in \reg \tv \tvs \\
	\neg \cyclic {\c} \\
       \tvbs' \disjoint \tvp, \tvc, \tvbs \\
       \x \disjoint \bvs \C}
      {\cletr \x \tv \tvs {\c}
	\C\where{\cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}}

      We aim to show that the weight of the rewritten constraint
      $\cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst$
      is strictly less than the original $\cpapp \x \tvp \tvc \inst$.

      \begin{mathpar}
	\begin{tabular}{RCL}
	  \cw {\cpapp \x \tvp \tvc \inst} &=& 1 + \tw \tv \c \\
	  &\geq& 1 + 2 \times \sw \sh + \sum\iton \tw \tvbi \c  \\[1ex]
	  \cw {\cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}
	  &=&
	  1 + \sw \sh + \sum\iton \tw \tvbi \c + |\tvbs'|
	\end{tabular}
      \end{mathpar}
      To esnure a strict decrease, it suffices to show that $\sw \sh > |\tvbs'|$.
      Given that $|\tvbs'| = |\sh|$, and by the definition of $\sw \sh$, this inequality holds.
      Therefore, the weight strictly decreases under \Rule{S-Inst-Copy}.

  \end{proofcases}

  Finally, we can measure whole constraints by the multiset of the weights of their partial instances. This order strictly decreases across all instantiation rules, and is preserved by all obviously destructive rules.

  Thus the constraint solver terminates.
\end{proof}

\subsection{Correctness}

\clearpage
\section{Properties of \OML}

\subsection{Simple syntax-directed system}
As a first step towards proving soundness and completeness of constraint generaztion,
we first present a variant of the \OML type system. For this system, the
syntax tree completely determines the derivation tree provided the term $\e$ is \emph{simple}.

We use the standard technique of removing the \Rule{Inst} and \Rule{Gen} rules,
and always apply instantiations in \Rule{Var} and always generalize at let-bindings.
We can show that this system is sound and complete with respect to the declarative rules.

\begin{theorem}[Soundness of the syntax directed rules]
  \label{thm:soundness-sd}
  If $\G \th_s \e : \t$ then we also have $\G \th_{simple} \e : \t$
  \begin{proof}
    Induction on the given derivation.
  \end{proof}
\end{theorem}

\begin{theorem}[Completeness of the syntax directed rules]
  \label{thm:completeness-sd}
  If $\G \th_{simple} \e : \ts$, then $\G \th_s \e : \t$ for any instance $\t$ of $\ts$.
  \begin{proof}
    Induction on the given derivation.
  \end{proof}
\end{theorem}

The simple syntax-directed system has an inversion lemma:
\begin{lemma}[Simple inversion]
  \label{lem:simple-inversion-sd}
  \TODO{THis}
\end{lemma}

\subsection{Canonicalization of typability}
Our system satisfies a similar canonicalization theorem to constraint satisfiability.

\begin{lemma}[Composability of unicity]
  ~
  \label{lem:comp-unicity-typing}
  \begin{enumerate}[(\roman*)]
    \item If $\Eshape \Ea \e \sh$, then $\Eshape {\Eb\where\Ea} \e \sh$.
    \item If $\eshape \Ea \e \sh$, then $\eshape {\Eb\where\Ea} \e \sh$.
    \item If $\Lshape \Lab \elab \T$, then $\Lshape {\Eb\where\Lab} \elab \T$.
  \end{enumerate}
  \begin{proof}
    By induction on $\Eb$.
  \end{proof}
\end{lemma}

\begin{lemma}[Decanonicalization]
  \label{lem:decanonicalization-typing}
  If $\Th \e : \t$, then $\eset \th \e : \t$.
  \begin{proof}
    By induction on the given derivation $\Th \e : \t$.
  \end{proof}
\end{lemma}

\begin{theorem}[Canonicalization]
  \label{thm:canonicalization-typing}
  If $\th \e : \ts$, then $\Th \e : \t$ for any instance $\t$ of $\ts$.
\end{theorem}

\subsection{Unifiers}

A substitution $\sub$ is an idempotent function from type variables to types.
The (finite) domain of $\sub$ is the set of type variables such that $\sub(\tv)
\neq \tv$ for any $\tv \in \dom \sub$, while the codomain consists of the free
type variables of its range.
%
We use the notation $\where{\tvs \is \tys}$ for the substitution $\sub$ with
domain $\tvs$ and $\sub(\tvs) = \tys$.

The constraint induced by a substitution $\sub$, written $\exists \sub$, is
$\cexists {\tvbs} \tvs = \tys$ where $\tvbs = \rng \sub$, $\tvs = \dom \sub$
and $\sub(\tvs) = \tys$.

\begin{definition}[Unifier]
  A substitution $\sub$ is a unifier of $\c$ if $\exists \sub$ entails $\c$.
  A unifier $\sub$ of $\c$ is \emph{most general} when $\exists \sub$ is equivalent
  to $\c$.
\end{definition}

\begin{lemma}[Simple inversion of unifiers]
  ~
  \begin{itemize}
    \item If $\sub$ is a unifier of $\cunif \ta \tb$, then $\sub(\ta) = \sub(\tb)$.
    \item For simple $\ca, \cb$, if $\sub$ is a unifier of $\ca \cand \cb$, then $\sub$ is a unifier of $\ca$ and $\cb$.
    \item For simple $\c$, if $\sub$ is a unifier of $\cexists \tv \c$, then $\sub\where{\tv \is \t}$ is a unifier of $\c$ for some $\t$.
    \item For simple $\c$, if $\sub$ is a unifier of $\cfor \tv \c$, then $\sub$ is a unifier of $\c$.
  \end{itemize}
  \begin{proof}
    Follows from \cref{lem:simple-inversion}.
  \end{proof}
\end{lemma}

\begin{lemma}
  If $\sub$ unifies $\cexists \tv \c$, then there exists a unifier $\subp$ that extends $\sub$ with $\tv$,
  where $\subp$ is most general unifier of $\exists \sub \cand \c$.


  Then $\cabs \tv \c$ is equivalent to $\cabs \tv \sigma \leq \tv$ under $\sub$, where $\ts = \tfor \tvbs \subp(\tv)$ and
  $\tvbs = \fvs {\subp(\tv)} \setminus \rng \sub$.
  \begin{proof}
    See \citep{Pottier-Remy/emlti}.
  \end{proof}
\end{lemma}

\subsection{Soundness and completeness of constraint generation}

\begin{lemma}
  For any term context $\E$, term $\e$, $\ctxinfer \E \ta \tb \where{\cinfer \e \ta} = \cinfer {\E\where{\e}} \tb$.
  \begin{proof}
    By induction on the structure of $\E$.
  \end{proof}
\end{lemma}

\begin{lemma}
  For any term $\e$, $\cerase {\cinfer \e \t} = \cinfer {\eerase \e} \t$.
  \begin{proof}
    By induction on $\e$.
  \end{proof}
\end{lemma}

\begin{lemma}[Simple soundness and completeness]
  For simple terms $\e$.
  $\sub(\G) \thsimplesd \e : \sub(\t)$ if and only if $\sub$ is a unifier of $\csem {\G \th \e : \t}$.
  \begin{proof}
    By induction on $\e \simple$.
  \end{proof}
\end{lemma}

\begin{theorem}[Soundness and completeness]
  $\Th \e : \sub(\tv)$ if and only if $\sub$ is a unifier of $\csem {\e : \tv}$
  \begin{proof}
    By induction on the number $n$ of implicit terms in $\e$.
    \begin{proofcases}
      \proofcase{$n$ is $0$}

	\begin{llproof}
	  \simplePf{\e}{Premise}
	  \iffPf{\eset\thsimplesd \e : \sub(\tv)}{\sub \text{ unifies } \csem {\e : \tv}}{Lemma XXX}
	  \iffPf{\eset \thsimplesd \e : \sub(\tv)}{\Th \e : \sub(\tv)}{When $\e \simple$}
\Hand	  \iffPf{\Th \e : \sub(\tv)}{\sub \text{ unifies } \csem {\e : \tv}}{Above}
	\end{llproof}

      \proofcase{$n$ is $k + 1$}

	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{proofcases}

	    \proofcasederivation
	      {Can-Proj-I}
	      {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\ \sub(\G) \Th \E\where{\exproj \e j n} : \sub(\tv)}
	      {\Th \E\where{\eproj \e j} : \sub(\tv)}

	      \begin{llproof}
		\ThTypPf{\sub(\G)}{\E\where{\exproj \e j n}}{\sub(\tv)}{Premise}
		\UnifierPf{\sub}{\csem {\G \th \E\where{\exproj \e j n} : \tv}}{By \ih}
		\eqPf{\csem {\G \th \E\where{\exproj \e j n } : \tv}}{\cletG {\cinfer {\E\where{\exproj \e j n}} \tv}}{By definition}
		\continueeqPf{\cletG {\ctxinfer \E \tvb \tv}\where{\cinfer {\exproj \e j n} \tvb}}{Lemma XXX}
		\equivPf{\cinfer {\exproj \e j n} \tvb}{\cexists {\tvaa \tvcs} {\cinfer \e \tvaa \cand \cunif \tvaa {\Pi\iton \tvcs} \cand \cunif \tvb \tvc_j}}{By definition}
		\continueequivPf{\cexists {\tvaa} \cinfer \e \tvaa \cand \cmatched \tvaa {\any \tvcs \Pi\iton \tvcs}{\cbranch {\cpatprod \tvc j} {\cunif \tvb \tvc}}}{\ditto}
		\UnifierPf{\sub}{\cletG \ctxinfer \E \tvb \tv \where{\cexists \tvaa \cinfer \e \tvaa \cand \ldots}}{Above}
		\eshapePf{\E}{\e}{\any \tvcs \Pi\iton \tvcs}{Premise}
		\LetPf{\C}{\cletG \ctxinfer\E \tvb \tv \where{\cexists \tvaa \cinfer \e \tvaa \cand \square}}{}
		\vdashPf{\semenv}{\cerase{\C\where{\cunif \tvaa \gt}}}{Premise}
		\eqPf{\cexists \tvaa \cinfer \e \tvaa \cand \cunif \tvaa \gt}{\cexists \tvaa \cinfer {\eannot \e {} \gt} \tvaa}{By definition}
		\continueeqPf{\cinfer {\emagic {\eannot \e {} \gt}} \tvb}{\ditto}
		\eqPf{\cerase {\C\where{\cunif \tvaa \gt}}}{\cerase {\cletG \ctxinfer \E \tvb \tv \where{\cinfer {\emagic {\eannot \e {} \gt}} \tvb}}}{\ditto}
		\continueeqPf{\cerase {\cletG \cinfer {\E\where{\emagic {\eannot \e {} \gt}}} \tv}}{Lemma XXX}
		\continueeqPf{\cletG \cerase {\cinfer {\E\where{\emagic {\eannot \e {} \gt}}} \tv}}{By definition}
		\continueeqPf{\cletG \cinfer {\eerase {\E\where{\emagic {\eannot \e {} \gt}}}} \tv}{Lemma XXX}
		\UnifierPf{\semenv}{\cletG \cinfer {\eerase {\E\where{\emagic {\eannot \e {} \gt}}}} \tv}{Above}
		\ThTypPf{}{\eerase {\E\where{\emagic {\eannot \e {} \gt}}}}{\semenv(\tv)}{By \ih}
		\thTypPf{\eset}{\eerase {\E\where{\emagic {\eannot \e {} \gt}}}}{\semenv(\tv)}{Lemma XXX}
		\eqPf{\shape \gt}{\any \tvcs \Pi\iton \tvcs}{$\implies$E}
		\shapePf \C \tvaa {\any \tvcs \Pi\iton \tvcs}{Above}
		\UnifierPf{\sub}{\C\where{\cmatch \tvaa {\cbranch {\cpatprod \tvc j} {\cunif \tvb \tvc}}}}{By \Rule{Susp-Ctx}}
		\eqPf{\cinfer {\eproj \e j} \tvb}{\cexists \tvaa \cinfer \e \tvaa \cand \cmatchdots \tvaa}{By definition}
		\eqPf{\C\where{\cmatchdots \tvaa}}{\cletG \ctxinfer \E \tvb \tv\where{\cexists \tvaa \cinfer \e \tvaa \cand \cmatchdots \tvaa}}{\ditto}
		\continueeqPf{\cletG \ctxinfer \E \tvb \tv \where{\cinfer {\eproj \e j} \tvb}}{Above}
		\continueeqPf{\cletG \cinfer {\E\where{\eproj \e j}} \tv}{Lemma XXX}
		\decolumnizePf
		\continueeqPf{\csem {\E\where{\eproj \e j} : \tv}}{}
\Hand  		\UnifierPf{\sub}{\csem {\E\where{\eproj \e j} : \tv}}{}
	      \end{llproof}

	    \proofcase{\Rule{Can-Poly-I}, \Rule{Can-Use-I}, \Rule{Can-Lab-I}}

	    \begin{llproof}
	      Similar arguments.
	    \end{llproof}
	  \end{proofcases}

	  \proofcase{$\impliedby$}

	  \begin{proofcases}
	    \proofcasederivation
	      {Lemma XXX}
	      {\Cshape \C \tvaa {\any \tvcs \Pi\iton \tvcs} \\
	       \sub \text{ unifies } \C\where{\cmatched \tvaa {\any \tvcs \Pi\iton \tvcs} {\ldots}}}
	      {\sub \text{ unifies } \underbrace{\C\where{\cmatch \tvaa {\cbranch {\cpatprod \tvc j} {\cunif \tvb \tvc}}}}_{\cinfer \e \tv}}

	      \begin{llproof}
		\eqPf{\csem {\e : \t}}{\cletG \cinfer {\E\where{\eproj \e j}} \tv}{Premise}
		\eqPf{\C}{\cletG \ctxinfer \E \tvb \tv\where{\cexists \tv \cinfer \e \tv \cand \square}}{Premise}
		\UnifierPf{\sub}{\C\where{\cmatched \tvaa {\any \tvcs \Pi\iton \tvcs} {\ldots}}}{Premise}
		\UnifierPf{\sub}{\csem {\E\where{\exproj \e j n} : \tv}}{Above (See $\implies$ direction)}
		\ThTypPf{}{\E\where{\exproj \e j n}}{\sub(\tv)}{By \ih}
		\thTypPf{\Gp}{\E\where{\emagic {\eannot \e {} \gt}}}{\tp}{Premise}
		\eqPf{\Gp}{\eset}{$\E\where{\emagic {\eannot \e {} \gt}}$ is closed}
		\ThTypPf{}{\E\where{\emagic {\eannot \e {} \gt}}}{\tp}{Lemma XXX}
		\UnifierPf{\where{\tv \is \tp}}{\csem {\E\where{\emagic {\eannot \e {} \gt}} : \tv}}{By \ih}
		\vdashPf{\semenv\where{\tv \is \semenv(\tp)}}{\cinfer {\E\where{\emagic {\eannot \e {} \gt}}} \tv}{By definition}
		\shapePf{\C}{\tvaa}{\any \tvcs \Pi\iton \tvcs}{Premise}
		\eqPf{\shape \gt}{\any \tvcs \Pi\iton \tvcs}{$\implies$E}
		\eshapePf{\E}{\e}{\any \tvcs \Pi\iton \tvcs}{Above}
		\ThTypPf{}{\E\where{\eproj \e j}}{\sub(\tv)}{By \Rule{Can-Proj-I}}
	      \end{llproof}

	    \proofcase{$\epoly \e$, $\einst \e$, $\ell$}

	    \begin{llproof}
	      Similar arguments.
	    \end{llproof}
	  \end{proofcases}
	\end{proofcases}
    \end{proofcases}
  \end{proof}
\end{theorem}


\section{Examples of suspended match constraints}

\Xgabriel{We have a problem in this definition, due to the fact that $\phi$ also contains polymorphic schemes, which are not necessarily the same as the one at the point where we use the \Rule{Susp-Ctx} rule. For example when the current environment $\phi$ has $x : \forall \alpha. \tint$, one would expect that $\phi \vdash \capp x \alpha \cand \cmatch \alpha \dots$ is satisfiable as $\capp x \alpha$ is morally equivalent to $\alpha = \tint$, but technically it is not because we can pick $\phi' := [x := \forall \alpha. \tbool]$.}
\Xalistair{Actually it's okay if this example fails, the ``fix'' is to use a wider $\C$ that contains the $\mathsf{let}~ x$ definition as part of the constraint.}
\Xgabriel{This example/discussion should go in the Unicity Testsuite Appendix.}

%
%\section{Well-foundedness of satisfiability}

%\section{Well-foundedness of \OML typing rules}
%
%\Xalistair{The same problem of well-foundedness comes up
%with the \OML typing rules. Should we have a separate
%section? Or deal with it in the above section (A single
%section for well-foundedness concerns)}
%
%\section{Ordered substitutions and unifiers}
%
%An ordered substitution $\sub$ is a refinement on substitutions, which
%defines the scope of existential variables in solutions and controls the free
%variables of their solutions.
%
%\begin{mathpar}
%  \begin{bnfgrammar}
%    \entry[Ordered substitution]{\sub}{
%      \cdot
%      \and \sub, \tv
%      \and \sub, \tv := \t
%      \and \sub, \x := \cabs \tv \c
%    }
%  \end{bnfgrammar}
%\end{mathpar
%Like typing contexts $\G$, substitutions $\sub$ are ordered and contain
%delcarations of polymorphic variables ($\tv$), they also provide term variable
%bindings ($\x \is \cabs \tv \c$). Unlike typing contexts, ordered substitutions
%$\sub$ also contain declarations of existential (flexible) type variables with
%solutions ($\tv \is \t$). We write $\dom \sub$ for the sequence of type
%variables and term variables defined in $\sub$.
%
%The well-formedness of substitutions $\sub$, written $\th \sub$ and defined
%below, enforces an order: if $\sub = \sub_L, \tv \is \t, \sub_R$, the solution
%$\t$ must be well-formed under $\sub_L$.
%
%\begin{mathpar}
%  \infer[Sub-Emp-Wf]
%    {}
%    {\th \eset}
%
%  \infer[Sub-TyVar-Wf]
%    {\th \sub}
%    {\th \sub, \tv}
%
%  \infer[Sub-TyAssn-Wf]
%    {\th \sub \\ \sub \th \t}
%    {\th \sub, \tv \is \t}
%
%  \infer[Sub-Var-Wf]
%    {\th \sub \\ \dom \sub \th \cabs \tv \c}
%    {\th \sub, \x \is \cabs \tv \c}
%\\
%  \infer[S-Var-Wf]
%    {\tv \in \dom \sub}
%    {\sub \th \tv}
%
%  \infer[S-Unit-Wf]
%    {}
%    {\sub \th \tunit}
%
%  \inferrule[S-Arr-Wf]
%    {\sub \th \t \\ \sub \th \tp}
%    {\sub \th \t \to \tp}
%
%  \inferrule[S-Prod-Wf]
%    {(\sub \th \ti)\iton}
%    {\sub \th \Pi\iton \ti}
%
%  \inferrule[S-Rcd-Wf]
%    {(\sub \th \ti)\iton \\
%     \T \in \dom \Omega}
%    {\sub \th \T \tys}
%
%  \inferrule[S-Poly-Wf]
%    {\sub \th \ts}
%    {\sub \th \tpoly \ts}
%
%  \inferrule[S-Forall-Wf]
%    {\sub, \tv \th \ts}
%    {\sub \th \tfor \tv \ts}
%
%\end{mathpar}
%Ordered substitutions $\sub$ can be viewed as parallel substitutions on types,
%substitutiong solved existential variables. We write $\sub(\t)$ for $\sub$
%applied as a substitution to type $\t$:
%\begin{mathpar}
%  \begin{tabular}{RCLL}
%    \sub(\tv) &\eqdef&
%      \begin{cases}
%	\theta(\t) &\text{if } \tv \is \t \in \theta \\
%	\tv &\text{otherwise}
%      \end{cases}\\
%    \sub(\tunit) &\eqdef& \tunit \\
%    \sub(\t \to \tp) &\eqdef& \sub(\t) \to \sub(\tp) \\
%    \sub(\Pi\iton \ti) &\eqdef& \Pi\iton \sub(\ti) \\
%    \sub(\Tapp \tys) &\eqdef&  \Tapp {\sub(\tys)} \\
%    \sub(\tpoly \ts) &\eqdef& \tpoly {\sub(\ts)} \\
%    \sub(\tfor \tv \ts) &\eqdef& \tfor \tv \sub(\ts) &\text{if } \tv \disjoint
%    \sub
%  \end{tabular}
%\end{mathpar}
%
%We can interpret $\sub$ as a set of semantic environments, written $\csem
%\sub$.
%\TODO{Semantic environments should not be ordered}
%\begin{mathpar}
%  \begin{tabular}{RCL}
%      \csem \cdot &\eqdef& \set {\cdot} \\
%      \csem {\sub, \tv} &\eqdef& \set{\semenv[\tv \is \gt] : \semenv \in \csem
%      \sub} \\
%      \csem {\sub, \tv \is \t} &\eqdef& \set{\semenv[\tv \is \semenv(\t)] :
%	\semenv \in \csem \sub} \\
%      \csem {\sub, \x \is \cabs \tv \c} &\eqdef& \set{\semenv[\x \is
%      \semenv(\cabs \tv \c)] : \semenv \in \csem \sub}
%  \end{tabular}
%\end{mathpar}
%
%We say that $\sub$ is a \emph{unifier} of $\c$ iff $\all {\semenv } \semenv
%\in \csem \sub \implies \semenv \th \c$.
%
%\begin{lemma}
%  If $\sub$ is unifier of $\cexists \tv \c$, there exists type $\t$ such that
%  $\sub \th \t$ and $\sub, \tv \is \t$ is a unifier of $\c$. Conversely,
%  if $\sub, \tv \is \t$ is a unifier of $\c$, then $\sub$ is a unifier of
%  $\cexists \tv \c$.
%
%
%\end{lemma}
%
%\TODO{Add some more stuff on ordered substitutions and unifiers (probably on
%an as need basis)}
%
%\section{Proofs for \cref{sec:constraint-gen}}
%
%In this appendix, we give the details for proving the soundness and completeness
%of the constraint generator, that is $\G \th \e : \ts$ if and only if
%$\cdot \th \cinfer {\G \th \e} \ts$. We begin by reformulating this statement using
%unifiers.
%%
%We write $\csem \G$ for the set of semantic environments induced by $\G$:
%\begin{mathpar}
%  \begin{tabular}{RCL}
%    \csem \cdot &\eqdef& \set \cdot \\
%    \csem {\G, \tv} &\eqdef& \set{\semenv[\tv \is \gt] : \semenv \in \csem \G} \\
%    \csem {\G, \x : \ts} &\eqdef& \set{\semenv[\x \is \semenv(\cabs \tv \ts \leq \tv)] : \semenv \in \csem \G}
%  \end{tabular}
%\end{mathpar}
%
%\begin{lemma}
%  $\cdot \th \csem{\G \th \e : \ts}$ if and only if $\csem \G \Vdash \cinfer \e \ts$
%  \begin{proof}
%    Induction on $\G$.
%  \end{proof}
%\end{lemma}
%
%We also relate $\G$ and ordered substitutions with the translation $\pparens \G$:
%\begin{mathpar}
%  \begin{tabular}{RCL}
%    \pparens \cdot &\eqdef& \cdot \\
%    \pparens {\G, \tv} &\eqdef& \pparens \G, \tv \\
%    \pparens {\G, \x : \ts} &\eqdef& \pparens \G, \x \is \cabs \tv \ts \leq \tv
%  \end{tabular}
%\end{mathpar}
%
%\begin{lemma}
%  $\csem \G = \csem {\pparens \G}$.
%  \begin{proof}
%    Induction on $\G$.
%  \end{proof}
%\end{lemma}
%
%We can now reformulate soundness and completeness as:
%$\G \th \e : \ts$ if and only if $\pparens \G$ is a
%unifier of $\cinfer \e \ts$.
%
%
%
%\begin{lemma}[X-soundness and completeness]
%  For the explicit term $\e$, we have
%  $\G \th \e : \ts$ if and only if $\pparens \G$ is a unifier of $\cinfer \e \ts$.
%  \begin{proof}
%    Structural induction on $\e$.
%  \end{proof}
%\end{lemma}
%
%\pagebreak
%\section{Unicity properties}
%
%\newcommand{\cscmmatch}[2]{\angles{#1}#2}
%\newcommand{\cscmmatchsub}[3]{\angles{#1 \is #2}#3}
%\newcommand{\Csshape}[4]{{#1}\where{\cscmmatch{#2}{#3} \uni #4}}
%\newcommand{\Cscshape}[7]{{#1}\where{\cscmmatch{#2}{#3} \uni {#4} \mid \csmatch{#5}{#6} \uni {#7}}}
%\newcommand{\cbrsp}{\cbrs'}
%
%In this section, we give details of the unicity predicate along with our main result: \emph{inversion of suspension}.
%We recall the following definition of unicity:
%
%\begin{definition}[Unicity]
%  The type variable $\tv$ has a uniquely known principal shape $\sh$ in the context $\C$,
%  written $\Cshape \C \tv \sh$ (or $\Csshape \C \tv \cbrs \sh$), iff for all assignments
%  $\semenv$ and ground types $\gt$, then $\C\where{\cunif \tv \gt}$ implies that the
%  principal shape of $\gt$ is equal to $\sh$:
%  \begin{mathpar}
%    \Csshape \C \tv \cbrs \sh \uad\eqdef\uad \all {\semenv, \gt} \; \semenv \th \C\where{\cunif \tv \gt} \implies \shape \gt = \sh
%  \end{mathpar}
%\end{definition}
%
%We introduce the notation $\Csshape \C \tv \cbrs \sh$ to be more consistent with our later notation on
%\emph{joint} and \emph{conditional} unicity.
%
%\begin{lemma}
%  If $\Csshape \Cb \tv \cbrs \sh$, then $\Csshape {\parens {\Ca\where\Cb}} \tv \cbrs \sh$.
%  \begin{proof}
%    Induction on $\Ca$.
%  \end{proof}
%\end{lemma}
%
%\begin{definition}[Conditional unicity] For two type variables $\tv, \tvp$, $\tv$ has the conditionally
%  known shape $\sh$ given that $\tvp$ has the shape $\shp$
%  within the match $\cscmmatch \tvp \cbrsp$, written
%  $\Cscshape \C \tv \cbrs \sh \tvp \cbrsp \shp$, is defined as:
%  \begin{mathpar}
%    \Cscshape \C \tv \cbrs \sh \tvp \cbrsp \shp \uad\eqdef\uad \Csshape {\parens{\C\where{\square, \cscmmatchsub \tvp \shp \cbrsp}}} \tv \cbrs \sh
%  \end{mathpar}
%
%  Here $\C$ is a two-hole context and $\C\where{\square, \cscmmatchsub \tvp \shp \cbrsp}$ is a one-hole context used in
%  the unicity predicate.
%\end{definition}
%
%
%\begin{theorem}[Bayes' theorem]
%  \begin{mathpar}
%    \Cscshape \C \tv \cbrs \sh \tvp \cbrsp \shp \wedge \Csshape {\parens{\C\where{\cscmmatch \tv \cbrs, \square}}} \tvp \cbrsp \shp \\
%    \iff \\
%    \Cscshape \C \tvp \cbrsp \shp \tv \cbrs \sh \wedge \Csshape {\parens{\C\where{\square, \cscmmatch \tvp \cbrsp}}} \tv \cbrs \sh
%  \end{mathpar}
%  \begin{proof}
%    ??
%  \end{proof}
%\end{theorem}
%
%
%\begin{theorem}[Inversion of suspension]
%  $\semenv \th \C\where{\cmatch \tv \cbrs}$ if and only if
%  $\Cshape \C \tv {\any \tvcs \t}$ and $\semenv \th \C\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs}$ for some $\tvcs, \t$.
%  \begin{proof}
%    The backwards direction is trivial, using \Rule{Susp-Ctx}.
%    We now consider the forwards direction, by induction on the given derivation.
%
%    \proofcase{\Rule{True}, \Rule{Multi-Unif}, \Rule{App}, \Rule{Susp-Use}, \Rule{AppR}, \Rule{Papp}} Impossible.
%
%    \proofcase{\Rule{Conj}}
%      \begin{mathpar}
%	\infer[Conj]
%	  {\semenv \th \ca \\ \semenv \th \cb}
%	  {\semenv \th \ca \cand \cb}
%      \end{mathpar}
%      We have $\C\where{\cmatch \tv \cbrs} = \ca \cand \cb$. Consider
%      cases on $\C$:
%      \begin{proofcases}
%	\item \proofcase{$\C = \Cp \cand \cb$}
%	  So we have $\semenv \th \Cp\where{\cmatch \tv \cbrs}$.
%	  By induction, we have $\Cshape \Cp \tv {\any \tvcs \t}$ and
%	  $\semenv \th \Cp\where{\cexists \tvcs \cunif \tv \tvcs \cand \cmatch \t \cbrs}$.
%	  By Lemma ??, we have $\Cshape {\parens {\Cp \cand \cb}} \tv {\any \tvcs \t}$.
%	  By \Rule{Conj}, we have
%	  \begin{mathpar}
%	    \infer[Conj]
%	      {\semenv \th \Cp\where{\cexists \tvcs \cunif \tv \tvcs \cand \cmatch \t \cbrs} \\
%	       \semenv \th \cb}
%	      {\semenv \th \parens{\Cp \cand \cb}\where{\cexists \tvcs \cunif \tv \tvcs \cand \cmatch \t \cbrs}}
%	  \end{mathpar}
%	\item \proofcase{$\C = \ca \cand \Cp$}
%	  Symmetric.
%      \end{proofcases}
%
%    \proofcase{\Rule{Let}}
%      \begin{mathpar}
%	\infer[Let]
%	  {\semenv \th \cexists \tvb \ca \\
%	   \semenv, \x \is \semenv(\cabs \tvb \ca) \th \cb}
%	  {\semenv \th \clet \x \tvb \ca \cb}
%      \end{mathpar}
%      We have $\C\where{\cmatch \tv \cbrs} = \clet \x \tv \ca \cb$.
%      Consider cases on $\C$:
%      \begin{proofcases}
%	\item \proofcase{$\C = \clet \x \tvb \Cp \cb$}
%	  So we have $\semenv \th \cexists \tvb \Cp\where{\cmatch \tv \cbrs}$ (1)
%	  and $\semenv, \x \is \semenv(\cabs \tvb \Cp\where{\cmatch \tv \cbrs}) \th \cb$ (2).
%
%	  By induction (1), we have $\cexists \tvb \Cshape \Cp \tv {\any \tvcs \t}$ and $\semenv \th \cexists \tvb
%	  \Cp\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs}$. By Lemma ??, we have $\Cshape \Cp \tv {\any \tvcs \t}$.
%
%	  We now claim that $\semenv(\cabs \tvb \Cp\where{\cmatch \tv \cbrs}) = \semenv(\cabs \tvb \Cp\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs})$.
%	  That is $\semenv, \tvb \is \gt \th \Cp\where{\cmatch \tv \cbrs} \iff \semenv, \tvb \is \gt \th \Cp\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs}$.
%	  This follows directly from induction, as we have $\Cshape \Cp \tv {\any \tvcs \t}$.
%
%	  So we have $\semenv, \x \is \semenv(\cabs \tvb \Cp\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs}) \th \cb$ from (2).
%	  Applying Lemma ??, we have $\Cshape {\parens {\clet \x \tvb \Cp \cb}} \tv {\any \tvcs \t}$, and applying the \Rule{Let} rule
%	  gives us:
%	  \begin{mathpar}
%	    \infer[Let]
%	      {\semenv \th \cexists \tvb \Cp\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs} \\
%	       \semenv, \x \is \semenv(\cabs \tvb \Cp\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs}) \th \cb}
%	      {\semenv \th \parens {\clet \x \tvb \Cp \cb} \where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs} }
%	  \end{mathpar}
%
%
%
%
%	\item \proofcase{$\C = \clet \x \tvb \ca \Cp$}
%	  Similiar to the \Rule{Conj} case.
%
%      \end{proofcases}
%
%
%    \proofcase{\Rule{Exists}}
%      \begin{mathpar}
%	\infer[Exists]
%	  {\semenv, \tvb \is \gt \th \c}
%	  {\semenv \th \cexists \tvb \c}
%      \end{mathpar}
%
%      We have $\C\where{\cmatch \tv \cbrs} = \cexists \tvb \c$.
%      Hence $\C = \cexists \tvb \Cp$ and $\Cp\where{\cmatch \tv \cbrs} = \c$.
%
%      By induction, we have $\Cshape \Cp \tv {\any \tvcs \t}$
%      and $\semenv, \tvb \is \gt \th \Cp\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs}$.
%
%      By Lemma ??, we have $\Cshape {\parens {\cexists \tvb \Cp}} \tv {\any \tvcs \t}$.
%      Applying \Rule{Exists} gives us:
%      \begin{mathpar}
%	\infer[Exists]
%	  {\semenv, \tvb \is \gt \th \Cp\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs}}
%	  {\semenv \th \cexists \tvb \Cp\where{\cexists \tvcs \cunif \tv \t \cand \cmatch \t \cbrs}}
%      \end{mathpar}
%
%
%    \proofcase{\Rule{Forall}} Similiar to the \Rule{Exists} case.
%
%    \proofcase{\Rule{Susp-Ctx}}
%      \begin{mathpar}
%	\infer[Susp-Ctx]
%	  {\Cshape \Cp \tvp {\any \tvcs' \typ} \\
%	   \semenv \th \Cp\where{\cexists {\tvcs'} \cunif \tvp \typ \cand \cmatch \typ \cbrs'}}
%	  {\semenv \th \Cp\where{\cmatch \tvp \cbrs'}}
%      \end{mathpar}
%
%      Consider whether $\C = \Cp$:
%      \begin{proofcases}
%	\item \proofcase{$\C = \Cp$} Trivial
%	\item \proofcase{$\C \neq \Cp$}
%	  Bayes' theorem + induction
%      \end{proofcases}
%  \end{proof}
%\end{theorem}
%
%%
%%We write $\e^i$ for an \emph{implicit} term, which is either: $\eproj \e j$, $\einst \e$, $\epoly \e$.
%%Let us define $x(\e^i, \sh)$ for the explicit elaboration of an implicit term $\e^i$ using the
%%shape $\sh$:
%%\begin{align*}
%%  x(\eproj \e j, \any \tvcs \Pi\iton \tvcs) &= \eproj[n] \e j \\
%%  x(\einst \e, \any \tvcs \tpoly \ts) &= \exinst \e \tvcs \ts \\
%%  x(\epoly \e, \any \tvcs \tpoly \ts) &= \expoly \e \tvcs \ts
%%\end{align*}
%%
%%\begin{theorem}
%%  $\G \th \E\where{\e^i} : \ts$ if and only if
%%  $\E\where{\e \mathop{\triangleleft\triangleright} \sh}$ and $\G \th \E\where{x(\e^i, \sh)} : \ts$ where
%%  $\decomp {\e^i} = \e, \triangleleft\triangleright$
%%  \begin{proof}
%%    \TODO{Unable to prove the hard cases yet (\eg \Rule{Proj-I}) --- this theorem is quite strong, }
%%  \end{proof}
%%\end{theorem}


\clearpage
\setcounter{tocdepth}{1}
\tableofcontents


%%% Below this line will is a draft
\Draft{}{\end{document}}\color{blue}

\clearpage

\section{DRAFT: a later TODO  list}

Problems to solve or leave unsolved:
\begin{itemize}

\item
  Overloading of the bracket notation for context filling and polytypes,
  as in $E\where{\epoly \e}$.

  A possibility would be to use braces for either one. Although they are
  used for record expressions, I would say the overlapping with either
  polytypes (they never appear simultaneously) or context (idem, since we
  put label accesses but not records in contexts.

  Alternatively, we could use $\ceils \e$ for polytypes---and then $\floors
  \e$ for the projections.


\end{itemize}

\section{The \OML calculus, feature by feature}

\Xgabriel{This section contains work-in-progress content that I intended to use to rewrite Section 4, ``The \OML calculus''. I still believe that there will not be enough space to keep Section 4 anyway, so I decided to stop this rewrite effort and dump the current content here.}

\subsection{The core fragment}
\label{sec:language:core}
\label{sec/language/typing-rules}

\begin{mathparfig}{fig/typing-core}{Typing and inference: Core \ML}
  \inferrule[Var]
    {x : \sigma \in \G}
    {\G \th x : \sigma}

  \inferrule[Fun]
    {\G, x : \ta \th e : \tb }
    {\G \th \efun x e : \ta \to \tb}

  \inferrule[App]
    {\G \th \ea : \ta \to \tb \\
     \G \th \eb : \ta}
    {\G \th \eapp \ea \eb : \tb}

  \inferrule[Annot]
    {\G \th e : \t\where {\tvs \is \tys}}
    {\G \th (e : \exi \tvs \t) : \t\where {\tvs \is \tys}}

  \inferrule[Gen]
    {\G \th e : \sigma \\ \tv \disjoint \G}
    {\G \th e : \tfor \tv \sigma}

  \inferrule[Inst]
    {\G \th e : \tfor \tv \ts}
    {\G \th e : \ts \where{\tv \is \t}}

  \inferrule[Let]
    {\G \th \ea : \sigma \\
     \G, x : \sigma \th \eb : \t}
    {\G \th \elet x \ea \eb : \t}
\\
\newcommand {\Crule}[2]{#1 & \eqdef & #2}
\begin{array}{l@{\uad} c@{\uad} l}
\Crule
  {\cinfer {\efun \x \e} \t}
  {\cexists {\tva, \tvb}
    \cunif \t {\tva \to \tvb}
    {}}
\\ & & \quad\uad {} \cand \clet \x \tvc {\cunif \tvc \tva} {\cinfer \e \tvb}
\\
\Crule
  {\cinfer {\eapp \ea \eb} \t}
  {\cexists {\tva} \cinfer \ea {\tva \to \t} \cand \cinfer \eb \tva}
\end{array}
\quad
\begin{array}{l@{\uad} c@{\uad} l}
\Crule
   {\cinfer x \t}
   {\cinst x \t}
\\
\Crule
  {\cinfer {\elet \x \ea \eb} \t}
  {\clet \x \tva {\cinfer \ea \tva} {\cinfer \eb \t}}
\\
\Crule
  {\cinfer {\eannot \e \tvs \tp} \t}
  {\cexists \tvs \cunif \t \tp \cand \cinfer \e \tp}
\end{array}
\end{mathparfig}

As usual, the main typing judgment $\G \th \e : \ts$ states that in
context $\G$, expression $\e$ has type scheme $\ts$. We give the
typing rules for the core \ML fragment in \cref{fig/typing-core}. It
also defines constraint generation for this fragment: given a term
$\e$ and its expected type $\t$, which may contain some free type
variables, we define a constraint $\cinfer e \t$ that is satisfiable
if and only if the term is well-typed for some instantiation of those
free type variables. Both typing rules and constraint generations are
standard on this fragment, and we will not comment them further due to
space restrictions.

\subsection{Unicity via magic rules}

TODO: a figure with the magic rule and the two unicity criterion (not for labels).

\subsection{Overloaded tuples}

\begin{mathparfig}{fig/typing-tuples}{Typing and inference: tuples}
  \inferrule[Tuple]
    {\parens{\G \th \ei : \ti}\iton}
    {\G \th (\ea, \ldots, \en) : \Pi\iton \ti}

  \inferrule[Proj-X]
    {\G \th \e : \Pi\iton \ti \\
     1 \leq j \leq n}
    {\G \th \exfield \e n j : \tj}

  \inferrule[Proj-I]
    {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\
     \G \th \E\where{\exfield \e n j} : \t}
    {\G \th \E\where{\efield \e j} : \t}
\\
  \newcommand{\Mrule}[5][]{{#2} \Matches {(#3)} \; #4 &\eqdef& {#5} & #1}
 \begin{array}{rcl@{\qquad}l@{\qquad\qquad} r}
   \cpat & ::= & \dots \mid \cpatprod \tv j & & \text{tuple patterns} \\
    \Mrule[\text{if } n \geq j]
      {\cpatprod \tv j}
      {\any \tvcs \Pi\iton \tvcs} \tvbs
      {[\tv \is \tvb_j]}
   & \text{matching relation}
 \end{array}
\\
\newcommand {\Crule}[2]{#1 & \eqdef & #2}
\begin{array}{l@{\uad} c@{\uad} l}
\Crule
  {\cinfer {\etuple {\ea, \ldots, \en}} \t}
  {\cexists \tvs \cunif \t {\Pi\iton \tvs}
    \cand \cAnd \iton \cinfer \ei {\tv_i}}
\\
\Crule
  {\cinfer {\exfield \e j n} \t}
  {\cexists {\tvbs}
    \cinfer \e {\Pi\iton \tvbs}
    \cand \cunif \t {\tvb_j}}
\\
\Crule
  {\cinfer {\efield \e j} \t}
  {\cexists \tv \cinfer \e \tv
    \cand \cmatch \tv {\cbranch {\cpatprod \tvb j} {\cunif \t \tvb}}}
\end{array}
\end{mathparfig}

\subsection{Polytypes}

\begin{mathparfig}{fig/typing-polytypes}{Typing and inference: polytypes}
  \inferrule [Poly-X]
    {\G \th \e : \ts\where {\tvs \is \tys}}
    {\G \th \epoly[\exi \tvs \ts] \e : \tpoly {\ts \where {\tvs \is \tys}}}

  \inferrule [Poly-I]
    {\Eshape \E \e {{\any \tvcs \tpoly \ts}} \\
     \G \th \E \where{\epoly[\exi \tvcs \ts] \e} : \t}
    {\G \th \E \where{\epoly \e} : \t}

  \inferrule [Use-X]
    {\G \th \e : \tpoly \ts \where {\tvs \is \tys}}
    {\G \th \exinst e \tvs \ts : \ts \where {\tvs \is \tys}}

  \inferrule [Use-I]
    {\eshape \E  \e {\any \tvcs \tpoly \ts} \\
     \G \th \E\where{\exinst \e \tvcs \ts} : \t}
    {\G \th \E\where{\einst \e} : \t}
\\
  \newcommand{\Mrule}[5][]{{#2} \Matches {(#3)} \; #4 &\eqdef& {#5} & #1}
 \begin{array}{rcl@{\qquad}l@{\qquad\qquad} r}
   \cpat & ::= & \dots \mid \cpatpoly \cscm
               & & \text{polytype patterns} \\
   \c & ::= & \dots \mid \cscm \leq \t \mid \ts \leq \t \mid \x \leq \cscm \mid \x \leq \ts
            & & \text{polytype constraints} \\
    \Mrule
      {\cpatpoly \cscm}
      {\any \tvcs \tpoly \ts} \tvbs
      {[\cscm \is \ts \where{\tvcs \is \tvbs}]}
   & \text{matching relation}
 \end{array}
\\
\newcommand {\Crule}[2]{#1 & \eqdef & #2}
\begin{array}{l@{\uad} c@{\uad} l}
\\
\Crule
  {\cinfer {\expoly \e \tvs \ts} \t}
  {\cexists {\tvs}
    \cinfer \e \ts
    \cand \cunif \t {\tpoly \ts}}
\\
\Crule
  {\cinfer {\exinst \e \tvs \ts} \t}
  {\cexists {\tvs}
    \cinfer \e {\tpoly \ts}
    \cand \ts \leq \t}
\\
\Crule
  {\cinfer {\einst \e} \t}
  {\cexists \tva
    \cinfer \e \tva
    \cand \cmatch \tva {\cbranch {\cpatpoly \cscm} \cscm \leq \t}}
\\
\Crule
  {\cinfer {\epoly \e} \t}
  {\clet \x \tv {\cinfer \e \tv}
    {\cmatch \t {\cbranch {\cpatpoly \cscm} {\x \leq \cscm}}}}
\end{array}
\end{mathparfig}

\subsection{Nominal records}

Todo: extend the magic rule and the disambiguation rule, and also provide the unicity-in-env criterion definition. I propose to add those to the figure below.

\begin{mathparfig}{fig/typing-records}{Typing and inference: nominal records}
  \inferrule[Rcd-Assn]
    {\G \th \e : \t \\
     \G \th \el : \t \to \tp}
    {\G \th \el = \e : \tp}

  \inferrule[Rcd]
    {\parens{\G \th \eli = \ei : \t}\iton \\
     \G \th \bar \el \uni \t}
    {\G \th \erecord {\ela = \ea; \ldots; \el_n = \en} : \t}

  \inferrule[Rcd-Proj]
    {\G \th \e : \tp \\
     \G \th \el : \t \to \tp \\
     \G \th \el \uni \t }
    {\G \th \efield \e \el : \t}

  \inferrule[Lab-X]
    {\Omega(\elab / \T) = \tfor \tvs \t \to \tvs \T }
    {\G \th \elab / \T : \tys\where{\tvs \is \tys} \to \tys \T}

  \inferrule[Lab-I]
    {\Lshape \Lab \elab \T \\
      \G \th \Lab[\elab / \T] : \t}
    {\G \th \Lab[\elab] : \t}

  \inferrule[Lab-!]
    {\bar \el \uni \T \in \labenv}
    {\G \th \bar \el \uni \tys \T}

  \inferrule[Lab-?]
    {\G \th \t}
    {\G \th \bar \el \uni \t}
\\
  \newcommand{\Mrule}[5][]{{#2} \Matches {(#3)} \; #4 &\eqdef& {#5} & #1}
 \begin{array}{rcl@{}l@{\qquad} r}
   \cpat & ::= & \dots \mid \cpatrcd \ct & & \text{record patterns} \\
   \c & ::= & \dots
              \mid \labenv(\elab/\ct) \leq \ta \to \tb
              \mid \labenv(\elab/\T) \leq \ta \to \tb
            & & \text{record constraints} \\
    \Mrule
      {\cpatrcd \ct}
      {\any \tvcs \tvcs \Tapp} \tvbs
      {[\ct \is ~ \T]}
   & \text{matching relation}
 \end{array}
\\
\newcommand {\Crule}[2]{#1 & \eqdef & #2}
\begin{array}{l@{\uad} c@{\uad} l}
\Crule
  {\cinferassn \el \e \t}
  {\cexists \tv \cinfer \e \tv
    \cand \cinferlab \el \tv \t}
\\
\Crule
  {\cinferlab \elab \ta \tb}
  {\cmatch \tb {\cbranch {\cpatrcd \ct} {\labenv(\elab/\ct) \leq \ta \to \tb}}}
\\
\Crule
  {\cinferlab {\elab/\T} \ta \tb}
  {\labenv(\elab/\T) \leq \ta \to \tb}
\\
\Crule
  {\cinferlab {\elmagic \elab} \ta \tb}
  {\ctrue}
\\
\Crule
  {\cinferlab {\elannot \el \tvs \t} \ta \tb}
  {\cexists \tvs \cinferlab \el \ta \tb \cand \cunif \tb \t}
\\
\Crule
  {\cinferlabuni {\bar \el} \t}
  {\begin{cases}
    \cexists \tvs \cunif \t {\tvs \Tapp} &\text{if } \bar \el \uni \T \in \labenv \\
    \ctrue &\text{otherwise}
   \end{cases}}
\end{array}
\end{mathparfig}


\end{document}

% LocalWords:  omnidirectional typecheck polymorphism Hindley Milner kinded
% LocalWords:  GADTs typechecked codomain typechecking subexpressions Bodin
% LocalWords:  monomorphic subexpression Dunfield Riboulet jfla subtyping
% LocalWords:  greek Chargueraud typable monotype polytype Garrigue Remy th
% LocalWords:  impredicative polytypes minimality RCL ary Proj toplevel
% LocalWords:  typability backpropagation arity Compositionality equi
% LocalWords:  equitypable compositionality inlined equitypability nullary
% LocalWords:  metatheoretical finiteness nonvariable mydesc Inlining
% LocalWords:  unicity inlining
